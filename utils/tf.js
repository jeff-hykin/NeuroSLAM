var __defProp = Object.defineProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/backends/backend.mjs
var n = class {
  constructor(t67, r56) {
    this.backend = t67, this.dataMover = r56, this.data = /* @__PURE__ */ new WeakMap(), this.dataIdsCount = 0;
  }
  get(t67) {
    return this.data.has(t67) || this.dataMover.moveData(this.backend, t67), this.data.get(t67);
  }
  set(t67, r56) {
    this.dataIdsCount++, this.data.set(t67, r56);
  }
  has(t67) {
    return this.data.has(t67);
  }
  delete(t67) {
    return this.dataIdsCount--, this.data.delete(t67);
  }
  numDataIds() {
    return this.dataIdsCount;
  }
};
var o = class {
  refCount(t67) {
    return e("refCount");
  }
  incRef(t67) {
    return e("incRef");
  }
  timerAvailable() {
    return true;
  }
  time(t67) {
    return e("time");
  }
  read(t67) {
    return e("read");
  }
  readSync(t67) {
    return e("readSync");
  }
  readToGPU(t67, r56) {
    return e("readToGPU");
  }
  numDataIds() {
    return e("numDataIds");
  }
  disposeData(t67, r56) {
    return e("disposeData");
  }
  write(t67, r56, s84) {
    return e("write");
  }
  move(t67, r56, s84, d55, i88) {
    return e("move");
  }
  createTensorFromGPUData(t67, r56, s84) {
    return e("createTensorFromGPUData");
  }
  memory() {
    return e("memory");
  }
  floatPrecision() {
    return e("floatPrecision");
  }
  epsilon() {
    return this.floatPrecision() === 32 ? 1e-7 : 1e-4;
  }
  dispose() {
    return e("dispose");
  }
};
function e(a71) {
  throw new Error(`'${a71}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/util_base.mjs
function g(r56) {
  let t67 = r56.length, n67 = 0;
  for (; t67 > 0; ) n67 = Math.random() * t67 | 0, t67--, a(r56, t67, n67);
}
function d(r56, t67) {
  if (r56.length !== t67.length) throw new Error(`Array sizes must match to be shuffled together First array length was ${r56.length}Second array length was ${t67.length}`);
  let n67 = r56.length, e36 = 0;
  for (; n67 > 0; ) e36 = Math.random() * n67 | 0, n67--, a(r56, n67, e36), a(t67, n67, e36);
}
function F(r56, t67, n67) {
  return Math.max(r56, Math.min(t67, n67));
}
function I(r56) {
  return r56 % 2 === 0 ? r56 : r56 + 1;
}
function a(r56, t67, n67) {
  let e36 = r56[t67];
  r56[t67] = r56[n67], r56[n67] = e36;
}
function N(r56) {
  let t67 = 0;
  for (let n67 = 0; n67 < r56.length; n67++) t67 += r56[n67];
  return t67;
}
function M(r56, t67) {
  let n67 = Math.random();
  return t67 * n67 + (1 - n67) * r56;
}
function U(r56, t67) {
  let n67 = 0;
  for (let e36 = 0; e36 < r56.length; e36++) {
    let o80 = Number(r56[e36]) - Number(t67[e36]);
    n67 += o80 * o80;
  }
  return n67;
}
function c(r56, t67) {
  if (!r56) throw new Error(typeof t67 == "string" ? t67 : t67());
}
function k(r56, t67, n67 = "") {
  c(w(r56, t67), () => n67 + ` Shapes ${r56} and ${t67} must match`);
}
function T(r56) {
  c(r56 != null, () => "The input to the tensor constructor must be a non-null value.");
}
function q(r56) {
  if (r56.length === 0) return 1;
  let t67 = r56[0];
  for (let n67 = 1; n67 < r56.length; n67++) t67 *= r56[n67];
  return t67;
}
function D(r56) {
  return r56.length === 0;
}
function P(r56, t67) {
  if (r56 === t67) return true;
  if (r56 == null || t67 == null || r56.length !== t67.length) return false;
  for (let n67 = 0; n67 < r56.length; n67++) if (r56[n67] !== null && t67[n67] !== null && r56[n67] !== t67[n67]) return false;
  return true;
}
function w(r56, t67) {
  if (r56 === t67) return true;
  if (r56 == null || t67 == null || r56.length !== t67.length) return false;
  for (let n67 = 0; n67 < r56.length; n67++) if (r56[n67] !== t67[n67]) return false;
  return true;
}
function p(r56) {
  return r56 % 1 === 0;
}
function B(r56) {
  if (Math.tanh != null) return Math.tanh(r56);
  if (r56 === 1 / 0) return 1;
  if (r56 === -1 / 0) return -1;
  {
    let t67 = Math.exp(2 * r56);
    return (t67 - 1) / (t67 + 1);
  }
}
function L(r56) {
  let t67 = Math.ceil(Math.sqrt(r56));
  return [t67, Math.ceil(r56 / t67)];
}
function v(r56) {
  let t67 = new Uint32Array(r56);
  for (let n67 = 0; n67 < r56; ++n67) t67[n67] = n67;
  return g(t67), t67;
}
function V(r56, t67) {
  return t67 <= r56.length ? r56 : r56 + " ".repeat(t67 - r56.length);
}
function Z(r56, t67 = (o80) => 0, n67, e36) {
  return new Promise((o80, i88) => {
    let l80 = 0, u86 = () => {
      if (r56()) {
        o80();
        return;
      }
      l80++;
      let f85 = t67(l80);
      if (n67 != null && l80 >= n67) {
        i88();
        return;
      }
      e36 != null ? e36(u86, f85) : setTimeout(u86, f85);
    };
    u86();
  });
}
function C(r56, t67) {
  let n67 = 1, e36 = -1;
  for (let i88 = 0; i88 < r56.length; ++i88) if (r56[i88] >= 0) n67 *= r56[i88];
  else if (r56[i88] === -1) {
    if (e36 !== -1) throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${e36} and dim ${i88}`);
    e36 = i88;
  } else if (r56[i88] < 0) throw Error(`Shapes can not be < 0. Found ${r56[i88]} at dim ${i88}`);
  if (e36 === -1) {
    if (t67 > 0 && t67 !== n67) throw Error(`Size(${t67}) must match the product of shape ${r56}`);
    return r56;
  }
  if (n67 === 0) throw Error(`Cannot infer the missing size in [${r56}] when there are 0 elements`);
  if (t67 % n67 !== 0) throw Error(`The implicit shape can't be a fractional number. Got ${t67} / ${n67}`);
  let o80 = r56.slice();
  return o80[e36] = t67 / n67, o80;
}
function x(r56, t67) {
  let n67 = t67.length;
  return r56 = r56 == null ? t67.map((e36, o80) => o80) : [].concat(r56), c(r56.every((e36) => e36 >= -n67 && e36 < n67), () => `All values in axis param must be in range [-${n67}, ${n67}) but got axis ${r56}`), c(r56.every((e36) => p(e36)), () => `All values in axis param must be integers but got axis ${r56}`), r56.map((e36) => e36 < 0 ? n67 + e36 : e36);
}
function G(r56, t67) {
  let n67 = [], e36 = [], o80 = t67 != null && Array.isArray(t67) && t67.length === 0, i88 = t67 == null || o80 ? null : x(t67, r56).sort(), l80 = 0;
  for (let u86 = 0; u86 < r56.length; ++u86) {
    if (i88 != null) {
      if (i88[l80] === u86 && r56[u86] !== 1) throw new Error(`Can't squeeze axis ${u86} since its dim '${r56[u86]}' is not 1`);
      (i88[l80] == null || i88[l80] > u86) && r56[u86] === 1 && (n67.push(r56[u86]), e36.push(u86)), i88[l80] <= u86 && l80++;
    }
    r56[u86] !== 1 && (n67.push(r56[u86]), e36.push(u86));
  }
  return { newShape: n67, keptDims: e36 };
}
function O(r56, t67) {
  return A(r56, t67);
}
function A(r56, t67) {
  let n67 = null;
  if (r56 == null || r56 === "float32") n67 = new Float32Array(t67);
  else if (r56 === "int32") n67 = new Int32Array(t67);
  else if (r56 === "bool") n67 = new Uint8Array(t67);
  else if (r56 === "string") n67 = new Array(t67);
  else throw new Error(`Unknown data type ${r56}`);
  return n67;
}
function W(r56, t67) {
  for (let n67 = 0; n67 < r56.length; n67++) {
    let e36 = r56[n67];
    if (isNaN(e36) || !isFinite(e36)) throw Error(`A tensor of type ${t67} being uploaded contains ${e36}.`);
  }
}
function H(r56) {
  return r56 === "bool" || r56 === "complex64" || r56 === "float32" || r56 === "int32" || r56 === "string";
}
function J(r56, t67) {
  return !(t67 === "complex64" || t67 === "float32" && r56 !== "complex64" || t67 === "int32" && r56 !== "float32" && r56 !== "complex64" || t67 === "bool" && r56 === "bool");
}
function K(r56) {
  if (r56 === "float32" || r56 === "int32") return 4;
  if (r56 === "complex64") return 8;
  if (r56 === "bool") return 1;
  throw new Error(`Unknown dtype ${r56}`);
}
function Q(r56) {
  if (r56 == null) return 0;
  let t67 = 0;
  return r56.forEach((n67) => t67 += n67.length), t67;
}
function y(r56) {
  return typeof r56 == "string" || r56 instanceof String;
}
function $(r56) {
  return typeof r56 == "boolean";
}
function b(r56) {
  return typeof r56 == "number";
}
function E(r56) {
  return Array.isArray(r56) ? E(r56[0]) : r56 instanceof Float32Array ? "float32" : r56 instanceof Int32Array || r56 instanceof Uint8Array || r56 instanceof Uint8ClampedArray ? "int32" : b(r56) ? "float32" : y(r56) ? "string" : $(r56) ? "bool" : "float32";
}
function R(r56) {
  return !!(r56 && r56.constructor && r56.call && r56.apply);
}
function X(r56, t67) {
  for (let n67 = t67; n67 < r56; ++n67) if (r56 % n67 === 0) return n67;
  return r56;
}
function Y(r56) {
  let t67 = r56.length;
  if (t67 < 2) return [];
  let n67 = new Array(t67 - 1);
  n67[t67 - 2] = r56[t67 - 1];
  for (let e36 = t67 - 3; e36 >= 0; --e36) n67[e36] = n67[e36 + 1] * r56[e36 + 1];
  return n67;
}
function h(r56, t67, n67, e36 = false) {
  let o80 = new Array();
  if (t67.length === 1) {
    let i88 = t67[0] * (e36 ? 2 : 1);
    for (let l80 = 0; l80 < i88; l80++) o80[l80] = n67[r56 + l80];
  } else {
    let i88 = t67[0], l80 = t67.slice(1), u86 = l80.reduce((f85, m96) => f85 * m96) * (e36 ? 2 : 1);
    for (let f85 = 0; f85 < i88; f85++) o80[f85] = h(r56 + f85 * u86, l80, n67, e36);
  }
  return o80;
}
function s(r56, t67, n67 = false) {
  if (r56.length === 0) return t67[0];
  let e36 = r56.reduce((o80, i88) => o80 * i88) * (n67 ? 2 : 1);
  if (e36 === 0) return [];
  if (e36 !== t67.length) throw new Error(`[${r56}] does not match the input size ${t67.length}${n67 ? " for a complex tensor" : ""}.`);
  return h(0, r56, t67, n67);
}
function _(r56, t67) {
  if (Array.isArray(r56)) return r56;
  if (t67 === "float32") return r56 instanceof Float32Array ? r56 : new Float32Array(r56);
  if (t67 === "int32") return r56 instanceof Int32Array ? r56 : new Int32Array(r56);
  if (t67 === "bool" || t67 === "string") return Uint8Array.from(new Int32Array(r56));
  throw new Error(`Unknown dtype ${t67}`);
}
function z(r56, t67) {
  let n67 = S(r56, t67);
  for (let e36 = 0; e36 < n67.length; e36++) n67[e36] = 1;
  return n67;
}
function S(r56, t67) {
  if (t67 == null || t67 === "float32" || t67 === "complex64") return new Float32Array(r56);
  if (t67 === "int32") return new Int32Array(r56);
  if (t67 === "bool") return new Uint8Array(r56);
  throw new Error(`Unknown data type ${t67}`);
}
function j(r56, t67) {
  let n67 = r56.reduce((e36, o80) => e36 * o80, 1);
  if (t67 == null || t67 === "float32") return s(r56, new Float32Array(n67));
  if (t67 === "int32") return s(r56, new Int32Array(n67));
  if (t67 === "bool") return s(r56, new Uint8Array(n67));
  throw new Error(`Unknown data type ${t67}`);
}
function rr(r56) {
  r56.forEach((t67) => {
    c(Number.isInteger(t67) && t67 >= 0, () => `Tensor must have a shape comprised of positive integers but got shape [${r56}].`);
  });
}
function tr(r56, t67, n67) {
  if (t67 === 0) return 0;
  if (t67 === 1) return r56[0];
  let e36 = r56[r56.length - 1];
  for (let o80 = 0; o80 < r56.length - 1; ++o80) e36 += n67[o80] * r56[o80];
  return e36;
}
function nr(r56, t67, n67) {
  if (t67 === 0) return [];
  if (t67 === 1) return [r56];
  let e36 = new Array(t67);
  for (let o80 = 0; o80 < e36.length - 1; ++o80) e36[o80] = Math.floor(r56 / n67[o80]), r56 -= e36[o80] * n67[o80];
  return e36[e36.length - 1] = r56, e36;
}
function er(r56) {
  return r56 && r56.then && typeof r56.then == "function";
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/environment.mjs
var o2 = "tfjsflags";
var n2 = class {
  constructor(t67) {
    this.global = t67, this.flags = {}, this.flagRegistry = {}, this.urlFlags = {}, this.getQueryParams = h2, this.populateURLFlags();
  }
  setPlatform(t67, s84) {
    this.platform != null && (l().getBool("IS_TEST") || l().getBool("PROD") || console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${t67}.`)), this.platformName = t67, this.platform = s84;
  }
  registerFlag(t67, s84, r56) {
    if (this.flagRegistry[t67] = { evaluationFn: s84, setHook: r56 }, this.urlFlags[t67] != null) {
      let i88 = this.urlFlags[t67];
      l().getBool("IS_TEST") || l().getBool("PROD") || console.warn(`Setting feature override from URL ${t67}: ${i88}.`), this.set(t67, i88);
    }
  }
  async getAsync(t67) {
    return t67 in this.flags ? this.flags[t67] : (this.flags[t67] = await this.evaluateFlag(t67), this.flags[t67]);
  }
  get(t67) {
    if (t67 in this.flags) return this.flags[t67];
    let s84 = this.evaluateFlag(t67);
    if (er(s84)) throw new Error(`Flag ${t67} cannot be synchronously evaluated. Please use getAsync() instead.`);
    return this.flags[t67] = s84, this.flags[t67];
  }
  getNumber(t67) {
    return this.get(t67);
  }
  getBool(t67) {
    return this.get(t67);
  }
  getString(t67) {
    return this.get(t67);
  }
  getFlags() {
    return this.flags;
  }
  get features() {
    return this.flags;
  }
  set(t67, s84) {
    if (this.flagRegistry[t67] == null) throw new Error(`Cannot set flag ${t67} as it has not been registered.`);
    this.flags[t67] = s84, this.flagRegistry[t67].setHook != null && this.flagRegistry[t67].setHook(s84);
  }
  evaluateFlag(t67) {
    if (this.flagRegistry[t67] == null) throw new Error(`Cannot evaluate flag '${t67}': no evaluation function found.`);
    return this.flagRegistry[t67].evaluationFn();
  }
  setFlags(t67) {
    this.flags = Object.assign({}, t67);
  }
  reset() {
    this.flags = {}, this.urlFlags = {}, this.populateURLFlags();
  }
  populateURLFlags() {
    if (typeof this.global > "u" || typeof this.global.location > "u" || typeof this.global.location.search > "u") return;
    let t67 = this.getQueryParams(this.global.location.search);
    o2 in t67 && t67[o2].split(",").forEach((r56) => {
      let [i88, u86] = r56.split(":");
      this.urlFlags[i88] = c2(i88, u86);
    });
  }
};
function h2(e36) {
  let t67 = {};
  return e36.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, (s84, ...r56) => (f(t67, r56[0], r56[1]), r56.join("="))), t67;
}
function f(e36, t67, s84) {
  e36[decodeURIComponent(t67)] = decodeURIComponent(s84 || "");
}
function c2(e36, t67) {
  let s84 = t67.toLowerCase();
  return s84 === "true" || s84 === "false" ? s84 === "true" : `${+s84}` === s84 ? +s84 : t67;
}
function l() {
  return a2;
}
var a2 = null;
function y2(e36) {
  a2 = e36;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/global_util.mjs
import __Process$ from "node:process";
var n3;
function f2() {
  if (n3 == null) {
    let e36;
    if (typeof globalThis < "u") e36 = globalThis;
    else if (typeof globalThis < "u") e36 = globalThis;
    else if (typeof __Process$ < "u") e36 = __Process$;
    else if (typeof self < "u") e36 = self;
    else throw new Error("Could not find a global object");
    n3 = e36;
  }
  return n3;
}
function s2() {
  let e36 = f2();
  return e36._tfGlobals == null && (e36._tfGlobals = /* @__PURE__ */ new Map()), e36._tfGlobals;
}
function a3(e36, o80) {
  let l80 = s2();
  if (l80.has(e36)) return l80.get(e36);
  {
    let t67 = o80();
    return l80.set(e36, t67), l80.get(e36);
  }
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/kernel_names.mjs
var o3 = "Abs";
var t = "Acos";
var e2 = "Acosh";
var r = "Add";
var n4 = "AddN";
var s3 = "All";
var p2 = "Any";
var c3 = "ArgMax";
var a4 = "ArgMin";
var x2 = "Asin";
var i = "Asinh";
var l2 = "Atan";
var d2 = "Atanh";
var u = "Atan2";
var S2 = "AvgPool";
var g2 = "AvgPoolGrad";
var D2 = "AvgPool3D";
var m = "AvgPool3DGrad";
var R2 = "BatchMatMul";
var h3 = "BatchToSpaceND";
var M2 = "Bincount";
var A2 = "BitwiseAnd";
var B2 = "BroadcastTo";
var N2 = "BroadcastArgs";
var C2 = "Cast";
var v2 = "Ceil";
var F2 = "ClipByValue";
var P2 = "Complex";
var T2 = "ComplexAbs";
var L2 = "Concat";
var k2 = "Conv2D";
var G2 = "Conv2DBackpropFilter";
var E2 = "Conv2DBackpropInput";
var f3 = "Conv3D";
var I2 = "Conv3DBackpropFilterV2";
var q2 = "Conv3DBackpropInputV2";
var w2 = "Cos";
var V2 = "Cosh";
var y3 = "Cumprod";
var b2 = "Cumsum";
var z2 = "CropAndResize";
var U2 = "DenseBincount";
var O2 = "DepthToSpace";
var H2 = "DepthwiseConv2dNative";
var W2 = "DepthwiseConv2dNativeBackpropFilter";
var K2 = "DepthwiseConv2dNativeBackpropInput";
var X2 = "Diag";
var Z2 = "Dilation2D";
var _2 = "Dilation2DBackpropInput";
var j2 = "Dilation2DBackpropFilter";
var J2 = "Draw";
var Q2 = "RealDiv";
var Y2 = "Einsum";
var $2 = "Elu";
var oo = "EluGrad";
var to = "Erf";
var eo = "Equal";
var ro = "Exp";
var no = "ExpandDims";
var so = "Expm1";
var po = "FFT";
var co = "Fill";
var ao = "FlipLeftRight";
var xo = "Floor";
var io = "FloorDiv";
var lo = "FusedBatchNorm";
var uo = "GatherV2";
var So = "GatherNd";
var go = "Greater";
var Do = "GreaterEqual";
var mo = "Identity";
var Ro = "IFFT";
var ho = "Imag";
var Mo = "IsFinite";
var Ao = "IsInf";
var Bo = "IsNan";
var No = "LeakyRelu";
var Co = "Less";
var vo = "LessEqual";
var Fo = "LinSpace";
var Po = "Log";
var To = "Log1p";
var Lo = "LogicalAnd";
var ko = "LogicalNot";
var Go = "LogicalOr";
var Eo = "LogicalXor";
var fo = "LogSoftmax";
var Io = "LowerBound";
var qo = "LRN";
var wo = "LRNGrad";
var Vo = "MatrixBandPart";
var yo = "Max";
var bo = "Maximum";
var zo = "MaxPool";
var Uo = "MaxPoolGrad";
var Oo = "MaxPool3D";
var Ho = "MaxPool3DGrad";
var Wo = "MaxPoolWithArgmax";
var Ko = "Mean";
var Xo = "Min";
var Zo = "Minimum";
var _o = "MirrorPad";
var jo = "Mod";
var Jo = "Multinomial";
var Qo = "Multiply";
var Yo = "Neg";
var $o = "NotEqual";
var ot = "NonMaxSuppressionV3";
var tt = "NonMaxSuppressionV4";
var et = "NonMaxSuppressionV5";
var rt = "OnesLike";
var nt = "OneHot";
var st = "Pack";
var pt = "PadV2";
var ct = "Pool";
var at = "Pow";
var xt = "Prelu";
var it = "Prod";
var lt = "RaggedGather";
var dt = "RaggedRange";
var ut = "RaggedTensorToTensor";
var St = "Range";
var gt = "Real";
var Dt = "Reciprocal";
var mt = "Relu";
var Rt = "Reshape";
var ht = "ResizeNearestNeighbor";
var Mt = "ResizeNearestNeighborGrad";
var At = "ResizeBilinear";
var Bt = "ResizeBilinearGrad";
var Nt = "Relu6";
var Ct = "Reverse";
var vt = "Round";
var Ft = "Rsqrt";
var Pt = "ScatterNd";
var Tt = "TensorScatterUpdate";
var Lt = "SearchSorted";
var kt = "Select";
var Gt = "Selu";
var Et = "Slice";
var ft = "Sin";
var It = "Sinh";
var qt = "Sign";
var wt = "Sigmoid";
var Vt = "Softplus";
var yt = "Sqrt";
var bt = "Sum";
var zt = "SpaceToBatchND";
var Ut = "SplitV";
var Ot = "Softmax";
var Ht = "SparseFillEmptyRows";
var Wt = "SparseReshape";
var Kt = "SparseSegmentMean";
var Xt = "SparseSegmentSum";
var Zt = "SparseToDense";
var _t = "SquaredDifference";
var jt = "Square";
var Jt = "StaticRegexReplace";
var Qt = "StridedSlice";
var Yt = "StringNGrams";
var $t = "StringSplit";
var oe = "StringToHashBucketFast";
var te = "Sub";
var ee = "Tan";
var re = "Tanh";
var ne = "Tile";
var se = "TopK";
var pe = "Transform";
var ce = "Transpose";
var ae = "Unique";
var xe = "Unpack";
var ie = "UnsortedSegmentSum";
var le = "UpperBound";
var de = "ZerosLike";
var ue = "Step";
var Se = "FromPixels";
var ge = "RotateWithOffset";
var De = "_FusedMatMul";
var me = "FusedConv2D";
var Re = "FusedDepthwiseConv2D";

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/log.mjs
function t2(...e36) {
  l().getBool("IS_TEST") || l().getBool("PROD") || console.warn(...e36);
}
function l3(...e36) {
  l().getBool("IS_TEST") || l().getBool("PROD") || console.log(...e36);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/kernel_registry.mjs
var o4 = a3("kernelRegistry", () => /* @__PURE__ */ new Map());
var i2 = a3("gradRegistry", () => /* @__PURE__ */ new Map());
function w3(e36, r56) {
  let t67 = a5(e36, r56);
  return o4.get(t67);
}
function x3(e36) {
  return i2.get(e36);
}
function k3(e36) {
  let r56 = o4.entries(), t67 = [];
  for (; ; ) {
    let { done: n67, value: s84 } = r56.next();
    if (n67) break;
    let [f85, l80] = s84, [d55] = f85.split("_");
    d55 === e36 && t67.push(l80);
  }
  return t67;
}
function p3(e36) {
  let { kernelName: r56, backendName: t67 } = e36, n67 = a5(r56, t67);
  o4.has(n67) && t2(`The kernel '${r56}' for backend '${t67}' is already registered`), o4.set(n67, e36);
}
function b3(e36) {
  let { kernelName: r56 } = e36;
  i2.has(r56) && l().getBool("DEBUG") && t2(`Overriding the gradient for '${r56}'`), i2.set(r56, e36);
}
function $3(e36, r56) {
  let t67 = a5(e36, r56);
  if (!o4.has(t67)) throw new Error(`The kernel '${e36}' for backend '${r56}' is not registered`);
  o4.delete(t67);
}
function m2(e36) {
  if (!i2.has(e36)) throw new Error(`The gradient '${e36}' for backend is not registered`);
  i2.delete(e36);
}
function K3(e36, r56) {
  k3(e36).forEach((n67) => {
    let s84 = Object.assign({}, n67, { backendName: r56 });
    p3(s84);
  });
}
function a5(e36, r56) {
  return `${r56}_${e36}`;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/util.mjs
var util_exports = {};
__export(util_exports, {
  arraysEqual: () => w,
  arraysEqualWithNull: () => P,
  assert: () => c,
  assertNonNegativeIntegerDimensions: () => rr,
  assertNonNull: () => T,
  assertShapesMatch: () => k,
  bytesFromStringArray: () => Q,
  bytesPerElement: () => K,
  checkConversionForErrors: () => W,
  clamp: () => F,
  computeStrides: () => Y,
  convertBackendValuesAndArrayBuffer: () => _,
  createScalarValue: () => A3,
  createShuffledIndices: () => v,
  decodeString: () => w5,
  distSquared: () => U,
  encodeString: () => m4,
  fetch: () => h4,
  fingerPrint64: () => H3,
  flatten: () => l5,
  getArrayFromDType: () => A,
  getTypedArrayFromDType: () => O,
  hasEncodingLoss: () => J,
  hexToLong: () => y4,
  indexToLoc: () => nr,
  inferDtype: () => E,
  inferFromImplicitShape: () => C,
  isBoolean: () => $,
  isFunction: () => R,
  isInt: () => p,
  isNumber: () => b,
  isPromise: () => er,
  isScalarShape: () => D,
  isString: () => y,
  isTypedArray: () => u2,
  isValidDtype: () => H,
  locToIndex: () => tr,
  makeOnesTypedArray: () => z,
  makeZerosNestedTypedArray: () => j,
  makeZerosTypedArray: () => S,
  nearestDivisor: () => X,
  nearestLargerEven: () => I,
  now: () => y5,
  parseAxisParam: () => x,
  randUniform: () => M,
  repeatedTry: () => Z,
  rightPad: () => V,
  shuffle: () => g,
  shuffleCombo: () => d,
  sizeFromShape: () => q,
  sizeToSquarishShape: () => L,
  squeezeShape: () => G,
  sum: () => N,
  swap: () => a,
  tanh: () => B,
  toNestedArray: () => s,
  toTypedArray: () => a6
});

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/platforms/is_typed_array_browser.mjs
function n5(r56) {
  return r56 instanceof Float32Array || r56 instanceof Int32Array || r56 instanceof Uint8Array || r56 instanceof Uint8ClampedArray;
}

// https://esm.sh/long@4.0.0/denonext/long.mjs
var long_exports = {};
__export(long_exports, {
  MAX_UNSIGNED_VALUE: () => lt2,
  MAX_VALUE: () => Ft2,
  MIN_VALUE: () => ct2,
  NEG_ONE: () => at2,
  ONE: () => gt2,
  UONE: () => ot2,
  UZERO: () => ut2,
  ZERO: () => ft2,
  default: () => _t2,
  fromBits: () => rt2,
  fromBytes: () => wt2,
  fromBytesBE: () => Nt2,
  fromBytesLE: () => Et2,
  fromInt: () => nt2,
  fromNumber: () => et2,
  fromString: () => ht2,
  fromValue: () => st2,
  isLong: () => it2
});
var j3 = Object.create;
var B3 = Object.defineProperty;
var C3 = Object.getOwnPropertyDescriptor;
var p4 = Object.getOwnPropertyNames;
var k4 = Object.getPrototypeOf;
var z3 = Object.prototype.hasOwnProperty;
var J3 = (i88, t67) => () => (t67 || i88((t67 = { exports: {} }).exports, t67), t67.exports);
var K4 = (i88, t67, e36, r56) => {
  if (t67 && typeof t67 == "object" || typeof t67 == "function") for (let h74 of p4(t67)) !z3.call(i88, h74) && h74 !== e36 && B3(i88, h74, { get: () => t67[h74], enumerable: !(r56 = C3(t67, h74)) || r56.enumerable });
  return i88;
};
var Q3 = (i88, t67, e36) => (e36 = i88 != null ? j3(k4(i88)) : {}, K4(t67 || !i88 || !i88.__esModule ? B3(e36, "default", { value: i88, enumerable: true }) : e36, i88));
var X3 = J3((tt3, H18) => {
  H18.exports = s84;
  var m96 = null;
  try {
    m96 = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;
  } catch {
  }
  function s84(i88, t67, e36) {
    this.low = i88 | 0, this.high = t67 | 0, this.unsigned = !!e36;
  }
  s84.prototype.__isLong__;
  Object.defineProperty(s84.prototype, "__isLong__", { value: true });
  function w45(i88) {
    return (i88 && i88.__isLong__) === true;
  }
  s84.isLong = w45;
  var M30 = {}, Z16 = {};
  function U24(i88, t67) {
    var e36, r56, h74;
    return t67 ? (i88 >>>= 0, (h74 = 0 <= i88 && i88 < 256) && (r56 = Z16[i88], r56) ? r56 : (e36 = f85(i88, (i88 | 0) < 0 ? -1 : 0, true), h74 && (Z16[i88] = e36), e36)) : (i88 |= 0, (h74 = -128 <= i88 && i88 < 128) && (r56 = M30[i88], r56) ? r56 : (e36 = f85(i88, i88 < 0 ? -1 : 0, false), h74 && (M30[i88] = e36), e36));
  }
  s84.fromInt = U24;
  function L22(i88, t67) {
    if (isNaN(i88)) return t67 ? q25 : O21;
    if (t67) {
      if (i88 < 0) return q25;
      if (i88 >= P36) return G30;
    } else {
      if (i88 <= -W15) return c103;
      if (i88 + 1 >= W15) return D42;
    }
    return i88 < 0 ? L22(-i88, t67).neg() : f85(i88 % x76 | 0, i88 / x76 | 0, t67);
  }
  s84.fromNumber = L22;
  function f85(i88, t67, e36) {
    return new s84(i88, t67, e36);
  }
  s84.fromBits = f85;
  var A35 = Math.pow;
  function d55(i88, t67, e36) {
    if (i88.length === 0) throw Error("empty string");
    if (i88 === "NaN" || i88 === "Infinity" || i88 === "+Infinity" || i88 === "-Infinity") return O21;
    if (typeof t67 == "number" ? (e36 = t67, t67 = false) : t67 = !!t67, e36 = e36 || 10, e36 < 2 || 36 < e36) throw RangeError("radix");
    var r56;
    if ((r56 = i88.indexOf("-")) > 0) throw Error("interior hyphen");
    if (r56 === 0) return d55(i88.substring(1), t67, e36).neg();
    for (var h74 = L22(A35(e36, 8)), u86 = O21, o80 = 0; o80 < i88.length; o80 += 8) {
      var l80 = Math.min(8, i88.length - o80), N58 = parseInt(i88.substring(o80, o80 + l80), e36);
      if (l80 < 8) {
        var F32 = L22(A35(e36, l80));
        u86 = u86.mul(F32).add(L22(N58));
      } else u86 = u86.mul(h74), u86 = u86.add(L22(N58));
    }
    return u86.unsigned = t67, u86;
  }
  s84.fromString = d55;
  function v42(i88, t67) {
    return typeof i88 == "number" ? L22(i88, t67) : typeof i88 == "string" ? d55(i88, t67) : f85(i88.low, i88.high, typeof t67 == "boolean" ? t67 : i88.unsigned);
  }
  s84.fromValue = v42;
  var S45 = 65536, Y14 = 1 << 24, x76 = S45 * S45, P36 = x76 * x76, W15 = P36 / 2, R26 = U24(Y14), O21 = U24(0);
  s84.ZERO = O21;
  var q25 = U24(0, true);
  s84.UZERO = q25;
  var y43 = U24(1);
  s84.ONE = y43;
  var V24 = U24(1, true);
  s84.UONE = V24;
  var b58 = U24(-1);
  s84.NEG_ONE = b58;
  var D42 = f85(-1, 2147483647, false);
  s84.MAX_VALUE = D42;
  var G30 = f85(-1, -1, true);
  s84.MAX_UNSIGNED_VALUE = G30;
  var c103 = f85(0, -2147483648, false);
  s84.MIN_VALUE = c103;
  var n67 = s84.prototype;
  n67.toInt = function() {
    return this.unsigned ? this.low >>> 0 : this.low;
  };
  n67.toNumber = function() {
    return this.unsigned ? (this.high >>> 0) * x76 + (this.low >>> 0) : this.high * x76 + (this.low >>> 0);
  };
  n67.toString = function(t67) {
    if (t67 = t67 || 10, t67 < 2 || 36 < t67) throw RangeError("radix");
    if (this.isZero()) return "0";
    if (this.isNegative()) if (this.eq(c103)) {
      var e36 = L22(t67), r56 = this.div(e36), h74 = r56.mul(e36).sub(this);
      return r56.toString(t67) + h74.toInt().toString(t67);
    } else return "-" + this.neg().toString(t67);
    for (var u86 = L22(A35(t67, 6), this.unsigned), o80 = this, l80 = ""; ; ) {
      var N58 = o80.div(u86), F32 = o80.sub(N58.mul(u86)).toInt() >>> 0, g72 = F32.toString(t67);
      if (o80 = N58, o80.isZero()) return g72 + l80;
      for (; g72.length < 6; ) g72 = "0" + g72;
      l80 = "" + g72 + l80;
    }
  };
  n67.getHighBits = function() {
    return this.high;
  };
  n67.getHighBitsUnsigned = function() {
    return this.high >>> 0;
  };
  n67.getLowBits = function() {
    return this.low;
  };
  n67.getLowBitsUnsigned = function() {
    return this.low >>> 0;
  };
  n67.getNumBitsAbs = function() {
    if (this.isNegative()) return this.eq(c103) ? 64 : this.neg().getNumBitsAbs();
    for (var t67 = this.high != 0 ? this.high : this.low, e36 = 31; e36 > 0 && !(t67 & 1 << e36); e36--) ;
    return this.high != 0 ? e36 + 33 : e36 + 1;
  };
  n67.isZero = function() {
    return this.high === 0 && this.low === 0;
  };
  n67.eqz = n67.isZero;
  n67.isNegative = function() {
    return !this.unsigned && this.high < 0;
  };
  n67.isPositive = function() {
    return this.unsigned || this.high >= 0;
  };
  n67.isOdd = function() {
    return (this.low & 1) === 1;
  };
  n67.isEven = function() {
    return (this.low & 1) === 0;
  };
  n67.equals = function(t67) {
    return w45(t67) || (t67 = v42(t67)), this.unsigned !== t67.unsigned && this.high >>> 31 === 1 && t67.high >>> 31 === 1 ? false : this.high === t67.high && this.low === t67.low;
  };
  n67.eq = n67.equals;
  n67.notEquals = function(t67) {
    return !this.eq(t67);
  };
  n67.neq = n67.notEquals;
  n67.ne = n67.notEquals;
  n67.lessThan = function(t67) {
    return this.comp(t67) < 0;
  };
  n67.lt = n67.lessThan;
  n67.lessThanOrEqual = function(t67) {
    return this.comp(t67) <= 0;
  };
  n67.lte = n67.lessThanOrEqual;
  n67.le = n67.lessThanOrEqual;
  n67.greaterThan = function(t67) {
    return this.comp(t67) > 0;
  };
  n67.gt = n67.greaterThan;
  n67.greaterThanOrEqual = function(t67) {
    return this.comp(t67) >= 0;
  };
  n67.gte = n67.greaterThanOrEqual;
  n67.ge = n67.greaterThanOrEqual;
  n67.compare = function(t67) {
    if (w45(t67) || (t67 = v42(t67)), this.eq(t67)) return 0;
    var e36 = this.isNegative(), r56 = t67.isNegative();
    return e36 && !r56 ? -1 : !e36 && r56 ? 1 : this.unsigned ? t67.high >>> 0 > this.high >>> 0 || t67.high === this.high && t67.low >>> 0 > this.low >>> 0 ? -1 : 1 : this.sub(t67).isNegative() ? -1 : 1;
  };
  n67.comp = n67.compare;
  n67.negate = function() {
    return !this.unsigned && this.eq(c103) ? c103 : this.not().add(y43);
  };
  n67.neg = n67.negate;
  n67.add = function(t67) {
    w45(t67) || (t67 = v42(t67));
    var e36 = this.high >>> 16, r56 = this.high & 65535, h74 = this.low >>> 16, u86 = this.low & 65535, o80 = t67.high >>> 16, l80 = t67.high & 65535, N58 = t67.low >>> 16, F32 = t67.low & 65535, g72 = 0, _24 = 0, a71 = 0, E44 = 0;
    return E44 += u86 + F32, a71 += E44 >>> 16, E44 &= 65535, a71 += h74 + N58, _24 += a71 >>> 16, a71 &= 65535, _24 += r56 + l80, g72 += _24 >>> 16, _24 &= 65535, g72 += e36 + o80, g72 &= 65535, f85(a71 << 16 | E44, g72 << 16 | _24, this.unsigned);
  };
  n67.subtract = function(t67) {
    return w45(t67) || (t67 = v42(t67)), this.add(t67.neg());
  };
  n67.sub = n67.subtract;
  n67.multiply = function(t67) {
    if (this.isZero()) return O21;
    if (w45(t67) || (t67 = v42(t67)), m96) {
      var e36 = m96.mul(this.low, this.high, t67.low, t67.high);
      return f85(e36, m96.get_high(), this.unsigned);
    }
    if (t67.isZero()) return O21;
    if (this.eq(c103)) return t67.isOdd() ? c103 : O21;
    if (t67.eq(c103)) return this.isOdd() ? c103 : O21;
    if (this.isNegative()) return t67.isNegative() ? this.neg().mul(t67.neg()) : this.neg().mul(t67).neg();
    if (t67.isNegative()) return this.mul(t67.neg()).neg();
    if (this.lt(R26) && t67.lt(R26)) return L22(this.toNumber() * t67.toNumber(), this.unsigned);
    var r56 = this.high >>> 16, h74 = this.high & 65535, u86 = this.low >>> 16, o80 = this.low & 65535, l80 = t67.high >>> 16, N58 = t67.high & 65535, F32 = t67.low >>> 16, g72 = t67.low & 65535, _24 = 0, a71 = 0, E44 = 0, T40 = 0;
    return T40 += o80 * g72, E44 += T40 >>> 16, T40 &= 65535, E44 += u86 * g72, a71 += E44 >>> 16, E44 &= 65535, E44 += o80 * F32, a71 += E44 >>> 16, E44 &= 65535, a71 += h74 * g72, _24 += a71 >>> 16, a71 &= 65535, a71 += u86 * F32, _24 += a71 >>> 16, a71 &= 65535, a71 += o80 * N58, _24 += a71 >>> 16, a71 &= 65535, _24 += r56 * g72 + h74 * F32 + u86 * N58 + o80 * l80, _24 &= 65535, f85(E44 << 16 | T40, _24 << 16 | a71, this.unsigned);
  };
  n67.mul = n67.multiply;
  n67.divide = function(t67) {
    if (w45(t67) || (t67 = v42(t67)), t67.isZero()) throw Error("division by zero");
    if (m96) {
      if (!this.unsigned && this.high === -2147483648 && t67.low === -1 && t67.high === -1) return this;
      var e36 = (this.unsigned ? m96.div_u : m96.div_s)(this.low, this.high, t67.low, t67.high);
      return f85(e36, m96.get_high(), this.unsigned);
    }
    if (this.isZero()) return this.unsigned ? q25 : O21;
    var r56, h74, u86;
    if (this.unsigned) {
      if (t67.unsigned || (t67 = t67.toUnsigned()), t67.gt(this)) return q25;
      if (t67.gt(this.shru(1))) return V24;
      u86 = q25;
    } else {
      if (this.eq(c103)) {
        if (t67.eq(y43) || t67.eq(b58)) return c103;
        if (t67.eq(c103)) return y43;
        var o80 = this.shr(1);
        return r56 = o80.div(t67).shl(1), r56.eq(O21) ? t67.isNegative() ? y43 : b58 : (h74 = this.sub(t67.mul(r56)), u86 = r56.add(h74.div(t67)), u86);
      } else if (t67.eq(c103)) return this.unsigned ? q25 : O21;
      if (this.isNegative()) return t67.isNegative() ? this.neg().div(t67.neg()) : this.neg().div(t67).neg();
      if (t67.isNegative()) return this.div(t67.neg()).neg();
      u86 = O21;
    }
    for (h74 = this; h74.gte(t67); ) {
      r56 = Math.max(1, Math.floor(h74.toNumber() / t67.toNumber()));
      for (var l80 = Math.ceil(Math.log(r56) / Math.LN2), N58 = l80 <= 48 ? 1 : A35(2, l80 - 48), F32 = L22(r56), g72 = F32.mul(t67); g72.isNegative() || g72.gt(h74); ) r56 -= N58, F32 = L22(r56, this.unsigned), g72 = F32.mul(t67);
      F32.isZero() && (F32 = y43), u86 = u86.add(F32), h74 = h74.sub(g72);
    }
    return u86;
  };
  n67.div = n67.divide;
  n67.modulo = function(t67) {
    if (w45(t67) || (t67 = v42(t67)), m96) {
      var e36 = (this.unsigned ? m96.rem_u : m96.rem_s)(this.low, this.high, t67.low, t67.high);
      return f85(e36, m96.get_high(), this.unsigned);
    }
    return this.sub(this.div(t67).mul(t67));
  };
  n67.mod = n67.modulo;
  n67.rem = n67.modulo;
  n67.not = function() {
    return f85(~this.low, ~this.high, this.unsigned);
  };
  n67.and = function(t67) {
    return w45(t67) || (t67 = v42(t67)), f85(this.low & t67.low, this.high & t67.high, this.unsigned);
  };
  n67.or = function(t67) {
    return w45(t67) || (t67 = v42(t67)), f85(this.low | t67.low, this.high | t67.high, this.unsigned);
  };
  n67.xor = function(t67) {
    return w45(t67) || (t67 = v42(t67)), f85(this.low ^ t67.low, this.high ^ t67.high, this.unsigned);
  };
  n67.shiftLeft = function(t67) {
    return w45(t67) && (t67 = t67.toInt()), (t67 &= 63) === 0 ? this : t67 < 32 ? f85(this.low << t67, this.high << t67 | this.low >>> 32 - t67, this.unsigned) : f85(0, this.low << t67 - 32, this.unsigned);
  };
  n67.shl = n67.shiftLeft;
  n67.shiftRight = function(t67) {
    return w45(t67) && (t67 = t67.toInt()), (t67 &= 63) === 0 ? this : t67 < 32 ? f85(this.low >>> t67 | this.high << 32 - t67, this.high >> t67, this.unsigned) : f85(this.high >> t67 - 32, this.high >= 0 ? 0 : -1, this.unsigned);
  };
  n67.shr = n67.shiftRight;
  n67.shiftRightUnsigned = function(t67) {
    if (w45(t67) && (t67 = t67.toInt()), t67 &= 63, t67 === 0) return this;
    var e36 = this.high;
    if (t67 < 32) {
      var r56 = this.low;
      return f85(r56 >>> t67 | e36 << 32 - t67, e36 >>> t67, this.unsigned);
    } else return t67 === 32 ? f85(e36, 0, this.unsigned) : f85(e36 >>> t67 - 32, 0, this.unsigned);
  };
  n67.shru = n67.shiftRightUnsigned;
  n67.shr_u = n67.shiftRightUnsigned;
  n67.toSigned = function() {
    return this.unsigned ? f85(this.low, this.high, false) : this;
  };
  n67.toUnsigned = function() {
    return this.unsigned ? this : f85(this.low, this.high, true);
  };
  n67.toBytes = function(t67) {
    return t67 ? this.toBytesLE() : this.toBytesBE();
  };
  n67.toBytesLE = function() {
    var t67 = this.high, e36 = this.low;
    return [e36 & 255, e36 >>> 8 & 255, e36 >>> 16 & 255, e36 >>> 24, t67 & 255, t67 >>> 8 & 255, t67 >>> 16 & 255, t67 >>> 24];
  };
  n67.toBytesBE = function() {
    var t67 = this.high, e36 = this.low;
    return [t67 >>> 24, t67 >>> 16 & 255, t67 >>> 8 & 255, t67 & 255, e36 >>> 24, e36 >>> 16 & 255, e36 >>> 8 & 255, e36 & 255];
  };
  s84.fromBytes = function(t67, e36, r56) {
    return r56 ? s84.fromBytesLE(t67, e36) : s84.fromBytesBE(t67, e36);
  };
  s84.fromBytesLE = function(t67, e36) {
    return new s84(t67[0] | t67[1] << 8 | t67[2] << 16 | t67[3] << 24, t67[4] | t67[5] << 8 | t67[6] << 16 | t67[7] << 24, e36);
  };
  s84.fromBytesBE = function(t67, e36) {
    return new s84(t67[4] << 24 | t67[5] << 16 | t67[6] << 8 | t67[7], t67[0] << 24 | t67[1] << 16 | t67[2] << 8 | t67[3], e36);
  };
});
var I3 = Q3(X3());
var { isLong: it2, fromInt: nt2, fromNumber: et2, fromBits: rt2, fromString: ht2, fromValue: st2, ZERO: ft2, UZERO: ut2, ONE: gt2, UONE: ot2, NEG_ONE: at2, MAX_VALUE: Ft2, MAX_UNSIGNED_VALUE: lt2, MIN_VALUE: ct2, fromBytes: wt2, fromBytesLE: Et2, fromBytesBE: Nt2 } = I3;
var _t2 = I3.default ?? I3;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/hash_util.mjs
var x4 = _t2 || long_exports;
function y4(d55) {
  return x4.fromString(d55, true, 16);
}
var w4 = y4("c3a5c85c97cb3127");
var s4 = y4("b492b66fbe98f273");
var l4 = y4("9ae16a3b2f90404f");
function E3(d55) {
  return d55.xor(d55.shru(47));
}
function O3(d55, t67, o80) {
  let a71 = d55.slice(t67, t67 + o80);
  return x4.fromBytes(Array.from(a71), true, true);
}
function r2(d55, t67) {
  return O3(d55, t67, 8);
}
function p5(d55, t67) {
  return O3(d55, t67, 4);
}
function m3(d55, t67) {
  return t67 === 0 ? d55 : d55.shru(t67).or(d55.shl(64 - t67));
}
function i3(d55, t67, o80 = y4("9ddfea08eb382d69")) {
  let a71 = d55.xor(t67).mul(o80);
  a71 = a71.xor(a71.shru(47));
  let n67 = t67.xor(a71).mul(o80);
  return n67 = n67.xor(n67.shru(47)), n67 = n67.mul(o80), n67;
}
function S3(d55, t67, o80, a71, n67, u86) {
  n67 = n67.add(d55), u86 = m3(u86.add(n67).add(a71), 21);
  let c103 = n67;
  return n67 = n67.add(t67), n67 = n67.add(o80), u86 = u86.add(m3(n67, 44)), [n67.add(a71), u86.add(c103)];
}
function b4(d55, t67, o80, a71) {
  return S3(r2(d55, t67), r2(d55, t67 + 8), r2(d55, t67 + 16), r2(d55, t67 + 24), o80, a71);
}
function U3(d55, t67 = d55.length) {
  if (t67 >= 8) {
    let o80 = l4.add(t67 * 2), a71 = r2(d55, 0).add(l4), n67 = r2(d55, t67 - 8), u86 = m3(n67, 37).mul(o80).add(a71), c103 = m3(a71, 25).add(n67).mul(o80);
    return i3(u86, c103, o80);
  }
  if (t67 >= 4) {
    let o80 = l4.add(t67 * 2), a71 = p5(d55, 0);
    return i3(a71.shl(3).add(t67), p5(d55, t67 - 4), o80);
  }
  if (t67 > 0) {
    let o80 = d55[0], a71 = d55[t67 >> 1], n67 = d55[t67 - 1], u86 = o80 + (a71 << 8), c103 = t67 + (n67 << 2);
    return E3(l4.mul(u86).xor(w4.mul(c103))).mul(l4);
  }
  return l4;
}
function Z3(d55, t67 = d55.length) {
  let o80 = l4.add(t67 * 2), a71 = r2(d55, 0).mul(s4), n67 = r2(d55, 8), u86 = r2(d55, t67 - 8).mul(o80), c103 = r2(d55, t67 - 16).mul(l4);
  return i3(m3(a71.add(n67), 43).add(m3(u86, 30)).add(c103), a71.add(m3(n67.add(l4), 18)).add(u86), o80);
}
function z4(d55, t67 = d55.length) {
  let o80 = l4.add(t67 * 2), a71 = r2(d55, 0).mul(l4), n67 = r2(d55, 8), u86 = r2(d55, t67 - 8).mul(o80), c103 = r2(d55, t67 - 16).mul(l4), e36 = m3(a71.add(n67), 43).add(m3(u86, 30)).add(c103), f85 = i3(e36, a71.add(m3(n67.add(l4), 18)).add(u86), o80), g72 = r2(d55, 16).mul(o80), L22 = r2(d55, 24), h74 = e36.add(r2(d55, t67 - 32)).mul(o80), R26 = f85.add(r2(d55, t67 - 24)).mul(o80);
  return i3(m3(g72.add(L22), 43).add(m3(h74, 30)).add(R26), g72.add(m3(L22.add(a71), 18)).add(h74), o80);
}
function H3(d55, t67 = d55.length) {
  let o80 = x4.fromNumber(81, true);
  if (t67 <= 32) return t67 <= 16 ? U3(d55, t67) : Z3(d55, t67);
  if (t67 <= 64) return z4(d55, t67);
  let a71 = o80, n67 = o80.mul(s4).add(113), u86 = E3(n67.mul(l4).add(113)).mul(l4), c103 = [x4.UZERO, x4.UZERO], e36 = [x4.UZERO, x4.UZERO];
  a71 = a71.mul(l4).add(r2(d55, 0));
  let f85 = 0, g72 = (t67 - 1 >> 6) * 64, L22 = g72 + (t67 - 1 & 63) - 63;
  do
    a71 = m3(a71.add(n67).add(c103[0]).add(r2(d55, f85 + 8)), 37).mul(s4), n67 = m3(n67.add(c103[1]).add(r2(d55, f85 + 48)), 42).mul(s4), a71 = a71.xor(e36[1]), n67 = n67.add(c103[0]).add(r2(d55, f85 + 40)), u86 = m3(u86.add(e36[0]), 33).mul(s4), c103 = b4(d55, f85, c103[1].mul(s4), a71.add(e36[0])), e36 = b4(d55, f85 + 32, u86.add(e36[1]), n67.add(r2(d55, f85 + 16))), [u86, a71] = [a71, u86], f85 += 64;
  while (f85 !== g72);
  let h74 = s4.add(u86.and(255).shl(1));
  return f85 = L22, e36[0] = e36[0].add(t67 - 1 & 63), c103[0] = c103[0].add(e36[0]), e36[0] = e36[0].add(c103[0]), a71 = m3(a71.add(n67).add(c103[0]).add(r2(d55, f85 + 8)), 37).mul(h74), n67 = m3(n67.add(c103[1]).add(r2(d55, f85 + 48)), 42).mul(h74), a71 = a71.xor(e36[1].mul(9)), n67 = n67.add(c103[0].mul(9).add(r2(d55, f85 + 40))), u86 = m3(u86.add(e36[0]), 33).mul(h74), c103 = b4(d55, f85, c103[1].mul(h74), a71.add(e36[0])), e36 = b4(d55, f85 + 32, u86.add(e36[1]), n67.add(r2(d55, f85 + 16))), [u86, a71] = [a71, u86], i3(i3(c103[0], e36[0], h74).add(E3(n67).mul(w4)).add(u86), i3(c103[1], e36[1], h74).add(a71), h74);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/util.mjs
function A3(r56, o80) {
  return o80 === "string" ? m4(r56) : a6([r56], o80);
}
function c4(r56, o80) {
  return r56 instanceof Float32Array && o80 === "float32" || r56 instanceof Int32Array && o80 === "int32" || r56 instanceof Uint8Array && o80 === "bool";
}
function a6(r56, o80) {
  if (o80 === "string") throw new Error("Cannot convert a string[] to a TypedArray");
  if (Array.isArray(r56) && (r56 = l5(r56)), l().getBool("DEBUG") && W(r56, o80), c4(r56, o80)) return r56;
  if (o80 == null || o80 === "float32" || o80 === "complex64") return new Float32Array(r56);
  if (o80 === "int32") return new Int32Array(r56);
  if (o80 === "bool") {
    let n67 = new Uint8Array(r56.length);
    for (let t67 = 0; t67 < n67.length; ++t67) Math.round(r56[t67]) !== 0 && (n67[t67] = 1);
    return n67;
  } else throw new Error(`Unknown data type ${o80}`);
}
function y5() {
  return l().platform.now();
}
function h4(r56, o80) {
  return l().platform.fetch(r56, o80);
}
function m4(r56, o80 = "utf-8") {
  return o80 = o80 || "utf-8", l().platform.encode(r56, o80);
}
function w5(r56, o80 = "utf-8") {
  return o80 = o80 || "utf-8", l().platform.decode(r56, o80);
}
function u2(r56) {
  return l().platform.isTypedArray != null ? l().platform.isTypedArray(r56) : n5(r56);
}
function l5(r56, o80 = [], n67 = false) {
  if (o80 == null && (o80 = []), typeof r56 == "boolean" || typeof r56 == "number" || typeof r56 == "string" || er(r56) || r56 == null || u2(r56) && n67) o80.push(r56);
  else if (Array.isArray(r56) || u2(r56)) for (let t67 = 0; t67 < r56.length; ++t67) l5(r56[t67], o80, n67);
  else {
    let t67 = -1;
    for (let f85 of Object.keys(r56)) /^([1-9]+[0-9]*|0)$/.test(f85) && (t67 = Math.max(t67, Number(f85)));
    for (let f85 = 0; f85 <= t67; f85++) l5(r56[f85], o80, n67);
  }
  return o80;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/profiler.mjs
var k5 = class {
  constructor(n67, e36) {
    this.backendTimer = n67, this.logger = e36, e36 == null && (this.logger = new p6());
  }
  profileKernel(n67, e36, r56) {
    let t67, i88 = () => {
      t67 = r56();
    }, l80, c103 = y5();
    if (this.backendTimer.timerAvailable()) l80 = this.backendTimer.time(i88);
    else {
      i88();
      for (let o80 of t67) o80.dataSync();
      l80 = Promise.resolve({ kernelMs: y5() - c103 });
    }
    if (l().getBool("CHECK_COMPUTATION_FOR_ERRORS")) for (let o80 = 0; o80 < t67.length; o80++) {
      let u86 = t67[o80];
      u86.data().then((h74) => {
        x5(h74, u86.dtype, n67);
      });
    }
    return { kernelName: n67, outputs: t67, inputs: e36, timeMs: l80.then((o80) => o80.kernelMs), extraInfo: l80.then((o80) => o80.getExtraProfileInfo != null ? o80.getExtraProfileInfo() : "") };
  }
  logKernelProfile(n67) {
    let { kernelName: e36, outputs: r56, timeMs: t67, inputs: i88, extraInfo: l80 } = n67;
    r56.forEach((c103) => {
      Promise.all([c103.data(), t67, l80]).then((a71) => {
        this.logger.logKernelProfile(e36, c103, a71[0], a71[1], i88, a71[2]);
      });
    });
  }
};
function x5(f85, n67, e36) {
  if (n67 !== "float32") return false;
  for (let r56 = 0; r56 < f85.length; r56++) {
    let t67 = f85[r56];
    if (isNaN(t67) || !isFinite(t67)) return console.warn(`Found ${t67} in the result of '${e36}'`), true;
  }
  return false;
}
var p6 = class {
  logKernelProfile(n67, e36, r56, t67, i88, l80) {
    let c103 = typeof t67 == "number" ? V(`${t67}ms`, 9) : t67.error, a71 = V(n67, 25), o80 = e36.rank, u86 = e36.size, h74 = V(e36.shape.toString(), 14), g72 = "";
    for (let m96 in i88) {
      let d55 = i88[m96];
      if (d55 != null) {
        let $37 = d55.shape || e36.shape, P36 = $37.length;
        g72 += `${m96}: ${P36}D ${P36 > 0 ? $37 : ""} `;
      }
    }
    console.log(`%c${a71}	%c${c103}	%c${o80}D ${h74}	%c${u86}	%c${g72}	%c${l80}`, "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/tape.mjs
function $4(e36, s84, l80) {
  let u86 = {}, d55 = {};
  for (let n67 = 0; n67 < s84.length; n67++) u86[s84[n67].id] = true;
  for (let n67 = 0; n67 < e36.length; n67++) {
    let t67 = e36[n67], o80 = t67.inputs;
    for (let i88 in o80) {
      let a71 = o80[i88], h74 = false;
      for (let c103 = 0; c103 < s84.length; c103++) if (u86[a71.id]) {
        t67.outputs.forEach((m96) => u86[m96.id] = true), h74 = true, d55[t67.id] = true;
        break;
      }
      if (h74) break;
    }
  }
  let r56 = {};
  r56[l80.id] = true;
  let p103 = {};
  for (let n67 = e36.length - 1; n67 >= 0; n67--) {
    let t67 = e36[n67], o80 = t67.inputs;
    for (let i88 = 0; i88 < t67.outputs.length; i88++) if (r56[t67.outputs[i88].id]) {
      for (let a71 in o80) r56[o80[a71].id] = true, p103[t67.id] = true;
      break;
    }
  }
  let f85 = [];
  for (let n67 = 0; n67 < e36.length; n67++) {
    let t67 = e36[n67];
    if (d55[t67.id] && p103[t67.id]) {
      let o80 = {};
      for (let a71 in t67.inputs) {
        let h74 = t67.inputs[a71];
        u86[h74.id] && (o80[a71] = h74);
      }
      let i88 = Object.assign({}, t67);
      i88.inputs = o80, i88.outputs = t67.outputs, f85.push(i88);
    }
  }
  return f85;
}
function b5(e36, s84, l80, u86) {
  for (let d55 = s84.length - 1; d55 >= 0; d55--) {
    let r56 = s84[d55], p103 = [];
    if (r56.outputs.forEach((n67) => {
      let t67 = e36[n67.id];
      t67 != null ? p103.push(t67) : p103.push(null);
    }), r56.gradient == null) throw new Error(`Cannot compute gradient: gradient function not found for ${r56.kernelName}.`);
    let f85 = r56.gradient(p103);
    for (let n67 in r56.inputs) {
      if (!(n67 in f85)) throw new Error(`Cannot backprop through input ${n67}. Available gradients found: ${Object.keys(f85)}.`);
      let t67 = l80(() => f85[n67]());
      if (t67.dtype !== "float32") throw new Error(`Error in gradient for op ${r56.kernelName}. The gradient of input ${n67} must have 'float32' dtype, but has '${t67.dtype}'`);
      let o80 = r56.inputs[n67];
      if (!w(t67.shape, o80.shape)) throw new Error(`Error in gradient for op ${r56.kernelName}. The gradient of input '${n67}' has shape '${t67.shape}', which does not match the shape of the input '${o80.shape}'`);
      if (e36[o80.id] == null) e36[o80.id] = t67;
      else {
        let i88 = e36[o80.id];
        e36[o80.id] = u86(i88, t67), i88.dispose();
      }
    }
  }
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/tensor_format.mjs
var I4 = 20;
var p7 = 3;
var j4 = 7;
function w6(n67, e36, t67, i88) {
  let f85 = Y(e36), g72 = O4(n67, e36, t67, f85), S45 = e36.length, r56 = A4(n67, e36, t67, f85, g72), c103 = ["Tensor"];
  return i88 && (c103.push(`  dtype: ${t67}`), c103.push(`  rank: ${S45}`), c103.push(`  shape: [${e36}]`), c103.push("  values:")), c103.push(r56.map((a71) => "    " + a71).join(`
`)), c103.join(`
`);
}
function O4(n67, e36, t67, i88) {
  let f85 = q(e36), g72 = i88[i88.length - 1], S45 = new Array(g72).fill(0), r56 = e36.length, c103 = t67 === "complex64" ? x6(n67) : n67;
  if (r56 > 1) for (let a71 = 0; a71 < f85 / g72; a71++) {
    let h74 = a71 * g72;
    for (let l80 = 0; l80 < g72; l80++) S45[l80] = Math.max(S45[l80], T3(c103[h74 + l80], 0, t67).length);
  }
  return S45;
}
function T3(n67, e36, t67) {
  let i88;
  return Array.isArray(n67) ? i88 = `${parseFloat(n67[0].toFixed(j4))} + ${parseFloat(n67[1].toFixed(j4))}j` : y(n67) ? i88 = `'${n67}'` : t67 === "bool" ? i88 = L3(n67) : i88 = parseFloat(n67.toFixed(j4)).toString(), V(i88, e36);
}
function L3(n67) {
  return n67 === 0 ? "false" : "true";
}
function A4(n67, e36, t67, i88, f85, g72 = true) {
  let S45 = t67 === "complex64" ? 2 : 1, r56 = e36[0], c103 = e36.length;
  if (c103 === 0) {
    if (t67 === "complex64") {
      let o80 = x6(n67);
      return [T3(o80[0], 0, t67)];
    }
    return t67 === "bool" ? [L3(n67[0])] : [n67[0].toString()];
  }
  if (c103 === 1) {
    if (r56 > I4) {
      let u86 = p7 * S45, m96 = Array.from(n67.slice(0, u86)), F32 = Array.from(n67.slice((r56 - p7) * S45, r56 * S45));
      return t67 === "complex64" && (m96 = x6(m96), F32 = x6(F32)), ["[" + m96.map((_24, M30) => T3(_24, f85[M30], t67)).join(", ") + ", ..., " + F32.map((_24, M30) => T3(_24, f85[r56 - p7 + M30], t67)).join(", ") + "]"];
    }
    return ["[" + (t67 === "complex64" ? x6(n67) : Array.from(n67)).map((u86, m96) => T3(u86, f85[m96], t67)).join(", ") + "]"];
  }
  let a71 = e36.slice(1), h74 = i88.slice(1), l80 = i88[0] * S45, s84 = [];
  if (r56 > I4) {
    for (let o80 = 0; o80 < p7; o80++) {
      let u86 = o80 * l80, m96 = u86 + l80;
      s84.push(...A4(n67.slice(u86, m96), a71, t67, h74, f85, false));
    }
    s84.push("...");
    for (let o80 = r56 - p7; o80 < r56; o80++) {
      let u86 = o80 * l80, m96 = u86 + l80;
      s84.push(...A4(n67.slice(u86, m96), a71, t67, h74, f85, o80 === r56 - 1));
    }
  } else for (let o80 = 0; o80 < r56; o80++) {
    let u86 = o80 * l80, m96 = u86 + l80;
    s84.push(...A4(n67.slice(u86, m96), a71, t67, h74, f85, o80 === r56 - 1));
  }
  let V24 = c103 === 2 ? "," : "";
  s84[0] = "[" + (r56 > 0 ? s84[0] + V24 : "");
  for (let o80 = 1; o80 < s84.length - 1; o80++) s84[o80] = " " + s84[o80] + V24;
  let b58 = `,
`;
  for (let o80 = 2; o80 < c103; o80++) b58 += `
`;
  return s84[s84.length - 1] = " " + s84[s84.length - 1] + "]" + (g72 ? "" : b58), s84;
}
function x6(n67) {
  let e36 = [];
  for (let t67 = 0; t67 < n67.length; t67 += 2) e36.push([n67[t67], n67[t67 + 1]]);
  return e36;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/tensor.mjs
var p8 = class {
  constructor(t67, e36, s84) {
    if (this.dtype = e36, this.shape = t67.slice(), this.size = q(t67), s84 != null) {
      let i88 = s84.length;
      c(i88 === this.size, () => `Length of values '${i88}' does not match the size inferred by the shape '${this.size}'.`);
    }
    if (e36 === "complex64") throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");
    this.values = s84 || A(e36, this.size), this.strides = Y(t67);
  }
  set(t67, ...e36) {
    e36.length === 0 && (e36 = [0]), c(e36.length === this.rank, () => `The number of provided coordinates (${e36.length}) must match the rank (${this.rank})`);
    let s84 = this.locToIndex(e36);
    this.values[s84] = t67;
  }
  get(...t67) {
    t67.length === 0 && (t67 = [0]);
    let e36 = 0;
    for (let i88 of t67) {
      if (i88 < 0 || i88 >= this.shape[e36]) {
        let f85 = `Requested out of range element at ${t67}.   Buffer shape=${this.shape}`;
        throw new Error(f85);
      }
      e36++;
    }
    let s84 = t67[t67.length - 1];
    for (let i88 = 0; i88 < t67.length - 1; ++i88) s84 += this.strides[i88] * t67[i88];
    return this.values[s84];
  }
  locToIndex(t67) {
    if (this.rank === 0) return 0;
    if (this.rank === 1) return t67[0];
    let e36 = t67[t67.length - 1];
    for (let s84 = 0; s84 < t67.length - 1; ++s84) e36 += this.strides[s84] * t67[s84];
    return e36;
  }
  indexToLoc(t67) {
    if (this.rank === 0) return [];
    if (this.rank === 1) return [t67];
    let e36 = new Array(this.shape.length);
    for (let s84 = 0; s84 < e36.length - 1; ++s84) e36[s84] = Math.floor(t67 / this.strides[s84]), t67 -= e36[s84] * this.strides[s84];
    return e36[e36.length - 1] = t67, e36;
  }
  get rank() {
    return this.shape.length;
  }
  toTensor() {
    return n6().makeTensor(this.values, this.shape, this.dtype);
  }
};
var n6 = null;
var h5 = null;
var g3 = null;
function k6(r56) {
  n6 = r56;
}
function T4(r56) {
  h5 = r56;
}
function D3(r56) {
  g3 = r56;
}
var o5 = class {
  constructor(t67, e36, s84, i88) {
    this.kept = false, this.isDisposedInternal = false, this.shape = t67.slice(), this.dtype = e36 || "float32", this.size = q(t67), this.strides = Y(t67), this.dataId = s84, this.id = i88, this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
  }
  get rank() {
    return this.shape.length;
  }
  async buffer() {
    let t67 = await this.data();
    return h5.buffer(this.shape, this.dtype, t67);
  }
  bufferSync() {
    return h5.buffer(this.shape, this.dtype, this.dataSync());
  }
  async array() {
    let t67 = await this.data();
    return s(this.shape, t67, this.dtype === "complex64");
  }
  arraySync() {
    return s(this.shape, this.dataSync(), this.dtype === "complex64");
  }
  async data() {
    this.throwIfDisposed();
    let t67 = n6().read(this.dataId);
    if (this.dtype === "string") {
      let e36 = await t67;
      try {
        return e36.map((s84) => w5(s84));
      } catch {
        throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
      }
    }
    return t67;
  }
  dataToGPU(t67) {
    return this.throwIfDisposed(), n6().readToGPU(this.dataId, t67);
  }
  dataSync() {
    this.throwIfDisposed();
    let t67 = n6().readSync(this.dataId);
    if (this.dtype === "string") try {
      return t67.map((e36) => w5(e36));
    } catch {
      throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
    }
    return t67;
  }
  async bytes() {
    this.throwIfDisposed();
    let t67 = await n6().read(this.dataId);
    return this.dtype === "string" ? t67 : new Uint8Array(t67.buffer);
  }
  dispose() {
    this.isDisposed || (this.kerasMask && this.kerasMask.dispose(), n6().disposeTensor(this), this.isDisposedInternal = true);
  }
  get isDisposed() {
    return this.isDisposedInternal;
  }
  throwIfDisposed() {
    if (this.isDisposed) throw new Error("Tensor is disposed.");
  }
  print(t67 = false) {
    return h5.print(this, t67);
  }
  clone() {
    return this.throwIfDisposed(), h5.clone(this);
  }
  toString(t67 = false) {
    let e36 = this.dataSync();
    return w6(e36, this.shape, this.dtype, t67);
  }
  cast(t67) {
    return this.throwIfDisposed(), h5.cast(this, t67);
  }
  variable(t67 = true, e36, s84) {
    return this.throwIfDisposed(), n6().makeVariable(this, t67, e36, s84);
  }
};
Object.defineProperty(o5, Symbol.hasInstance, { value: (r56) => !!r56 && r56.data != null && r56.dataSync != null && r56.throwIfDisposed != null });
function m5() {
  return a3("Tensor", () => o5);
}
m5();
var d3 = class extends o5 {
  constructor(t67, e36, s84, i88) {
    super(t67.shape, t67.dtype, t67.dataId, i88), this.trainable = e36, this.name = s84;
  }
  assign(t67) {
    if (t67.dtype !== this.dtype) throw new Error(`dtype of the new value (${t67.dtype}) and previous value (${this.dtype}) must match`);
    if (!w(t67.shape, this.shape)) throw new Error(`shape of the new value (${t67.shape}) and previous value (${this.shape}) must match`);
    n6().disposeTensor(this), this.dataId = t67.dataId, n6().incRef(this, null);
  }
  dispose() {
    n6().disposeVariable(this), this.isDisposedInternal = true;
  }
};
Object.defineProperty(d3, Symbol.hasInstance, { value: (r56) => r56 instanceof o5 && r56.assign != null && r56.assign instanceof Function });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/tensor_util.mjs
var tensor_util_exports = {};
__export(tensor_util_exports, {
  assertTypesMatch: () => T5,
  getTensorsInContainer: () => l7,
  isTensorInList: () => h6,
  makeTypesMatch: () => m6
});

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/types.mjs
var i4;
(function(o80) {
  o80.R0 = "R0", o80.R1 = "R1", o80.R2 = "R2", o80.R3 = "R3", o80.R4 = "R4", o80.R5 = "R5", o80.R6 = "R6";
})(i4 || (i4 = {}));
var n7;
(function(o80) {
  o80.float32 = "float32", o80.int32 = "int32", o80.bool = "int32", o80.complex64 = "complex64";
})(n7 || (n7 = {}));
var r3;
(function(o80) {
  o80.float32 = "float32", o80.int32 = "int32", o80.bool = "bool", o80.complex64 = "complex64";
})(r3 || (r3 = {}));
var f4;
(function(o80) {
  o80.float32 = "float32", o80.int32 = "float32", o80.bool = "float32", o80.complex64 = "complex64";
})(f4 || (f4 = {}));
var e3;
(function(o80) {
  o80.float32 = "complex64", o80.int32 = "complex64", o80.bool = "complex64", o80.complex64 = "complex64";
})(e3 || (e3 = {}));
var u3 = { float32: f4, int32: n7, bool: r3, complex64: e3 };
function c5(o80, t67) {
  if (o80 === "string" || t67 === "string") {
    if (o80 === "string" && t67 === "string") return "string";
    throw new Error(`Can not upcast ${o80} with ${t67}`);
  }
  return u3[o80][t67];
}
function l6(o80) {
  return c5(o80, "int32");
}
function x7(o80) {
  return o80 != null && typeof o80 == "object" && "texture" in o80 && o80.texture instanceof WebGLTexture;
}
function b6(o80) {
  return typeof GPUBuffer < "u" && o80 != null && typeof o80 == "object" && "buffer" in o80 && o80.buffer instanceof GPUBuffer;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/tensor_util.mjs
function m6(t67, e36) {
  if (t67.dtype === e36.dtype) return [t67, e36];
  let r56 = c5(t67.dtype, e36.dtype);
  return [t67.cast(r56), e36.cast(r56)];
}
function T5(t67, e36) {
  c(t67.dtype === e36.dtype, () => `The dtypes of the first(${t67.dtype}) and second(${e36.dtype}) input must match`);
}
function h6(t67, e36) {
  return e36.some((r56) => r56.id === t67.id);
}
function l7(t67) {
  let e36 = [];
  return o6(t67, e36, /* @__PURE__ */ new Set()), e36;
}
function o6(t67, e36, r56) {
  if (t67 == null) return;
  if (t67 instanceof o5) {
    e36.push(t67);
    return;
  }
  if (!c6(t67)) return;
  let s84 = t67;
  for (let p103 in s84) {
    let n67 = s84[p103];
    r56.has(n67) || (r56.add(n67), o6(n67, e36, r56));
  }
}
function c6(t67) {
  return Array.isArray(t67) || typeof t67 == "object";
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/engine.mjs
function S4(l80) {
  return l80.kernelName != null;
}
var B4 = class {
  constructor() {
    this.registeredVariables = {}, this.nextTapeNodeId = 0, this.numBytes = 0, this.numTensors = 0, this.numStringTensors = 0, this.numDataBuffers = 0, this.gradientDepth = 0, this.kernelDepth = 0, this.scopeStack = [], this.numDataMovesStack = [], this.nextScopeId = 0, this.tensorInfo = /* @__PURE__ */ new WeakMap(), this.profiling = false, this.activeProfile = { newBytes: 0, newTensors: 0, peakBytes: 0, kernels: [], result: null, get kernelNames() {
      return Array.from(new Set(this.kernels.map((t67) => t67.name)));
    } };
  }
  dispose() {
    for (let t67 in this.registeredVariables) this.registeredVariables[t67].dispose();
  }
};
var I5 = class l8 {
  constructor(t67) {
    this.ENV = t67, this.registry = {}, this.registryFactory = {}, this.pendingBackendInitId = 0, this.state = new B4();
  }
  async ready() {
    if (this.pendingBackendInit != null) return this.pendingBackendInit.then(() => {
    });
    if (this.backendInstance != null) return;
    let t67 = this.getSortedBackends();
    for (let e36 = 0; e36 < t67.length; e36++) {
      let s84 = t67[e36];
      if (await this.initializeBackend(s84).success) {
        await this.setBackend(s84);
        return;
      }
    }
    throw new Error("Could not initialize any backends, all backend initializations failed.");
  }
  get backend() {
    if (this.pendingBackendInit != null) throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
    if (this.backendInstance == null) {
      let { name: t67, asyncInit: e36 } = this.initializeBackendsAndReturnBest();
      if (e36) throw new Error(`The highest priority backend '${t67}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);
      this.setBackend(t67);
    }
    return this.backendInstance;
  }
  backendNames() {
    return Object.keys(this.registryFactory);
  }
  findBackend(t67) {
    if (!(t67 in this.registry)) if (t67 in this.registryFactory) {
      let { asyncInit: e36 } = this.initializeBackend(t67);
      if (e36) return null;
    } else return null;
    return this.registry[t67];
  }
  findBackendFactory(t67) {
    return t67 in this.registryFactory ? this.registryFactory[t67].factory : null;
  }
  registerBackend(t67, e36, s84 = 1) {
    return t67 in this.registryFactory ? (t2(`${t67} backend was already registered. Reusing existing backend factory.`), false) : (this.registryFactory[t67] = { factory: e36, priority: s84 }, true);
  }
  async setBackend(t67) {
    if (this.registryFactory[t67] == null) throw new Error(`Backend name '${t67}' not found in registry`);
    if (this.backendName = t67, this.registry[t67] == null) {
      this.backendInstance = null;
      let { success: e36, asyncInit: s84 } = this.initializeBackend(t67);
      if (!(s84 ? await e36 : e36)) return false;
    }
    return this.backendInstance = this.registry[t67], this.setupRegisteredKernels(), this.profiler = new k5(this.backendInstance), true;
  }
  setupRegisteredKernels() {
    k3(this.backendName).forEach((e36) => {
      e36.setupFunc != null && e36.setupFunc(this.backendInstance);
    });
  }
  disposeRegisteredKernels(t67) {
    k3(t67).forEach((s84) => {
      s84.disposeFunc != null && s84.disposeFunc(this.registry[t67]);
    });
  }
  initializeBackend(t67) {
    let e36 = this.registryFactory[t67];
    if (e36 == null) throw new Error(`Cannot initialize backend ${t67}, no registration found.`);
    try {
      let s84 = e36.factory();
      if (s84 && !(s84 instanceof o) && typeof s84.then == "function") {
        let n67 = ++this.pendingBackendInitId, r56 = s84.then((i88) => n67 < this.pendingBackendInitId ? false : (this.registry[t67] = i88, this.pendingBackendInit = null, true)).catch((i88) => (n67 < this.pendingBackendInitId || (this.pendingBackendInit = null, t2(`Initialization of backend ${t67} failed`), t2(i88.stack || i88.message)), false));
        return this.pendingBackendInit = r56, { success: r56, asyncInit: true };
      } else return this.registry[t67] = s84, { success: true, asyncInit: false };
    } catch (s84) {
      return t2(`Initialization of backend ${t67} failed`), t2(s84.stack || s84.message), { success: false, asyncInit: false };
    }
  }
  removeBackend(t67) {
    if (!(t67 in this.registryFactory)) throw new Error(`${t67} backend not found in registry`);
    this.backendName === t67 && this.pendingBackendInit != null && this.pendingBackendInitId++, t67 in this.registry && (this.disposeRegisteredKernels(t67), this.registry[t67].dispose(), delete this.registry[t67]), delete this.registryFactory[t67], this.backendName === t67 && (this.pendingBackendInit = null, this.backendName = null, this.backendInstance = null);
  }
  getSortedBackends() {
    if (Object.keys(this.registryFactory).length === 0) throw new Error("No backend found in registry.");
    return Object.keys(this.registryFactory).sort((t67, e36) => this.registryFactory[e36].priority - this.registryFactory[t67].priority);
  }
  initializeBackendsAndReturnBest() {
    let t67 = this.getSortedBackends();
    for (let e36 = 0; e36 < t67.length; e36++) {
      let s84 = t67[e36], { success: n67, asyncInit: r56 } = this.initializeBackend(s84);
      if (r56 || n67) return { name: s84, asyncInit: r56 };
    }
    throw new Error("Could not initialize any backends, all backend initializations failed.");
  }
  moveData(t67, e36) {
    let s84 = this.state.tensorInfo.get(e36), n67 = s84.backend, r56 = this.readSync(e36), i88 = n67.refCount(e36);
    n67.disposeData(e36, true), s84.backend = t67, t67.move(e36, r56, s84.shape, s84.dtype, i88), this.shouldCheckForMemLeaks() && this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
  }
  tidy(t67, e36) {
    let s84 = null;
    if (e36 == null) {
      if (typeof t67 != "function") throw new Error("Please provide a function to tidy()");
      e36 = t67;
    } else {
      if (typeof t67 != "string" && !(t67 instanceof String)) throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
      if (typeof e36 != "function") throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
      s84 = t67;
    }
    let n67;
    return this.scopedRun(() => this.startScope(s84), () => this.endScope(n67), () => (n67 = e36(), n67 instanceof Promise && console.error("Cannot return a Promise inside of tidy."), n67));
  }
  scopedRun(t67, e36, s84) {
    t67();
    try {
      let n67 = s84();
      return e36(), n67;
    } catch (n67) {
      throw e36(), n67;
    }
  }
  nextTensorId() {
    return l8.nextTensorId++;
  }
  nextVariableId() {
    return l8.nextVariableId++;
  }
  clone(t67) {
    let e36 = v3.runKernel(mo, { x: t67 }), s84 = { x: t67 }, n67 = (i88) => ({ x: () => {
      let o80 = "float32", a71 = { x: i88 }, c103 = { dtype: o80 };
      return v3.runKernel(C2, a71, c103);
    } }), r56 = [];
    return this.addTapeNode(this.state.activeScope.name, s84, [e36], n67, r56, {}), e36;
  }
  runKernel(t67, e36, s84) {
    if (this.backendName == null && this.backend, !(w3(t67, this.backendName) != null)) throw new Error(`Kernel '${t67}' not registered for backend '${this.backendName}'`);
    return this.runKernelFunc({ kernelName: t67, inputs: e36, attrs: s84 });
  }
  shouldCheckForMemLeaks() {
    return this.ENV.getBool("IS_TEST");
  }
  checkKernelForMemLeak(t67, e36, s84) {
    let n67 = this.backend.numDataIds(), r56 = 0;
    s84.forEach((a71) => {
      r56 += a71.dtype === "complex64" ? 3 : 1;
    });
    let i88 = this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1], o80 = n67 - e36 - r56 - i88;
    if (o80 > 0) throw new Error(`Backend '${this.backendName}' has an internal memory leak (${o80} data ids) after running '${t67}'`);
  }
  runKernelFunc(t67) {
    let e36, s84 = [], n67 = this.isTapeOn(), r56 = this.state.numBytes, i88 = this.state.numTensors;
    this.shouldCheckForMemLeaks() && this.state.numDataMovesStack.push(0);
    let o80;
    this.backendName == null && this.backend;
    let a71, c103 = S4(t67) ? t67.kernelName : this.state.activeScope != null ? this.state.activeScope.name : "";
    if (S4(t67)) {
      let { kernelName: d55, inputs: w45, attrs: b58 } = t67;
      this.backendName == null && this.backend;
      let g72 = w3(d55, this.backendName);
      c(g72 != null, () => `Cannot find registered kernel '${d55}' for backend '${this.backendName}'`), o80 = () => {
        let A35 = this.backend.numDataIds();
        a71 = g72.kernelFunc({ inputs: w45, attrs: b58, backend: this.backend });
        let F32 = Array.isArray(a71) ? a71 : [a71];
        this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(d55, A35, F32);
        let E44 = F32.map((T40) => T40.rank != null ? T40 : this.makeTensorFromTensorInfo(T40));
        if (n67) {
          let T40 = this.getTensorsForGradient(d55, w45, E44);
          s84 = this.saveTensorsForBackwardMode(T40);
        }
        return E44;
      };
    } else {
      let { forwardFunc: d55 } = t67, w45 = (b58) => {
        n67 && (s84 = b58.map((g72) => this.keep(this.clone(g72))));
      };
      o80 = () => {
        let b58 = this.backend.numDataIds();
        a71 = this.tidy(() => d55(this.backend, w45));
        let g72 = Array.isArray(a71) ? a71 : [a71];
        return this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(c103, b58, g72), g72;
      };
    }
    let { inputs: u86, attrs: k63 } = t67, f85 = S4(t67) ? null : t67.backwardsFunc, p103;
    return this.scopedRun(() => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {
      !this.ENV.getBool("DEBUG") && !this.state.profiling ? e36 = o80() : (p103 = this.profiler.profileKernel(c103, u86, () => o80()), this.ENV.getBool("DEBUG") && this.profiler.logKernelProfile(p103), e36 = p103.outputs);
    }), n67 && this.addTapeNode(c103, u86, e36, f85, s84, k63), this.state.profiling && this.state.activeProfile.kernels.push({ name: c103, bytesAdded: this.state.numBytes - r56, totalBytesSnapshot: this.state.numBytes, tensorsAdded: this.state.numTensors - i88, totalTensorsSnapshot: this.state.numTensors, inputShapes: Object.keys(u86).map((d55) => u86[d55] != null ? u86[d55].shape : null), outputShapes: e36.map((d55) => d55.shape), kernelTimeMs: p103.timeMs, extraInfo: p103.extraInfo }), Array.isArray(a71) ? e36 : e36[0];
  }
  saveTensorsForBackwardMode(t67) {
    return t67.map((s84) => this.keep(this.clone(s84)));
  }
  getTensorsForGradient(t67, e36, s84) {
    let n67 = x3(t67);
    if (n67 != null) {
      let r56 = n67.inputsToSave || [], i88 = n67.outputsToSave || [], o80;
      n67.saveAllInputs ? (c(Array.isArray(e36), () => "saveAllInputs is true, expected inputs to be an array."), o80 = Object.keys(e36).map((c103) => e36[c103])) : o80 = r56.map((c103) => e36[c103]);
      let a71 = s84.filter((c103, u86) => i88[u86]);
      return o80.concat(a71);
    }
    return [];
  }
  makeTensor(t67, e36, s84, n67) {
    if (t67 == null) throw new Error("Values passed to engine.makeTensor() are null");
    s84 = s84 || "float32", n67 = n67 || this.backend;
    let r56 = t67;
    s84 === "string" && y(t67[0]) && (r56 = t67.map((a71) => m4(a71)));
    let i88 = n67.write(r56, e36, s84), o80 = new o5(e36, s84, i88, this.nextTensorId());
    if (this.trackTensor(o80, n67), s84 === "string") {
      let a71 = this.state.tensorInfo.get(i88), c103 = Q(r56);
      this.state.numBytes += c103 - a71.bytes, a71.bytes = c103;
    }
    return o80;
  }
  makeTensorFromDataId(t67, e36, s84, n67) {
    s84 = s84 || "float32";
    let r56 = { dataId: t67, shape: e36, dtype: s84 };
    return this.makeTensorFromTensorInfo(r56, n67);
  }
  makeTensorFromTensorInfo(t67, e36) {
    let { dataId: s84, shape: n67, dtype: r56 } = t67, i88 = new o5(n67, r56, s84, this.nextTensorId());
    return this.trackTensor(i88, e36), i88;
  }
  makeVariable(t67, e36 = true, s84, n67) {
    s84 = s84 || this.nextVariableId().toString(), n67 != null && n67 !== t67.dtype && (t67 = t67.cast(n67));
    let r56 = new d3(t67, e36, s84, this.nextTensorId());
    if (this.state.registeredVariables[r56.name] != null) throw new Error(`Variable with name ${r56.name} was already registered`);
    return this.state.registeredVariables[r56.name] = r56, this.incRef(r56, this.backend), r56;
  }
  trackTensor(t67, e36) {
    this.state.numTensors++, t67.dtype === "string" && this.state.numStringTensors++;
    let s84 = 0;
    t67.dtype !== "complex64" && t67.dtype !== "string" && (s84 = t67.size * K(t67.dtype)), this.state.numBytes += s84, this.state.tensorInfo.has(t67.dataId) || (this.state.numDataBuffers++, this.state.tensorInfo.set(t67.dataId, { backend: e36 || this.backend, dtype: t67.dtype, shape: t67.shape, bytes: s84 })), t67 instanceof d3 || this.track(t67);
  }
  incRef(t67, e36) {
    this.trackTensor(t67, e36), this.backend.incRef(t67.dataId);
  }
  removeDataId(t67, e36) {
    this.state.tensorInfo.has(t67) && this.state.tensorInfo.get(t67).backend === e36 && (this.state.tensorInfo.delete(t67), this.state.numDataBuffers--);
  }
  disposeTensor(t67) {
    if (!this.state.tensorInfo.has(t67.dataId)) return;
    let e36 = this.state.tensorInfo.get(t67.dataId);
    if (this.state.numTensors--, t67.dtype === "string" && (this.state.numStringTensors--, this.state.numBytes -= e36.bytes), t67.dtype !== "complex64" && t67.dtype !== "string") {
      let s84 = t67.size * K(t67.dtype);
      this.state.numBytes -= s84;
    }
    e36.backend.disposeData(t67.dataId) && this.removeDataId(t67.dataId, e36.backend);
  }
  disposeVariables() {
    for (let t67 in this.state.registeredVariables) {
      let e36 = this.state.registeredVariables[t67];
      this.disposeVariable(e36);
    }
  }
  disposeVariable(t67) {
    this.disposeTensor(t67), this.state.registeredVariables[t67.name] != null && delete this.state.registeredVariables[t67.name];
  }
  memory() {
    let t67 = this.backend.memory();
    return t67.numTensors = this.state.numTensors, t67.numDataBuffers = this.state.numDataBuffers, t67.numBytes = this.state.numBytes, this.state.numStringTensors > 0 && (t67.unreliable = true, t67.reasons == null && (t67.reasons = []), t67.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")), t67;
  }
  async profile(t67) {
    this.state.profiling = true;
    let e36 = this.state.numBytes, s84 = this.state.numTensors;
    this.state.activeProfile.kernels = [], this.state.activeProfile.result = await t67(), this.state.profiling = false, this.state.activeProfile.peakBytes = Math.max(...this.state.activeProfile.kernels.map((n67) => n67.totalBytesSnapshot)), this.state.activeProfile.newBytes = this.state.numBytes - e36, this.state.activeProfile.newTensors = this.state.numTensors - s84;
    for (let n67 of this.state.activeProfile.kernels) n67.kernelTimeMs = await n67.kernelTimeMs, n67.extraInfo = await n67.extraInfo;
    return this.state.activeProfile;
  }
  isTapeOn() {
    return this.state.gradientDepth > 0 && this.state.kernelDepth === 0;
  }
  addTapeNode(t67, e36, s84, n67, r56, i88) {
    let o80 = { id: this.state.nextTapeNodeId++, kernelName: t67, inputs: e36, outputs: s84, saved: r56 }, a71 = x3(t67);
    a71 != null && (n67 = a71.gradFunc), n67 != null && (o80.gradient = (c103) => (c103 = c103.map((u86, k63) => {
      if (u86 == null) {
        let f85 = s84[k63], p103 = S(f85.size, f85.dtype);
        return this.makeTensor(p103, f85.shape, f85.dtype);
      }
      return u86;
    }), n67(c103.length > 1 ? c103 : c103[0], r56, i88))), this.state.activeTape.push(o80);
  }
  keep(t67) {
    return t67.kept = true, t67;
  }
  startTape() {
    this.state.gradientDepth === 0 && (this.state.activeTape = []), this.state.gradientDepth++;
  }
  endTape() {
    this.state.gradientDepth--;
  }
  startScope(t67) {
    let e36 = { track: [], name: "unnamed scope", id: this.state.nextScopeId++ };
    t67 && (e36.name = t67), this.state.scopeStack.push(e36), this.state.activeScope = e36;
  }
  endScope(t67) {
    let e36 = l7(t67), s84 = new Set(e36.map((r56) => r56.id));
    for (let r56 = 0; r56 < this.state.activeScope.track.length; r56++) {
      let i88 = this.state.activeScope.track[r56];
      !i88.kept && !s84.has(i88.id) && i88.dispose();
    }
    let n67 = this.state.scopeStack.pop();
    this.state.activeScope = this.state.scopeStack.length === 0 ? null : this.state.scopeStack[this.state.scopeStack.length - 1], e36.forEach((r56) => {
      !r56.kept && r56.scopeId === n67.id && this.track(r56);
    });
  }
  gradients(t67, e36, s84, n67 = false) {
    if (c(e36.length > 0, () => "gradients() received an empty list of xs."), s84 != null && s84.dtype !== "float32") throw new Error(`dy must have 'float32' dtype, but has '${s84.dtype}'`);
    let r56 = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", t67));
    c(r56 instanceof o5, () => "The result y returned by f() must be a tensor.");
    let i88 = $4(this.state.activeTape, e36, r56);
    if (!n67 && i88.length === 0 && e36.length > 0) throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
    return this.tidy("backward", () => {
      let o80 = {};
      o80[r56.id] = s84 ?? Z4(r56.shape), b5(o80, i88, (c103) => this.tidy(c103), H4);
      let a71 = e36.map((c103) => o80[c103.id]);
      return this.state.gradientDepth === 0 && (this.state.activeTape.forEach((c103) => {
        for (let u86 of c103.saved) u86.dispose();
      }), this.state.activeTape = null), { value: r56, grads: a71 };
    });
  }
  customGrad(t67) {
    return c(R(t67), () => "The f passed in customGrad(f) must be a function."), (...e36) => {
      c(e36.every((o80) => o80 instanceof o5), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
      let s84, n67 = {};
      e36.forEach((o80, a71) => {
        n67[a71] = o80;
      });
      let r56 = (o80, a71) => (s84 = t67(...e36, a71), c(s84.value instanceof o5, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor"), c(R(s84.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function."), s84.value), i88 = (o80, a71) => {
        let c103 = s84.gradFunc(o80, a71), u86 = Array.isArray(c103) ? c103 : [c103];
        c(u86.length === e36.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...)."), c(u86.every((f85) => f85 instanceof o5), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
        let k63 = {};
        return u86.forEach((f85, p103) => {
          k63[p103] = () => f85;
        }), k63;
      };
      return this.runKernelFunc({ forwardFunc: r56, backwardsFunc: i88, inputs: n67 });
    };
  }
  readSync(t67) {
    return this.state.tensorInfo.get(t67).backend.readSync(t67);
  }
  read(t67) {
    return this.state.tensorInfo.get(t67).backend.read(t67);
  }
  readToGPU(t67, e36) {
    return this.state.tensorInfo.get(t67).backend.readToGPU(t67, e36);
  }
  async time(t67) {
    let e36 = y5(), s84 = await this.backend.time(t67);
    return s84.wallMs = y5() - e36, s84;
  }
  track(t67) {
    return this.state.activeScope != null && (t67.scopeId = this.state.activeScope.id, this.state.activeScope.track.push(t67)), t67;
  }
  get registeredVariables() {
    return this.state.registeredVariables;
  }
  reset() {
    this.pendingBackendInitId++, this.state.dispose(), this.ENV.reset(), this.state = new B4();
    for (let t67 in this.registry) this.disposeRegisteredKernels(t67), this.registry[t67].dispose(), delete this.registry[t67];
    this.backendName = null, this.backendInstance = null, this.pendingBackendInit = null;
  }
};
I5.nextTensorId = 0;
I5.nextVariableId = 0;
function Z4(l80) {
  let t67 = z(q(l80), "float32");
  return v3.makeTensor(t67, l80, "float32");
}
function q3() {
  let l80 = f2();
  if (l80._tfengine == null) {
    let t67 = new n2(l80);
    l80._tfengine = new I5(t67);
  }
  return y2(l80._tfengine.ENV), k6(() => l80._tfengine), l80._tfengine;
}
var v3 = q3();
function H4(l80, t67) {
  let e36 = { a: l80, b: t67 };
  return v3.runKernel(r, e36);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/flags.mjs
import __Process$2 from "node:process";

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/device_util.mjs
var device_util_exports = {};
__export(device_util_exports, {
  isBrowser: () => c7,
  isMobile: () => r4,
  mockIsMobile: () => n8
});
function a7() {
  return typeof navigator < "u" && navigator != null;
}
var o7;
function n8(e36) {
  o7 = e36;
}
function r4(e36) {
  if (o7 !== void 0) return o7;
  if (e36 || a7()) {
    if (e36 || (e36 = navigator), e36.product === "ReactNative") return true;
    let i88 = e36.userAgent || e36.vendor || (typeof globalThis < "u" ? globalThis.opera : "");
    if (!i88) {
      let t67 = e36;
      return t67.userAgentData && t67.userAgentData.mobile;
    }
    return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(i88) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(i88.substr(0, 4));
  }
  return false;
}
function c7() {
  return typeof globalThis < "u" && globalThis.document != null || typeof WorkerGlobalScope < "u";
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/flags.mjs
var e4 = l();
e4.registerFlag("DEBUG", () => false, (t67) => {
  t67 && console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
});
e4.registerFlag("IS_BROWSER", () => c7());
e4.registerFlag("IS_NODE", () => typeof __Process$2 < "u" && typeof __Process$2.versions < "u" && typeof __Process$2.versions.node < "u");
e4.registerFlag("IS_CHROME", () => typeof navigator < "u" && navigator != null && navigator.userAgent != null && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor));
e4.registerFlag("IS_SAFARI", () => typeof navigator < "u" && navigator != null && navigator.userAgent != null && /Safari/.test(navigator.userAgent) && /Apple/.test(navigator.vendor));
e4.registerFlag("PROD", () => false);
e4.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => e4.getBool("DEBUG"));
e4.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => true);
e4.registerFlag("IS_TEST", () => false);
e4.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => e4.getBool("DEBUG"));
e4.registerFlag("WRAP_TO_IMAGEBITMAP", () => false);
e4.registerFlag("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU", () => false);
e4.registerFlag("USE_SETTIMEOUTCUSTOM", () => false);

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/io_utils.mjs
import { Buffer as __Buffer$ } from "node:buffer";

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/tensor_util_env.mjs
function w7(r56, n67) {
  let t67 = r56;
  if (u2(r56)) return n67 === "string" ? [] : [r56.length];
  if (x7(r56)) {
    let e36 = r56.channels || "RGBA";
    return [r56.height, r56.width * e36.length];
  } else if (b6(r56)) return [r56.buffer.size / (n67 == null ? 4 : K(n67))];
  if (!Array.isArray(r56)) return [];
  let o80 = [];
  for (; Array.isArray(t67) || u2(t67) && n67 !== "string"; ) o80.push(t67.length), t67 = t67[0];
  return Array.isArray(r56) && l().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY") && l9(r56, o80, []), o80;
}
function l9(r56, n67, t67) {
  if (t67 = t67 || [], !Array.isArray(r56) && !u2(r56)) {
    c(n67.length === 0, () => `Element arr[${t67.join("][")}] is a primitive, but should be an array/TypedArray of ${n67[0]} elements`);
    return;
  }
  c(n67.length > 0, () => `Element arr[${t67.join("][")}] should be a primitive, but is an array of ${r56.length} elements`), c(r56.length === n67[0], () => `Element arr[${t67.join("][")}] should have ${n67[0]} elements, but has ${r56.length} elements`);
  let o80 = n67.slice(1);
  for (let e36 = 0; e36 < r56.length; ++e36) l9(r56[e36], o80, t67.concat(e36));
}
function m7(r56, n67, t67, o80) {
  if (r56 !== "string_or_numeric") {
    if (r56 == null) throw new Error("Expected dtype cannot be null.");
    if (r56 !== "numeric" && r56 !== n67 || r56 === "numeric" && n67 === "string") throw new Error(`Argument '${t67}' passed to '${o80}' must be ${r56} tensor, but got ${n67} tensor`);
  }
}
function S5(r56, n67, t67, o80 = "numeric") {
  if (r56 instanceof m5()) return m7(o80, r56.dtype, n67, t67), r56;
  let e36 = E(r56);
  if (e36 !== "string" && ["bool", "int32", "float32"].indexOf(o80) >= 0 && (e36 = o80), m7(o80, e36, n67, t67), r56 == null || !u2(r56) && !Array.isArray(r56) && typeof r56 != "number" && typeof r56 != "boolean" && typeof r56 != "string") {
    let y43 = r56 == null ? "null" : r56.constructor.name;
    throw new Error(`Argument '${n67}' passed to '${t67}' must be a Tensor or TensorLike, but got '${y43}'`);
  }
  let i88 = w7(r56, e36);
  !u2(r56) && !Array.isArray(r56) && (r56 = [r56]);
  let h74 = e36 !== "string" ? a6(r56, e36) : l5(r56, [], true);
  return v3.makeTensor(h74, i88, e36);
}
function j5(r56, n67, t67, o80 = "numeric") {
  if (!Array.isArray(r56)) throw new Error(`Argument ${n67} passed to ${t67} must be a \`Tensor[]\` or \`TensorLike[]\``);
  return r56.map((i88, f85) => S5(i88, `${n67}[${f85}]`, t67, o80));
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/operation.mjs
var p9 = "__op";
function u4(r56) {
  let o80 = Object.keys(r56);
  if (o80.length !== 1) throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${o80.length} keys.`);
  let e36 = o80[0], s84 = r56[e36];
  e36.endsWith("_") && (e36 = e36.substring(0, e36.length - 1)), e36 = e36 + p9;
  let i88 = (...c103) => {
    v3.startScope(e36);
    try {
      let t67 = s84(...c103);
      return er(t67) && console.error("Cannot return a Promise inside of tidy."), v3.endScope(t67), t67;
    } catch (t67) {
      throw v3.endScope(null), t67;
    }
  };
  return Object.defineProperty(i88, "name", { value: e36, configurable: true }), i88;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/complex.mjs
function c8(t67, a71) {
  let o80 = S5(t67, "real", "complex"), e36 = S5(a71, "imag", "complex");
  k(o80.shape, e36.shape, `real and imag shapes, ${o80.shape} and ${e36.shape}, must match in call to tf.complex().`);
  let p103 = { real: o80, imag: e36 };
  return v3.runKernel(P2, p103);
}
var x8 = u4({ complex_: c8 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tensor_ops_util.mjs
function G3(r56, o80, n67, t67) {
  if (t67 == null) t67 = E(r56);
  else if (t67 === "complex64") throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");
  if (b6(r56) || x7(r56)) {
    if (t67 !== "float32" && t67 !== "int32") throw new Error(`Creating tensor from GPU data only supports 'float32'|'int32' dtype, while the dtype is ${t67}.`);
    return v3.backend.createTensorFromGPUData(r56, o80 || n67, t67);
  }
  if (!u2(r56) && !Array.isArray(r56) && typeof r56 != "number" && typeof r56 != "boolean" && typeof r56 != "string") throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");
  if (o80 != null) {
    rr(o80);
    let s84 = q(o80), a71 = q(n67);
    c(s84 === a71, () => `Based on the provided shape, [${o80}], the tensor should have ${s84} values but has ${a71}`);
    for (let e36 = 0; e36 < n67.length; ++e36) {
      let l80 = n67[e36], b58 = e36 === n67.length - 1 ? l80 !== q(o80.slice(e36)) : true;
      c(n67[e36] === o80[e36] || !b58, () => `Error creating a new Tensor. Inferred shape (${n67}) does not match the provided shape (${o80}). `);
    }
  }
  return !u2(r56) && !Array.isArray(r56) && (r56 = [r56]), o80 = o80 || n67, r56 = t67 !== "string" ? a6(r56, t67) : l5(r56, [], true), v3.makeTensor(r56, o80, t67);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tensor.mjs
function p10(r56, e36, o80) {
  let n67 = w7(r56, o80);
  return G3(r56, e36, n67, o80);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/types.mjs
var o8 = { float32: 4, float16: 2, int32: 4, uint16: 2, uint8: 1, bool: 1, complex64: 8 };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/composite_array_buffer.mjs
var d4 = class s5 {
  static join(t67) {
    return new s5(t67).slice();
  }
  constructor(t67) {
    if (this.shards = [], this.previousShardIndex = 0, t67 == null || (t67 instanceof Array || (t67 = [t67]), t67 = t67.map((i88) => u2(i88) ? i88.buffer : i88), t67.length === 0)) return;
    this.bufferUniformSize = t67[0].byteLength;
    let r56 = 0;
    for (let i88 = 0; i88 < t67.length; i88++) {
      let n67 = t67[i88];
      i88 !== t67.length - 1 && n67.byteLength !== this.bufferUniformSize && (this.bufferUniformSize = void 0);
      let e36 = r56 + n67.byteLength;
      this.shards.push({ buffer: n67, start: r56, end: e36 }), r56 = e36;
    }
    this.shards.length === 0 && (this.byteLength = 0), this.byteLength = this.shards[this.shards.length - 1].end;
  }
  slice(t67 = 0, r56 = this.byteLength) {
    if (this.shards.length === 0) return new ArrayBuffer(0);
    if (t67 = isNaN(Number(t67)) ? 0 : t67, r56 = isNaN(Number(r56)) ? 0 : r56, t67 = Math.max(0, t67), r56 = Math.min(this.byteLength, r56), r56 <= t67) return new ArrayBuffer(0);
    let i88 = this.findShardForByte(t67);
    if (i88 === -1) throw new Error(`Could not find start shard for byte ${t67}`);
    let n67 = r56 - t67, e36 = new ArrayBuffer(n67), c103 = new Uint8Array(e36), o80 = 0;
    for (let a71 = i88; a71 < this.shards.length; a71++) {
      let h74 = this.shards[a71], l80 = t67 + o80 - h74.start, g72 = o80, S45 = Math.min(r56, h74.end) - h74.start, u86 = new Uint8Array(h74.buffer, l80, S45 - l80);
      if (c103.set(u86, g72), o80 += u86.length, r56 < h74.end) break;
    }
    return e36;
  }
  findShardForByte(t67) {
    if (this.shards.length === 0 || t67 < 0 || t67 >= this.byteLength) return -1;
    if (this.bufferUniformSize != null) return this.previousShardIndex = Math.floor(t67 / this.bufferUniformSize), this.previousShardIndex;
    function r56(n67) {
      return t67 < n67.start ? -1 : t67 >= n67.end ? 1 : 0;
    }
    if (r56(this.shards[this.previousShardIndex]) === 0) return this.previousShardIndex;
    let i88 = m8(this.shards, r56);
    return i88 === -1 ? -1 : (this.previousShardIndex = i88, this.previousShardIndex);
  }
};
function m8(s84, t67) {
  let r56 = 0, i88 = s84.length;
  for (; r56 <= i88; ) {
    let n67 = Math.floor((i88 - r56) / 2) + r56, e36 = t67(s84[n67]);
    if (e36 === 0) return n67;
    e36 < 0 ? i88 = n67 : r56 = n67 + 1;
  }
  return -1;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/globals.mjs
function f5() {
  l().set("PROD", true);
}
function x9() {
  l().set("DEBUG", true);
}
function m9() {
  l().set("DEPRECATION_WARNINGS_ENABLED", false), console.warn("TensorFlow.js deprecation warnings have been disabled.");
}
function c9(e36) {
  l().getBool("DEPRECATION_WARNINGS_ENABLED") && console.warn(e36 + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
}
D3(c9);
function l10() {
  v3.disposeVariables();
}
function k7() {
  return v3;
}
function B5() {
  return v3.memory();
}
function b7(e36) {
  return v3.profile(e36);
}
function g4(e36, r56) {
  return v3.tidy(e36, r56);
}
function E4(e36) {
  l7(e36).forEach((o80) => o80.dispose());
}
function N3(e36) {
  return v3.keep(e36);
}
function D4(e36) {
  return v3.time(e36);
}
function y6(e36) {
  return v3.setBackend(e36);
}
function w8() {
  return v3.ready();
}
function A5() {
  return v3.backendName;
}
function I6(e36) {
  v3.removeBackend(e36);
}
function P3(e36) {
  return v3.findBackend(e36);
}
function W3(e36) {
  return v3.findBackendFactory(e36);
}
function R3(e36, r56, o80 = 1) {
  return v3.registerBackend(e36, r56, o80);
}
function v4() {
  return v3.backend;
}
function F3(e36, r56) {
  l().setPlatform(e36, r56);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/io_utils.mjs
var p11 = 4;
async function Z5(e36, n67) {
  let r56 = [], t67 = [], o80 = Array.isArray(e36) ? e36.map((a71) => a71.name) : Object.keys(e36);
  for (let a71 = 0; a71 < o80.length; ++a71) {
    let l80 = o80[a71], i88 = Array.isArray(e36) ? e36[a71].tensor : e36[l80];
    if (i88.dtype !== "float32" && i88.dtype !== "int32" && i88.dtype !== "bool" && i88.dtype !== "string" && i88.dtype !== "complex64") throw new Error(`Unsupported dtype in weight '${l80}': ${i88.dtype}`);
    let y43 = { name: l80, shape: i88.shape, dtype: i88.dtype };
    if (i88.dtype === "string") {
      let f85 = new Promise(async (u86) => {
        let c103 = await i88.bytes(), A35 = c103.reduce((h74, w45) => h74 + w45.length, 0) + p11 * c103.length, g72 = new Uint8Array(A35), b58 = 0;
        for (let h74 = 0; h74 < c103.length; h74++) {
          let w45 = c103[h74], x76 = new Uint8Array(new Uint32Array([w45.length]).buffer);
          g72.set(x76, b58), b58 += p11, g72.set(w45, b58), b58 += w45.length;
        }
        u86(g72);
      });
      t67.push(f85);
    } else t67.push(i88.data());
    n67 != null && (y43.group = n67), r56.push(y43);
  }
  let s84 = await Promise.all(t67);
  return { data: q4(s84), specs: r56 };
}
function N4(e36, n67) {
  let r56 = new d4(e36), t67 = {}, o80 = 0;
  for (let s84 of n67) {
    let a71 = $5(s84, (l80, i88) => r56.slice(o80 + l80, o80 + i88));
    t67[s84.name] = S6(s84, r56.slice(o80, o80 + a71)), o80 += a71;
  }
  return t67;
}
function $5(e36, n67) {
  let r56 = q(e36.shape), t67;
  if ("quantization" in e36) {
    let o80 = e36.quantization;
    t67 = o8[o80.dtype];
  } else if (e36.dtype === "string") {
    let o80 = 0;
    for (let s84 = 0; s84 < r56; s84++) o80 += p11 + new Uint32Array(n67(o80, o80 + p11))[0];
    return o80;
  } else t67 = o8[e36.dtype];
  return r56 * t67;
}
async function v5(e36, n67) {
  let r56 = q(e36.shape), t67;
  if ("quantization" in e36) {
    let o80 = e36.quantization;
    t67 = o8[o80.dtype];
  } else if (e36.dtype === "string") {
    let o80 = 0;
    for (let s84 = 0; s84 < r56; s84++) o80 += p11 + new Uint32Array(await n67(o80, o80 + p11))[0];
    return o80;
  } else t67 = o8[e36.dtype];
  return r56 * t67;
}
function S6(e36, n67) {
  let r56 = e36.name, t67 = e36.dtype, o80 = e36.shape, s84 = q(o80), a71, l80 = 0;
  if ("quantization" in e36) {
    let i88 = e36.quantization;
    if (i88.dtype === "uint8" || i88.dtype === "uint16") {
      if (!("min" in i88 && "scale" in i88)) throw new Error(`Weight ${e36.name} with quantization ${i88.dtype} doesn't have corresponding metadata min and scale.`);
    } else if (i88.dtype === "float16") {
      if (t67 !== "float32") throw new Error(`Weight ${e36.name} is quantized with ${i88.dtype} which only supports weights of type float32 not ${t67}.`);
    } else throw new Error(`Weight ${e36.name} has unknown quantization dtype ${i88.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);
    let y43 = o8[i88.dtype], f85 = i88.dtype === "uint8" ? new Uint8Array(n67) : new Uint16Array(n67);
    if (t67 === "float32") if (i88.dtype === "uint8" || i88.dtype === "uint16") {
      a71 = new Float32Array(f85.length);
      for (let u86 = 0; u86 < f85.length; u86++) {
        let c103 = f85[u86];
        a71[u86] = c103 * i88.scale + i88.min;
      }
    } else if (i88.dtype === "float16") a71 = _3()(f85);
    else throw new Error(`Unsupported quantization type ${i88.dtype} for weight type float32.`);
    else if (t67 === "int32") {
      if (i88.dtype !== "uint8" && i88.dtype !== "uint16") throw new Error(`Unsupported quantization type ${i88.dtype} for weight type int32.`);
      a71 = new Int32Array(f85.length);
      for (let u86 = 0; u86 < f85.length; u86++) {
        let c103 = f85[u86];
        a71[u86] = Math.round(c103 * i88.scale + i88.min);
      }
    } else throw new Error(`Unsupported dtype in weight '${r56}': ${t67}`);
    l80 += s84 * y43;
  } else if (t67 === "string") {
    let i88 = q(e36.shape);
    a71 = [];
    for (let y43 = 0; y43 < i88; y43++) {
      let f85 = new Uint32Array(n67.slice(l80, l80 + p11))[0];
      l80 += p11;
      let u86 = new Uint8Array(n67.slice(l80, l80 + f85));
      a71.push(u86), l80 += f85;
    }
  } else {
    let i88 = o8[t67];
    if (t67 === "float32") a71 = new Float32Array(n67);
    else if (t67 === "int32") a71 = new Int32Array(n67);
    else if (t67 === "bool") a71 = new Uint8Array(n67);
    else if (t67 === "complex64") {
      a71 = new Float32Array(n67);
      let y43 = new Float32Array(a71.length / 2), f85 = new Float32Array(a71.length / 2);
      for (let g72 = 0; g72 < y43.length; g72++) y43[g72] = a71[g72 * 2], f85[g72] = a71[g72 * 2 + 1];
      let u86 = p10(y43, o80, "float32"), c103 = p10(f85, o80, "float32"), A35 = x8(u86, c103);
      return u86.dispose(), c103.dispose(), A35;
    } else throw new Error(`Unsupported dtype in weight '${r56}': ${t67}`);
    l80 += s84 * i88;
  }
  return p10(a71, o80, t67);
}
async function B6(e36, n67, r56) {
  let t67 = new Uint8Array(n67);
  for (; t67.byteLength < r56; ) {
    let { done: o80, value: s84 } = await e36.read();
    if (o80 && s84 == null) {
      let l80 = r56 - t67.byteLength;
      throw new Error(`Reader is done but ${l80} bytes are still expected`);
    }
    let a71 = new Uint8Array(t67.length + s84.byteLength);
    a71.set(t67, 0), a71.set(new Uint8Array(s84), t67.length), t67 = a71;
  }
  return t67.buffer;
}
async function X4(e36, n67) {
  let r56 = {}, t67 = e36.getReader(), o80 = new ArrayBuffer(0);
  for (let s84 of n67) {
    let a71 = await v5(s84, async (y43, f85) => (o80 = await B6(t67, o80, f85), o80.slice(y43, f85)));
    o80 = await B6(t67, o80, a71);
    let l80 = o80.slice(0, a71);
    o80 = o80.slice(a71);
    let i88 = S6(s84, l80);
    if (r56[s84.name] = i88, A5() === "webgpu") {
      let y43 = v4();
      "uploadToGPU" in y43 && q(i88.shape) >= l().get("WEBGPU_CPU_HANDOFF_SIZE_THRESHOLD") && y43.uploadToGPU(i88.dataId);
    }
  }
  return r56;
}
function q4(e36) {
  if (e36 === null) throw new Error(`Invalid input value: ${JSON.stringify(e36)}`);
  let n67 = 0, r56 = [];
  e36.forEach((s84) => {
    if (n67 += s84.byteLength, r56.push(s84.byteLength === s84.buffer.byteLength ? s84 : new s84.constructor(s84)), !(s84 instanceof Float32Array || s84 instanceof Int32Array || s84 instanceof Uint8Array)) throw new Error(`Unsupported TypedArray subtype: ${s84.constructor.name}`);
  });
  let t67 = new Uint8Array(n67), o80 = 0;
  return r56.forEach((s84) => {
    t67.set(new Uint8Array(s84.buffer), o80), o80 += s84.byteLength;
  }), t67.buffer;
}
var U4 = typeof __Buffer$ < "u" && (typeof Blob > "u" || typeof atob > "u" || typeof btoa > "u");
function E5(e36) {
  return U4 ? __Buffer$.byteLength(e36, "utf8") : new Blob([e36]).size;
}
function K5(e36) {
  if (U4) return __Buffer$.from(e36).toString("base64");
  let n67 = new Uint8Array(e36), r56 = "";
  for (let t67 = 0, o80 = n67.length; t67 < o80; t67++) r56 += String.fromCharCode(n67[t67]);
  return btoa(r56);
}
function Q4(e36) {
  if (U4) {
    let t67 = __Buffer$.from(e36, "base64");
    return t67.buffer.slice(t67.byteOffset, t67.byteOffset + t67.byteLength);
  }
  let n67 = atob(e36), r56 = new Uint8Array(n67.length);
  for (let t67 = 0; t67 < n67.length; ++t67) r56.set([n67.charCodeAt(t67)], t67);
  return r56.buffer;
}
function J4(e36) {
  return d4.join(e36);
}
function ee2(e36) {
  let n67 = "/";
  for (e36 = e36.trim(); e36.endsWith(n67); ) e36 = e36.slice(0, e36.length - 1);
  let r56 = e36.split(n67);
  return r56[r56.length - 1];
}
function te2(e36, n67) {
  let r56 = { modelTopology: e36.modelTopology, format: e36.format, generatedBy: e36.generatedBy, convertedBy: e36.convertedBy, weightsManifest: n67 };
  return e36.signature != null && (r56.signature = e36.signature), e36.userDefinedMetadata != null && (r56.userDefinedMetadata = e36.userDefinedMetadata), e36.modelInitializer != null && (r56.modelInitializer = e36.modelInitializer), e36.initializerSignature != null && (r56.initializerSignature = e36.initializerSignature), e36.trainingConfig != null && (r56.trainingConfig = e36.trainingConfig), r56;
}
function I7(e36, n67, r56) {
  let t67 = { modelTopology: e36.modelTopology, format: e36.format, generatedBy: e36.generatedBy, convertedBy: e36.convertedBy };
  if (e36.trainingConfig != null && (t67.trainingConfig = e36.trainingConfig), e36.weightsManifest != null) {
    if (!n67) throw new Error("modelJSON has weightsManifest but weightSpecs is null");
    if (!r56) throw new Error("modelJSON has weightsManifest but weightData is null");
    t67.weightSpecs = n67, t67.weightData = r56;
  }
  return e36.signature != null && (t67.signature = e36.signature), e36.userDefinedMetadata != null && (t67.userDefinedMetadata = e36.userDefinedMetadata), e36.modelInitializer != null && (t67.modelInitializer = e36.modelInitializer), e36.initializerSignature != null && (t67.initializerSignature = e36.initializerSignature), t67;
}
async function ne2(e36, n67) {
  let r56, t67;
  return e36.weightsManifest != null && ([r56, t67] = await n67(e36.weightsManifest)), I7(e36, r56, t67);
}
function re2(e36) {
  if (e36.modelTopology instanceof ArrayBuffer) throw new Error("Expected JSON model topology, received ArrayBuffer.");
  return { dateSaved: /* @__PURE__ */ new Date(), modelTopologyType: "JSON", modelTopologyBytes: e36.modelTopology == null ? 0 : E5(JSON.stringify(e36.modelTopology)), weightSpecsBytes: e36.weightSpecs == null ? 0 : E5(JSON.stringify(e36.weightSpecs)), weightDataBytes: e36.weightData == null ? 0 : new d4(e36.weightData).byteLength };
}
function oe2(e36) {
  let n67 = [];
  for (let r56 of e36) n67.push(...r56.weights);
  return n67;
}
function P4() {
  let e36 = (r56) => {
    let t67 = r56 << 13, o80 = 0;
    for (; !(t67 & 8388608); ) o80 -= 8388608, t67 <<= 1;
    return t67 &= -8388609, o80 += 947912704, t67 | o80;
  }, n67 = new Uint32Array(2048);
  n67[0] = 0;
  for (let r56 = 1; r56 < 1024; r56++) n67[r56] = e36(r56);
  for (let r56 = 1024; r56 < 2048; r56++) n67[r56] = 939524096 + (r56 - 1024 << 13);
  return n67;
}
function W4() {
  let e36 = new Uint32Array(64);
  e36[0] = 0, e36[31] = 1199570944, e36[32] = 2147483648, e36[63] = 3347054592;
  for (let n67 = 1; n67 < 31; n67++) e36[n67] = n67 << 23;
  for (let n67 = 33; n67 < 63; n67++) e36[n67] = 2147483648 + (n67 - 32 << 23);
  return e36;
}
function C4() {
  let e36 = new Uint32Array(64);
  for (let n67 = 0; n67 < 64; n67++) e36[n67] = 1024;
  return e36[0] = e36[32] = 0, e36;
}
function _3() {
  let e36 = P4(), n67 = W4(), r56 = C4();
  return (t67) => {
    let o80 = new ArrayBuffer(4 * t67.length), s84 = new Uint32Array(o80);
    for (let a71 = 0; a71 < t67.length; a71++) {
      let l80 = t67[a71], i88 = e36[r56[l80 >> 10] + (l80 & 1023)] + n67[l80 >> 10];
      s84[a71] = i88;
    }
    return new Float32Array(o80);
  };
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/router_registry.mjs
var s6 = class e5 {
  constructor() {
    this.saveRouters = [], this.loadRouters = [];
  }
  static getInstance() {
    return e5.instance == null && (e5.instance = new e5()), e5.instance;
  }
  static registerSaveRouter(t67) {
    e5.getInstance().saveRouters.push(t67);
  }
  static registerLoadRouter(t67) {
    e5.getInstance().loadRouters.push(t67);
  }
  static getSaveHandlers(t67) {
    return e5.getHandlers(t67, "save");
  }
  static getLoadHandlers(t67, r56) {
    return e5.getHandlers(t67, "load", r56);
  }
  static getHandlers(t67, r56, o80) {
    let a71 = [];
    return (r56 === "load" ? e5.getInstance().loadRouters : e5.getInstance().saveRouters).forEach((c103) => {
      let n67 = c103(t67, o80);
      n67 !== null && a71.push(n67);
    }), a71;
  }
};
var u5 = (e36) => s6.registerSaveRouter(e36);
var l11 = (e36) => s6.registerLoadRouter(e36);
var g5 = (e36) => s6.getSaveHandlers(e36);
var i5 = (e36, t67) => s6.getLoadHandlers(e36, t67);

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/indexed_db.mjs
var w9 = "tensorflowjs";
var R4 = 1;
var p12 = "models_store";
var m10 = "model_info_store";
function E6() {
  if (!l().getBool("IS_BROWSER")) throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
  let r56 = typeof globalThis > "u" ? self : globalThis, e36 = r56.indexedDB || r56.mozIndexedDB || r56.webkitIndexedDB || r56.msIndexedDB || r56.shimIndexedDB;
  if (e36 == null) throw new Error("The current browser does not appear to support IndexedDB.");
  return e36;
}
function x10(r56) {
  let e36 = r56.result;
  e36.createObjectStore(p12, { keyPath: "modelPath" }), e36.createObjectStore(m10, { keyPath: "modelPath" });
}
var f6 = class {
  constructor(e36) {
    if (this.indexedDB = E6(), e36 == null || !e36) throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
    this.modelPath = e36;
  }
  async save(e36) {
    if (e36.modelTopology instanceof ArrayBuffer) throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
    return this.databaseAction(this.modelPath, e36);
  }
  async load() {
    return this.databaseAction(this.modelPath);
  }
  databaseAction(e36, i88) {
    return new Promise((t67, o80) => {
      let n67 = this.indexedDB.open(w9, R4);
      n67.onupgradeneeded = () => x10(n67), n67.onsuccess = () => {
        let l80 = n67.result;
        if (i88 == null) {
          let d55 = l80.transaction(p12, "readonly"), s84 = d55.objectStore(p12).get(this.modelPath);
          s84.onsuccess = () => {
            if (s84.result == null) return l80.close(), o80(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));
            t67(s84.result.modelArtifacts);
          }, s84.onerror = (a71) => (l80.close(), o80(s84.error)), d55.oncomplete = () => l80.close();
        } else {
          i88.weightData = d4.join(i88.weightData);
          let d55 = re2(i88), c103 = l80.transaction(m10, "readwrite"), s84 = c103.objectStore(m10), a71;
          try {
            a71 = s84.put({ modelPath: this.modelPath, modelArtifactsInfo: d55 });
          } catch (S45) {
            return o80(S45);
          }
          let h74;
          a71.onsuccess = () => {
            h74 = l80.transaction(p12, "readwrite");
            let S45 = h74.objectStore(p12), u86;
            try {
              u86 = S45.put({ modelPath: this.modelPath, modelArtifacts: i88, modelArtifactsInfo: d55 });
            } catch (b58) {
              return o80(b58);
            }
            u86.onsuccess = () => t67({ modelArtifactsInfo: d55 }), u86.onerror = (b58) => {
              s84 = c103.objectStore(m10);
              let y43 = s84.delete(this.modelPath);
              y43.onsuccess = () => (l80.close(), o80(u86.error)), y43.onerror = (q25) => (l80.close(), o80(u86.error));
            };
          }, a71.onerror = (S45) => (l80.close(), o80(a71.error)), c103.oncomplete = () => {
            h74 == null ? l80.close() : h74.oncomplete = () => l80.close();
          };
        }
      }, n67.onerror = (l80) => o80(n67.error);
    });
  }
};
f6.URL_SCHEME = "indexeddb://";
var I8 = (r56) => l().getBool("IS_BROWSER") && !Array.isArray(r56) && r56.startsWith(f6.URL_SCHEME) ? _4(r56.slice(f6.URL_SCHEME.length)) : null;
s6.registerSaveRouter(I8);
s6.registerLoadRouter(I8);
function _4(r56) {
  return new f6(r56);
}
function M3(r56) {
  return r56.startsWith(f6.URL_SCHEME) ? r56.slice(f6.URL_SCHEME.length) : r56;
}
var D5 = class {
  constructor() {
    this.indexedDB = E6();
  }
  async listModels() {
    return new Promise((e36, i88) => {
      let t67 = this.indexedDB.open(w9, R4);
      t67.onupgradeneeded = () => x10(t67), t67.onsuccess = () => {
        let o80 = t67.result, n67 = o80.transaction(m10, "readonly"), d55 = n67.objectStore(m10).getAll();
        d55.onsuccess = () => {
          let c103 = {};
          for (let s84 of d55.result) c103[s84.modelPath] = s84.modelArtifactsInfo;
          e36(c103);
        }, d55.onerror = (c103) => (o80.close(), i88(d55.error)), n67.oncomplete = () => o80.close();
      }, t67.onerror = (o80) => i88(t67.error);
    });
  }
  async removeModel(e36) {
    return e36 = M3(e36), new Promise((i88, t67) => {
      let o80 = this.indexedDB.open(w9, R4);
      o80.onupgradeneeded = () => x10(o80), o80.onsuccess = () => {
        let n67 = o80.result, l80 = n67.transaction(m10, "readwrite"), d55 = l80.objectStore(m10), c103 = d55.get(e36), s84;
        c103.onsuccess = () => {
          if (c103.result == null) return n67.close(), t67(new Error(`Cannot find model with path '${e36}' in IndexedDB.`));
          {
            let a71 = d55.delete(e36), h74 = () => {
              s84 = n67.transaction(p12, "readwrite");
              let u86 = s84.objectStore(p12).delete(e36);
              u86.onsuccess = () => i88(c103.result.modelArtifactsInfo), u86.onerror = (b58) => t67(c103.error);
            };
            a71.onsuccess = h74, a71.onerror = (S45) => (h74(), n67.close(), t67(c103.error));
          }
        }, c103.onerror = (a71) => (n67.close(), t67(c103.error)), l80.oncomplete = () => {
          s84 == null ? n67.close() : s84.oncomplete = () => n67.close();
        };
      }, o80.onerror = (n67) => t67(o80.error);
    });
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/local_storage.mjs
var a8 = "/";
var d5 = "tensorflowjs_models";
var S7 = "info";
var O5 = "model_topology";
var _5 = "weight_specs";
var M4 = "weight_data";
var v6 = "model_metadata";
function y7(t67) {
  return { info: [d5, t67, S7].join(a8), topology: [d5, t67, O5].join(a8), weightSpecs: [d5, t67, _5].join(a8), weightData: [d5, t67, M4].join(a8), modelMetadata: [d5, t67, v6].join(a8) };
}
function m11(t67) {
  for (let e36 of Object.values(t67)) globalThis.localStorage.removeItem(e36);
}
function w10(t67) {
  let e36 = t67.split(a8);
  if (e36.length < 3) throw new Error(`Invalid key format: ${t67}`);
  return e36.slice(1, e36.length - 1).join(a8);
}
function R5(t67) {
  return t67.startsWith(l12.URL_SCHEME) ? t67.slice(l12.URL_SCHEME.length) : t67;
}
var l12 = class {
  constructor(e36) {
    if (!l().getBool("IS_BROWSER") || typeof globalThis > "u" || typeof globalThis.localStorage > "u") throw new Error("The current environment does not support local storage.");
    if (this.LS = globalThis.localStorage, e36 == null || !e36) throw new Error("For local storage, modelPath must not be null, undefined or empty.");
    this.modelPath = e36, this.keys = y7(this.modelPath);
  }
  async save(e36) {
    if (e36.modelTopology instanceof ArrayBuffer) throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
    {
      let o80 = JSON.stringify(e36.modelTopology), i88 = JSON.stringify(e36.weightSpecs), n67 = re2(e36), s84 = d4.join(e36.weightData);
      try {
        this.LS.setItem(this.keys.info, JSON.stringify(n67)), this.LS.setItem(this.keys.topology, o80), this.LS.setItem(this.keys.weightSpecs, i88), this.LS.setItem(this.keys.weightData, K5(s84));
        let g72 = { format: e36.format, generatedBy: e36.generatedBy, convertedBy: e36.convertedBy, signature: e36.signature != null ? e36.signature : void 0, userDefinedMetadata: e36.userDefinedMetadata != null ? e36.userDefinedMetadata : void 0, modelInitializer: e36.modelInitializer != null ? e36.modelInitializer : void 0, initializerSignature: e36.initializerSignature != null ? e36.initializerSignature : void 0, trainingConfig: e36.trainingConfig != null ? e36.trainingConfig : void 0 };
        return this.LS.setItem(this.keys.modelMetadata, JSON.stringify(g72)), { modelArtifactsInfo: n67 };
      } catch {
        throw m11(this.keys), new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${n67.modelTopologyBytes}, weightSpecsBytes=${n67.weightSpecsBytes}, weightDataBytes=${n67.weightDataBytes}.`);
      }
    }
  }
  async load() {
    let e36 = JSON.parse(this.LS.getItem(this.keys.info));
    if (e36 == null) throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);
    if (e36.modelTopologyType !== "JSON") throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
    let o80 = {}, i88 = JSON.parse(this.LS.getItem(this.keys.topology));
    if (i88 == null) throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);
    o80.modelTopology = i88;
    let n67 = JSON.parse(this.LS.getItem(this.keys.weightSpecs));
    if (n67 == null) throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);
    o80.weightSpecs = n67;
    let s84 = this.LS.getItem(this.keys.modelMetadata);
    if (s84 != null) {
      let r56 = JSON.parse(s84);
      o80.format = r56.format, o80.generatedBy = r56.generatedBy, o80.convertedBy = r56.convertedBy, r56.signature != null && (o80.signature = r56.signature), r56.userDefinedMetadata != null && (o80.userDefinedMetadata = r56.userDefinedMetadata), r56.modelInitializer != null && (o80.modelInitializer = r56.modelInitializer), r56.initializerSignature != null && (o80.initializerSignature = r56.initializerSignature), r56.trainingConfig != null && (o80.trainingConfig = r56.trainingConfig);
    }
    let g72 = this.LS.getItem(this.keys.weightData);
    if (g72 == null) throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);
    return o80.weightData = Q4(g72), o80;
  }
};
l12.URL_SCHEME = "localstorage://";
var p13 = (t67) => l().getBool("IS_BROWSER") && !Array.isArray(t67) && t67.startsWith(l12.URL_SCHEME) ? T6(t67.slice(l12.URL_SCHEME.length)) : null;
s6.registerSaveRouter(p13);
s6.registerLoadRouter(p13);
function T6(t67) {
  return new l12(t67);
}
var f7 = class {
  constructor() {
    c(l().getBool("IS_BROWSER"), () => "Current environment is not a web browser"), c(typeof globalThis > "u" || typeof globalThis.localStorage < "u", () => "Current browser does not appear to support localStorage"), this.LS = globalThis.localStorage;
  }
  async listModels() {
    let e36 = {}, o80 = d5 + a8, i88 = a8 + S7;
    for (let n67 = 0; n67 < this.LS.length; ++n67) {
      let s84 = this.LS.key(n67);
      if (s84.startsWith(o80) && s84.endsWith(i88)) {
        let g72 = w10(s84);
        e36[g72] = JSON.parse(this.LS.getItem(s84));
      }
    }
    return e36;
  }
  async removeModel(e36) {
    e36 = R5(e36);
    let o80 = y7(e36);
    if (this.LS.getItem(o80.info) == null) throw new Error(`Cannot find model at path '${e36}'`);
    let i88 = JSON.parse(this.LS.getItem(o80.info));
    return m11(o80), i88;
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/model_management.mjs
var r5 = "://";
var s7 = class e6 {
  constructor() {
    this.managers = {};
  }
  static getInstance() {
    return e6.instance == null && (e6.instance = new e6()), e6.instance;
  }
  static registerManager(n67, t67) {
    c(n67 != null, () => "scheme must not be undefined or null."), n67.endsWith(r5) && (n67 = n67.slice(0, n67.indexOf(r5))), c(n67.length > 0, () => "scheme must not be an empty string.");
    let a71 = e6.getInstance();
    c(a71.managers[n67] == null, () => `A model store manager is already registered for scheme '${n67}'.`), a71.managers[n67] = t67;
  }
  static getManager(n67) {
    let t67 = e6.getInstance().managers[n67];
    if (t67 == null) throw new Error(`Cannot find model manager for scheme '${n67}'`);
    return t67;
  }
  static getSchemes() {
    return Object.keys(e6.getInstance().managers);
  }
};
function l13(e36) {
  if (e36.indexOf(r5) === -1) throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${s7.getSchemes().join(",")}`);
  return { scheme: e36.split(r5)[0], path: e36.split(r5)[1] };
}
async function u6(e36, n67, t67 = false) {
  c(e36 !== n67, () => `Old path and new path are the same: '${e36}'`);
  let a71 = s6.getLoadHandlers(e36);
  c(a71.length > 0, () => `Copying failed because no load handler is found for source URL ${e36}.`), c(a71.length < 2, () => `Copying failed because more than one (${a71.length}) load handlers for source URL ${e36}.`);
  let i88 = a71[0], c103 = s6.getSaveHandlers(n67);
  c(c103.length > 0, () => `Copying failed because no save handler is found for destination URL ${n67}.`), c(c103.length < 2, () => `Copying failed because more than one (${a71.length}) save handlers for destination URL ${n67}.`);
  let h74 = c103[0], d55 = l13(e36).scheme, g72 = l13(e36).path, m96 = d55 === l13(e36).scheme, p103 = await i88.load();
  t67 && m96 && await s7.getManager(d55).removeModel(g72);
  let M30 = await h74.save(p103);
  return t67 && !m96 && await s7.getManager(d55).removeModel(g72), M30.modelArtifactsInfo;
}
async function w11() {
  let e36 = s7.getSchemes(), n67 = {};
  for (let t67 of e36) {
    let a71 = await s7.getManager(t67).listModels();
    for (let i88 in a71) {
      let c103 = t67 + r5 + i88;
      n67[c103] = a71[i88];
    }
  }
  return n67;
}
async function S8(e36) {
  let n67 = l13(e36);
  return s7.getManager(n67.scheme).removeModel(n67.path);
}
async function $6(e36, n67) {
  return u6(e36, n67, false);
}
async function I9(e36, n67) {
  return u6(e36, n67, true);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/platforms/platform_browser.mjs
var o9 = class {
  constructor() {
    this.messageName = "setTimeoutCustom", this.functionRefs = [], this.handledMessageCount = 0, this.hasEventListener = false;
  }
  fetch(e36, t67) {
    return fetch(e36, t67);
  }
  now() {
    return performance.now();
  }
  encode(e36, t67) {
    if (t67 !== "utf-8" && t67 !== "utf8") throw new Error(`Browser's encoder only supports utf-8, but got ${t67}`);
    return this.textEncoder == null && (this.textEncoder = new TextEncoder()), this.textEncoder.encode(e36);
  }
  decode(e36, t67) {
    return new TextDecoder(t67).decode(e36);
  }
  setTimeoutCustom(e36, t67) {
    if (typeof globalThis > "u" || !l().getBool("USE_SETTIMEOUTCUSTOM")) {
      setTimeout(e36, t67);
      return;
    }
    this.functionRefs.push(e36), setTimeout(() => {
      globalThis.postMessage({ name: this.messageName, index: this.functionRefs.length - 1 }, "*");
    }, t67), this.hasEventListener || (this.hasEventListener = true, globalThis.addEventListener("message", (r56) => {
      if (r56.source === globalThis && r56.data.name === this.messageName) {
        r56.stopPropagation();
        let a71 = this.functionRefs[r56.data.index];
        a71(), this.handledMessageCount++, this.handledMessageCount === this.functionRefs.length && (this.functionRefs = [], this.handledMessageCount = 0);
      }
    }, true));
  }
  isTypedArray(e36) {
    return n5(e36);
  }
};
if (l().get("IS_BROWSER")) {
  l().setPlatform("browser", new o9());
  try {
    s7.registerManager(l12.URL_SCHEME, new f7());
  } catch {
  }
  try {
    s7.registerManager(f6.URL_SCHEME, new D5());
  } catch {
  }
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/platforms/platform_node.mjs
import __Process$3 from "node:process";
import * as __1$ from "node:util";
var __0$ = (() => {
  const { Blob: s84, fetch: n67, File: i88, FormData: c103, Headers: p103, Request: b58, Response: a71, AbortController: f85 } = globalThis, u86 = Error, w45 = Error, l80 = (e36) => e36 > 300 && e36 < 304 || e36 > 306 && e36 < 309;
  n67.isRedirect = l80, n67.Promise = globalThis.Promise;
  var x76 = n67;
  async function F32(e36, o80) {
    const r56 = await Deno.open(e36), t67 = new a71(r56.readable);
    return new s84([await t67.blob()], { type: o80 });
  }
  function d55(e36, o80) {
    const r56 = Deno.readFileSync(e36);
    return new s84([r56], { type: o80 });
  }
  async function m96(e36, o80) {
    const r56 = await Deno.open(e36), t67 = new a71(r56.readable);
    return new i88([await t67.blob()], e36.split(/[\/\\]/).pop(), { type: o80 });
  }
  function y43(e36, o80) {
    const r56 = Deno.readFileSync(e36);
    return new i88([r56], e36.split(/[\/\\]/).pop(), { type: o80 });
  }
  return { AbortController: f85, AbortError: u86, Blob: s84, FetchError: w45, File: i88, FormData: c103, Headers: p103, Request: b58, Response: a71, blobFrom: F32, blobFromSync: d55, default: x76, fetch: n67, fileFrom: m96, fileFromSync: y43, isRedirect: l80 };
})();
var require2 = (n67) => {
  const e36 = (m96) => typeof m96.default < "u" ? m96.default : m96, c103 = (m96) => Object.assign({ __esModule: true }, m96);
  switch (n67) {
    case "npm:node-fetch":
      return e36(__0$);
    case "node:util":
      return e36(__1$);
    default:
      console.error('module "' + n67 + '" not found');
      return null;
  }
};
var s8 = ((r56) => typeof require2 < "u" ? require2 : typeof Proxy < "u" ? new Proxy(r56, { get: (t67, e36) => (typeof require2 < "u" ? require2 : t67)[e36] }) : r56)(function(r56) {
  if (typeof require2 < "u") return require2.apply(this, arguments);
  throw Error('Dynamic require of "' + r56 + '" is not supported');
});
var u7 = { importFetch: () => s8("npm:node-fetch") };
var i6;
var n9 = class {
  constructor() {
    this.util = s8("node:util"), this.textEncoder = new this.util.TextEncoder();
  }
  fetch(t67, e36) {
    return l().global.fetch != null ? l().global.fetch(t67, e36) : (i6 == null && (i6 = u7.importFetch()), i6(t67, e36));
  }
  now() {
    let t67 = __Process$3.hrtime();
    return t67[0] * 1e3 + t67[1] / 1e6;
  }
  encode(t67, e36) {
    if (e36 !== "utf-8" && e36 !== "utf8") throw new Error(`Node built-in encoder only supports utf-8, but got ${e36}`);
    return this.textEncoder.encode(t67);
  }
  decode(t67, e36) {
    return t67.length === 0 ? "" : new this.util.TextDecoder(e36).decode(t67);
  }
  isTypedArray(t67) {
    return this.util.types.isFloat32Array(t67) || this.util.types.isInt32Array(t67) || this.util.types.isUint8Array(t67) || this.util.types.isUint8ClampedArray(t67);
  }
};
l().get("IS_NODE") && !l().get("IS_BROWSER") && l().setPlatform("node", new n9());

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/buffer.mjs
function i7(o80, r56 = "float32", e36) {
  return r56 = r56 || "float32", rr(o80), new p8(o80, r56, e36);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/cast.mjs
function f8(n67, t67) {
  let r56 = S5(n67, "x", "cast");
  if (!H(t67)) throw new Error(`Failed to cast to unknown dtype ${t67}`);
  if (t67 === "string" && r56.dtype !== "string" || t67 !== "string" && r56.dtype === "string") throw new Error("Only strings can be casted to strings");
  let s84 = { x: r56 }, i88 = { dtype: t67 };
  return v3.runKernel(C2, s84, i88);
}
var w12 = u4({ cast_: f8 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/clone.mjs
function i8(o80) {
  let r56 = { x: S5(o80, "x", "clone", "string_or_numeric") };
  return v3.runKernel(mo, r56);
}
var x11 = u4({ clone_: i8 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/print.mjs
function t3(o80, n67 = false) {
  console.log(o80.toString(n67));
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/base_side_effects.mjs
q3();
var e7 = { buffer: i7, cast: w12, clone: x11, print: t3 };
T4(e7);

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/add.mjs
function f9(m96, d55) {
  let o80 = S5(m96, "a", "add"), r56 = S5(d55, "b", "add");
  [o80, r56] = m6(o80, r56);
  let e36 = { a: o80, b: r56 };
  return v3.runKernel(r, e36);
}
var T7 = u4({ add_: f9 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/floorDiv.mjs
function v7(i88, m96) {
  let o80 = S5(i88, "a", "floorDiv"), r56 = S5(m96, "b", "floorDiv");
  [o80, r56] = m6(o80, r56);
  let e36 = { a: o80, b: r56 };
  return v3.runKernel(io, e36);
}
var b8 = u4({ floorDiv_: v7 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/div.mjs
function c10(i88, e36) {
  let t67 = S5(i88, "a", "div"), o80 = S5(e36, "b", "div");
  if ([t67, o80] = m6(t67, o80), t67.dtype === "int32" && o80.dtype === "int32") return b8(t67, o80);
  let n67 = { a: t67, b: o80 }, m96 = {};
  return v3.runKernel(Q2, n67, m96);
}
var D6 = u4({ div_: c10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/mul.mjs
function f10(m96, e36) {
  let o80 = S5(m96, "a", "mul"), r56 = S5(e36, "b", "mul");
  [o80, r56] = m6(o80, r56);
  let n67 = { a: o80, b: r56 };
  return v3.runKernel(Qo, n67);
}
var y8 = u4({ mul_: f10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/abs.mjs
function i9(t67) {
  let o80 = S5(t67, "x", "abs");
  if (o80.dtype === "complex64") {
    let r56 = { x: o80 };
    return v3.runKernel(T2, r56);
  } else {
    let r56 = { x: o80 };
    return v3.runKernel(o3, r56);
  }
}
var b9 = u4({ abs_: i9 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/acos.mjs
function m12(o80) {
  let r56 = { x: S5(o80, "x", "acos") };
  return v3.runKernel(t, r56);
}
var u8 = u4({ acos_: m12 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/acosh.mjs
function m13(o80) {
  let r56 = { x: S5(o80, "x", "acosh") };
  return v3.runKernel(e2, r56);
}
var h7 = u4({ acosh_: m13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/add_n.mjs
function i10(s84) {
  c(Array.isArray(s84), () => "The argument passed to tf.addN() must be a list of tensors"), c(s84.length >= 1, () => `Must pass at least one tensor to tf.addN(), but got ${s84.length}`);
  let o80 = s84.map((t67, d55) => S5(t67, `tensors${d55}`, "addN")), e36 = o80[0];
  o80.forEach((t67) => {
    if (t67.dtype !== e36.dtype) throw new Error("All tensors passed to tf.addN() must have the same dtype");
  }), o80.forEach((t67) => {
    if (!w(t67.shape, e36.shape)) throw new Error("All tensors passed to tf.addN() must have the same shape");
  });
  let a71 = o80;
  return v3.runKernel(n4, a71);
}
var c11 = u4({ addN_: i10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/all.mjs
function c12(o80, r56 = null, t67 = false) {
  let l80 = { x: S5(o80, "x", "all", "bool") }, n67 = { axis: r56, keepDims: t67 };
  return v3.runKernel(s3, l80, n67);
}
var E7 = u4({ all_: c12 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/any.mjs
function f11(o80, n67 = null, r56 = false) {
  let t67 = { x: S5(o80, "x", "any", "bool") }, m96 = { axis: n67, keepDims: r56 };
  return v3.runKernel(p2, t67, m96);
}
var y9 = u4({ any_: f11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/arg_max.mjs
function s9(r56, o80 = 0) {
  let t67 = { x: S5(r56, "x", "argMax") }, n67 = { axis: o80 };
  return v3.runKernel(c3, t67, n67);
}
var u9 = u4({ argMax_: s9 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/arg_min.mjs
function c13(r56, o80 = 0) {
  let n67 = { x: S5(r56, "x", "argMin") }, t67 = { axis: o80 };
  return v3.runKernel(a4, n67, t67);
}
var u10 = u4({ argMin_: c13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/asin.mjs
function m14(o80) {
  let n67 = { x: S5(o80, "x", "asin") };
  return v3.runKernel(x2, n67);
}
var u11 = u4({ asin_: m14 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/asinh.mjs
function m15(o80) {
  let n67 = { x: S5(o80, "x", "asinh") };
  return v3.runKernel(i, n67);
}
var h8 = u4({ asinh_: m15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/atan.mjs
function p14(o80) {
  let t67 = { x: S5(o80, "x", "atan") };
  return v3.runKernel(l2, t67);
}
var x12 = u4({ atan_: p14 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/atan2.mjs
function c14(n67, a71) {
  let t67 = S5(n67, "a", "atan2"), o80 = S5(a71, "b", "atan2");
  [t67, o80] = m6(t67, o80);
  let m96 = { a: t67, b: o80 };
  return v3.runKernel(u, m96);
}
var E8 = u4({ atan2_: c14 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/atanh.mjs
function p15(o80) {
  let t67 = { x: S5(o80, "x", "atanh") };
  return v3.runKernel(d2, t67);
}
var x13 = u4({ atanh_: p15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/conv_util.mjs
function K6(t67, n67, e36, s84, l80 = "NHWC", i88) {
  let r56 = t67[3], o80 = [...n67, r56], c103 = J5(l80);
  return V3(t67, o80, e36, i88, s84, null, null, c103);
}
function Q5(t67, n67, e36, s84, l80, i88, r56 = "channelsLast") {
  let [o80, c103] = k8(n67), f85;
  if (r56 === "channelsLast") f85 = [o80, c103, t67[3], t67[3]];
  else if (r56 === "channelsFirst") f85 = [o80, c103, t67[1], t67[1]];
  else throw new Error(`Unknown dataFormat ${r56}`);
  return V3(t67, f85, e36, s84, l80, i88, false, r56);
}
function Y3(t67, n67, e36, s84, l80, i88, r56 = "NDHWC") {
  let [o80, c103, f85] = N5(n67), h74, u86;
  if (r56 === "NDHWC") u86 = "channelsLast", h74 = [o80, c103, f85, t67[4], t67[4]];
  else if (r56 === "NCDHW") u86 = "channelsFirst", h74 = [o80, c103, f85, t67[1], t67[1]];
  else throw new Error(`Unknown dataFormat ${r56}`);
  return j6(t67, h74, e36, s84, l80, false, u86, i88);
}
function V3(t67, n67, e36, s84, l80, i88, r56 = false, o80 = "channelsLast") {
  let [c103, f85, h74, u86] = [-1, -1, -1, -1];
  if (o80 === "channelsLast") [c103, f85, h74, u86] = t67;
  else if (o80 === "channelsFirst") [c103, u86, f85, h74] = t67;
  else throw new Error(`Unknown dataFormat ${o80}`);
  let [w45, g72, , p103] = n67, [D42, b58] = k8(e36), [E44, y43] = k8(s84), I44 = x14(w45, E44), C28 = x14(g72, y43), { padInfo: L22, outHeight: $37, outWidth: M30 } = q5(l80, f85, h74, D42, b58, I44, C28, i88, o80), a71 = r56 ? p103 * u86 : p103, A35;
  return o80 === "channelsFirst" ? A35 = [c103, a71, $37, M30] : o80 === "channelsLast" && (A35 = [c103, $37, M30, a71]), { batchSize: c103, dataFormat: o80, inHeight: f85, inWidth: h74, inChannels: u86, outHeight: $37, outWidth: M30, outChannels: a71, padInfo: L22, strideHeight: D42, strideWidth: b58, filterHeight: w45, filterWidth: g72, effectiveFilterHeight: I44, effectiveFilterWidth: C28, dilationHeight: E44, dilationWidth: y43, inShape: t67, outShape: A35, filterShape: n67 };
}
function j6(t67, n67, e36, s84, l80, i88 = false, r56 = "channelsLast", o80) {
  let [c103, f85, h74, u86, w45] = [-1, -1, -1, -1, -1];
  if (r56 === "channelsLast") [c103, f85, h74, u86, w45] = t67;
  else if (r56 === "channelsFirst") [c103, w45, f85, h74, u86] = t67;
  else throw new Error(`Unknown dataFormat ${r56}`);
  let [g72, p103, D42, , b58] = n67, [E44, y43, I44] = N5(e36), [C28, L22, $37] = N5(s84), M30 = x14(g72, C28), a71 = x14(p103, L22), A35 = x14(D42, $37), { padInfo: B30, outDepth: U24, outHeight: W15, outWidth: O21 } = G4(l80, f85, h74, u86, E44, y43, I44, M30, a71, A35, o80), T40 = i88 ? b58 * w45 : b58, H18;
  return r56 === "channelsFirst" ? H18 = [c103, T40, U24, W15, O21] : r56 === "channelsLast" && (H18 = [c103, U24, W15, O21, T40]), { batchSize: c103, dataFormat: r56, inDepth: f85, inHeight: h74, inWidth: u86, inChannels: w45, outDepth: U24, outHeight: W15, outWidth: O21, outChannels: T40, padInfo: B30, strideDepth: E44, strideHeight: y43, strideWidth: I44, filterDepth: g72, filterHeight: p103, filterWidth: D42, effectiveFilterDepth: M30, effectiveFilterHeight: a71, effectiveFilterWidth: A35, dilationDepth: C28, dilationHeight: L22, dilationWidth: $37, inShape: t67, outShape: H18, filterShape: n67 };
}
function F4(t67, n67, e36, s84, l80) {
  s84 == null && (s84 = P5(t67, n67, e36));
  let i88 = t67[0], r56 = t67[1], o80 = v8((i88 - n67 + 2 * s84) / e36 + 1, l80), c103 = v8((r56 - n67 + 2 * s84) / e36 + 1, l80);
  return [o80, c103];
}
function X5(t67, n67, e36, s84, l80, i88) {
  l80 == null && (l80 = P5(t67, n67[0], s84[0]));
  let r56 = [0, 0, 0, e36];
  for (let o80 = 0; o80 < 3; o80++) t67[o80] + 2 * l80 >= n67[o80] && (r56[o80] = v8((t67[o80] - n67[o80] + 2 * l80) / s84[o80] + 1, i88));
  return r56;
}
function P5(t67, n67, e36, s84 = 1) {
  let l80 = x14(n67, s84);
  return Math.floor((t67[0] * (e36 - 1) - e36 + l80) / 2);
}
function k8(t67) {
  return typeof t67 == "number" ? [t67, t67, t67] : t67.length === 2 ? [t67[0], t67[1], 1] : t67;
}
function N5(t67) {
  return typeof t67 == "number" ? [t67, t67, t67] : t67;
}
function x14(t67, n67) {
  return n67 <= 1 ? t67 : t67 + (t67 - 1) * (n67 - 1);
}
function q5(t67, n67, e36, s84, l80, i88, r56, o80, c103) {
  let f85, h74, u86;
  if (typeof t67 == "number") {
    f85 = { top: t67, bottom: t67, left: t67, right: t67, type: t67 === 0 ? "VALID" : "NUMBER" };
    let g72 = F4([n67, e36], i88, s84, t67, o80);
    h74 = g72[0], u86 = g72[1];
  } else if (t67 === "same") {
    h74 = Math.ceil(n67 / s84), u86 = Math.ceil(e36 / l80);
    let w45 = Math.max(0, (h74 - 1) * s84 + i88 - n67), g72 = Math.max(0, (u86 - 1) * l80 + r56 - e36), p103 = Math.floor(w45 / 2), D42 = w45 - p103, b58 = Math.floor(g72 / 2), E44 = g72 - b58;
    f85 = { top: p103, bottom: D42, left: b58, right: E44, type: "SAME" };
  } else if (t67 === "valid") f85 = { top: 0, bottom: 0, left: 0, right: 0, type: "VALID" }, h74 = Math.ceil((n67 - i88 + 1) / s84), u86 = Math.ceil((e36 - r56 + 1) / l80);
  else if (typeof t67 == "object") {
    let w45 = c103 === "channelsLast" ? t67[1][0] : t67[2][0], g72 = c103 === "channelsLast" ? t67[1][1] : t67[2][1], p103 = c103 === "channelsLast" ? t67[2][0] : t67[3][0], D42 = c103 === "channelsLast" ? t67[2][1] : t67[3][1];
    f85 = { top: w45, bottom: g72, left: p103, right: D42, type: w45 === 0 && g72 === 0 && p103 === 0 && D42 === 0 ? "VALID" : "EXPLICIT" }, h74 = v8((n67 - i88 + w45 + g72) / s84 + 1, o80), u86 = v8((e36 - r56 + p103 + D42) / l80 + 1, o80);
  } else throw Error(`Unknown padding parameter: ${t67}`);
  return { padInfo: f85, outHeight: h74, outWidth: u86 };
}
function G4(t67, n67, e36, s84, l80, i88, r56, o80, c103, f85, h74) {
  let u86, w45, g72, p103;
  if (t67 === "valid" && (t67 = 0), typeof t67 == "number") {
    u86 = { top: t67, bottom: t67, left: t67, right: t67, front: t67, back: t67, type: t67 === 0 ? "VALID" : "NUMBER" };
    let b58 = X5([n67, e36, s84, 1], [o80, c103, f85], 1, [l80, i88, r56], t67, h74);
    w45 = b58[0], g72 = b58[1], p103 = b58[2];
  } else if (t67 === "same") {
    w45 = Math.ceil(n67 / l80), g72 = Math.ceil(e36 / i88), p103 = Math.ceil(s84 / r56);
    let D42 = (w45 - 1) * l80 + o80 - n67, b58 = (g72 - 1) * i88 + c103 - e36, E44 = (p103 - 1) * r56 + f85 - s84, y43 = Math.floor(D42 / 2), I44 = D42 - y43, C28 = Math.floor(b58 / 2), L22 = b58 - C28, $37 = Math.floor(E44 / 2), M30 = E44 - $37;
    u86 = { top: C28, bottom: L22, left: $37, right: M30, front: y43, back: I44, type: "SAME" };
  } else throw Error(`Unknown padding parameter: ${t67}`);
  return { padInfo: u86, outDepth: w45, outHeight: g72, outWidth: p103 };
}
function v8(t67, n67) {
  if (!n67) return Math.trunc(t67);
  switch (n67) {
    case "round":
      return Math.round(t67);
    case "ceil":
      return Math.ceil(t67);
    case "floor":
      return Math.floor(t67);
    default:
      throw new Error(`Unknown roundingMode ${n67}`);
  }
}
function R6(t67) {
  let [n67, e36, s84] = k8(t67);
  return n67 === 1 && e36 === 1 && s84 === 1;
}
function Z6(t67, n67) {
  return R6(t67) || R6(n67);
}
function _6(t67) {
  return k8(t67).every((n67) => n67 > 0);
}
function J5(t67) {
  if (t67 === "NHWC") return "channelsLast";
  if (t67 === "NCHW") return "channelsFirst";
  throw new Error(`Unknown dataFormat ${t67}`);
}
function z5(t67, n67, e36) {
  if (e36 != null) {
    if (typeof n67 == "string") throw Error(`Error in ${t67}: pad must be an integer when using dimRoundingMode ${e36} but got pad ${n67}.`);
    if (typeof n67 == "number") c(p(n67), () => `Error in ${t67}: pad must be an integer when using dimRoundingMode ${e36} but got pad ${n67}.`);
    else if (typeof n67 == "object") n67.forEach((s84) => {
      s84.forEach((l80) => {
        c(p(l80), () => `Error in ${t67}: pad must be an integer when using dimRoundingMode ${e36} but got pad ${l80}.`);
      });
    });
    else throw Error(`Error in ${t67}: Unknown padding parameter: ${n67}`);
  }
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/reshape.mjs
function i11(r56, o80) {
  let t67 = { x: S5(r56, "x", "reshape", "string_or_numeric") }, e36 = { shape: o80 };
  return v3.runKernel(Rt, t67, e36);
}
var h9 = u4({ reshape_: i11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/avg_pool.mjs
function x15(u86, c103, a71, i88, n67) {
  let o80 = S5(u86, "x", "avgPool", "float32"), l80 = 1;
  c(Z6(a71, l80), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${a71} and dilations '${l80}'`);
  let t67 = o80, p103 = false;
  o80.rank === 3 && (p103 = true, t67 = h9(o80, [1, o80.shape[0], o80.shape[1], o80.shape[2]])), c(t67.rank === 4, () => `Error in avgPool: x must be rank 4 but got rank ${t67.rank}.`), z5("avgPool", i88, n67);
  let f85 = { x: t67 }, h74 = { filterSize: c103, strides: a71, pad: i88, dimRoundingMode: n67 }, r56 = v3.runKernel(S2, f85, h74);
  return r56 = w12(r56, o80.dtype), p103 ? h9(r56, [r56.shape[1], r56.shape[2], r56.shape[3]]) : r56;
}
var T8 = u4({ avgPool_: x15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/avg_pool_3d.mjs
function k9(u86, f85, o80, p103, l80, n67 = "NDHWC") {
  let t67 = S5(u86, "x", "avgPool3d", "float32"), e36 = t67, m96 = false;
  t67.rank === 4 && (m96 = true, e36 = h9(t67, [1, t67.shape[0], t67.shape[1], t67.shape[2], t67.shape[3]])), c(e36.rank === 5, () => `Error in avgPool3d: x must be rank 5 but got rank ${e36.rank}.`), c(n67 === "NDHWC", () => `Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${n67}`), c(typeof o80 == "number" && o80 > 0 || Array.isArray(o80) && o80[0] > 0 && o80[1] > 0 && o80[2] > 0, () => `Error in avgPool3d: Stride must be > 0, but got '${o80}'`), z5("avgPool3d", p103, l80);
  let i88 = { x: e36 }, g72 = { filterSize: f85, strides: o80, pad: p103, dimRoundingMode: l80, dataFormat: n67 }, r56 = v3.runKernel(D2, i88, g72);
  return r56 = w12(r56, e36.dtype), m96 ? h9(r56, [r56.shape[1], r56.shape[2], r56.shape[3], r56.shape[4]]) : r56;
}
var H5 = u4({ avgPool3d_: k9 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/concat.mjs
function l14(o80, n67 = 0) {
  c(o80.length >= 1, () => "Pass at least one tensor to concat");
  let t67 = j5(o80, "tensors", "concat", "string_or_numeric");
  if (t67[0].dtype === "complex64" && t67.forEach((r56) => {
    if (r56.dtype !== "complex64") throw new Error(`Cannot concatenate complex64 tensors with a tensor
          with dtype ${r56.dtype}. `);
  }), t67.length === 1) return x11(t67[0]);
  let e36 = t67, c103 = { axis: n67 };
  return v3.runKernel(L2, e36, c103);
}
var E9 = u4({ concat_: l14 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/mat_mul.mjs
function i12(m96, a71, e36 = false, n67 = false) {
  let t67 = S5(m96, "a", "matMul"), o80 = S5(a71, "b", "matMul");
  [t67, o80] = m6(t67, o80);
  let l80 = { a: t67, b: o80 }, p103 = { transposeA: e36, transposeB: n67 };
  return v3.runKernel(R2, l80, p103);
}
var N6 = u4({ matMul_: i12 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sigmoid.mjs
function s10(o80) {
  let r56 = { x: S5(o80, "x", "sigmoid", "float32") };
  return v3.runKernel(wt, r56);
}
var d6 = u4({ sigmoid_: s10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/slice.mjs
function p16(o80, n67, t67) {
  let r56 = S5(o80, "x", "slice", "string_or_numeric");
  if (r56.rank === 0) throw new Error("Slicing scalar is not possible");
  let i88 = { x: r56 }, s84 = { begin: n67, size: t67 };
  return v3.runKernel(Et, i88, s84);
}
var E10 = u4({ slice_: p16 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tanh.mjs
function e8(o80) {
  let t67 = { x: S5(o80, "x", "tanh", "float32") };
  return v3.runKernel(re, t67);
}
var x16 = u4({ tanh_: e8 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/basic_lstm_cell.mjs
function k10(a71, f85, p103, b58, C28, S45) {
  let T40 = S5(a71, "forgetBias", "basicLSTMCell"), M30 = S5(f85, "lstmKernel", "basicLSTMCell"), L22 = S5(p103, "lstmBias", "basicLSTMCell"), d55 = S5(b58, "data", "basicLSTMCell"), h74 = S5(C28, "c", "basicLSTMCell"), $37 = S5(S45, "h", "basicLSTMCell"), g72 = E9([d55, $37], 1), u86 = N6(g72, M30), o80 = T7(u86, L22), B30 = o80.shape[0], s84 = o80.shape[1] / 4, c103 = [B30, s84], w45 = E10(o80, [0, 0], c103), z32 = E10(o80, [0, s84], c103), K21 = E10(o80, [0, s84 * 2], c103), j22 = E10(o80, [0, s84 * 3], c103), r56 = T7(y8(d6(w45), x16(z32)), y8(h74, d6(T7(T40, K21)))), v42 = y8(x16(r56), d6(j22));
  return [r56, v42];
}
var N7 = u4({ basicLSTMCell_: k10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/batch_to_space_nd.mjs
function g6(s84, t67, o80) {
  let e36 = S5(s84, "x", "batchToSpaceND"), r56 = t67.reduce((h74, u86) => h74 * u86);
  c(e36.rank >= 1 + t67.length, () => `input rank is ${e36.rank} but should be > than blockShape.length ${t67.length}`), c(o80.length === t67.length, () => `crops.length is ${o80.length} but should be equal to blockShape.length  ${t67.length}`), c(e36.shape[0] % r56 === 0, () => `input tensor batch is ${e36.shape[0]} but is not divisible by the product of the elements of blockShape ${t67.join(" * ")} === ${r56}`);
  let i88 = { x: e36 }, a71 = { blockShape: t67, crops: o80 };
  return v3.runKernel(h3, i88, a71);
}
var N8 = u4({ batchToSpaceND_: g6 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/batchnorm_util.mjs
function p17(e36) {
  let s84;
  return e36.rank === 0 || e36.rank === 1 ? s84 = h9(e36, [1, 1, 1, e36.size]) : e36.rank === 2 ? s84 = h9(e36, [1, 1, e36.shape[0], e36.shape[1]]) : e36.rank === 3 ? s84 = h9(e36, [1, e36.shape[0], e36.shape[1], e36.shape[2]]) : s84 = e36, s84;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/batchnorm.mjs
function v9(l80, u86, f85, s84, m96, e36) {
  e36 == null && (e36 = 1e-3);
  let i88 = S5(l80, "x", "batchNorm"), r56 = S5(u86, "mean", "batchNorm"), c103 = S5(f85, "variance", "batchNorm"), t67;
  m96 != null && (t67 = S5(m96, "scale", "batchNorm"));
  let n67;
  s84 != null && (n67 = S5(s84, "offset", "batchNorm")), c(r56.rank === c103.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks."), c(n67 == null || r56.rank === n67.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks."), c(t67 == null || r56.rank === t67.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  let h74 = { x: p17(i88), scale: t67, offset: n67, mean: r56, variance: c103 }, p103 = { varianceEpsilon: e36 }, N58 = v3.runKernel(lo, h74, p103);
  return h9(N58, i88.shape);
}
var F5 = u4({ batchNorm_: v9 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/batchnorm2d.mjs
function h10(c103, b58, i88, e36, s84, u86) {
  let k63 = S5(c103, "x", "batchNorm"), o80 = S5(b58, "mean", "batchNorm"), m96 = S5(i88, "variance", "batchNorm"), r56;
  s84 != null && (r56 = S5(s84, "scale", "batchNorm"));
  let a71;
  return e36 != null && (a71 = S5(e36, "offset", "batchNorm")), c(k63.rank === 2, () => `Error in batchNorm2D: x must be rank 2 but got rank ${k63.rank}.`), c(o80.rank === 2 || o80.rank === 1, () => `Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${o80.rank}.`), c(m96.rank === 2 || m96.rank === 1, () => `Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${m96.rank}.`), r56 != null && c(r56.rank === 2 || r56.rank === 1, () => `Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${r56.rank}.`), a71 != null && c(a71.rank === 2 || a71.rank === 1, () => `Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${a71.rank}.`), F5(k63, o80, m96, a71, r56, u86);
}
var g7 = u4({ batchNorm2d_: h10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/batchnorm3d.mjs
function h11(c103, b58, i88, e36, s84, u86) {
  let k63 = S5(c103, "x", "batchNorm"), o80 = S5(b58, "mean", "batchNorm"), m96 = S5(i88, "variance", "batchNorm"), r56;
  s84 != null && (r56 = S5(s84, "scale", "batchNorm"));
  let a71;
  return e36 != null && (a71 = S5(e36, "offset", "batchNorm")), c(k63.rank === 3, () => `Error in batchNorm3D: x must be rank 3 but got rank ${k63.rank}.`), c(o80.rank === 3 || o80.rank === 1, () => `Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${o80.rank}.`), c(m96.rank === 3 || m96.rank === 1, () => `Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${m96.rank}.`), r56 != null && c(r56.rank === 3 || r56.rank === 1, () => `Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${r56.rank}.`), a71 != null && c(a71.rank === 3 || a71.rank === 1, () => `Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${a71.rank}.`), F5(k63, o80, m96, a71, r56, u86);
}
var g8 = u4({ batchNorm3d_: h11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/batchnorm4d.mjs
function h12(c103, b58, i88, e36, s84, u86) {
  let k63 = S5(c103, "x", "batchNorm"), o80 = S5(b58, "mean", "batchNorm"), m96 = S5(i88, "variance", "batchNorm"), r56;
  s84 != null && (r56 = S5(s84, "scale", "batchNorm"));
  let a71;
  return e36 != null && (a71 = S5(e36, "offset", "batchNorm")), c(k63.rank === 4, () => `Error in batchNorm4D: x must be rank 4 but got rank ${k63.rank}.`), c(o80.rank === 4 || o80.rank === 1, () => `Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${o80.rank}.`), c(m96.rank === 4 || m96.rank === 1, () => `Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${m96.rank}.`), r56 != null && c(r56.rank === 4 || r56.rank === 1, () => `Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${r56.rank}.`), a71 != null && c(a71.rank === 4 || a71.rank === 1, () => `Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${a71.rank}.`), F5(k63, o80, m96, a71, r56, u86);
}
var g9 = u4({ batchNorm4d_: h12 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/bincount.mjs
function h13(s84, r56, i88) {
  let t67 = S5(s84, "x", "bincount"), n67 = S5(r56, "weights", "bincount");
  c(t67.dtype === "int32", () => `Error in bincount: input dtype must be int32, but got ${t67.dtype}`), c(i88 >= 0, () => `size must be non-negative, but got ${i88}.`), c(n67.size === t67.size || n67.size === 0, () => `Error in bincount: weights must have the same size as input or0-length, but got input shape: ${t67.shape}, weights shape: ${n67.shape}.`);
  let u86 = { x: t67, weights: n67 }, p103 = { size: i88 };
  return v3.runKernel(M2, u86, p103);
}
var $7 = u4({ bincount_: h13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/bitwise_and.mjs
function m16(o80, r56) {
  let t67 = S5(o80, "x", "bitwiseAnd"), e36 = S5(r56, "y", "bitwiseAnd");
  if (!w(t67.shape, e36.shape)) throw new Error(`BitwiseAnd: Tensors must have the same shape. x: ${t67.shape}, y: ${e36.shape}`);
  if (t67.dtype !== "int32" || e36.dtype !== "int32") throw new Error(`BitwiseAnd: Only supports 'int32' values in tensor, found type of x: ${t67.dtype} and type of y: ${e36.dtype}`);
  let i88 = { a: t67, b: e36 };
  return v3.runKernel(A2, i88);
}
var A6 = u4({ bitwiseAnd_: m16 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/broadcast_args.mjs
function p18(s84, n67) {
  let r56 = S5(s84, "s0", "broadcastArgs", "int32"), t67 = S5(n67, "s1", "broadcastArgs", "int32");
  if (r56.rank !== 1) throw new Error(`broadcastArgs(): first input must be a vector (rank=1). Has rank ${r56.rank}`);
  if (t67.rank !== 1) throw new Error(`broadcastArgs(): second input must be a vector (rank=1). Has rank ${t67.rank}`);
  let a71 = { s0: r56, s1: t67 };
  return v3.runKernel(N2, a71);
}
var f12 = u4({ broadcastArgs_: p18 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/broadcast_to.mjs
function b10(e36, o80) {
  let t67 = S5(e36, "broadcastTo", "x"), i88 = t67.shape;
  if (rr(o80), o80.length < t67.rank) throw new Error(`broadcastTo(): shape.length=${o80.length} < input.rank=${t67.rank}.`);
  if (o80.length > t67.rank) {
    let r56 = t67.shape.slice();
    for (; r56.length < o80.length; ) r56.unshift(1);
    t67 = h9(t67, r56);
  }
  let a71 = t67.shape, n67 = Array.from(o80);
  for (let r56 = o80.length - 1; r56 >= 0; r56--) if (a71[r56] === o80[r56]) n67[r56] = 1;
  else if (t67.shape[r56] !== 1) throw new Error(`broadcastTo(): [${i88}] cannot be broadcast to [${o80}].`);
  if (n67.map((r56, f85) => r56 > 1 ? f85 : -1).filter((r56) => r56 >= 0).length === 0) return x11(t67);
  let s84 = { x: t67 }, c103 = { reps: n67 };
  return v3.runKernel(ne, s84, c103);
}
var v10 = u4({ broadcastTo_: b10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/ceil.mjs
function c15(o80) {
  let r56 = { x: S5(o80, "x", "ceil", "float32") };
  return v3.runKernel(v2, r56);
}
var x17 = u4({ ceil_: c15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/fill.mjs
function c16(o80, t67, r56) {
  rr(o80), r56 = r56 || E(t67);
  let i88 = { shape: o80, value: t67, dtype: r56 };
  return v3.runKernel(co, {}, i88);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/clip_by_value.mjs
function B7(s84, r56, o80) {
  let t67 = S5(s84, "x", "clipByValue");
  if (c(r56 <= o80, () => `Error in clip: min (${r56}) must be less than or equal to max (${o80}).`), r56 === o80) return c16(t67.shape, r56, t67.dtype);
  let n67 = { x: t67 }, e36 = { clipValueMin: r56, clipValueMax: o80 };
  return v3.runKernel(F2, n67, e36);
}
var x18 = u4({ clipByValue_: B7 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/concat_1d.mjs
function n10(o80) {
  return E9(o80, 0);
}
var p19 = u4({ concat1d_: n10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/concat_2d.mjs
function r6(o80, t67) {
  return E9(o80, t67);
}
var a9 = u4({ concat2d_: r6 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/concat_3d.mjs
function r7(o80, t67) {
  return E9(o80, t67);
}
var a10 = u4({ concat3d_: r7 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/concat_4d.mjs
function r8(o80, t67) {
  return E9(o80, t67);
}
var a11 = u4({ concat4d_: r8 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/conv2d.mjs
function _7(m96, d55, i88, l80, u86 = "NHWC", a71 = [1, 1], c103) {
  let o80 = S5(m96, "x", "conv2d", "float32"), n67 = S5(d55, "filter", "conv2d", "float32"), e36 = o80, p103 = false;
  o80.rank === 3 && (p103 = true, e36 = h9(o80, [1, o80.shape[0], o80.shape[1], o80.shape[2]])), c(e36.rank === 4, () => `Error in conv2d: input must be rank 4, but got rank ${e36.rank}.`), c(n67.rank === 4, () => `Error in conv2d: filter must be rank 4, but got rank ${n67.rank}.`), z5("conv2d", l80, c103);
  let h74 = u86 === "NHWC" ? e36.shape[3] : e36.shape[1];
  c(h74 === n67.shape[2], () => `Error in conv2d: depth of input (${h74}) must match input depth for filter ${n67.shape[2]}.`), c(Z6(i88, a71), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${i88} and dilations '${a71}'`), c(_6(a71), () => "Error in conv2D: Dilated rates should be larger than 0."), c(_6(i88), () => "Error in conv2D: Strides should be larger than 0.");
  let D42 = { x: e36, filter: n67 }, k63 = { strides: i88, pad: l80, dataFormat: u86, dilations: a71, dimRoundingMode: c103 }, s84 = v3.runKernel(k2, D42, k63);
  return p103 ? h9(s84, [s84.shape[1], s84.shape[2], s84.shape[3]]) : s84;
}
var C5 = u4({ conv2d_: _7 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/conv1d.mjs
function b11(v42, m96, a71, p103, l80 = "NWC", c103 = 1, u86) {
  let n67 = S5(v42, "x", "conv1d"), t67 = S5(m96, "filter", "conv1d"), r56 = n67, h74 = false;
  n67.rank === 2 && (h74 = true, r56 = h9(n67, [1, n67.shape[0], n67.shape[1]])), c(r56.rank === 3, () => `Error in conv1d: input must be rank 3, but got rank ${r56.rank}.`), c(t67.rank === 3, () => `Error in conv1d: filter must be rank 3, but got rank ${t67.rank}.`), z5("conv1d", p103, u86), c(r56.shape[2] === t67.shape[1], () => `Error in conv1d: depth of input (${r56.shape[2]}) must match input depth for filter ${t67.shape[1]}.`), c(Z6(a71, c103), () => `Error in conv1D: Either stride or dilation must be 1. Got stride ${a71} and dilation '${c103}'`), c(_6(c103), () => "Error in conv1D: Dilated rates should be larger than 0."), c(_6(a71), () => "Error in conv1D: Stride should be larger than 0."), c(l80 === "NWC", () => `Error in conv1d: got dataFormat of ${l80} but only NWC is currently supported.`);
  let f85 = h9(t67, [1, t67.shape[0], t67.shape[1], t67.shape[2]]), D42 = h9(r56, [r56.shape[0], 1, r56.shape[1], r56.shape[2]]), e36 = C5(D42, f85, [1, a71], p103, "NHWC", [1, c103], u86);
  return h74 ? h9(e36, [e36.shape[2], e36.shape[3]]) : h9(e36, [e36.shape[0], e36.shape[2], e36.shape[3]]);
}
var W5 = u4({ conv1d_: b11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/conv2d_backprop_input.mjs
function E11(e36, t67, n67, D42, a71, u86 = "NHWC", h74) {
  c(e36.length === t67.rank, () => `Length of inShape (${e36.length}) and rank of dy (${t67.rank}) must match`);
  let o80 = e36, p103 = t67, i88 = false;
  t67.rank === 3 && (i88 = true, p103 = h9(t67, [1, t67.shape[0], t67.shape[1], t67.shape[2]]), o80 = [1, e36[0], e36[1], e36[2]]), c(o80.length === 4, () => `Error in conv2dDerInput: inShape must be length 4, but got length ${o80.length}.`), c(p103.rank === 4, () => `Error in conv2dDerInput: dy must be rank 4, but got rank ${p103.rank}`), c(n67.rank === 4, () => `Error in conv2dDerInput: filter must be rank 4, but got rank ${n67.rank}`);
  let c103 = u86 === "NHWC" ? o80[3] : o80[1], m96 = u86 === "NHWC" ? p103.shape[3] : p103.shape[1];
  c(c103 === n67.shape[2], () => `Error in conv2dDerInput: depth of input (${c103}) must match input depth for filter ${n67.shape[2]}.`), c(m96 === n67.shape[3], () => `Error in conv2dDerInput: depth of output (${m96}) must match output depth for filter ${n67.shape[3]}.`), z5("conv2dDerInput", a71, h74);
  let f85 = { dy: p103, filter: n67 }, v42 = { strides: D42, pad: a71, dataFormat: u86, dimRoundingMode: h74, inputShape: o80 }, s84 = v3.runKernel(E2, f85, v42);
  return i88 ? h9(s84, [s84.shape[1], s84.shape[2], s84.shape[3]]) : s84;
}
var B8 = u4({ conv2DBackpropInput_: E11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/conv2d_transpose.mjs
function v11(n67, r56, t67, p103, s84, c103) {
  let e36 = S5(n67, "x", "conv2dTranspose"), f85 = S5(r56, "filter", "conv2dTranspose");
  return B8(t67, e36, f85, p103, s84, "NHWC", c103);
}
var u12 = u4({ conv2dTranspose_: v11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/conv3d.mjs
function b12(c103, f85, s84, m96, a71 = "NDHWC", i88 = [1, 1, 1]) {
  let t67 = S5(c103, "x", "conv3d"), n67 = S5(f85, "filter", "conv3d"), e36 = t67, p103 = false;
  t67.rank === 4 && (p103 = true, e36 = h9(t67, [1, t67.shape[0], t67.shape[1], t67.shape[2], t67.shape[3]])), c(e36.rank === 5, () => `Error in conv3d: input must be rank 5, but got rank ${e36.rank}.`), c(n67.rank === 5, () => `Error in conv3d: filter must be rank 5, but got rank ${n67.rank}.`), c(e36.shape[4] === n67.shape[3], () => `Error in conv3d: depth of input (${e36.shape[4]}) must match input depth for filter ${n67.shape[3]}.`), c(Z6(s84, i88), () => `Error in conv3D: Either strides or dilations must be 1. Got strides ${s84} and dilations '${i88}'`), c(a71 === "NDHWC", () => `Error in conv3d: got dataFormat of ${a71} but only NDHWC is currently supported.`), c(_6(i88), () => "Error in conv3D: Dilated rates should be larger than 0."), c(_6(s84), () => "Error in conv3D: Strides should be larger than 0.");
  let d55 = { x: e36, filter: n67 }, v42 = { strides: s84, pad: m96, dataFormat: a71, dilations: i88 }, o80 = v3.runKernel(f3, d55, v42);
  return p103 ? h9(o80, [o80.shape[1], o80.shape[2], o80.shape[3], o80.shape[4]]) : o80;
}
var T9 = u4({ conv3d_: b12 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/conv3d_backprop_input.mjs
function I10(r56, t67, n67, c103, m96) {
  c(r56.length === t67.rank, () => `Length of inShape (${r56.length}) and rank of dy (${t67.rank}) must match`);
  let p103 = r56, s84 = t67, a71 = false;
  t67.rank === 4 && (a71 = true, s84 = h9(t67, [1, t67.shape[0], t67.shape[1], t67.shape[2], t67.shape[3]]), p103 = [1, r56[0], r56[1], r56[2], r56[3]]);
  let u86 = p103[4], h74 = s84.shape[4];
  c(p103.length === 5, () => `Error in conv3dDerInput: inShape must be length 5, but got length ${p103.length}.`), c(s84.rank === 5, () => `Error in conv3dDerInput: dy must be rank 5, but got rank ${s84.rank}`), c(n67.rank === 5, () => `Error in conv3dDerInput: filter must be rank 5, but got rank ${n67.rank}`), c(u86 === n67.shape[3], () => `Error in conv3dDerInput: depth of input (${u86}) must match input depth for filter ${n67.shape[3]}.`), c(h74 === n67.shape[4], () => `Error in conv3dDerInput: depth of output (${h74}) must match output depth for filter ${n67.shape[4]}.`);
  let k63 = { dy: s84, filter: n67 }, l80 = { pad: m96, strides: c103, inputShape: p103 }, o80 = v3.runKernel(q2, k63, l80);
  return a71 ? h9(o80, [o80.shape[1], o80.shape[2], o80.shape[3], o80.shape[4]]) : o80;
}
var b13 = u4({ conv3DBackpropInput_: I10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/conv3d_transpose.mjs
function m17(n67, r56, t67, p103, s84) {
  let c103 = S5(n67, "x", "conv3dTranspose"), e36 = S5(r56, "filter", "conv3dTranspose");
  return b13(t67, c103, e36, p103, s84);
}
var d7 = u4({ conv3dTranspose_: m17 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/cos.mjs
function m18(o80) {
  let r56 = { x: S5(o80, "x", "cos", "float32") };
  return v3.runKernel(w2, r56);
}
var u13 = u4({ cos_: m18 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/cosh.mjs
function m19(o80) {
  let r56 = { x: S5(o80, "x", "cosh", "float32") };
  return v3.runKernel(V2, r56);
}
var h14 = u4({ cosh_: m19 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/cumprod.mjs
function f13(o80, r56 = 0, t67 = false, m96 = false) {
  let n67 = { x: S5(o80, "x", "cumprod") }, p103 = { axis: r56, exclusive: t67, reverse: m96 };
  return v3.runKernel(y3, n67, p103);
}
var E12 = u4({ cumprod_: f13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/cumsum.mjs
function p20(o80, m96 = 0, r56 = false, t67 = false) {
  let s84 = { x: S5(o80, "x", "cumsum") }, n67 = { axis: m96, exclusive: r56, reverse: t67 };
  return v3.runKernel(b2, s84, n67);
}
var N9 = u4({ cumsum_: p20 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/dense_bincount.mjs
function g10(r56, i88, s84, u86 = false) {
  let t67 = S5(r56, "x", "denseBincount"), e36 = S5(i88, "weights", "denseBincount");
  c(t67.dtype === "int32", () => `Error in denseBincount: input dtype must be int32, but got ${t67.dtype}`), c(t67.rank <= 2, () => `Error in denseBincount: input must be at most rank 2, but got rank ${t67.rank}.`), c(s84 >= 0, () => `size must be non-negative, but got ${s84}.`), c(e36.size === t67.size || e36.size === 0, () => `Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${t67.shape}, weights shape: ${e36.shape}.`);
  let a71 = { x: t67, weights: e36 }, p103 = { size: s84, binaryOutput: u86 };
  return v3.runKernel(U2, a71, p103);
}
var f14 = u4({ denseBincount_: g10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/depth_to_space.mjs
function $8(h74, e36, s84 = "NHWC") {
  let t67 = S5(h74, "x", "depthToSpace", "float32"), n67 = s84 === "NHWC" ? t67.shape[1] : t67.shape[2], i88 = s84 === "NHWC" ? t67.shape[2] : t67.shape[3], o80 = s84 === "NHWC" ? t67.shape[3] : t67.shape[1];
  c(e36 > 1, () => `blockSize should be > 1 for depthToSpace, but was: ${e36}`), c(n67 * e36 >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${n67} and ${e36}  for depthToSpace with input shape
    ${t67.shape}`), c(i88 * e36 >= 0, () => `Negative dimension size caused by overflow when multiplying
    ${i88} and ${e36} for depthToSpace with input shape
        ${t67.shape}`), c(o80 % (e36 * e36) === 0, () => `Dimension size must be evenly divisible by ${e36 * e36} but is ${o80} for depthToSpace with input shape ${t67.shape}`);
  let a71 = { x: t67 }, r56 = { blockSize: e36, dataFormat: s84 };
  return v3.runKernel(O2, a71, r56);
}
var l15 = u4({ depthToSpace_: $8 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/depthwise_conv2d.mjs
function x19(m96, d55, c103, o80, i88 = "NHWC", v42 = [1, 1], a71) {
  let e36 = S5(m96, "x", "depthwiseConv2d", "float32"), n67 = S5(d55, "filter", "depthwiseConv2d", "float32"), t67 = e36, p103 = false;
  e36.rank === 3 && (p103 = true, t67 = h9(e36, [1, e36.shape[0], e36.shape[1], e36.shape[2]])), c(t67.rank === 4, () => `Error in depthwiseConv2d: input must be rank 4, but got rank ${t67.rank}.`), c(n67.rank === 4, () => `Error in depthwiseConv2d: filter must be rank 4, but got rank ${n67.rank}.`);
  let h74 = i88 === "NHWC" ? t67.shape[3] : t67.shape[1];
  c(h74 === n67.shape[2], () => `Error in depthwiseConv2d: number of input channels (${h74}) must match the inChannels dimension in filter ${n67.shape[2]}.`), z5("depthwiseConv2d", o80, a71);
  let C28 = { x: t67, filter: n67 }, k63 = { strides: c103, pad: o80, dataFormat: i88, dilations: v42, dimRoundingMode: a71 }, r56 = v3.runKernel(H2, C28, k63);
  return p103 ? h9(r56, [r56.shape[1], r56.shape[2], r56.shape[3]]) : r56;
}
var g11 = u4({ depthwiseConv2d_: x19 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/diag.mjs
function p21(o80) {
  let r56 = { x: S5(o80, "x", "diag") };
  return v3.runKernel(X2, r56);
}
var a12 = u4({ diag_: p21 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/dilation2d.mjs
function b14(l80, u86, d55, f85, m96 = [1, 1], n67 = "NHWC") {
  let r56 = S5(l80, "x", "dilation2d"), t67 = S5(u86, "filter", "dilation2d");
  c(r56.rank === 3 || r56.rank === 4, () => `Error in dilation2d: input must be rank 3 or 4, but got rank ${r56.rank}.`), c(t67.rank === 3, () => `Error in dilation2d: filter must be rank 3, but got rank ${t67.rank}.`), c(n67 === "NHWC", () => `Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${n67}`);
  let e36 = r56, a71 = false;
  r56.rank === 3 && (e36 = h9(r56, [1, r56.shape[0], r56.shape[1], r56.shape[2]]), a71 = true), c(e36.shape[3] === t67.shape[2], () => `Error in dilation2d:  input and filter must have the same depth: ${e36.shape[3]} vs ${t67.shape[2]}`);
  let h74 = { x: e36, filter: t67 }, k63 = { strides: d55, pad: f85, dilations: m96 }, i88 = v3.runKernel(Z2, h74, k63);
  return a71 ? h9(i88, [i88.shape[1], i88.shape[2], i88.shape[3]]) : i88;
}
var C6 = u4({ dilation2d_: b14 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/broadcast_util.mjs
var broadcast_util_exports = {};
__export(broadcast_util_exports, {
  assertAndGetBroadcastShape: () => u14,
  getBroadcastDims: () => c17,
  getReductionAxes: () => f15
});
function c17(l80, o80) {
  let r56 = l80.length, n67 = [];
  for (let t67 = 0; t67 < r56; t67++) {
    let e36 = r56 - 1 - t67, s84 = l80[e36] || 1;
    (o80[o80.length - 1 - t67] || 1) > 1 && s84 === 1 && n67.unshift(e36);
  }
  return n67;
}
function f15(l80, o80) {
  let r56 = [];
  for (let n67 = 0; n67 < o80.length; n67++) {
    let t67 = l80[l80.length - n67 - 1], e36 = o80.length - n67 - 1, s84 = o80[e36];
    (t67 == null || t67 === 1 && s84 > 1) && r56.unshift(e36);
  }
  return r56;
}
function u14(l80, o80) {
  let r56 = Math.max(l80.length, o80.length), n67 = new Array(r56);
  for (let t67 = 0; t67 < r56; t67++) {
    let e36 = l80[l80.length - t67 - 1];
    e36 == null && (e36 = 1);
    let s84 = o80[o80.length - t67 - 1];
    if (s84 == null && (s84 = 1), e36 === 1) n67[r56 - t67 - 1] = s84;
    else if (s84 === 1) n67[r56 - t67 - 1] = e36;
    else if (e36 !== s84) {
      let i88 = `Operands could not be broadcast together with shapes ${l80} and ${o80}.`;
      throw Error(i88);
    } else n67[r56 - t67 - 1] = e36;
  }
  return n67;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/equal.mjs
function c18(t67, a71) {
  let r56 = S5(t67, "a", "equal", "string_or_numeric"), o80 = S5(a71, "b", "equal", "string_or_numeric");
  [r56, o80] = m6(r56, o80), u14(r56.shape, o80.shape);
  let m96 = { a: r56, b: o80 };
  return v3.runKernel(eo, m96);
}
var E13 = u4({ equal_: c18 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/where.mjs
function u15(a71, i88, d55) {
  let e36 = S5(i88, "a", "where"), n67 = S5(d55, "b", "where"), s84 = S5(a71, "condition", "where", "bool"), o80 = u14(u14(s84.shape, e36.shape), n67.shape), p103 = v10(s84, o80), m96 = v10(e36, o80), h74 = v10(n67, o80), b58 = { condition: p103, t: m96, e: h74 };
  return v3.runKernel(kt, b58);
}
var G5 = u4({ where_: u15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/zeros_like.mjs
function s11(o80) {
  let r56 = { x: S5(o80, "x", "zerosLike") };
  return v3.runKernel(de, r56);
}
var k11 = u4({ zerosLike_: s11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/div_no_nan.mjs
function l16(m96, n67) {
  let r56 = S5(m96, "a", "div"), o80 = S5(n67, "b", "div");
  [r56, o80] = m6(r56, o80);
  let t67 = D6(r56, o80), e36 = k11(t67), p103 = E13(o80, e36);
  return G5(p103, e36, t67);
}
var z6 = u4({ divNoNan_: l16 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/dot.mjs
function d8(m96, u86) {
  let n67 = S5(m96, "t1", "dot"), t67 = S5(u86, "t2", "dot");
  c((n67.rank === 1 || n67.rank === 2) && (t67.rank === 1 || t67.rank === 2), () => `Error in dot: inputs must all be rank 1 or 2, but got ranks ${n67.rank} and ${t67.rank}.`);
  let c103 = n67.rank === 1 ? n67.size : n67.shape[1], k63 = t67.rank === 1 ? t67.size : t67.shape[0];
  if (c(c103 === k63, () => `Error in dot: inner dimensions of inputs must match, but got ${c103} and ${k63}.`), n67.rank === 1 && t67.rank === 1) {
    let o80 = h9(n67, [1, -1]), s84 = h9(t67, [-1, 1]), e36 = N6(o80, s84);
    return h9(e36, []);
  } else if (n67.rank === 1 && t67.rank === 2) {
    let o80 = h9(n67, [1, -1]), s84 = h9(t67, [t67.shape[0], t67.shape[1]]), e36 = N6(o80, s84);
    return h9(e36, [e36.size]);
  } else if (n67.rank === 2 && t67.rank === 1) {
    let o80 = h9(t67, [-1, 1]), s84 = N6(n67, o80);
    return h9(s84, [s84.size]);
  } else {
    let o80 = h9(t67, [t67.shape[0], t67.shape[1]]);
    return N6(n67, o80);
  }
}
var z7 = u4({ dot_: d8 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/einsum.mjs
function c19(o80, ...r56) {
  let n67 = r56.map((m96, s84) => S5(m96, `tensors${s84}`, "einsum")), t67 = { equation: o80 };
  return v3.runKernel(Y2, n67, t67);
}
var N10 = u4({ einsum_: c19 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/elu.mjs
function u16(o80) {
  let r56 = { x: S5(o80, "x", "elu", "float32") };
  return v3.runKernel($2, r56);
}
var s12 = u4({ elu_: u16 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/ensure_shape.mjs
function s13(e36, r56) {
  let o80 = S5(e36, "x", "ensureShape", "string_or_numeric");
  if (!P(o80.shape, r56)) throw new Error(`EnsureShape: Shape of tensor ${o80.shape} is not compatible with expected shape ${r56}`);
  return e36;
}
var u17 = u4({ ensureShape_: s13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/erf.mjs
function s14(o80) {
  let t67 = S5(o80, "x", "erf");
  c(t67.dtype === "int32" || t67.dtype === "float32", () => "Input dtype must be `int32` or `float32`."), t67.dtype === "int32" && (t67 = w12(t67, "float32"));
  let e36 = { x: t67 };
  return v3.runKernel(to, e36);
}
var x20 = u4({ erf_: s14 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/axis_util.mjs
function p22(n67, t67) {
  for (let e36 = 0; e36 < n67.length; ++e36) if (n67[n67.length - e36 - 1] !== t67 - 1 - e36) return false;
  return true;
}
function c20(n67, t67, e36) {
  let r56 = n67.length + t67.length, u86 = [], o80 = 0, f85 = 0;
  for (let s84 = 0; s84 < r56; s84++) e36.indexOf(s84) === -1 ? u86.push(n67[o80++]) : u86.push(t67[f85++]);
  return u86;
}
function l17(n67, t67) {
  let e36 = [], r56 = n67.length;
  for (let o80 = 0; o80 < r56; o80++) t67.indexOf(o80) === -1 && e36.push(n67[o80]);
  let u86 = t67.map((o80) => n67[o80]);
  return [e36, u86];
}
function m20(n67, t67) {
  let e36 = t67.map((r56) => 1);
  return c20(n67, e36, t67);
}
function h15(n67, t67, e36) {
  c(p22(t67, e36), () => `${n67} supports only inner-most axes for now. Got axes ${t67} and rank-${e36} input.`);
}
function x21(n67, t67) {
  if (p22(n67, t67)) return null;
  let e36 = [];
  for (let r56 = 0; r56 < t67; ++r56) n67.indexOf(r56) === -1 && e36.push(r56);
  return n67.forEach((r56) => e36.push(r56)), e36;
}
function d9(n67) {
  return n67.map((t67, e36) => [e36, t67]).sort((t67, e36) => t67[1] - e36[1]).map((t67) => t67[0]);
}
function a13(n67, t67) {
  let e36 = [];
  for (let r56 = t67 - n67; r56 < t67; ++r56) e36.push(r56);
  return e36;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/max.mjs
function i13(o80, r56 = null, t67 = false) {
  let n67 = { x: S5(o80, "x", "max") }, m96 = { reductionIndices: r56, keepDims: t67 };
  return v3.runKernel(yo, n67, m96);
}
var d10 = u4({ max_: i13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/min.mjs
function c21(o80, n67 = null, r56 = false) {
  let t67 = { x: S5(o80, "x", "min") }, m96 = { axis: n67, keepDims: r56 };
  return v3.runKernel(Xo, t67, m96);
}
var E14 = u4({ min_: c21 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/pow.mjs
function a14(t67, e36) {
  let o80 = S5(t67, "base", "pow"), r56 = S5(e36, "exp", "pow");
  [o80, r56] = m6(o80, r56);
  let m96 = { a: o80, b: r56 };
  return v3.runKernel(at, m96);
}
var x22 = u4({ pow_: a14 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/scalar.mjs
function m21(r56, n67) {
  if ((u2(r56) && n67 !== "string" || Array.isArray(r56)) && n67 !== "complex64") throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
  if (n67 === "string" && u2(r56) && !(r56 instanceof Uint8Array)) throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
  return G3(r56, [], [], n67);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sqrt.mjs
function p23(r56) {
  let o80 = { x: S5(r56, "x", "sqrt", "float32") };
  return v3.runKernel(yt, o80);
}
var q6 = u4({ sqrt_: p23 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/square.mjs
function u18(r56) {
  let o80 = S5(r56, "x", "square"), t67 = {};
  return v3.runKernel("Square", { x: o80 }, t67);
}
var p24 = u4({ square_: u18 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sum.mjs
function c22(t67, r56 = null, m96 = false) {
  let o80 = S5(t67, "x", "sum");
  o80.dtype === "bool" && (o80 = w12(o80, "int32"));
  let n67 = { x: o80 }, s84 = { axis: r56, keepDims: m96 };
  return v3.runKernel(bt, n67, s84);
}
var T10 = u4({ sum_: c22 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/norm.mjs
function I11(n67, o80 = "euclidean", r56 = null, c103 = false) {
  n67 = S5(n67, "x", "norm");
  let m96 = h16(n67, o80, r56), f85 = m96.shape;
  if (c103) {
    let d55 = x(r56, n67.shape);
    f85 = m20(m96.shape, d55);
  }
  return h9(m96, f85);
}
function h16(n67, o80, r56 = null) {
  if (n67.rank === 0) return b9(n67);
  if (n67.rank !== 1 && r56 === null) return h16(h9(n67, [-1]), o80, r56);
  if (n67.rank === 1 || typeof r56 == "number" || Array.isArray(r56) && r56.length === 1) {
    if (o80 === 1) return T10(b9(n67), r56);
    if (o80 === 1 / 0) return d10(b9(n67), r56);
    if (o80 === -1 / 0) return E14(b9(n67), r56);
    if (o80 === "euclidean" || o80 === 2) return q6(T10(x22(b9(n67), m21(2, "int32")), r56));
    throw new Error(`Error in norm: invalid ord value: ${o80}`);
  }
  if (Array.isArray(r56) && r56.length === 2) {
    if (o80 === 1) return d10(T10(b9(n67), r56[0]), r56[1] - 1);
    if (o80 === 1 / 0) return d10(T10(b9(n67), r56[1]), r56[0]);
    if (o80 === -1 / 0) return E14(T10(b9(n67), r56[1]), r56[0]);
    if (o80 === "fro" || o80 === "euclidean") return q6(T10(p24(n67), r56));
    throw new Error(`Error in norm: invalid ord value: ${o80}`);
  }
  throw new Error(`Error in norm: invalid axis: ${r56}`);
}
var z8 = u4({ norm_: I11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/euclidean_norm.mjs
function i14(o80, r56 = null, e36 = false) {
  return z8(o80, "euclidean", r56, e36);
}
var u19 = u4({ euclideanNorm_: i14 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/exp.mjs
function x23(o80) {
  let r56 = { x: S5(o80, "x", "exp") };
  return v3.runKernel(ro, r56);
}
var u20 = u4({ exp_: x23 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/expand_dims.mjs
function a15(n67, r56 = 0) {
  let t67 = S5(n67, "x", "expandDims", "string_or_numeric");
  c(r56 <= t67.rank, () => "Axis must be <= rank of the tensor");
  let i88 = { input: t67 }, m96 = { dim: r56 };
  return v3.runKernel(no, i88, m96);
}
var D7 = u4({ expandDims_: a15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/expm1.mjs
function e9(o80) {
  let r56 = { x: S5(o80, "x", "expm1") };
  return v3.runKernel(so, r56);
}
var u21 = u4({ expm1_: e9 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tile.mjs
function u22(n67, t67) {
  let r56 = S5(n67, "x", "tile", "string_or_numeric");
  c(r56.rank === t67.length, () => `Error in transpose: rank of input ${r56.rank} must match length of reps ${t67}.`);
  let i88 = { x: r56 }, e36 = { reps: t67 };
  return v3.runKernel(ne, i88, e36);
}
var g12 = u4({ tile_: u22 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/eye.mjs
function p25(f85, e36, r56, s84 = "float32") {
  e36 == null && (e36 = f85);
  let n67 = i7([f85, e36], s84), y43 = f85 <= e36 ? f85 : e36;
  for (let i88 = 0; i88 < y43; ++i88) n67.set(1, i88, i88);
  let o80 = h9(n67.toTensor(), [f85, e36]);
  if (r56 == null) return o80;
  if (r56.length === 1) return g12(D7(o80, 0), [r56[0], 1, 1]);
  if (r56.length === 2) return g12(D7(D7(o80, 0), 0), [r56[0], r56[1], 1, 1]);
  if (r56.length === 3) return g12(D7(D7(D7(o80, 0), 0), 0), [r56[0], r56[1], r56[2], 1, 1]);
  throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${r56.length}D.`);
}
var $9 = u4({ eye_: p25 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/floor.mjs
function p26(o80) {
  let r56 = { x: S5(o80, "x", "floor", "float32") };
  return v3.runKernel(xo, r56);
}
var x24 = u4({ floor_: p26 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/gather.mjs
function h17(r56, o80, n67 = 0, e36 = 0) {
  let i88 = S5(r56, "x", "gather"), s84 = S5(o80, "indices", "gather", "int32"), c103 = { x: i88, indices: s84 }, m96 = { axis: n67, batchDims: e36 };
  return v3.runKernel(uo, c103, m96);
}
var E15 = u4({ gather_: h17 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/greater.mjs
function f16(o80, a71) {
  let r56 = S5(o80, "a", "greater", "string_or_numeric"), e36 = S5(a71, "b", "greater", "string_or_numeric");
  [r56, e36] = m6(r56, e36), u14(r56.shape, e36.shape);
  let m96 = { a: r56, b: e36 };
  return v3.runKernel(go, m96);
}
var G6 = u4({ greater_: f16 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/greater_equal.mjs
function c23(o80, a71) {
  let r56 = S5(o80, "a", "greaterEqual", "string_or_numeric"), e36 = S5(a71, "b", "greaterEqual", "string_or_numeric");
  [r56, e36] = m6(r56, e36), u14(r56.shape, e36.shape);
  let m96 = { a: r56, b: e36 };
  return v3.runKernel(Do, m96);
}
var h18 = u4({ greaterEqual_: c23 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/imag.mjs
function p27(o80) {
  let t67 = { input: S5(o80, "input", "imag") };
  return v3.runKernel(ho, t67);
}
var a16 = u4({ imag_: p27 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/is_finite.mjs
function s15(i88) {
  let o80 = { x: S5(i88, "x", "isFinite") };
  return v3.runKernel(Mo, o80);
}
var u23 = u4({ isFinite_: s15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/is_inf.mjs
function s16(o80) {
  let n67 = { x: S5(o80, "x", "isInf") };
  return v3.runKernel(Ao, n67);
}
var x25 = u4({ isInf_: s16 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/is_nan.mjs
function N11(o80) {
  let r56 = { x: S5(o80, "x", "isNaN") };
  return v3.runKernel(Bo, r56);
}
var x26 = u4({ isNaN_: N11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/leaky_relu.mjs
function p28(o80, r56 = 0.2) {
  let t67 = { x: S5(o80, "x", "leakyRelu") }, e36 = { alpha: r56 };
  return v3.runKernel(No, t67, e36);
}
var x27 = u4({ leakyRelu_: p28 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/less.mjs
function f17(s84, t67) {
  let r56 = S5(s84, "a", "less", "string_or_numeric"), o80 = S5(t67, "b", "less", "string_or_numeric");
  [r56, o80] = m6(r56, o80), u14(r56.shape, o80.shape);
  let m96 = { a: r56, b: o80 };
  return v3.runKernel(Co, m96);
}
var d11 = u4({ less_: f17 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/less_equal.mjs
function u24(s84, t67) {
  let r56 = S5(s84, "a", "lessEqual", "string_or_numeric"), o80 = S5(t67, "b", "lessEqual", "string_or_numeric");
  [r56, o80] = m6(r56, o80), u14(r56.shape, o80.shape);
  let a71 = { a: r56, b: o80 };
  return v3.runKernel(vo, a71);
}
var b15 = u4({ lessEqual_: u24 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/linspace.mjs
function f18(e36, o80, r56) {
  if (r56 <= 0) throw new Error("The number of values should be positive.");
  let t67 = { start: e36, stop: o80, num: r56 };
  return v3.runKernel(Fo, {}, t67);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/local_response_normalization.mjs
function x28(i88, e36 = 5, l80 = 1, p103 = 1, m96 = 0.5) {
  let o80 = S5(i88, "x", "localResponseNormalization");
  c(o80.rank === 4 || o80.rank === 3, () => `Error in localResponseNormalization: x must be rank 3 or 4 but got
               rank ${o80.rank}.`), c(p(e36), () => `Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${e36}.`);
  let s84 = o80, a71 = false;
  o80.rank === 3 && (a71 = true, s84 = h9(o80, [1, o80.shape[0], o80.shape[1], o80.shape[2]]));
  let u86 = { x: s84 }, c103 = { depthRadius: e36, bias: l80, alpha: p103, beta: m96 }, r56 = v3.runKernel(qo, u86, c103);
  return a71 ? h9(r56, [r56.shape[1], r56.shape[2], r56.shape[3]]) : r56;
}
var T11 = u4({ localResponseNormalization_: x28 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/log.mjs
function e10(o80) {
  let r56 = { x: S5(o80, "x", "log", "float32") };
  return v3.runKernel(Po, r56);
}
var x29 = u4({ log_: e10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/log1p.mjs
function e11(o80) {
  let r56 = { x: S5(o80, "x", "log1p") };
  return v3.runKernel(To, r56);
}
var g13 = u4({ log1p_: e11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients.mjs
function v12(t67) {
  return c(R(t67), () => "The f passed in grad(f) must be a function"), (e36, s84) => {
    let n67 = S5(e36, "x", "tf.grad", "string_or_numeric"), r56 = s84 != null ? S5(s84, "dy", "tf.grad") : null;
    return v3.tidy(() => {
      let { value: o80, grads: l80 } = v3.gradients(() => t67(n67), [n67], r56);
      return r56 != null && k(o80.shape, r56.shape, "The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)"), f19(l80), l80[0];
    });
  };
}
function A7(t67) {
  return c(R(t67), () => "The f passed in grads(f) must be a function"), (e36, s84) => {
    c(Array.isArray(e36), () => "The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s");
    let n67 = j5(e36, "args", "tf.grads", "string_or_numeric"), r56 = s84 != null ? S5(s84, "dy", "tf.grads") : null;
    return v3.tidy(() => {
      let { value: o80, grads: l80 } = v3.gradients(() => t67(...n67), n67, r56);
      return r56 != null && k(o80.shape, r56.shape, "The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])"), f19(l80), l80;
    });
  };
}
function x30(t67) {
  return c(R(t67), () => "The f passed in valueAndGrad(f) must be a function"), (e36, s84) => {
    c(e36 instanceof o5, () => "The x passed in valueAndGrad(f)(x) must be a tensor"), c(s84 == null || s84 instanceof o5, () => "The dy passed in valueAndGrad(f)(x, dy) must be a tensor");
    let { grads: n67, value: r56 } = v3.gradients(() => t67(e36), [e36], s84);
    return f19(n67), { grad: n67[0], value: r56 };
  };
}
function k12(t67) {
  return c(R(t67), () => "The f passed in valueAndGrads(f) must be a function"), (e36, s84) => {
    c(Array.isArray(e36) && e36.every((r56) => r56 instanceof o5), () => "The args passed in valueAndGrads(f)(args) must be array of tensors"), c(s84 == null || s84 instanceof o5, () => "The dy passed in valueAndGrads(f)(args, dy) must be a tensor");
    let n67 = v3.gradients(() => t67(...e36), e36, s84);
    return s84 != null && k(n67.value.shape, s84.shape, "The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])"), f19(n67.grads), n67;
  };
}
function N12(t67, e36) {
  c(R(t67), () => "The f passed in variableGrads(f) must be a function"), c(e36 == null || Array.isArray(e36) && e36.every((i88) => i88 instanceof d3), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
  let s84 = e36 != null;
  if (!s84) {
    e36 = [];
    for (let i88 in v3.registeredVariables) e36.push(v3.registeredVariables[i88]);
  }
  let n67 = s84 ? e36.filter((i88) => !i88.trainable) : null, r56 = e36.length;
  e36 = e36.filter((i88) => i88.trainable), c(e36.length > 0, () => `variableGrads() expects at least one of the input variables to be trainable, but none of the ${r56} variables is trainable.`);
  let o80 = true, { value: l80, grads: c103 } = v3.gradients(t67, e36, null, o80);
  c(c103.some((i88) => i88 != null), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize()."), c(l80.rank === 0, () => `The f passed in variableGrads(f) must return a scalar, but it returned a rank-${l80.rank} tensor`);
  let h74 = {};
  return e36.forEach((i88, m96) => {
    c103[m96] != null && (h74[i88.name] = c103[m96]);
  }), n67?.forEach((i88) => h74[i88.name] = null), { value: l80, grads: h74 };
}
function $10(t67) {
  return v3.customGrad(t67);
}
function f19(t67) {
  if (t67.filter((s84) => s84 == null).length > 0) throw new Error(`Cannot compute gradient of y=f(x) with respect to x. Make sure that
    the f you passed encloses all operations that lead from x to y.`);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/neg.mjs
function p29(o80) {
  let r56 = { x: S5(o80, "x", "neg") };
  return v3.runKernel(Yo, r56);
}
var g14 = u4({ neg_: p29 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/softplus.mjs
function f20(o80) {
  let t67 = { x: S5(o80, "x", "softplus") };
  return v3.runKernel(Vt, t67);
}
var l18 = u4({ softplus_: f20 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/log_sigmoid.mjs
function g15(t67) {
  let m96 = S5(t67, "x", "logSigmoid");
  return $10((r56) => ({ value: g14(l18(g14(r56))), gradFunc: (i88) => y8(i88, d6(g14(r56))) }))(m96);
}
var G7 = u4({ logSigmoid_: g15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sub.mjs
function i15(m96, e36) {
  let o80 = S5(m96, "a", "sub"), r56 = S5(e36, "b", "sub");
  [o80, r56] = m6(o80, r56);
  let n67 = { a: o80, b: r56 };
  return v3.runKernel(te, n67);
}
var E16 = u4({ sub_: i15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/log_softmax.mjs
function h19(a71, o80 = -1) {
  let t67 = S5(a71, "logits", "logSoftmax");
  if (o80 === -1 && (o80 = t67.rank - 1), o80 !== t67.rank - 1) throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${t67.rank} and axis was ${o80}`);
  return $10((m96, c103) => {
    let u86 = d10(m96, o80, true), n67 = E16(m96, u86), s84 = E16(w12(n67, "float32"), x29(T10(u20(n67), o80, true)));
    return c103([s84]), { value: s84, gradFunc: (e36, i88) => {
      let [l80] = i88, g72 = true, k63 = u20(l80);
      return E16(e36, y8(T10(e36, o80, g72), k63));
    } };
  })(t67);
}
var A8 = u4({ logSoftmax_: h19 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/log_sum_exp.mjs
function w13(s84, n67 = null, a71 = false) {
  let o80 = S5(s84, "x", "logSumExp"), r56 = x(n67, o80.shape), t67 = d10(o80, r56, true), i88 = E16(o80, t67), f85 = u20(i88), c103 = T10(f85, r56), p103 = x29(c103), m96 = T7(h9(t67, p103.shape), p103);
  if (a71) {
    let x76 = m20(m96.shape, r56);
    return h9(m96, x76);
  }
  return m96;
}
var z9 = u4({ logSumExp_: w13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/logical_and.mjs
function s17(t67, a71) {
  let o80 = S5(t67, "a", "logicalAnd", "bool"), r56 = S5(a71, "b", "logicalAnd", "bool");
  u14(o80.shape, r56.shape);
  let c103 = { a: o80, b: r56 };
  return v3.runKernel(Lo, c103);
}
var g16 = u4({ logicalAnd_: s17 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/logical_not.mjs
function l19(o80) {
  let t67 = { x: S5(o80, "x", "logicalNot", "bool") };
  return v3.runKernel(ko, t67);
}
var s18 = u4({ logicalNot_: l19 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/logical_or.mjs
function s19(a71, n67) {
  let o80 = S5(a71, "a", "logicalOr", "bool"), r56 = S5(n67, "b", "logicalOr", "bool");
  u14(o80.shape, r56.shape);
  let c103 = { a: o80, b: r56 };
  return v3.runKernel(Go, c103);
}
var u25 = u4({ logicalOr_: s19 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/logical_xor.mjs
function e12(o80, r56) {
  let i88 = S5(o80, "a", "logicalXor", "bool"), a71 = S5(r56, "b", "logicalXor", "bool");
  return u14(i88.shape, a71.shape), g16(u25(o80, r56), s18(g16(o80, r56)));
}
var b16 = u4({ logicalXor_: e12 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/search_sorted.mjs
var r9 = 2147483648;
function v13(i88, h74, u86 = "left") {
  let t67 = S5(i88, "sortedSequence", "searchSorted"), s84 = S5(h74, "values", "searchSorted"), c103 = t67.shape[t67.shape.length - 1], p103 = s84.shape[s84.shape.length - 1], e36 = h9(t67, [-1, c103]), o80 = h9(s84, [-1, p103]);
  if (e36.rank < 2) throw new Error("Sorted input argument must be at least 2-dimensional");
  if (e36.shape[0] !== o80.shape[0]) throw new Error("Leading dimension of 'sortedSequence' and 'values' must match.");
  if (q(o80.shape) >= r9) throw new Error(`values tensor size must less than ${r9}`);
  if (e36.shape[1] >= r9) throw new Error(`trailing dim_size must less than ${r9} for int32 output type, was ${e36.shape[1]}`);
  let m96 = { sortedSequence: e36, values: o80 }, d55 = { side: u86 };
  return v3.runKernel(Lt, m96, d55);
}
var T12 = u4({ searchSorted_: v13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/lower_bound.mjs
function n11(r56, o80) {
  return T12(r56, o80, "left");
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/max_pool.mjs
function E17(u86, c103, n67, a71, i88) {
  let o80 = S5(u86, "x", "maxPool"), m96 = 1, t67 = o80, l80 = false;
  o80.rank === 3 && (l80 = true, t67 = h9(o80, [1, o80.shape[0], o80.shape[1], o80.shape[2]])), c(t67.rank === 4, () => `Error in maxPool: input must be rank 4 but got rank ${t67.rank}.`), c(Z6(n67, m96), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${n67} and dilations '${m96}'`), z5("maxPool", a71, i88);
  let x76 = { x: t67 }, f85 = { filterSize: c103, strides: n67, pad: a71, dimRoundingMode: i88 }, r56 = v3.runKernel(zo, x76, f85);
  return l80 ? h9(r56, [r56.shape[1], r56.shape[2], r56.shape[3]]) : r56;
}
var O6 = u4({ maxPool_: E17 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/max_pool_3d.mjs
function k13(i88, l80 = [1, 1, 1], u86, a71, n67, e36 = "NDHWC") {
  let o80 = S5(i88, "x", "maxPool3d"), t67 = o80, p103 = false;
  o80.rank === 4 && (p103 = true, t67 = h9(o80, [1, o80.shape[0], o80.shape[1], o80.shape[2], o80.shape[3]])), c(t67.rank === 5, () => `Error in maxPool3d: x must be rank 5 but got rank ${t67.rank}.`), c(e36 === "NDHWC", () => `Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${e36}`), z5("maxPool3d", a71, n67);
  let x76 = { x: t67 }, f85 = { filterSize: l80, strides: u86, pad: a71, dimRoundingMode: n67, dataFormat: e36 }, r56 = v3.runKernel(Oo, x76, f85);
  return p103 ? h9(r56, [r56.shape[1], r56.shape[2], r56.shape[3], r56.shape[4]]) : r56;
}
var W6 = u4({ maxPool3d_: k13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/max_pool_with_argmax.mjs
function p30(r56, t67, m96, n67, x76 = false) {
  let s84 = { x: S5(r56, "x", "maxPoolWithArgmax") }, e36 = { filterSize: t67, strides: m96, pad: n67, includeBatchInIndex: x76 }, o80 = v3.runKernel(Wo, s84, e36);
  return { result: o80[0], indexes: o80[1] };
}
var P6 = u4({ maxPoolWithArgmax_: p30 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/maximum.mjs
function c24(a71, i88) {
  let m96 = S5(a71, "a", "maximum"), o80 = S5(i88, "b", "maximum");
  [m96, o80] = m6(m96, o80), m96.dtype === "bool" && (m96 = w12(m96, "int32"), o80 = w12(o80, "int32")), u14(m96.shape, o80.shape);
  let e36 = { a: m96, b: o80 };
  return v3.runKernel(bo, e36);
}
var E18 = u4({ maximum_: c24 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/mean.mjs
function c25(o80, n67 = null, r56 = false) {
  let t67 = { x: S5(o80, "x", "mean") }, e36 = { axis: n67, keepDims: r56 };
  return v3.runKernel(Ko, t67, e36);
}
var E19 = u4({ mean_: c25 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/zeros.mjs
function e13(o80, r56 = "float32") {
  if (rr(o80), r56 === "complex64") {
    let m96 = e13(o80, "float32"), n67 = e13(o80, "float32");
    return x8(m96, n67);
  }
  let t67 = S(q(o80), r56);
  return v3.makeTensor(t67, o80, r56);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/ones.mjs
function c26(o80, r56 = "float32") {
  if (rr(o80), r56 === "complex64") {
    let e36 = c26(o80, "float32"), t67 = e13(o80, "float32");
    return x8(e36, t67);
  }
  let m96 = z(q(o80), r56);
  return v3.makeTensor(m96, o80, r56);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/meshgrid.mjs
function $11(t67, o80, { indexing: m96 = "xy" } = {}) {
  if (m96 !== "xy" && m96 !== "ij") throw new TypeError(`${m96} is not a valid third argument to meshgrid`);
  if (t67 === void 0) return [];
  let r56 = S5(t67, "x", "meshgrid", t67 instanceof o5 ? t67.dtype : "float32");
  if (o80 === void 0) return [r56];
  let e36 = S5(o80, "y", "meshgrid", o80 instanceof o5 ? o80.dtype : "float32"), n67 = q(r56.shape), s84 = q(e36.shape);
  return m96 === "xy" ? (r56 = h9(r56, [1, -1]), e36 = h9(e36, [-1, 1]), [N6(c26([s84, 1], r56.dtype), r56), N6(e36, c26([1, n67], e36.dtype))]) : (r56 = h9(r56, [-1, 1]), e36 = h9(e36, [1, -1]), [N6(r56, c26([1, s84], r56.dtype)), N6(c26([n67, 1], e36.dtype), e36)]);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/minimum.mjs
function c27(i88, n67) {
  let m96 = S5(i88, "a", "minimum"), o80 = S5(n67, "b", "minimum");
  [m96, o80] = m6(m96, o80), m96.dtype === "bool" && (m96 = w12(m96, "int32"), o80 = w12(o80, "int32")), u14(m96.shape, o80.shape);
  let e36 = { a: m96, b: o80 };
  return v3.runKernel(Zo, e36);
}
var G8 = u4({ minimum_: c27 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/mirror_pad.mjs
function u26(s84, e36, o80) {
  c(o80 === "reflect" || o80 === "symmetric", () => `Invalid mode. Mode must be either reflect or symmetric. Got ${o80}.`);
  let t67 = S5(s84, "x", "mirrorPad");
  if (t67.rank === 0) throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
  c(e36.length === t67.rank, () => `Padding doesn't match input. Must be ${t67.rank}. Got ${e36.length}.`);
  let a71 = o80 === "reflect" ? 1 : 0;
  for (let r56 = 0; r56 < t67.rank; r56++) c(e36[r56].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), c(e36[r56][0] >= 0 && e36[r56][0] <= t67.shape[r56] - a71 && e36[r56][1] >= 0 && e36[r56][1] <= t67.shape[r56] - a71, () => `Padding in dimension ${r56} cannot be greater than or equal to ${t67.shape[r56] - a71} or less than 0 for input of shape ${t67.shape}`);
  let i88 = { paddings: e36, mode: o80 }, l80 = { x: t67 };
  return v3.runKernel(_o, l80, i88);
}
var k14 = u4({ mirrorPad_: u26 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/mod.mjs
function c28(t67, e36) {
  let o80 = S5(t67, "a", "mod"), r56 = S5(e36, "b", "mod");
  [o80, r56] = m6(o80, r56);
  let n67 = { a: o80, b: r56 };
  return v3.runKernel(jo, n67);
}
var T13 = u4({ mod_: c28 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/moments.mjs
function S9(o80, n67 = null, m96 = false) {
  o80 = S5(o80, "x", "moments");
  let e36 = x(n67, o80.shape), r56 = E19(o80, e36, m96), t67 = r56.shape;
  m96 || (t67 = m20(r56.shape, e36));
  let p103 = p24(E16(w12(o80, "float32"), h9(r56, t67))), s84 = E19(p103, e36, m96);
  return { mean: r56, variance: s84 };
}
var g17 = u4({ moments_: S9 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/multi_rnn_cell.mjs
function C7(e36, s84, i88, p103) {
  let N58 = S5(s84, "data", "multiRNNCell"), h74 = j5(i88, "c", "multiRNNCell"), m96 = j5(p103, "h", "multiRNNCell"), l80 = N58, o80 = [];
  for (let t67 = 0; t67 < e36.length; t67++) {
    let n67 = e36[t67](l80, h74[t67], m96[t67]);
    o80.push(n67[0]), o80.push(n67[1]), l80 = n67[1];
  }
  let r56 = [], u86 = [];
  for (let t67 = 0; t67 < o80.length; t67 += 2) r56.push(o80[t67]), u86.push(o80[t67 + 1]);
  return [r56, u86];
}
var w14 = u4({ multiRNNCell_: C7 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/multinomial.mjs
function b17(m96, l80, r56, e36 = false) {
  let o80 = S5(m96, "logits", "multinomial"), n67 = o80.size, t67 = o80.rank;
  if (n67 < 2) throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${n67}.`);
  if (t67 > 2) throw new Error(`Rank of probabilities must be 1 or 2, but is ${t67}`);
  r56 = r56 || Math.random();
  let a71 = { logits: t67 === 1 ? h9(o80, [1, -1]) : o80 }, u86 = { numSamples: l80, seed: r56, normalized: e36 }, i88 = v3.runKernel(Jo, a71, u86);
  return t67 === 1 ? h9(i88, [i88.size]) : i88;
}
var D8 = u4({ multinomial_: b17 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/not_equal.mjs
function c29(n67, e36) {
  let o80 = S5(n67, "a", "notEqual", "string_or_numeric"), r56 = S5(e36, "b", "notEqual", "string_or_numeric");
  [o80, r56] = m6(o80, r56), u14(o80.shape, r56.shape);
  let a71 = { a: o80, b: r56 };
  return v3.runKernel($o, a71);
}
var b18 = u4({ notEqual_: c29 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/one_hot.mjs
function u27(n67, o80, t67 = 1, r56 = 0, i88 = "int32") {
  if (o80 < 2) throw new Error(`Error in oneHot: depth must be >=2, but it is ${o80}`);
  let e36 = { indices: S5(n67, "indices", "oneHot", "int32") }, s84 = { dtype: i88, depth: o80, onValue: t67, offValue: r56 };
  return v3.runKernel(nt, e36, s84);
}
var w15 = u4({ oneHot_: u27 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/ones_like.mjs
function s20(o80) {
  let n67 = { x: S5(o80, "x", "onesLike") };
  return v3.runKernel(rt, n67);
}
var k15 = u4({ onesLike_: s20 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/outer_product.mjs
function p31(e36, s84) {
  let r56 = S5(e36, "v1", "outerProduct"), o80 = S5(s84, "v2", "outerProduct");
  c(r56.rank === 1 && o80.rank === 1, () => `Error in outerProduct: inputs must be rank 1, but got ranks ${r56.rank} and ${o80.rank}.`);
  let c103 = h9(r56, [-1, 1]), m96 = h9(o80, [1, -1]);
  return N6(c103, m96);
}
var P7 = u4({ outerProduct_: p31 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/pad.mjs
function d12(r56, n67, t67 = 0) {
  let o80 = S5(r56, "x", "pad");
  if (o80.rank === 0) throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
  let a71 = { paddings: n67, constantValue: t67 }, p103 = { x: o80 };
  return v3.runKernel(pt, p103, a71);
}
var l20 = u4({ pad_: d12 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/pad1d.mjs
function m22(r56, o80, t67 = 0) {
  return c(o80.length === 2, () => "Invalid number of paddings. Must be length of 2."), l20(r56, [o80], t67);
}
var i16 = u4({ pad1d_: m22 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/pad2d.mjs
function f21(o80, t67, r56 = 0) {
  return c(t67.length === 2 && t67[0].length === 2 && t67[1].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), l20(o80, t67, r56);
}
var a17 = u4({ pad2d_: f21 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/pad3d.mjs
function f22(o80, t67, e36 = 0) {
  return c(t67.length === 3 && t67[0].length === 2 && t67[1].length === 2 && t67[2].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), l20(o80, t67, e36);
}
var u28 = u4({ pad3d_: f22 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/pad4d.mjs
function l21(e36, t67, o80 = 0) {
  return c(t67.length === 4 && t67[0].length === 2 && t67[1].length === 2 && t67[2].length === 2 && t67[3].length === 2, () => "Invalid number of paddings. Must be length of 2 each."), l20(e36, t67, o80);
}
var u29 = u4({ pad4d_: l21 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/space_to_batch_nd.mjs
function $12(u86, t67, r56) {
  let e36 = S5(u86, "x", "spaceToBatchND");
  c(e36.rank >= 1 + t67.length, () => `input rank ${e36.rank} should be > than [blockShape] ${t67.length}`), c(r56.length === t67.length, () => `paddings.shape[0] ${r56.length} must be equal to [blockShape] ${t67.length}`), c(e36.shape.reduce((o80, h74, n67) => n67 > 0 && n67 <= t67.length ? o80 && (h74 + r56[n67 - 1][0] + r56[n67 - 1][1]) % t67[n67 - 1] === 0 : o80, true), () => `input spatial dimensions ${e36.shape.slice(1)} with paddings ${r56.toString()} must be divisible by blockShapes ${t67.toString()}`);
  let i88 = { x: e36 }, a71 = { blockShape: t67, paddings: r56 };
  return v3.runKernel(zt, i88, a71);
}
var x31 = u4({ spaceToBatchND_: $12 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/pool.mjs
function W7(s84, p103, l80, n67, e36, i88, o80) {
  e36 == null && (e36 = [1, 1]), i88 == null && (i88 = 1), n67 === 0 && (n67 = "valid");
  let a71 = S5(s84, "x", "maxPool"), c103 = a71, d55 = false;
  a71.rank === 3 && (d55 = true, c103 = h9(a71, [1, a71.shape[0], a71.shape[1], a71.shape[2]])), c(Z6(i88, e36), () => `Error in pool: Either strides or dilations must be 1. Got strides ${i88} and dilations '${e36}'`);
  let t67 = Q5(c103.shape, p103, i88, e36, n67), r56 = [t67.dilationHeight, t67.dilationWidth], h74;
  n67 === "same" ? h74 = j7([t67.filterHeight, t67.filterWidth], r56) : h74 = [[0, 0], [0, 0]];
  let u86 = r56[0] === 1 && r56[1] === 1, [D42, T40] = $13([t67.inHeight, t67.inWidth], r56, h74), v42 = u86 ? n67 : "valid", x76 = u86 ? c103 : x31(c103, r56, D42), E44 = (l80 === "avg" ? () => T8(x76, p103, i88, v42, o80) : () => O6(x76, p103, i88, v42, o80))(), m96 = u86 ? E44 : N8(E44, r56, T40);
  return d55 ? h9(m96, [m96.shape[1], m96.shape[2], m96.shape[3]]) : m96;
}
function $13(s84, p103, l80) {
  let n67 = l80.map((t67) => t67[0]), e36 = l80.map((t67) => t67[1]), i88 = s84.concat(n67, e36), o80 = p103.map((t67, r56) => (t67 - i88[r56] % t67) % t67), a71 = e36.map((t67, r56) => t67 + o80[r56]), c103 = p103.map((t67, r56) => [n67[r56], a71[r56]]), d55 = p103.map((t67, r56) => [0, o80[r56]]);
  return [c103, d55];
}
function j7(s84, p103) {
  let n67 = s84.map((o80, a71) => o80 + (o80 - 1) * (p103[a71] - 1)).map((o80) => o80 - 1), e36 = n67.map((o80) => Math.floor(o80 / 2)), i88 = n67.map((o80, a71) => o80 - e36[a71]);
  return n67.map((o80, a71) => [e36[a71], i88[a71]]);
}
var z10 = u4({ pool_: W7 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/prelu.mjs
function a18(o80, p103) {
  let t67 = S5(o80, "x", "prelu"), n67 = S5(p103, "alpha", "prelu"), e36 = { x: t67, alpha: n67 };
  return v3.runKernel(xt, e36);
}
var x32 = u4({ prelu_: a18 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/prod.mjs
function l22(r56, t67 = null, n67 = false) {
  let o80 = S5(r56, "x", "prod");
  o80.dtype === "bool" && (o80 = w12(o80, "int32"));
  let p103 = { x: o80 }, m96 = { axis: t67, keepDims: n67 };
  return v3.runKernel(it, p103, m96);
}
var N13 = u4({ prod_: l22 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/ragged_gather.mjs
function G9(s84, r56, a71, n67) {
  let o80 = s84.map((c103, u86) => S5(c103, `tensors${u86}`, "raggedGather", "int32")), i88 = S5(r56, "paramsDenseValues", "raggedGather"), p103 = S5(a71, "indices", "raggedGather", "int32"), g72 = { paramsNestedSplits: o80, paramsDenseValues: i88, indices: p103 }, m96 = { outputRaggedRank: n67 }, e36 = v3.runKernel(lt, g72, m96);
  return { outputNestedSplits: e36.slice(0, e36.length - 1), outputDenseValues: e36[e36.length - 1] };
}
var $14 = u4({ raggedGather_: G9 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/ragged_range.mjs
function p32(s84, n67, o80) {
  let t67 = S5(s84, "starts", "raggedRange"), a71 = S5(n67, "limits", "raggedRange", t67.dtype), g72 = S5(o80, "deltas", "raggedRange", t67.dtype), i88 = { starts: t67, limits: a71, deltas: g72 }, r56 = v3.runKernel(dt, i88);
  return { rtNestedSplits: r56[0], rtDenseValues: r56[1] };
}
var N14 = u4({ raggedRange_: p32 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/ragged_tensor_to_tensor.mjs
function $15(r56, n67, s84, t67, T40) {
  let a71 = S5(r56, "shape", "raggedTensorToTensor", "int32"), e36 = S5(n67, "values", "raggedTensorToTensor"), g72 = S5(s84, "defaultValue", "raggedTensorToTensor", e36.dtype), u86 = t67.map((d55, l80) => S5(d55, `tensors${l80}`, "raggedTensorToTensor", "int32")), i88 = { shape: a71, values: e36, defaultValue: g72, rowPartitionTensors: u86 }, p103 = { rowPartitionTypes: T40 };
  return v3.runKernel(ut, i88, p103);
}
var E20 = u4({ raggedTensorToTensor_: $15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/rand.mjs
function f23(e36, i88, r56) {
  rr(e36);
  let n67 = q(e36), o80 = null;
  if (r56 == null || r56 === "float32") o80 = new Float32Array(n67);
  else if (r56 === "int32") o80 = new Int32Array(n67);
  else if (r56 === "bool") o80 = new Uint8Array(n67);
  else throw new Error(`Unknown data type ${r56}`);
  for (let t67 = 0; t67 < n67; t67++) o80[t67] = i88();
  return v3.makeTensor(o80, e36, r56);
}
var A9 = u4({ rand_: f23 });

// https://esm.sh/seedrandom@3.0.5/denonext/seedrandom.mjs
import * as __0$2 from "node:crypto";
var require3 = (n67) => {
  const e36 = (m96) => typeof m96.default < "u" ? m96.default : m96, c103 = (m96) => Object.assign({ __esModule: true }, m96);
  switch (n67) {
    case "node:crypto":
      return e36(__0$2);
    default:
      console.error('module "' + n67 + '" not found');
      return null;
  }
};
var fn = Object.create;
var K7 = Object.defineProperty;
var un = Object.getOwnPropertyDescriptor;
var cn = Object.getOwnPropertyNames;
var an = Object.getPrototypeOf;
var xn = Object.prototype.hasOwnProperty;
var sn = ((x76) => typeof require3 < "u" ? require3 : typeof Proxy < "u" ? new Proxy(x76, { get: (c103, a71) => (typeof require3 < "u" ? require3 : c103)[a71] }) : x76)(function(x76) {
  if (typeof require3 < "u") return require3.apply(this, arguments);
  throw Error('Dynamic require of "' + x76 + '" is not supported');
});
var S10 = (x76, c103) => () => (c103 || x76((c103 = { exports: {} }).exports, c103), c103.exports);
var ln = (x76, c103, a71, v42) => {
  if (c103 && typeof c103 == "object" || typeof c103 == "function") for (let l80 of cn(c103)) !xn.call(x76, l80) && l80 !== a71 && K7(x76, l80, { get: () => c103[l80], enumerable: !(v42 = un(c103, l80)) || v42.enumerable });
  return x76;
};
var hn = (x76, c103, a71) => (a71 = x76 != null ? fn(an(x76)) : {}, ln(c103 || !x76 || !x76.__esModule ? K7(a71, "default", { value: x76, enumerable: true }) : a71, x76));
var N15 = S10((L22, V24) => {
  (function(x76, c103, a71) {
    function v42(n67) {
      var e36 = this, i88 = o80();
      e36.next = function() {
        var t67 = 2091639 * e36.s0 + e36.c * 23283064365386963e-26;
        return e36.s0 = e36.s1, e36.s1 = e36.s2, e36.s2 = t67 - (e36.c = t67 | 0);
      }, e36.c = 1, e36.s0 = i88(" "), e36.s1 = i88(" "), e36.s2 = i88(" "), e36.s0 -= i88(n67), e36.s0 < 0 && (e36.s0 += 1), e36.s1 -= i88(n67), e36.s1 < 0 && (e36.s1 += 1), e36.s2 -= i88(n67), e36.s2 < 0 && (e36.s2 += 1), i88 = null;
    }
    function l80(n67, e36) {
      return e36.c = n67.c, e36.s0 = n67.s0, e36.s1 = n67.s1, e36.s2 = n67.s2, e36;
    }
    function w45(n67, e36) {
      var i88 = new v42(n67), t67 = e36 && e36.state, r56 = i88.next;
      return r56.int32 = function() {
        return i88.next() * 4294967296 | 0;
      }, r56.double = function() {
        return r56() + (r56() * 2097152 | 0) * 11102230246251565e-32;
      }, r56.quick = r56, t67 && (typeof t67 == "object" && l80(t67, i88), r56.state = function() {
        return l80(i88, {});
      }), r56;
    }
    function o80() {
      var n67 = 4022871197, e36 = function(i88) {
        i88 = String(i88);
        for (var t67 = 0; t67 < i88.length; t67++) {
          n67 += i88.charCodeAt(t67);
          var r56 = 0.02519603282416938 * n67;
          n67 = r56 >>> 0, r56 -= n67, r56 *= n67, n67 = r56 >>> 0, r56 -= n67, n67 += r56 * 4294967296;
        }
        return (n67 >>> 0) * 23283064365386963e-26;
      };
      return e36;
    }
    c103 && c103.exports ? c103.exports = w45 : a71 && a71.amd ? a71(function() {
      return w45;
    }) : this.alea = w45;
  })(L22, typeof V24 == "object" && V24, typeof define == "function" && define);
});
var P8 = S10((O21, E44) => {
  (function(x76, c103, a71) {
    function v42(o80) {
      var n67 = this, e36 = "";
      n67.x = 0, n67.y = 0, n67.z = 0, n67.w = 0, n67.next = function() {
        var t67 = n67.x ^ n67.x << 11;
        return n67.x = n67.y, n67.y = n67.z, n67.z = n67.w, n67.w ^= n67.w >>> 19 ^ t67 ^ t67 >>> 8;
      }, o80 === (o80 | 0) ? n67.x = o80 : e36 += o80;
      for (var i88 = 0; i88 < e36.length + 64; i88++) n67.x ^= e36.charCodeAt(i88) | 0, n67.next();
    }
    function l80(o80, n67) {
      return n67.x = o80.x, n67.y = o80.y, n67.z = o80.z, n67.w = o80.w, n67;
    }
    function w45(o80, n67) {
      var e36 = new v42(o80), i88 = n67 && n67.state, t67 = function() {
        return (e36.next() >>> 0) / 4294967296;
      };
      return t67.double = function() {
        do
          var r56 = e36.next() >>> 11, f85 = (e36.next() >>> 0) / 4294967296, u86 = (r56 + f85) / (1 << 21);
        while (u86 === 0);
        return u86;
      }, t67.int32 = e36.next, t67.quick = t67, i88 && (typeof i88 == "object" && l80(i88, e36), t67.state = function() {
        return l80(e36, {});
      }), t67;
    }
    c103 && c103.exports ? c103.exports = w45 : a71 && a71.amd ? a71(function() {
      return w45;
    }) : this.xor128 = w45;
  })(O21, typeof E44 == "object" && E44, typeof define == "function" && define);
});
var T14 = S10((Q13, F32) => {
  (function(x76, c103, a71) {
    function v42(o80) {
      var n67 = this, e36 = "";
      n67.next = function() {
        var t67 = n67.x ^ n67.x >>> 2;
        return n67.x = n67.y, n67.y = n67.z, n67.z = n67.w, n67.w = n67.v, (n67.d = n67.d + 362437 | 0) + (n67.v = n67.v ^ n67.v << 4 ^ (t67 ^ t67 << 1)) | 0;
      }, n67.x = 0, n67.y = 0, n67.z = 0, n67.w = 0, n67.v = 0, o80 === (o80 | 0) ? n67.x = o80 : e36 += o80;
      for (var i88 = 0; i88 < e36.length + 64; i88++) n67.x ^= e36.charCodeAt(i88) | 0, i88 == e36.length && (n67.d = n67.x << 10 ^ n67.x >>> 4), n67.next();
    }
    function l80(o80, n67) {
      return n67.x = o80.x, n67.y = o80.y, n67.z = o80.z, n67.w = o80.w, n67.v = o80.v, n67.d = o80.d, n67;
    }
    function w45(o80, n67) {
      var e36 = new v42(o80), i88 = n67 && n67.state, t67 = function() {
        return (e36.next() >>> 0) / 4294967296;
      };
      return t67.double = function() {
        do
          var r56 = e36.next() >>> 11, f85 = (e36.next() >>> 0) / 4294967296, u86 = (r56 + f85) / (1 << 21);
        while (u86 === 0);
        return u86;
      }, t67.int32 = e36.next, t67.quick = t67, i88 && (typeof i88 == "object" && l80(i88, e36), t67.state = function() {
        return l80(e36, {});
      }), t67;
    }
    c103 && c103.exports ? c103.exports = w45 : a71 && a71.amd ? a71(function() {
      return w45;
    }) : this.xorwow = w45;
  })(Q13, typeof F32 == "object" && F32, typeof define == "function" && define);
});
var Y4 = S10((W15, H18) => {
  (function(x76, c103, a71) {
    function v42(o80) {
      var n67 = this;
      n67.next = function() {
        var i88 = n67.x, t67 = n67.i, r56, f85, u86;
        return r56 = i88[t67], r56 ^= r56 >>> 7, f85 = r56 ^ r56 << 24, r56 = i88[t67 + 1 & 7], f85 ^= r56 ^ r56 >>> 10, r56 = i88[t67 + 3 & 7], f85 ^= r56 ^ r56 >>> 3, r56 = i88[t67 + 4 & 7], f85 ^= r56 ^ r56 << 7, r56 = i88[t67 + 7 & 7], r56 = r56 ^ r56 << 13, f85 ^= r56 ^ r56 << 9, i88[t67] = f85, n67.i = t67 + 1 & 7, f85;
      };
      function e36(i88, t67) {
        var r56, f85, u86 = [];
        if (t67 === (t67 | 0)) f85 = u86[0] = t67;
        else for (t67 = "" + t67, r56 = 0; r56 < t67.length; ++r56) u86[r56 & 7] = u86[r56 & 7] << 15 ^ t67.charCodeAt(r56) + u86[r56 + 1 & 7] << 13;
        for (; u86.length < 8; ) u86.push(0);
        for (r56 = 0; r56 < 8 && u86[r56] === 0; ++r56) ;
        for (r56 == 8 ? f85 = u86[7] = -1 : f85 = u86[r56], i88.x = u86, i88.i = 0, r56 = 256; r56 > 0; --r56) i88.next();
      }
      e36(n67, o80);
    }
    function l80(o80, n67) {
      return n67.x = o80.x.slice(), n67.i = o80.i, n67;
    }
    function w45(o80, n67) {
      o80 == null && (o80 = +/* @__PURE__ */ new Date());
      var e36 = new v42(o80), i88 = n67 && n67.state, t67 = function() {
        return (e36.next() >>> 0) / 4294967296;
      };
      return t67.double = function() {
        do
          var r56 = e36.next() >>> 11, f85 = (e36.next() >>> 0) / 4294967296, u86 = (r56 + f85) / (1 << 21);
        while (u86 === 0);
        return u86;
      }, t67.int32 = e36.next, t67.quick = t67, i88 && (i88.x && l80(i88, e36), t67.state = function() {
        return l80(e36, {});
      }), t67;
    }
    c103 && c103.exports ? c103.exports = w45 : a71 && a71.amd ? a71(function() {
      return w45;
    }) : this.xorshift7 = w45;
  })(W15, typeof H18 == "object" && H18, typeof define == "function" && define);
});
var _8 = S10((Z16, I44) => {
  (function(x76, c103, a71) {
    function v42(o80) {
      var n67 = this;
      n67.next = function() {
        var i88 = n67.w, t67 = n67.X, r56 = n67.i, f85, u86;
        return n67.w = i88 = i88 + 1640531527 | 0, u86 = t67[r56 + 34 & 127], f85 = t67[r56 = r56 + 1 & 127], u86 ^= u86 << 13, f85 ^= f85 << 17, u86 ^= u86 >>> 15, f85 ^= f85 >>> 12, u86 = t67[r56] = u86 ^ f85, n67.i = r56, u86 + (i88 ^ i88 >>> 16) | 0;
      };
      function e36(i88, t67) {
        var r56, f85, u86, b58, z32, X20 = [], M30 = 128;
        for (t67 === (t67 | 0) ? (f85 = t67, t67 = null) : (t67 = t67 + "\0", f85 = 0, M30 = Math.max(M30, t67.length)), u86 = 0, b58 = -32; b58 < M30; ++b58) t67 && (f85 ^= t67.charCodeAt((b58 + 32) % t67.length)), b58 === 0 && (z32 = f85), f85 ^= f85 << 10, f85 ^= f85 >>> 15, f85 ^= f85 << 4, f85 ^= f85 >>> 13, b58 >= 0 && (z32 = z32 + 1640531527 | 0, r56 = X20[b58 & 127] ^= f85 + z32, u86 = r56 == 0 ? u86 + 1 : 0);
        for (u86 >= 128 && (X20[(t67 && t67.length || 0) & 127] = -1), u86 = 127, b58 = 4 * 128; b58 > 0; --b58) f85 = X20[u86 + 34 & 127], r56 = X20[u86 = u86 + 1 & 127], f85 ^= f85 << 13, r56 ^= r56 << 17, f85 ^= f85 >>> 15, r56 ^= r56 >>> 12, X20[u86] = f85 ^ r56;
        i88.w = z32, i88.X = X20, i88.i = u86;
      }
      e36(n67, o80);
    }
    function l80(o80, n67) {
      return n67.i = o80.i, n67.w = o80.w, n67.X = o80.X.slice(), n67;
    }
    function w45(o80, n67) {
      o80 == null && (o80 = +/* @__PURE__ */ new Date());
      var e36 = new v42(o80), i88 = n67 && n67.state, t67 = function() {
        return (e36.next() >>> 0) / 4294967296;
      };
      return t67.double = function() {
        do
          var r56 = e36.next() >>> 11, f85 = (e36.next() >>> 0) / 4294967296, u86 = (r56 + f85) / (1 << 21);
        while (u86 === 0);
        return u86;
      }, t67.int32 = e36.next, t67.quick = t67, i88 && (i88.X && l80(i88, e36), t67.state = function() {
        return l80(e36, {});
      }), t67;
    }
    c103 && c103.exports ? c103.exports = w45 : a71 && a71.amd ? a71(function() {
      return w45;
    }) : this.xor4096 = w45;
  })(Z16, typeof I44 == "object" && I44, typeof define == "function" && define);
});
var nn = S10(($37, J17) => {
  (function(x76, c103, a71) {
    function v42(o80) {
      var n67 = this, e36 = "";
      n67.next = function() {
        var t67 = n67.b, r56 = n67.c, f85 = n67.d, u86 = n67.a;
        return t67 = t67 << 25 ^ t67 >>> 7 ^ r56, r56 = r56 - f85 | 0, f85 = f85 << 24 ^ f85 >>> 8 ^ u86, u86 = u86 - t67 | 0, n67.b = t67 = t67 << 20 ^ t67 >>> 12 ^ r56, n67.c = r56 = r56 - f85 | 0, n67.d = f85 << 16 ^ r56 >>> 16 ^ u86, n67.a = u86 - t67 | 0;
      }, n67.a = 0, n67.b = 0, n67.c = -1640531527, n67.d = 1367130551, o80 === Math.floor(o80) ? (n67.a = o80 / 4294967296 | 0, n67.b = o80 | 0) : e36 += o80;
      for (var i88 = 0; i88 < e36.length + 20; i88++) n67.b ^= e36.charCodeAt(i88) | 0, n67.next();
    }
    function l80(o80, n67) {
      return n67.a = o80.a, n67.b = o80.b, n67.c = o80.c, n67.d = o80.d, n67;
    }
    function w45(o80, n67) {
      var e36 = new v42(o80), i88 = n67 && n67.state, t67 = function() {
        return (e36.next() >>> 0) / 4294967296;
      };
      return t67.double = function() {
        do
          var r56 = e36.next() >>> 11, f85 = (e36.next() >>> 0) / 4294967296, u86 = (r56 + f85) / (1 << 21);
        while (u86 === 0);
        return u86;
      }, t67.int32 = e36.next, t67.quick = t67, i88 && (typeof i88 == "object" && l80(i88, e36), t67.state = function() {
        return l80(e36, {});
      }), t67;
    }
    c103 && c103.exports ? c103.exports = w45 : a71 && a71.amd ? a71(function() {
      return w45;
    }) : this.tychei = w45;
  })($37, typeof J17 == "object" && J17, typeof define == "function" && define);
});
var rn = S10((tn, B30) => {
  (function(x76, c103, a71) {
    var v42 = 256, l80 = 6, w45 = 52, o80 = "random", n67 = a71.pow(v42, l80), e36 = a71.pow(2, w45), i88 = e36 * 2, t67 = v42 - 1, r56;
    function f85(s84, h74, g72) {
      var p103 = [];
      h74 = h74 == true ? { entropy: true } : h74 || {};
      var y43 = X20(z32(h74.entropy ? [s84, D42(c103)] : s84 ?? M30(), 3), p103), j22 = new u86(p103), q25 = function() {
        for (var m96 = j22.g(l80), C28 = n67, d55 = 0; m96 < e36; ) m96 = (m96 + d55) * v42, C28 *= v42, d55 = j22.g(1);
        for (; m96 >= i88; ) m96 /= 2, C28 /= 2, d55 >>>= 1;
        return (m96 + d55) / C28;
      };
      return q25.int32 = function() {
        return j22.g(4) | 0;
      }, q25.quick = function() {
        return j22.g(4) / 4294967296;
      }, q25.double = q25, X20(D42(j22.S), c103), (h74.pass || g72 || function(m96, C28, d55, A35) {
        return A35 && (A35.S && b58(A35, j22), m96.state = function() {
          return b58(j22, {});
        }), d55 ? (a71[o80] = m96, C28) : m96;
      })(q25, y43, "global" in h74 ? h74.global : this == a71, h74.state);
    }
    function u86(s84) {
      var h74, g72 = s84.length, p103 = this, y43 = 0, j22 = p103.i = p103.j = 0, q25 = p103.S = [];
      for (g72 || (s84 = [g72++]); y43 < v42; ) q25[y43] = y43++;
      for (y43 = 0; y43 < v42; y43++) q25[y43] = q25[j22 = t67 & j22 + s84[y43 % g72] + (h74 = q25[y43])], q25[j22] = h74;
      (p103.g = function(m96) {
        for (var C28, d55 = 0, A35 = p103.i, k63 = p103.j, R26 = p103.S; m96--; ) C28 = R26[A35 = t67 & A35 + 1], d55 = d55 * v42 + R26[t67 & (R26[A35] = R26[k63 = t67 & k63 + C28]) + (R26[k63] = C28)];
        return p103.i = A35, p103.j = k63, d55;
      })(v42);
    }
    function b58(s84, h74) {
      return h74.i = s84.i, h74.j = s84.j, h74.S = s84.S.slice(), h74;
    }
    function z32(s84, h74) {
      var g72 = [], p103 = typeof s84, y43;
      if (h74 && p103 == "object") for (y43 in s84) try {
        g72.push(z32(s84[y43], h74 - 1));
      } catch {
      }
      return g72.length ? g72 : p103 == "string" ? s84 : s84 + "\0";
    }
    function X20(s84, h74) {
      for (var g72 = s84 + "", p103, y43 = 0; y43 < g72.length; ) h74[t67 & y43] = t67 & (p103 ^= h74[t67 & y43] * 19) + g72.charCodeAt(y43++);
      return D42(h74);
    }
    function M30() {
      try {
        var s84;
        return r56 && (s84 = r56.randomBytes) ? s84 = s84(v42) : (s84 = new Uint8Array(v42), (x76.crypto || x76.msCrypto).getRandomValues(s84)), D42(s84);
      } catch {
        var h74 = x76.navigator, g72 = h74 && h74.plugins;
        return [+/* @__PURE__ */ new Date(), x76, g72, x76.screen, D42(c103)];
      }
    }
    function D42(s84) {
      return String.fromCharCode.apply(0, s84);
    }
    if (X20(a71.random(), c103), typeof B30 == "object" && B30.exports) {
      B30.exports = f85;
      try {
        r56 = sn("node:crypto");
      } catch {
      }
    } else typeof define == "function" && define.amd ? define(function() {
      return f85;
    }) : a71["seed" + o80] = f85;
  })(typeof self < "u" ? self : tn, [], Math);
});
var on = S10((mn2, en2) => {
  var vn2 = N15(), wn2 = P8(), yn2 = T14(), pn2 = Y4(), gn2 = _8(), bn2 = nn(), G30 = rn();
  G30.alea = vn2;
  G30.xor128 = wn2;
  G30.xorwow = yn2;
  G30.xorshift7 = pn2;
  G30.xor4096 = gn2;
  G30.tychei = bn2;
  en2.exports = G30;
});
var U5 = hn(on());
var { alea: qn, xor128: Xn, xorwow: dn, xorshift7: Cn, xor4096: zn, tychei: An } = U5;
var Sn = U5.default ?? U5;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/test_util.mjs
var test_util_exports = {};
__export(test_util_exports, {
  TEST_EPSILON_FLOAT16: () => $16,
  createVideoElement: () => I12,
  encodeStrings: () => w16,
  expectArrayBuffersEqual: () => v14,
  expectArraysClose: () => T15,
  expectArraysEqual: () => S11,
  expectNumbersClose: () => C8,
  expectPromiseToFail: () => N16,
  expectValuesInRange: () => P9,
  play: () => q7,
  testEpsilon: () => d13
});
var g18 = 1e-3;
var $16 = 0.1;
function T15(r56, e36, t67) {
  return t67 == null && (t67 = d13()), c30(r56, e36, (n67, o80) => u30(n67, o80, t67));
}
function d13() {
  return v3.backend.floatPrecision() === 32 ? g18 : $16;
}
function c30(r56, e36, t67) {
  let n67 = true;
  if ((u2(r56) || u2(e36)) && (n67 = false), u2(r56) && u2(e36) && (n67 = true), n67) {
    let i88 = r56.constructor.name, f85 = e36.constructor.name;
    if (i88 !== f85) throw new Error(`Arrays are of different type. Actual: ${i88}. Expected: ${f85}`);
  }
  if (Array.isArray(r56) && Array.isArray(e36)) {
    let i88 = w7(r56), f85 = w7(e36);
    if (!w(i88, f85)) throw new Error(`Arrays have different shapes. Actual: [${i88}]. Expected: [${f85}]`);
  }
  let o80 = u2(r56) ? r56 : l5(r56), a71 = u2(e36) ? e36 : l5(e36);
  if (o80.length !== a71.length) throw new Error(`Arrays have different lengths actual: ${o80.length} vs expected: ${a71.length}.
Actual:   ${o80}.
Expected: ${a71}.`);
  for (let i88 = 0; i88 < a71.length; ++i88) {
    let f85 = o80[i88], p103 = a71[i88];
    if (!t67(f85, p103)) throw new Error(`Arrays differ: actual[${i88}] = ${f85}, expected[${i88}] = ${p103}.
Actual:   ${o80}.
Expected: ${a71}.`);
  }
  typeof expect < "u" && expect().nothing();
}
function N16(r56, e36) {
  r56().then(() => e36.fail(), () => e36()), typeof expect < "u" && expect().nothing();
}
function S11(r56, e36) {
  let t67 = typeof e36 == "string" || typeof e36 == "number" || typeof e36 == "boolean" ? [e36] : e36;
  return y(r56) || y(r56[0]) || y(e36) || y(e36[0]) ? c30(r56, t67, (n67, o80) => n67 == o80) : c30(r56, e36, (n67, o80) => u30(n67, o80, 0));
}
function C8(r56, e36, t67) {
  if (t67 == null && (t67 = d13()), !u30(r56, e36, t67)) throw new Error(`Numbers differ: actual === ${r56}, expected === ${e36}`);
  typeof expect < "u" && expect().nothing();
}
function u30(r56, e36, t67) {
  return !isFinite(r56) && !isFinite(e36) ? true : !(isNaN(r56) || isNaN(e36) || Math.abs(r56 - e36) > t67);
}
function P9(r56, e36, t67) {
  for (let n67 = 0; n67 < r56.length; n67++) if (r56[n67] < e36 || r56[n67] > t67) throw new Error(`Value out of range:${r56[n67]} low: ${e36}, high: ${t67}`);
}
function v14(r56, e36) {
  let t67 = new Float32Array(r56), n67 = new Float32Array(e36);
  if (t67.length !== n67.length) throw new Error(`Expected ArrayBuffer to be of length ${n67.length}, but it was ${t67.length}`);
  for (let o80 = 0; o80 < n67.length; o80++) if (t67[o80] !== n67[o80]) throw new Error(`Expected ArrayBuffer value at ${o80} to be ${n67[o80]} but got ${t67[o80]} instead`);
}
function w16(r56) {
  for (let e36 = 0; e36 < r56.length; e36++) {
    let t67 = r56[e36];
    Array.isArray(t67) ? w16(t67) : r56[e36] = m4(t67);
  }
  return r56;
}
function I12(r56) {
  let e36 = document.createElement("video");
  return "playsInline" in e36 && (e36.playsInline = true), e36.muted = true, e36.loop = true, e36.style.position = "fixed", e36.style.left = "0px", e36.style.top = "0px", e36.preload = "auto", e36.appendChild(r56), new Promise((t67) => {
    e36.addEventListener("loadeddata", (n67) => t67(e36)), e36.load();
  });
}
async function q7(r56) {
  await r56.play(), "requestVideoFrameCallback" in r56 && await new Promise((e36) => {
    r56.requestVideoFrameCallback(e36);
  });
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/rand_util.mjs
var o10 = class {
  constructor(t67, n67, r56, e36, a71) {
    this.mean = t67, this.stdDev = n67, this.dtype = r56, this.nextVal = NaN, this.truncated = e36, this.truncated && (this.upper = this.mean + this.stdDev * 2, this.lower = this.mean - this.stdDev * 2);
    let i88 = a71 || Math.random();
    this.random = qn(i88.toString());
  }
  nextValue() {
    if (!isNaN(this.nextVal)) {
      let e36 = this.nextVal;
      return this.nextVal = NaN, e36;
    }
    let t67, n67, r56 = false;
    for (; !r56; ) {
      let e36, a71, i88;
      do
        e36 = 2 * this.random() - 1, a71 = 2 * this.random() - 1, i88 = e36 * e36 + a71 * a71;
      while (i88 >= 1 || i88 === 0);
      let u86 = Math.sqrt(-2 * Math.log(i88) / i88);
      t67 = this.mean + this.stdDev * e36 * u86, n67 = this.mean + this.stdDev * a71 * u86, (!this.truncated || this.isValidTruncated(t67)) && (r56 = true);
    }
    return (!this.truncated || this.isValidTruncated(n67)) && (this.nextVal = this.convertValue(n67)), this.convertValue(t67);
  }
  convertValue(t67) {
    return this.dtype == null || this.dtype === "float32" ? t67 : Math.round(t67);
  }
  isValidTruncated(t67) {
    return t67 <= this.upper && t67 >= this.lower;
  }
};
var c31 = class {
  constructor(t67, n67, r56, e36) {
    this.alpha = t67, this.beta = 1 / n67, this.dtype = r56;
    let a71 = e36 || Math.random();
    this.randu = qn(a71.toString()), this.randn = new o10(0, 1, r56, false, this.randu()), t67 < 1 ? this.d = t67 + 2 / 3 : this.d = t67 - 1 / 3, this.c = 1 / Math.sqrt(9 * this.d);
  }
  nextValue() {
    let t67, n67, r56, e36, a71, i88;
    for (; ; ) {
      do
        e36 = this.randn.nextValue(), i88 = 1 + this.c * e36;
      while (i88 <= 0);
      if (i88 *= i88 * i88, t67 = e36 * e36, n67 = 1 - 0.331 * t67 * t67, r56 = 0.5 * t67 + this.d * (1 - i88 + Math.log(i88)), a71 = this.randu(), a71 < n67 || Math.log(a71) < r56) break;
    }
    return i88 = 1 / this.beta * this.d * i88, this.alpha < 1 && (i88 *= Math.pow(this.randu(), 1 / this.alpha)), this.convertValue(i88);
  }
  convertValue(t67) {
    return this.dtype === "float32" ? t67 : Math.round(t67);
  }
};
var f24 = class {
  constructor(t67 = 0, n67 = 1, r56, e36) {
    if (this.canReturnFloat = () => this.dtype == null || this.dtype === "float32", this.min = t67, this.range = n67 - t67, this.dtype = r56, e36 == null && (e36 = Math.random()), typeof e36 == "number" && (e36 = e36.toString()), !this.canReturnFloat() && this.range <= 1) throw new Error(`The difference between ${t67} - ${n67} <= 1 and dtype is not float`);
    this.random = qn(e36);
  }
  convertValue(t67) {
    return this.canReturnFloat() ? t67 : Math.round(t67);
  }
  nextValue() {
    return this.convertValue(this.min + this.range * this.random());
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/random_gamma.mjs
function c32(a71, t67, r56 = 1, o80 = "float32", f85) {
  if (rr(a71), r56 == null && (r56 = 1), o80 == null && (o80 = "float32"), o80 !== "float32" && o80 !== "int32") throw new Error(`Unsupported data type ${o80}`);
  let i88 = new c31(t67, r56, o80, f85), n67 = i7(a71, o80);
  for (let m96 = 0; m96 < n67.values.length; m96++) n67.values[m96] = i88.nextValue();
  return n67.toTensor();
}
var p33 = u4({ randomGamma_: c32 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/random_normal.mjs
function c33(e36, t67 = 0, s84 = 1, o80, a71) {
  if (rr(e36), o80 != null && o80 === "bool") throw new Error(`Unsupported data type ${o80}`);
  let m96 = new o10(t67, s84, o80, false, a71), r56 = i7(e36, o80);
  for (let n67 = 0; n67 < r56.values.length; n67++) r56.values[n67] = m96.nextValue();
  return r56.toTensor();
}
var w17 = u4({ randomNormal_: c33 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/random_standard_normal.mjs
function t4(o80, r56, a71) {
  if (r56 != null && r56 === "bool") throw new Error(`Unsupported data type ${r56}`);
  return w17(o80, 0, 1, r56, a71);
}
var f25 = u4({ randomStandardNormal_: t4 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/random_uniform.mjs
function p34(n67, t67 = 0, e36 = 1, m96 = "float32", f85) {
  rr(n67);
  let o80 = i7(n67, m96), i88 = new f24(t67, e36, null, f85);
  for (let r56 = 0; r56 < o80.values.length; r56++) o80.values[r56] = i88.nextValue();
  return o80.toTensor();
}
var U6 = u4({ randomUniform_: p34 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/random_uniform_int.mjs
function f26(o80, n67, r56, m96) {
  return U6(o80, n67, r56, "int32", m96);
}
var d14 = u4({ randomUniformInt_: f26 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/range.mjs
function p35(o80, n67, r56 = 1, t67 = "float32") {
  if (r56 === 0) throw new Error("Cannot have a step of zero");
  let e36 = { start: o80, stop: n67, step: r56, dtype: t67 };
  return v3.runKernel(St, {}, e36);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/real.mjs
function i17(r56) {
  let o80 = { input: S5(r56, "input", "real") };
  return v3.runKernel(gt, o80);
}
var s21 = u4({ real_: i17 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/reciprocal.mjs
function e14(r56) {
  let o80 = { x: S5(r56, "x", "reciprocal") };
  return v3.runKernel(Dt, o80);
}
var x33 = u4({ reciprocal_: e14 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/relu.mjs
function u31(r56) {
  let o80 = { x: S5(r56, "x", "relu") };
  return v3.runKernel(mt, o80);
}
var s22 = u4({ relu_: u31 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/relu6.mjs
function u32(r56) {
  let o80 = { x: S5(r56, "x", "relu6") };
  return v3.runKernel(Nt, o80);
}
var s23 = u4({ relu6_: u32 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/reverse.mjs
function p36(r56, e36) {
  let o80 = { x: S5(r56, "x", "reverse") }, t67 = { dims: e36 };
  return v3.runKernel(Ct, o80, t67);
}
var E21 = u4({ reverse_: p36 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/reverse_1d.mjs
function m23(o80) {
  let r56 = S5(o80, "x", "reverse");
  return c(r56.rank === 1, () => `Error in reverse1D: x must be rank 1 but got rank ${r56.rank}.`), E21(r56, 0);
}
var u33 = u4({ reverse1d_: m23 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/reverse_2d.mjs
function i18(o80, t67) {
  let r56 = S5(o80, "x", "reverse");
  return c(r56.rank === 2, () => `Error in reverse2D: x must be rank 2 but got rank ${r56.rank}.`), E21(r56, t67);
}
var v15 = u4({ reverse2d_: i18 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/reverse_3d.mjs
function i19(o80, t67) {
  let r56 = S5(o80, "x", "reverse");
  return c(r56.rank === 3, () => `Error in reverse3D: x must be rank 3 but got rank ${r56.rank}.`), E21(r56, t67);
}
var v16 = u4({ reverse3d_: i19 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/reverse_4d.mjs
function i20(o80, t67) {
  let r56 = S5(o80, "x", "reverse");
  return c(r56.rank === 4, () => `Error in reverse4D: x must be rank 4 but got rank ${r56.rank}.`), E21(r56, t67);
}
var v17 = u4({ reverse4d_: i20 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/round.mjs
function p37(o80) {
  let r56 = { x: S5(o80, "x", "round") };
  return v3.runKernel(vt, r56);
}
var x34 = u4({ round_: p37 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/rsqrt.mjs
function p38(r56) {
  let o80 = { x: S5(r56, "x", "rsqrt", "float32") };
  return v3.runKernel(Ft, o80);
}
var q8 = u4({ rsqrt_: p38 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/selu.mjs
function s24(o80) {
  let r56 = { x: S5(o80, "x", "selu") };
  return v3.runKernel(Gt, r56);
}
var l23 = u4({ selu_: s24 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/separable_conv2d.mjs
function E22(u86, b58, f85, m96, C28, v42 = [1, 1], i88 = "NHWC") {
  let t67 = S5(u86, "x", "separableConv2d"), s84 = S5(b58, "depthwiseFilter", "separableConv2d"), e36 = S5(f85, "pointwiseFilter", "separableConv2d"), n67 = t67, p103 = false;
  if (t67.rank === 3 && (p103 = true, n67 = h9(t67, [1, t67.shape[0], t67.shape[1], t67.shape[2]])), i88 === "NCHW") throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
  c(n67.rank === 4, () => `Error in separableConv2d: input must be rank 4, but got rank ${n67.rank}.`), c(s84.rank === 4, () => `Error in separableConv2d: depthwise filter must be rank 4, but got rank ${s84.rank}.`), c(e36.rank === 4, () => `Error in separableConv2d: pointwise filter must be rank 4, but got rank ${s84.rank}.`), c(e36.shape[0] === 1, () => `Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${e36.shape[0]}.`), c(e36.shape[1] === 1, () => `Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${e36.shape[1]}.`);
  let l80 = s84.shape[2], d55 = s84.shape[3];
  c(e36.shape[2] === l80 * d55, () => `Error in separableConv2d: the third dimension of pointwise filter must be ${l80 * d55}, but got ${e36.shape[2]}.`);
  let c103 = g11(n67, s84, m96, C28, i88, v42), o80 = C5(c103, e36, 1, "valid", i88);
  return p103 ? h9(o80, [o80.shape[1], o80.shape[2], o80.shape[3]]) : o80;
}
var T16 = u4({ separableConv2d_: E22 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/setdiff1d_async.mjs
async function h20(l80, c103) {
  let e36 = S5(l80, "x", "setdiff1d"), s84 = S5(c103, "y", "setdiff1d");
  c(e36.dtype === s84.dtype, () => `x and y should have the same dtype, but got x (${e36.dtype}) and y (${s84.dtype}).`), c(e36.rank === 1, () => `x should be 1D tensor, but got x (${e36.shape}).`), c(s84.rank === 1, () => `y should be 1D tensor, but got y (${s84.shape}).`);
  let o80 = await e36.data(), p103 = await s84.data(), d55 = new Set(p103), a71 = 0;
  for (let t67 = 0; t67 < o80.length; t67++) d55.has(o80[t67]) || a71++;
  let i88 = new p8([a71], e36.dtype), f85 = new p8([a71], "int32");
  for (let t67 = 0, r56 = 0; t67 < o80.length; t67++) d55.has(o80[t67]) || (i88.values[r56] = o80[t67], f85.values[r56] = t67, r56++);
  return [i88.toTensor(), f85.toTensor()];
}
var b19 = h20;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sign.mjs
function s25(o80) {
  let n67 = { x: S5(o80, "x", "sign") };
  return v3.runKernel(qt, n67);
}
var g19 = u4({ sign_: s25 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sin.mjs
function s26(o80) {
  let n67 = { x: S5(o80, "x", "sin", "float32") };
  return v3.runKernel(ft, n67);
}
var u34 = u4({ sin_: s26 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sinh.mjs
function s27(o80) {
  let n67 = { x: S5(o80, "x", "sinh") };
  return v3.runKernel(It, n67);
}
var h21 = u4({ sinh_: s27 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/slice1d.mjs
function a19(t67, e36, s84) {
  let r56 = S5(t67, "x", "slice1d");
  return c(r56.rank === 1, () => `slice1d expects a rank-1 tensor, but got a rank-${r56.rank} tensor`), E10(r56, [e36], [s84]);
}
var f27 = u4({ slice1d_: a19 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/slice2d.mjs
function a20(t67, e36, s84) {
  let r56 = S5(t67, "x", "slice2d");
  return c(r56.rank === 2, () => `slice2d expects a rank-2 tensor, but got a rank-${r56.rank} tensor`), E10(r56, e36, s84);
}
var f28 = u4({ slice2d_: a20 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/slice3d.mjs
function a21(t67, e36, s84) {
  let r56 = S5(t67, "x", "slice3d");
  return c(r56.rank === 3, () => `slice3d expects a rank-3 tensor, but got a rank-${r56.rank} tensor`), E10(r56, e36, s84);
}
var f29 = u4({ slice3d_: a21 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/slice4d.mjs
function a22(t67, e36, s84) {
  let r56 = S5(t67, "x", "slice4d");
  return c(r56.rank === 4, () => `slice4d expects a rank-4 tensor, but got a rank-${r56.rank} tensor`), E10(r56, e36, s84);
}
var f30 = u4({ slice4d_: a22 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/softmax.mjs
function e15(r56, o80 = -1) {
  let t67 = S5(r56, "logits", "softmax", "float32");
  if (o80 === -1 && (o80 = t67.rank - 1), o80 !== t67.rank - 1) throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${t67.rank} and dim was ${o80}`);
  let n67 = { logits: t67 }, s84 = { dim: o80 };
  return v3.runKernel(Ot, n67, s84);
}
var g20 = u4({ softmax_: e15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/spectral/fft.mjs
function p39(t67) {
  c(t67.dtype === "complex64", () => `The dtype for tf.spectral.fft() must be complex64 but got ${t67.dtype}.`);
  let o80 = { input: t67 };
  return v3.runKernel(po, o80);
}
var l24 = u4({ fft_: p39 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/spectral/ifft.mjs
function p40(t67) {
  c(t67.dtype === "complex64", () => `The dtype for tf.spectral.ifft() must be complex64 but got ${t67.dtype}.`);
  let o80 = { input: t67 };
  return v3.runKernel(Ro, o80);
}
var l25 = u4({ ifft_: p40 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/spectral/irfft.mjs
function d15(r56) {
  let t67 = r56.shape[r56.shape.length - 1], e36 = r56.size / t67, o80;
  if (t67 <= 2) {
    let m96 = h9(r56, [e36, t67]);
    o80 = l25(m96);
  } else {
    let m96 = [e36, 2 * (t67 - 1)], s84 = h9(s21(r56), [e36, t67]), p103 = h9(a16(r56), [e36, t67]), h74 = E21(E10(s84, [0, 1], [e36, t67 - 2]), 1), g72 = y8(E21(E10(p103, [0, 1], [e36, t67 - 2]), 1), m21(-1)), x76 = E9([s84, h74], 1), I44 = E9([p103, g72], 1), u86 = h9(x8(x76, I44), [m96[0], m96[1]]);
    o80 = l25(u86);
  }
  if (o80 = s21(o80), r56.rank === 3 && r56.shape[0] !== 0) {
    let m96 = o80, s84 = r56.shape[0];
    o80 = h9(o80, [s84, o80.shape[0] / s84, o80.shape[1]]), m96.dispose();
  }
  return o80;
}
var G10 = u4({ irfft_: d15 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/split.mjs
function e16(t67, o80, r56 = 0) {
  let n67 = { x: S5(t67, "x", "split") }, p103 = { numOrSizeSplits: o80, axis: r56 };
  return v3.runKernel(Ut, n67, p103);
}
var N17 = u4({ split_: e16 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/spectral/rfft.mjs
function M5(o80, s84) {
  c(o80.dtype === "float32", () => `The dtype for rfft() must be real value but got ${o80.dtype}`);
  let e36 = o80.shape[o80.shape.length - 1], z32 = o80.size / e36, r56;
  if (s84 != null && s84 < e36) {
    let m96 = o80.shape.map((n67) => 0), t67 = o80.shape.map((n67) => n67);
    t67[o80.shape.length - 1] = s84, r56 = E10(o80, m96, t67), e36 = s84;
  } else if (s84 != null && s84 > e36) {
    let m96 = o80.shape.map((t67) => t67);
    m96[o80.shape.length - 1] = s84 - e36, r56 = E9([o80, e13(m96)], o80.shape.length - 1), e36 = s84;
  } else r56 = o80;
  let d55 = k11(r56), x76 = h9(x8(r56, d55), [z32, e36]), l80 = l24(x76), a71 = Math.floor(e36 / 2) + 1, p103 = s21(l80), c103 = a16(l80), b58 = N17(p103, [a71, e36 - a71], p103.shape.length - 1), u86 = N17(c103, [a71, e36 - a71], c103.shape.length - 1), h74 = r56.shape.slice();
  return h74[r56.shape.length - 1] = a71, h9(x8(b58[0], u86[0]), h74);
}
var K8 = u4({ rfft_: M5 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/squared_difference.mjs
function u35(t67, a71) {
  let e36 = S5(t67, "a", "squaredDifference"), r56 = S5(a71, "b", "squaredDifference");
  [e36, r56] = m6(e36, r56), u14(e36.shape, r56.shape);
  let f85 = { a: e36, b: r56 }, n67 = {};
  return v3.runKernel(_t, f85, n67);
}
var T17 = u4({ squaredDifference_: u35 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/squeeze.mjs
function m24(o80, r56) {
  let e36 = S5(o80, "x", "squeeze", "string_or_numeric");
  return h9(e36, G(e36.shape, r56).newShape);
}
var a23 = u4({ squeeze_: m24 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/stack.mjs
function f31(s84, o80 = 0) {
  let t67 = j5(s84, "tensors", "stack", "string_or_numeric");
  c(t67.length >= 1, () => "Pass at least one tensor to tf.stack"), t67.length > 0 && c(o80 <= t67[0].rank, () => "Axis must be <= rank of the tensor");
  let n67 = t67, e36 = { axis: o80 };
  return v3.runKernel(st, n67, e36);
}
var g21 = u4({ stack_: f31 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/step.mjs
function c34(t67, o80 = 0) {
  let r56 = { x: S5(t67, "x", "step") }, n67 = { alpha: o80 };
  return v3.runKernel(ue, r56, n67);
}
var N18 = u4({ step_: c34 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/strided_slice.mjs
function S12(r56, t67, o80, i88, e36 = 0, n67 = 0, c103 = 0, s84 = 0, m96 = 0) {
  let d55 = { x: S5(r56, "x", "stridedSlice", "string_or_numeric") }, p103 = { begin: t67, end: o80, strides: i88, beginMask: e36, endMask: n67, ellipsisMask: c103, newAxisMask: s84, shrinkAxisMask: m96 };
  return v3.runKernel(Qt, d55, p103);
}
var a24 = u4({ stridedSlice_: S12 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tan.mjs
function e17(o80) {
  let t67 = { x: S5(o80, "x", "tan", "float32") };
  return v3.runKernel(ee, t67);
}
var x35 = u4({ tan_: e17 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tensor1d.mjs
function m25(r56, e36) {
  T(r56);
  let o80 = w7(r56, e36);
  if (o80.length !== 1) throw new Error("tensor1d() requires values to be a flat/TypedArray");
  return G3(r56, null, o80, e36);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tensor2d.mjs
function h22(o80, r56, n67) {
  if (T(o80), r56 != null && r56.length !== 2) throw new Error("tensor2d() requires shape to have two numbers");
  let e36 = w7(o80, n67);
  if (e36.length !== 2 && e36.length !== 1) throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
  if (e36.length === 1 && r56 == null) throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
  return G3(o80, r56, e36, n67);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tensor3d.mjs
function s28(o80, r56, n67) {
  if (T(o80), r56 != null && r56.length !== 3) throw new Error("tensor3d() requires shape to have three numbers");
  let e36 = w7(o80, n67);
  if (e36.length !== 3 && e36.length !== 1) throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
  if (e36.length === 1 && r56 == null) throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
  return G3(o80, r56, e36, n67);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tensor4d.mjs
function u36(o80, r56, n67) {
  if (T(o80), r56 != null && r56.length !== 4) throw new Error("tensor4d() requires shape to have four numbers");
  let e36 = w7(o80, n67);
  if (e36.length !== 4 && e36.length !== 1) throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
  if (e36.length === 1 && r56 == null) throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
  return G3(o80, r56, e36, n67);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tensor5d.mjs
function h23(o80, r56, n67) {
  if (T(o80), r56 != null && r56.length !== 5) throw new Error("tensor5d() requires shape to have five numbers");
  let e36 = w7(o80, n67);
  if (e36.length !== 5 && e36.length !== 1) throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
  if (e36.length === 1 && r56 == null) throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
  return G3(o80, r56, e36, n67);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tensor6d.mjs
function a25(o80, r56, n67) {
  if (T(o80), r56 != null && r56.length !== 6) throw new Error("tensor6d() requires shape to have six numbers");
  let e36 = w7(o80, n67);
  if (e36.length !== 6 && e36.length !== 1) throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
  if (e36.length === 1 && r56 == null) throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
  return r56 = r56 || e36, G3(o80, r56, e36, n67);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/scatter_nd_util.mjs
var scatter_nd_util_exports = {};
__export(scatter_nd_util_exports, {
  calculateShapes: () => m26,
  validateInput: () => $17,
  validateUpdateShape: () => k16
});
function k16(a71, t67, r56) {
  let n67 = t67.rank > 1 ? t67.shape[t67.rank - 1] : 1, e36 = t67.rank > 1 ? t67.rank - 1 : 1, h74 = `Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${r56.shape}, indices.shape: ${t67.shape}, shape: ${a71}, sliceDim: ${n67}, and batchDim: ${e36}.`;
  if (r56.rank < e36) throw new Error(h74 + ` update.rank < ${e36}. `);
  if (a71.length < n67 + (r56.rank - e36)) throw new Error(h74 + ` Output shape length < ${n67 + (r56.rank - e36)}`);
  if (r56.rank !== e36 + a71.length - n67) throw new Error(h74 + ` update.rank != ${e36 + a71.length - n67}`);
  for (let o80 = 0; o80 < e36; ++o80) if (r56.shape[o80] !== t67.shape[o80]) throw new Error(h74 + ` updates.shape[${o80}] (${r56.shape[o80]}) != indices.shape[${o80}] (${t67.shape[o80]}).`);
  for (let o80 = 0; o80 < r56.rank - e36; ++o80) if (r56.shape[o80 + e36] !== a71[o80 + n67]) throw new Error(h74 + ` updates.shape[${o80 + e36}] (${r56.shape[o80 + e36]}) != shape[${o80 + e36}] (${a71[o80 + e36]})`);
}
function $17(a71, t67, r56) {
  if (t67.rank < 1) throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${t67.rank}.`);
  if (a71.rank < 1) throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${a71.rank}.`);
  if (t67.dtype !== "int32") throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${t67.dtype}`);
  if (r56.length < 1) throw new Error(`Output rank must be greater or equal to 1, but got shape: ${r56}`);
  if (r56.length === 0) {
    if (t67.size === 0) throw new Error(`Indices specified for empty output. indices shape: ${t67.shape}`);
    if (a71.size === 0) throw new Error(`Updates specified for empty output. updates shape: ${a71.shape}`);
  }
  k16(r56, t67, a71);
}
function m26(a71, t67, r56) {
  let n67 = t67.shape.length, e36 = n67 > 1 ? t67.shape[n67 - 1] : 1, h74 = r56.length, o80 = 1;
  for (let s84 = e36; s84 < h74; ++s84) o80 *= r56[s84];
  let i88 = e36 < 1 ? 1 : e36, f85 = q(t67.shape) / i88, l80 = [...Y(r56.slice(0, e36)), 1], c103 = q(r56);
  return { sliceRank: e36, numUpdates: f85, sliceSize: o80, strides: l80, outputSize: c103 };
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/tensor_scatter_update.mjs
function f32(s84, a71, p103) {
  let t67 = S5(s84, "tensor", "tensorScatterupdate"), n67 = S5(a71, "indices", "tensorScatterupdate", "int32"), e36 = S5(p103, "updates", "tensorScatterupdate");
  if ($17(e36, n67, t67.shape), t67.dtype !== e36.dtype) throw new Error(`tensor and updates must have the same dtype, instead they are ${t67.dtype} and ${e36.dtype}.`);
  let d55 = { tensor: t67, indices: n67, updates: e36 }, c103 = {};
  return v3.runKernel(Tt, d55, c103);
}
var $18 = u4({ tensorScatterUpdate_: f32 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/topk.mjs
function f33(e36, t67 = 1, n67 = true) {
  let o80 = S5(e36, "x", "topk");
  if (o80.rank === 0) throw new Error("topk() expects the input to be of rank 1 or higher");
  let r56 = o80.shape[o80.shape.length - 1];
  if (t67 < 0) throw new Error(`'k' passed to topk() must be >= 0 but got ${t67}`);
  if (t67 > r56) throw new Error(`'k' passed to topk() must be <= the last dimension (${r56}) but got ${t67}`);
  let s84 = { x: o80 }, p103 = { k: t67, sorted: n67 }, [i88, m96] = v3.runKernel(se, s84, p103);
  return { values: i88, indices: m96 };
}
var x36 = u4({ topk_: f33 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/truncated_normal.mjs
function c35(e36, n67 = 0, s84 = 1, r56, a71) {
  if (rr(e36), r56 != null && r56 === "bool") throw new Error("Unsupported data type $ { dtype }");
  let u86 = new o10(n67, s84, r56, true, a71), o80 = i7(e36, r56);
  for (let t67 = 0; t67 < o80.values.length; t67++) o80.values[t67] = u86.nextValue();
  return o80.toTensor();
}
var v18 = u4({ truncatedNormal_: c35 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/unique.mjs
function f34(t67, n67 = 0) {
  let r56 = S5(t67, "x", "unique", "string_or_numeric");
  c(r56.rank > 0, () => "The input tensor must be at least 1D");
  let o80 = { x: r56 }, e36 = { axis: n67 }, [i88, s84] = v3.runKernel(ae, o80, e36);
  return { values: i88, indices: s84 };
}
var v19 = u4({ unique_: f34 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/unsorted_segment_sum.mjs
function c36(n67, o80, t67) {
  let m96 = S5(n67, "x", "unsortedSegmentSum"), r56 = S5(o80, "segmentIds", "unsortedSegmentSum", "int32");
  c(p(t67), () => "numSegments must be of dtype int");
  let s84 = { x: m96, segmentIds: r56 }, u86 = { numSegments: t67 };
  return v3.runKernel(ie, s84, u86);
}
var N19 = u4({ unsortedSegmentSum_: c36 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/unstack.mjs
function u37(r56, n67 = 0) {
  let t67 = S5(r56, "x", "unstack", "string_or_numeric");
  c(n67 >= -t67.shape.length && n67 < t67.shape.length, () => `Axis = ${n67} is not in [-${t67.shape.length}, ${t67.shape.length})`);
  let e36 = { value: t67 }, s84 = { axis: n67 };
  return v3.runKernel(xe, e36, s84);
}
var g22 = u4({ unstack_: u37 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/upper_bound.mjs
function n12(r56, o80) {
  return T12(r56, o80, "right");
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/variable.mjs
function m27(r56, e36 = true, a71, t67) {
  return v3.makeVariable(r56, e36, a71, t67);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/backends/where_impl.mjs
function c37(n67, o80) {
  let e36 = [];
  for (let t67 = 0; t67 < o80.length; t67++) o80[t67] && e36.push(t67);
  let r56 = i7(n67, "int32"), f85 = i7([e36.length, n67.length], "int32");
  for (let t67 = 0; t67 < e36.length; t67++) {
    let s84 = r56.indexToLoc(e36[t67]), l80 = t67 * n67.length;
    f85.values.set(s84, l80);
  }
  return f85.toTensor();
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/where_async.mjs
async function c38(e36) {
  let o80 = S5(e36, "condition", "whereAsync", "bool"), n67 = await o80.data(), r56 = c37(o80.shape, n67);
  return e36 !== o80 && o80.dispose(), r56;
}
var p41 = c38;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/boolean_mask.mjs
async function g23(i88, c103, p103) {
  let e36 = S5(i88, "tensor", "boolMask"), o80 = S5(c103, "mask", "boolMask", "bool"), s84 = p103 ?? 0, t67 = o80.rank, n67 = e36.shape;
  c(t67 > 0, () => "mask cannot be scalar"), k(n67.slice(s84, s84 + t67), o80.shape, "mask's shape must match the first K dimensions of tensor's shape,");
  let m96 = 1;
  for (let r56 = s84; r56 < s84 + t67; r56++) m96 *= n67[r56];
  let b58 = n67.slice(0, s84).concat([m96], n67.slice(s84 + t67)), l80 = h9(e36, b58), h74 = h9(o80, [-1]), f85 = await p41(h74), d55 = a23(f85, [1]), M30 = E15(l80, d55, s84);
  return i88 !== e36 && e36.dispose(), c103 !== o80 && o80.dispose(), d55.dispose(), l80.dispose(), h74.dispose(), f85.dispose(), M30;
}
var q9 = g23;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/transpose.mjs
function h24(a71, t67, p103) {
  let r56 = S5(a71, "x", "transpose");
  if (t67 == null && (t67 = r56.shape.map((o80, n67) => n67).reverse()), c(r56.rank === t67.length, () => `Error in transpose: rank of input ${r56.rank} must match length of perm ${t67}.`), t67.forEach((o80) => {
    c(o80 >= 0 && o80 < r56.rank, () => `All entries in 'perm' must be between 0 and ${r56.rank - 1} but got ${t67}`);
  }), r56.rank <= 1) return r56.clone();
  let l80 = { x: r56 }, e36 = { perm: t67 };
  return r56.dtype === "complex64" ? g4(() => {
    let o80 = s21(r56), n67 = a16(r56);
    return o80 = v3.runKernel(ce, { x: o80 }, e36), n67 = v3.runKernel(ce, { x: n67 }, e36), p103 && (n67 = g14(n67)), x8(o80, n67);
  }) : v3.runKernel(ce, l80, e36);
}
var A10 = u4({ transpose_: h24 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/moving_average.mjs
function T18(p103, v42, u86, s84, c103 = true) {
  let r56 = S5(p103, "v", "movingAverage"), t67 = S5(v42, "x", "movingAverage"), a71 = S5(u86, "decay", "movingAverage");
  T5(r56, t67), c(w(r56.shape, t67.shape), () => "Shape mismatch in v and x");
  let n67 = m21(1), g72 = E16(n67, a71), i88 = y8(E16(t67, r56), g72);
  if (c103) {
    c(s84 != null, () => "When using zeroDebias: true, step is required.");
    let f85 = S5(s84, "step", "movingAverage");
    i88 = D6(i88, E16(n67, x22(a71, f85)));
  }
  return T7(r56, i88);
}
var _9 = u4({ movingAverage_: T18 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/scatter_nd.mjs
function N20(s84, i88, t67) {
  rr(t67);
  let r56 = S5(s84, "indices", "scatterND", "int32"), o80 = S5(i88, "updates", "scatterND");
  $17(o80, r56, t67);
  let c103 = { indices: r56, updates: o80 }, a71 = { shape: t67 };
  return v3.runKernel(Pt, c103, a71);
}
var I13 = u4({ scatterND_: N20 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sparse_to_dense_util.mjs
function u38(t67, e36, r56, h74) {
  if (t67.dtype !== "int32") throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${t67.dtype}.`);
  if (t67.rank > 2) throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${t67.shape}.`);
  let o80 = t67.rank > 0 ? t67.shape[0] : 1, n67 = t67.rank > 1 ? t67.shape[1] : 1;
  if (r56.length !== n67) throw new Error(`outputShape has incorrect number of elements:, ${r56.length}, should be: ${n67}.`);
  let a71 = e36.size;
  if (!(e36.rank === 0 || e36.rank === 1 && a71 === o80)) throw new Error(`sparseValues has incorrect shape ${e36.shape}, should be [] or [${o80}]`);
  if (e36.dtype !== h74.dtype) throw new Error("sparseValues.dtype must match defaultValues.dtype");
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sparse_to_dense.mjs
function T19(a71, p103, s84, i88 = 0) {
  rr(s84);
  let n67 = S5(a71, "sparseIndices", "sparseToDense", "int32"), e36 = S5(p103, "sparseValues", "sparseToDense", "string_or_numeric"), o80 = S5(i88, "defaultValue", "sparseToDense", e36.dtype);
  u38(n67, e36, s84, o80);
  let m96 = { sparseIndices: n67, sparseValues: e36, defaultValue: o80 }, c103 = { outputShape: s84 };
  return v3.runKernel(Zt, m96, c103);
}
var g24 = u4({ sparseToDense_: T19 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/gather_nd.mjs
function m28(t67, o80) {
  let n67 = S5(o80, "indices", "gatherND", "int32"), e36 = { params: S5(t67, "x", "gatherND", "string_or_numeric"), indices: n67 };
  return v3.runKernel(So, e36);
}
var h25 = u4({ gatherND_: m28 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/dropout_util.mjs
function n13(t67, l80) {
  if (l80 == null) return t67.shape.slice();
  if (w(t67.shape, l80)) return l80;
  if (t67.shape.length === l80.length) {
    let u86 = [];
    for (let r56 = 0; r56 < t67.shape.length; r56++) l80[r56] == null && t67.shape[r56] != null ? u86.push(t67.shape[r56]) : u86.push(l80[r56]);
    return u86;
  }
  return l80;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/dropout.mjs
function $19(i88, t67, n67, m96) {
  let o80 = S5(i88, "x", "dropout");
  if (c(o80.dtype === "float32", () => `x has to be a floating point tensor since it's going to be scaled, but got a ${o80.dtype} tensor instead.`), c(t67 >= 0 && t67 < 1, () => `rate must be a float in the range [0, 1), but got ${t67}.`), t67 === 0) return i88 instanceof o5 ? o80.clone() : o80;
  let s84 = n13(o80, n67), e36 = 1 - t67, p103 = D6(x24(T7(U6(s84, 0, 1, "float32", m96), e36)), e36);
  return y8(o80, p103);
}
var _10 = u4({ dropout_: $19 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/signal_ops_util.mjs
function f35(o80) {
  return Math.floor(Math.pow(2, Math.ceil(Math.log(o80) / Math.log(2))));
}
function M6(o80, e36, a71) {
  let n67 = 1 - o80 % 2, r56 = new Float32Array(o80);
  for (let t67 = 0; t67 < o80; ++t67) {
    let c103 = 2 * Math.PI * t67 / (o80 + n67 - 1);
    r56[t67] = e36 - a71 * Math.cos(c103);
  }
  return m25(r56, "float32");
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/in_top_k.mjs
async function v20(c103, h74, o80 = 1) {
  let t67 = S5(c103, "predictions", "inTopK"), s84 = S5(h74, "targets", "inTopK");
  c(t67.rank > 1, () => `inTopK() expects the predictions to be of rank 2 or higher, but got ${t67.rank}`), c(t67.rank - 1 === s84.rank, () => `predictions rank should be 1 larger than targets rank, but got predictions rank ${t67.rank} and targets rank ${s84.rank}`), k(t67.shape.slice(0, t67.shape.length - 1), s84.shape, "predictions's shape should be align with the targets' shape, except the last dimension.");
  let a71 = t67.shape[t67.shape.length - 1];
  c(o80 > 0 && o80 <= a71, () => `'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${a71}), but got ${o80}`);
  let l80 = await t67.data(), m96 = await s84.data(), [d55, g72] = [l80.length / a71, a71], r56 = O("bool", d55);
  for (let n67 = 0; n67 < d55; n67++) {
    let b58 = n67 * g72, f85 = l80.subarray(b58, b58 + g72), i88 = [];
    for (let e36 = 0; e36 < f85.length; e36++) i88.push({ value: f85[e36], index: e36 });
    i88.sort((e36, k63) => k63.value - e36.value), r56[n67] = 0;
    for (let e36 = 0; e36 < o80; e36++) if (i88[e36].index === m96[n67]) {
      r56[n67] = 1;
      break;
    }
  }
  return c103 !== t67 && t67.dispose(), h74 !== s84 && s84.dispose(), p10(r56, s84.shape, "bool");
}
var w18 = v20;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/fused_ops.mjs
var fused_ops_exports = {};
__export(fused_ops_exports, {
  conv2d: () => lt3,
  depthwiseConv2d: () => ie2,
  matMul: () => ie3
});

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/conv2d_backprop_filter.mjs
function E23(e36, s84, t67, m96, p103, i88 = "NHWC", u86) {
  let o80 = e36;
  e36.rank === 3 && (o80 = h9(e36, [1, e36.shape[0], e36.shape[1], e36.shape[2]]));
  let r56 = s84;
  r56.rank === 3 && (r56 = h9(s84, [1, s84.shape[0], s84.shape[1], s84.shape[2]])), c(o80.rank === 4, () => `Error in conv2dDerFilter: input must be rank 4, but got shape ${o80.shape}.`), c(r56.rank === 4, () => `Error in conv2dDerFilter: dy must be rank 4, but got shape ${r56.shape}.`), c(t67.length === 4, () => `Error in conv2dDerFilter: filterShape must be length 4, but got ${t67}.`);
  let a71 = i88 === "NHWC" ? o80.shape[3] : o80.shape[1], c103 = i88 === "NHWC" ? r56.shape[3] : r56.shape[1];
  c(a71 === t67[2], () => `Error in conv2dDerFilter: depth of input ${a71}) must match input depth in filter (${t67[2]}.`), c(c103 === t67[3], () => `Error in conv2dDerFilter: depth of dy (${c103}) must match output depth for filter (${t67[3]}).`), z5("conv2dDerFilter", p103, u86);
  let D42 = { x: o80, dy: r56 }, v42 = { strides: m96, pad: p103, dataFormat: i88, dimRoundingMode: u86, filterShape: t67 };
  return v3.runKernel(G2, D42, v42);
}
var N21 = u4({ conv2DBackpropFilter_: E23 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/fused_util.mjs
function _11(r56, e36, o80) {
  if (o80 == null || o80 === "linear") return r56;
  if (o80 === "relu") return y8(r56, N18(e36));
  throw new Error(`Cannot compute gradient for fused activation ${o80}.`);
}
function $20(r56, e36) {
  let o80 = e36, u86 = f15(r56.shape, e36.shape);
  return u86.length > 0 && (o80 = T10(o80, u86)), h9(o80, r56.shape);
}
function b20(r56, e36, o80, u86) {
  if (e36 === "linear") return r56;
  if (e36 === "relu") return s22(r56);
  if (e36 === "elu") return s12(r56);
  if (e36 === "relu6") return s23(r56);
  if (e36 === "prelu") return x32(r56, o80);
  if (e36 === "leakyrelu") return x27(r56, u86);
  if (e36 === "sigmoid") return d6(r56);
  throw new Error(`Unknown fused activation ${e36}.`);
}
var B9 = (r56, e36) => !(r56 > 0) || e36 === "linear";

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/fused/conv2d.mjs
function X6({ x: _24, filter: w45, strides: l80, pad: d55, dataFormat: a71 = "NHWC", dilations: c103 = [1, 1], dimRoundingMode: b58, bias: $37, activation: m96 = "linear", preluActivationWeights: D42, leakyreluAlpha: H18 }) {
  if (m96 = m96 || "linear", B9(v3.state.gradientDepth, m96) === false) {
    c(a71 === "NHWC", () => `Error in fused conv2d: got dataFormat of ${a71} but only NHWC is currently supported for the case of gradient depth is 0 and the activation is not linear.`);
    let t67 = C5(_24, w45, l80, d55, a71, c103, b58);
    return $37 != null && (t67 = T7(t67, $37)), b20(t67, m96, D42, H18);
  }
  let h74 = S5(_24, "x", "conv2d", "float32"), u86 = S5(w45, "filter", "conv2d", "float32"), n67 = h74, E44 = false;
  h74.rank === 3 && (E44 = true, n67 = h9(h74, [1, h74.shape[0], h74.shape[1], h74.shape[2]])), c(n67.rank === 4, () => `Error in fused conv2d: input must be rank 4, but got rank ${n67.rank}.`), c(u86.rank === 4, () => `Error in fused conv2d: filter must be rank 4, but got rank ${u86.rank}.`), z5("fused conv2d", d55, b58);
  let O21 = a71 === "NHWC" ? n67.shape[3] : n67.shape[1];
  c(u86.shape[2] === O21, () => `Error in conv2d: depth of input (${O21}) must match input depth for filter ${u86.shape[2]}.`), c(Z6(l80, c103), () => `Error in conv2D: Either strides or dilations must be 1. Got strides ${l80} and dilations '${c103}'`);
  let f85 = V3(n67.shape, u86.shape, l80, c103, d55, b58), e36;
  $37 != null && (e36 = S5($37, "bias", "fused conv2d"), [e36] = m6(e36, h74), a71 === "NHWC" ? u14(f85.outShape, e36.shape) : (c(e36.shape.length <= 1, () => `Error in fused conv2d: only supports scalar or 1-D Tensor bias for NCHW format but got the bias of rank-${e36.shape.length}.`), c(e36.shape.length === 0 || e36.shape[0] === f85.outChannels || e36.shape[0] === 1, () => `Error in fused conv2d: bias shape (${e36.shape}) is not compatible with the number of output channels (${f85.outChannels})`)));
  let B30;
  if (D42 != null) {
    let t67 = D42.shape;
    if (c(t67.length <= 1 || t67.length === 3, () => `Error in fused conv2d: only supports scalar, 1-D Tensor or 3-D Tensor PReLU activation weights but got a tensor of rank-${t67.length}.`), t67.length === 1) c(t67[0] === 1 || t67[0] === f85.outChannels, () => `Error in fused conv2d: PReLU activation weights (${t67}) is not compatible with the number of output channels (${f85.outChannels}).`);
    else if (t67.length === 3) try {
      u14(t67, f85.outShape);
    } catch {
      let i88 = `Error in fused conv2d: PReLU activation weights (${t67}) is not compatible with the output shape of the conv2d (${f85.outShape}).`;
      throw Error(i88);
    }
    B30 = S5(D42, "prelu weights", "fused conv2d");
  }
  let G30 = (t67, v42) => {
    c(a71 === "NHWC", () => `Error in gradient of fused conv2D: got dataFormat of ${a71} but only NHWC is currently supported.`);
    let [i88, g72, o80, s84] = v42, k63 = _11(t67, o80, m96);
    c(R6(c103), () => `Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${c103}'`);
    let P36 = B8(g72.shape, k63, i88, l80, d55), L22 = N21(g72, k63, i88.shape, l80, d55), x76 = [P36, L22];
    if (s84 != null) {
      let U24 = $20(s84, k63);
      x76.push(U24);
    }
    return x76;
  }, S45 = { x: n67, filter: u86, bias: e36, preluActivationWeights: B30 }, T40 = { strides: l80, pad: d55, dataFormat: a71, dilations: c103, dimRoundingMode: b58, activation: m96, leakyreluAlpha: H18 };
  return $37 == null ? $10((v42, i88, g72) => {
    let o80 = v3.runKernel(me, S45, T40);
    return g72([i88, v42, o80]), E44 && (o80 = h9(o80, [o80.shape[1], o80.shape[2], o80.shape[3]])), { value: o80, gradFunc: G30 };
  })(n67, u86) : $10((v42, i88, g72, o80) => {
    let s84 = v3.runKernel(me, S45, T40);
    return o80([i88, v42, s84, g72]), E44 && (s84 = h9(s84, [s84.shape[1], s84.shape[2], s84.shape[3]])), { value: s84, gradFunc: G30 };
  })(n67, u86, e36);
}
var lt3 = u4({ fusedConv2d_: X6 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/depthwise_conv2d_native_backprop_filter.mjs
function k17(e36, t67, i88, a71, s84, n67 = [1, 1], h74) {
  let r56 = e36;
  e36.rank === 3 && (r56 = h9(e36, [1, e36.shape[0], e36.shape[1], e36.shape[2]]));
  let p103 = t67;
  p103.rank === 3 && (p103 = h9(t67, [1, t67.shape[0], t67.shape[1], t67.shape[2]]));
  let m96 = { x: r56, dy: p103 }, c103 = { strides: a71, pad: s84, dimRoundingMode: h74, dilations: n67, filterShape: i88 };
  return v3.runKernel(W2, m96, c103);
}
var B10 = u4({ depthwiseConv2dNativeBackpropFilter_: k17 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/depthwise_conv2d_native_backprop_input.mjs
function k18(n67, e36, s84, a71, i88, h74 = [1, 1], u86) {
  let t67 = e36, r56 = false;
  e36.rank === 3 && (r56 = true, t67 = h9(e36, [1, e36.shape[0], e36.shape[1], e36.shape[2]]));
  let c103 = { dy: t67, filter: s84 }, f85 = { strides: a71, pad: i88, dimRoundingMode: u86, dilations: h74, inputShape: n67 }, p103 = v3.runKernel(K2, c103, f85);
  return r56 ? h9(p103, [p103.shape[1], p103.shape[2], p103.shape[3]]) : p103;
}
var B11 = u4({ depthwiseConv2dNativeBackpropInput_: k18 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/fused/depthwise_conv2d.mjs
function X7({ x: O21, filter: _24, strides: p103, pad: h74, dataFormat: g72 = "NHWC", dilations: e36 = [1, 1], dimRoundingMode: f85, bias: d55, activation: C28 = "linear", preluActivationWeights: D42, leakyreluAlpha: x76 }) {
  if (B9(v3.state.gradientDepth, C28) === false) {
    let a71 = g11(O21, _24, p103, h74, g72, e36, f85);
    return d55 != null && (a71 = T7(a71, d55)), b20(a71, C28, D42, x76);
  }
  let u86 = S5(O21, "x", "depthwiseConv2d", "float32"), o80 = S5(_24, "filter", "depthwiseConv2d", "float32"), r56 = u86, k63 = false;
  u86.rank === 3 && (k63 = true, r56 = h9(u86, [1, u86.shape[0], u86.shape[1], u86.shape[2]])), c(r56.rank === 4, () => `Error in fused depthwiseConv2d: input must be rank 4, but got rank ${r56.rank}.`), c(o80.rank === 4, () => `Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${o80.rank}.`), c(r56.shape[3] === o80.shape[2], () => `Error in fused depthwiseConv2d: number of input channels (${r56.shape[3]}) must match the inChannels dimension in filter ${o80.shape[2]}.`), e36 == null && (e36 = [1, 1]), c(Z6(p103, e36), () => `Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${p103} and dilations '${e36}'`), z5("fused depthwiseConv2d", h74, f85);
  let W15 = V3(r56.shape, o80.shape, p103, e36, h74, f85, true), i88;
  d55 != null && (i88 = S5(d55, "bias", "fused conv2d"), [i88] = m6(i88, u86), u14(W15.outShape, i88.shape));
  let B30;
  D42 != null && (B30 = S5(D42, "prelu weights", "fused depthwiseConv2d"));
  let F32 = (a71, v42) => {
    c(R6(e36), () => `Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${e36}'`);
    let [l80, c103, t67, s84] = v42, $37 = _11(a71, t67, C28), A35 = B11(c103.shape, $37, l80, p103, h74, e36, f85), N58 = B10(c103, $37, l80.shape, p103, h74, e36, f85);
    if (s84 != null) {
      let K21 = $20(i88, $37);
      return [A35, N58, K21];
    }
    return [A35, N58];
  }, G30 = { x: r56, filter: o80, bias: i88, preluActivationWeights: B30 }, y43 = { strides: p103, pad: h74, dataFormat: g72, dilations: e36, dimRoundingMode: f85, activation: C28, leakyreluAlpha: x76 };
  return d55 == null ? $10((v42, l80, c103) => {
    let t67 = v3.runKernel(Re, G30, y43);
    return c103([l80, v42, t67]), k63 && (t67 = h9(t67, [t67.shape[1], t67.shape[2], t67.shape[3]])), { value: t67, gradFunc: F32 };
  })(r56, o80) : $10((v42, l80, c103, t67) => {
    let s84 = v3.runKernel(Re, G30, y43);
    return t67([l80, v42, s84, c103]), k63 && (s84 = h9(s84, [s84.shape[1], s84.shape[2], s84.shape[3]])), { value: s84, gradFunc: F32 };
  })(r56, o80, i88);
}
var ie2 = u4({ fusedDepthwiseConv2d_: X7 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/fused/mat_mul.mjs
function X8({ a: E44, b: w45, transposeA: s84 = false, transposeB: a71 = false, bias: m96, activation: M30 = "linear", preluActivationWeights: F32, leakyreluAlpha: z32 = 0.2 }) {
  if (B9(v3.state.gradientDepth, M30) === false) {
    let n67 = N6(E44, w45, s84, a71);
    return m96 != null && (n67 = T7(n67, m96)), b20(n67, M30, F32, z32);
  }
  let e36 = S5(E44, "a", "fused matMul"), t67 = S5(w45, "b", "fused matMul");
  [e36, t67] = m6(e36, t67);
  let S45 = s84 ? e36.shape[e36.rank - 2] : e36.shape[e36.rank - 1], $37 = a71 ? t67.shape[t67.rank - 1] : t67.shape[t67.rank - 2], g72 = s84 ? e36.shape[e36.rank - 1] : e36.shape[e36.rank - 2], O21 = a71 ? t67.shape[t67.rank - 2] : t67.shape[t67.rank - 1], C28 = e36.shape.slice(0, -2), H18 = t67.shape.slice(0, -2), B30 = q(C28), K21 = q(H18);
  c(S45 === $37, () => `Error in fused matMul: inner shapes (${S45}) and (${$37}) of Tensors with shapes ${e36.shape} and ${t67.shape} and transposeA=${s84} and transposeB=${a71} must match.`);
  let G30 = u14(e36.shape.slice(0, -2), t67.shape.slice(0, -2)).concat([g72, O21]), _24 = s84 ? h9(e36, [B30, S45, g72]) : h9(e36, [B30, g72, S45]), y43 = a71 ? h9(t67, [K21, O21, $37]) : h9(t67, [K21, $37, O21]), f85;
  m96 != null && (f85 = S5(m96, "bias", "fused matMul"), [f85] = m6(f85, e36), u14(G30, f85.shape));
  let N58;
  F32 != null && (N58 = S5(F32, "prelu weights", "fused matMul"));
  let W15 = (n67, d55) => {
    let [o80, l80, i88, b58] = d55, r56 = _11(h9(n67, i88.shape), i88, M30), h74, p103;
    if (!s84 && !a71 ? (h74 = N6(r56, l80, false, true), p103 = N6(o80, r56, true, false)) : !s84 && a71 ? (h74 = N6(r56, l80, false, false), p103 = N6(r56, o80, true, false)) : s84 && !a71 ? (h74 = N6(l80, r56, false, true), p103 = N6(o80, r56, false, false)) : (h74 = N6(l80, r56, true, true), p103 = N6(r56, o80, true, true)), m96 != null) {
      let J17 = $20(b58, r56);
      return [h74, p103, J17];
    } else return [h74, p103];
  }, x76 = { a: _24, b: y43, bias: f85, preluActivationWeights: N58 }, A35 = { transposeA: s84, transposeB: a71, activation: M30, leakyreluAlpha: z32 };
  return m96 == null ? $10((d55, o80, l80) => {
    let i88 = v3.runKernel(De, x76, A35);
    return l80([d55, o80, i88]), { value: h9(i88, G30), gradFunc: W15 };
  })(_24, y43) : $10((d55, o80, l80, i88) => {
    let b58 = v3.runKernel(De, x76, A35);
    return i88([d55, o80, b58, l80]), { value: h9(b58, G30), gradFunc: W15 };
  })(_24, y43, f85);
}
var ie3 = u4({ fusedMatMul_: X8 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/signal/hamming_window.mjs
function m29(o80) {
  return M6(o80, 0.54, 0.46);
}
var p42 = u4({ hammingWindow_: m29 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/signal/hann_window.mjs
function r10(n67) {
  return M6(n67, 0.5, 0.5);
}
var p43 = u4({ hannWindow_: r10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/signal/frame.mjs
function h26(r56, t67, i88, e36 = false, f85 = 0) {
  let o80 = 0, p103 = [];
  for (; o80 + t67 <= r56.size; ) p103.push(E10(r56, o80, t67)), o80 += i88;
  if (e36) for (; o80 < r56.size; ) {
    let s84 = o80 + t67 - r56.size, u86 = E9([E10(r56, o80, t67 - s84), c16([s84], f85)]);
    p103.push(u86), o80 += i88;
  }
  return p103.length === 0 ? h22([], [0, t67]) : h9(E9(p103), [p103.length, t67]);
}
var q10 = u4({ frame_: h26 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/signal/stft.mjs
function u39(i88, o80, m96, r56, n67 = p43) {
  r56 == null && (r56 = f35(o80));
  let t67 = q10(i88, o80, m96), f85 = y8(t67, n67(o80));
  return K8(f85, r56);
}
var T20 = u4({ stft_: u39 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/crop_and_resize.mjs
function g25(u86, b58, p103, s84, t67 = "bilinear", m96 = 0) {
  let n67 = S5(u86, "image", "cropAndResize"), r56 = S5(b58, "boxes", "cropAndResize", "float32"), o80 = S5(p103, "boxInd", "cropAndResize", "int32"), a71 = r56.shape[0];
  c(n67.rank === 4, () => `Error in cropAndResize: image must be rank 4,but got rank ${n67.rank}.`), c(r56.rank === 2 && r56.shape[1] === 4, () => `Error in cropAndResize: boxes must be have size [${a71},4] but had shape ${r56.shape}.`), c(o80.rank === 1 && o80.shape[0] === a71, () => `Error in cropAndResize: boxInd must be have size [${a71}] but had shape ${r56.shape}.`), c(s84.length === 2, () => `Error in cropAndResize: cropSize must be of length 2, but got length ${s84.length}.`), c(s84[0] >= 1 && s84[1] >= 1, () => `cropSize must be atleast [1,1], but was ${s84}`), c(t67 === "bilinear" || t67 === "nearest", () => `method must be bilinear or nearest, but was ${t67}`);
  let l80 = { image: n67, boxes: r56, boxInd: o80 }, c103 = { method: t67, extrapolationValue: m96, cropSize: s84 };
  return v3.runKernel(z2, l80, c103);
}
var k19 = u4({ cropAndResize_: g25 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/flip_left_right.mjs
function p44(i88) {
  let t67 = S5(i88, "image", "flipLeftRight", "float32");
  c(t67.rank === 4, () => `Error in flipLeftRight: image must be rank 4,but got rank ${t67.rank}.`);
  let o80 = { image: t67 };
  return v3.runKernel(ao, o80, {});
}
var c39 = u4({ flipLeftRight_: p44 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/grayscale_to_rgb.mjs
function m30(e36) {
  let r56 = S5(e36, "image", "grayscaleToRGB"), a71 = r56.rank - 1, t67 = r56.shape[a71];
  c(r56.rank >= 2, () => `Error in grayscaleToRGB: images must be at least rank 2, but got rank ${r56.rank}.`), c(t67 === 1, () => `Error in grayscaleToRGB: last dimension of a grayscale image should be size 1, but got size ${t67}.`);
  let o80 = new Array(r56.rank);
  return o80.fill(1, 0, a71), o80[a71] = 3, g12(r56, o80);
}
var p45 = u4({ grayscaleToRGB_: m30 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/rgb_to_grayscale.mjs
function f36(m96) {
  let a71 = S5(m96, "image", "RGBToGrayscale"), l80 = a71.rank - 1, i88 = a71.shape[l80];
  c(a71.rank >= 2, () => `Error in RGBToGrayscale: images must be at least rank 2, but got rank ${a71.rank}.`), c(i88 === 3, () => `Error in RGBToGrayscale: last dimension of an RGB image should be size 3, but got size ${i88}.`);
  let c103 = a71.dtype, o80 = w12(a71, "float32"), t67 = m25([0.2989, 0.587, 0.114]), r56;
  switch (a71.rank) {
    case 2:
      r56 = N10("ij,j->i", o80, t67);
      break;
    case 3:
      r56 = N10("ijk,k->ij", o80, t67);
      break;
    case 4:
      r56 = N10("ijkl,l->ijk", o80, t67);
      break;
    case 5:
      r56 = N10("ijklm,m->ijkl", o80, t67);
      break;
    case 6:
      r56 = N10("ijklmn,n->ijklm", o80, t67);
      break;
    default:
      throw new Error("Not a valid tensor rank.");
  }
  return r56 = D7(r56, -1), w12(r56, c103);
}
var h27 = u4({ rgbToGrayscale_: f36 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/rotate_with_offset.mjs
function c40(o80, e36, i88 = 0, s84 = 0.5) {
  let t67 = S5(o80, "image", "rotateWithOffset", "float32");
  c(t67.rank === 4, () => `Error in rotateWithOffset: image must be rank 4,but got rank ${t67.rank}.`);
  let n67 = { image: t67 }, a71 = { radians: e36, fillValue: i88, center: s84 };
  return v3.runKernel(ge, n67, a71);
}
var l26 = u4({ rotateWithOffset_: c40 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/nonmax_util.mjs
function p46(s84, u86, e36, n67, i88, a71) {
  n67 == null && (n67 = 0.5), i88 == null && (i88 = Number.NEGATIVE_INFINITY), a71 == null && (a71 = 0);
  let b58 = s84.shape[0];
  return e36 = Math.min(e36, b58), c(0 <= n67 && n67 <= 1, () => `iouThreshold must be in [0, 1], but was '${n67}'`), c(s84.rank === 2, () => `boxes must be a 2D tensor, but was of rank '${s84.rank}'`), c(s84.shape[1] === 4, () => `boxes must have 4 columns, but 2nd dimension was ${s84.shape[1]}`), c(u86.rank === 1, () => "scores must be a 1D tensor"), c(u86.shape[0] === b58, () => `scores has incompatible shape with boxes. Expected ${b58}, but was ${u86.shape[0]}`), c(0 <= a71 && a71 <= 1, () => `softNmsSigma must be in [0, 1], but was '${a71}'`), { maxOutputSize: e36, iouThreshold: n67, scoreThreshold: i88, softNmsSigma: a71 };
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/non_max_suppression.mjs
function N22(i88, c103, o80, n67 = 0.5, r56 = Number.NEGATIVE_INFINITY) {
  let p103 = S5(i88, "boxes", "nonMaxSuppression", "float32"), t67 = S5(c103, "scores", "nonMaxSuppression", "float32"), s84 = p46(p103, t67, o80, n67, r56);
  o80 = s84.maxOutputSize, n67 = s84.iouThreshold, r56 = s84.scoreThreshold;
  let m96 = { maxOutputSize: o80, iouThreshold: n67, scoreThreshold: r56 };
  return v3.runKernel(ot, { boxes: p103, scores: t67 }, m96);
}
var G11 = u4({ nonMaxSuppression_: N22 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/backends/non_max_suppression_util.mjs
function a26(t67, e36, i88) {
  let n67 = u40(t67, e36, i88), o80 = n67 < 0 ? -(n67 + 1) : n67;
  t67.splice(o80, 0, e36);
}
function u40(t67, e36, i88) {
  return s29(t67, e36, i88 || f37);
}
function f37(t67, e36) {
  return t67 > e36 ? 1 : t67 < e36 ? -1 : 0;
}
function s29(t67, e36, i88) {
  let n67 = 0, o80 = t67.length, r56 = 0, l80 = false;
  for (; n67 < o80; ) {
    r56 = n67 + (o80 - n67 >>> 1);
    let c103 = i88(e36, t67[r56]);
    c103 > 0 ? n67 = r56 + 1 : (o80 = r56, l80 = !c103);
  }
  return l80 ? n67 : -n67 - 1;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/backends/non_max_suppression_impl.mjs
function B12(o80, e36, r56, n67, t67) {
  return y10(o80, e36, r56, n67, t67, 0);
}
function V4(o80, e36, r56, n67, t67, i88) {
  return y10(o80, e36, r56, n67, t67, 0, false, i88, true);
}
function O7(o80, e36, r56, n67, t67, i88) {
  return y10(o80, e36, r56, n67, t67, i88, true);
}
function y10(o80, e36, r56, n67, t67, i88, l80 = false, f85 = false, h74 = false) {
  let c103 = [];
  for (let s84 = 0; s84 < e36.length; s84++) e36[s84] > t67 && c103.push({ score: e36[s84], boxIndex: s84, suppressBeginIndex: 0 });
  c103.sort(w19);
  let d55 = i88 > 0 ? -0.5 / i88 : 0, a71 = [], x76 = [];
  for (; a71.length < r56 && c103.length > 0; ) {
    let s84 = c103.pop(), { score: M30, boxIndex: I44, suppressBeginIndex: g72 } = s84;
    if (M30 < t67) break;
    let J17 = false;
    for (let b58 = a71.length - 1; b58 >= g72; --b58) {
      let S45 = k20(o80, I44, a71[b58]);
      if (S45 >= n67) {
        J17 = true;
        break;
      }
      if (s84.score = s84.score * v21(n67, d55, S45), s84.score <= t67) break;
    }
    s84.suppressBeginIndex = a71.length, J17 || (s84.score === M30 ? (a71.push(I44), x76.push(s84.score)) : s84.score > t67 && a26(c103, s84, w19));
  }
  let u86 = a71.length, p103 = r56 - u86;
  f85 && p103 > 0 && (a71.push(...new Array(p103).fill(0)), x76.push(...new Array(p103).fill(0)));
  let m96 = { selectedIndices: a71 };
  return l80 && (m96.selectedScores = x76), h74 && (m96.validOutputs = u86), m96;
}
function k20(o80, e36, r56) {
  let n67 = o80.subarray(e36 * 4, e36 * 4 + 4), t67 = o80.subarray(r56 * 4, r56 * 4 + 4), i88 = Math.min(n67[0], n67[2]), l80 = Math.min(n67[1], n67[3]), f85 = Math.max(n67[0], n67[2]), h74 = Math.max(n67[1], n67[3]), c103 = Math.min(t67[0], t67[2]), d55 = Math.min(t67[1], t67[3]), a71 = Math.max(t67[0], t67[2]), x76 = Math.max(t67[1], t67[3]), u86 = (f85 - i88) * (h74 - l80), p103 = (a71 - c103) * (x76 - d55);
  if (u86 <= 0 || p103 <= 0) return 0;
  let m96 = Math.max(i88, c103), s84 = Math.max(l80, d55), M30 = Math.min(f85, a71), I44 = Math.min(h74, x76), g72 = Math.max(M30 - m96, 0) * Math.max(I44 - s84, 0);
  return g72 / (u86 + p103 - g72);
}
function v21(o80, e36, r56) {
  let n67 = Math.exp(e36 * r56 * r56);
  return r56 <= o80 ? n67 : 0;
}
function w19(o80, e36) {
  return o80.score - e36.score || o80.score === e36.score && e36.boxIndex - o80.boxIndex;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/non_max_suppression_async.mjs
async function y11(c103, p103, o80, t67 = 0.5, e36 = Number.NEGATIVE_INFINITY) {
  let n67 = S5(c103, "boxes", "nonMaxSuppressionAsync"), s84 = S5(p103, "scores", "nonMaxSuppressionAsync"), r56 = p46(n67, s84, o80, t67, e36);
  o80 = r56.maxOutputSize, t67 = r56.iouThreshold, e36 = r56.scoreThreshold;
  let i88 = await Promise.all([n67.data(), s84.data()]), m96 = i88[0], x76 = i88[1], { selectedIndices: f85 } = B12(m96, x76, o80, t67, e36);
  return n67 !== c103 && n67.dispose(), s84 !== p103 && s84.dispose(), m25(f85, "int32");
}
var l27 = y11;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/non_max_suppression_with_score.mjs
function f38(m96, u86, n67, s84 = 0.5, r56 = Number.NEGATIVE_INFINITY, e36 = 0) {
  let t67 = S5(m96, "boxes", "nonMaxSuppression"), p103 = S5(u86, "scores", "nonMaxSuppression"), o80 = p46(t67, p103, n67, s84, r56, e36);
  n67 = o80.maxOutputSize, s84 = o80.iouThreshold, r56 = o80.scoreThreshold, e36 = o80.softNmsSigma;
  let x76 = { boxes: t67, scores: p103 }, a71 = { maxOutputSize: n67, iouThreshold: s84, scoreThreshold: r56, softNmsSigma: e36 }, c103 = v3.runKernel(et, x76, a71);
  return { selectedIndices: c103[0], selectedScores: c103[1] };
}
var V5 = u4({ nonMaxSuppressionWithScore_: f38 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/non_max_suppression_with_score_async.mjs
async function y12(p103, i88, e36, c103 = 0.5, r56 = Number.NEGATIVE_INFINITY, t67 = 0) {
  let s84 = S5(p103, "boxes", "nonMaxSuppressionAsync"), n67 = S5(i88, "scores", "nonMaxSuppressionAsync"), o80 = p46(s84, n67, e36, c103, r56, t67);
  e36 = o80.maxOutputSize, c103 = o80.iouThreshold, r56 = o80.scoreThreshold, t67 = o80.softNmsSigma;
  let a71 = await Promise.all([s84.data(), n67.data()]), m96 = a71[0], x76 = a71[1], { selectedIndices: l80, selectedScores: I44 } = O7(m96, x76, e36, c103, r56, t67);
  return s84 !== p103 && s84.dispose(), n67 !== i88 && n67.dispose(), { selectedIndices: m25(l80, "int32"), selectedScores: m25(I44) };
}
var N23 = y12;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/non_max_suppression_padded.mjs
function I14(t67, p103, u86, c103 = 0.5, i88 = Number.NEGATIVE_INFINITY, a71 = false) {
  let s84 = S5(t67, "boxes", "nonMaxSuppression"), e36 = S5(p103, "scores", "nonMaxSuppression"), o80 = p46(s84, e36, u86, c103, i88, null), d55 = o80.maxOutputSize, m96 = o80.iouThreshold, h74 = o80.scoreThreshold, l80 = { boxes: s84, scores: e36 }, x76 = { maxOutputSize: d55, iouThreshold: m96, scoreThreshold: h74, padToMaxOutputSize: a71 }, r56 = v3.runKernel(tt, l80, x76);
  return { selectedIndices: r56[0], validOutputs: r56[1] };
}
var z11 = u4({ nonMaxSuppressionPadded_: I14 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/non_max_suppression_padded_async.mjs
async function M7(e36, t67, a71, i88 = 0.5, c103 = Number.NEGATIVE_INFINITY, p103 = false) {
  let s84 = S5(e36, "boxes", "nonMaxSuppressionAsync"), o80 = S5(t67, "scores", "nonMaxSuppressionAsync"), n67 = p46(s84, o80, a71, i88, c103, null), d55 = n67.maxOutputSize, u86 = n67.iouThreshold, l80 = n67.scoreThreshold, [m96, x76] = await Promise.all([s84.data(), o80.data()]), { selectedIndices: f85, validOutputs: h74 } = V4(m96, x76, d55, u86, l80, p103);
  return s84 !== e36 && s84.dispose(), o80 !== t67 && o80.dispose(), { selectedIndices: m25(f85, "int32"), validOutputs: m21(h74, "int32") };
}
var b21 = M7;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/resize_bilinear.mjs
function B13(m96, s84, a71 = false, i88 = false) {
  let e36 = S5(m96, "images", "resizeBilinear");
  c(e36.rank === 3 || e36.rank === 4, () => `Error in resizeBilinear: x must be rank 3 or 4, but got rank ${e36.rank}.`), c(s84.length === 2, () => `Error in resizeBilinear: new shape must 2D, but got shape ${s84}.`), c(i88 === false || a71 === false, () => "Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.");
  let n67 = e36, o80 = false;
  e36.rank === 3 && (o80 = true, n67 = h9(e36, [1, e36.shape[0], e36.shape[1], e36.shape[2]]));
  let [] = s84, p103 = { images: n67 }, f85 = { alignCorners: a71, halfPixelCenters: i88, size: s84 }, r56 = v3.runKernel(At, p103, f85);
  return o80 ? h9(r56, [r56.shape[1], r56.shape[2], r56.shape[3]]) : r56;
}
var T21 = u4({ resizeBilinear_: B13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/resize_nearest_neighbor.mjs
function b22(m96, t67, a71 = false, o80 = false) {
  let e36 = S5(m96, "images", "resizeNearestNeighbor");
  c(e36.rank === 3 || e36.rank === 4, () => `Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${e36.rank}.`), c(t67.length === 2, () => `Error in resizeNearestNeighbor: new shape must 2D, but got shape ${t67}.`), c(e36.dtype === "float32" || e36.dtype === "int32", () => "`images` must have `int32` or `float32` as dtype"), c(o80 === false || a71 === false, () => "Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.");
  let i88 = e36, n67 = false;
  e36.rank === 3 && (n67 = true, i88 = h9(e36, [1, e36.shape[0], e36.shape[1], e36.shape[2]]));
  let [] = t67, h74 = { images: i88 }, f85 = { alignCorners: a71, halfPixelCenters: o80, size: t67 }, r56 = v3.runKernel(ht, h74, f85);
  return n67 ? h9(r56, [r56.shape[1], r56.shape[2], r56.shape[3]]) : r56;
}
var y13 = u4({ resizeNearestNeighbor_: b22 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/threshold.mjs
function D9(m96, n67 = "binary", l80 = false, p103 = 0.5) {
  let t67 = S5(m96, "image", "threshold"), r56 = 0.2989, e36 = 0.587, u86 = 0.114, f85 = t67.shape[0] * t67.shape[1], a71 = y8(m25([p103]), 255), d55, s84, E44, i88;
  if (c(t67.rank === 3, () => `Error in threshold: image must be rank 3,but got rank ${t67.rank}.`), c(t67.shape[2] === 3 || t67.shape[2] === 1, () => `Error in threshold: image color channel must be equal to 3 or 1but got ${t67.shape[2]}.`), c(t67.dtype === "int32" || t67.dtype === "float32", () => `Error in dtype: image dtype must be int32 or float32,but got dtype ${t67.dtype}.`), c(n67 === "otsu" || n67 === "binary", () => `Method must be binary or otsu, but was ${n67}`), t67.shape[2] === 3) {
    [d55, s84, E44] = N17(t67, [1, 1, 1], -1);
    let h74 = y8(d55, r56), $37 = y8(s84, e36), T40 = y8(E44, u86);
    i88 = T7(T7(h74, $37), T40);
  } else i88 = m96;
  if (n67 === "otsu") {
    let h74 = $7(w12(x34(i88), "int32"), p10([]), 256);
    a71 = R7(h74, f85);
  }
  let y43 = l80 ? b15(i88, a71) : G6(i88, a71);
  return w12(y8(y43, 255), "int32");
}
function R7(m96, n67) {
  let l80 = m25([-1]), p103 = m25([0]), t67 = m25([0]), r56, e36, u86, f85, a71, d55;
  for (let s84 = 0; s84 < m96.size - 1; s84++) {
    r56 = E10(m96, 0, s84 + 1), e36 = E10(m96, s84 + 1), a71 = D6(T10(r56), n67), d55 = D6(T10(e36), n67);
    let E44 = T10(y8(r56, p35(0, r56.size)));
    u86 = D6(E44, T10(r56));
    let i88 = c16(e36.shape, r56.size), y43 = T7(p35(0, e36.size), i88), F32 = y8(e36, y43);
    f85 = D6(T10(F32), T10(e36));
    let h74 = E16(u86, f85), $37 = E16(u86, f85), T40 = y8(a71, d55);
    t67 = y8(y8(T40, h74), $37);
    let C28 = G6(t67, p103);
    p103 = G5(C28, t67, p103), l80 = G5(C28, m25([s84]), l80);
  }
  return l80;
}
var mt2 = u4({ threshold_: D9 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/image/transform.mjs
function h28(a71, m96, e36 = "nearest", f85 = "constant", i88 = 0, t67) {
  let o80 = S5(a71, "image", "transform", "float32"), r56 = S5(m96, "transforms", "transform", "float32");
  c(o80.rank === 4, () => `Error in transform: image must be rank 4,but got rank ${o80.rank}.`), c(r56.rank === 2 && (r56.shape[0] === o80.shape[0] || r56.shape[0] === 1) && r56.shape[1] === 8, () => "Error in transform: Input transform should be batch x 8 or 1 x 8"), c(t67 == null || t67.length === 2, () => `Error in transform: outputShape must be [height, width] or null, but got ${t67}.`);
  let l80 = { image: o80, transforms: r56 }, u86 = { interpolation: e36, fillMode: f85, fillValue: i88, outputShape: t67 };
  return v3.runKernel(pe, l80, u86);
}
var x37 = u4({ transform_: h28 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/linalg/band_part.mjs
function M8(P36, t67, r56) {
  let e36 = S5(P36, "a", "bandPart");
  c(e36.rank >= 2, () => `bandPart(): Rank must be at least 2, got ${e36.rank}.`);
  let g72 = e36.shape, [o80, a71] = e36.shape.slice(-2), m96, s84;
  typeof t67 == "number" ? (c(t67 % 1 === 0, () => `bandPart(): numLower must be an integer, got ${t67}.`), c(t67 <= o80, () => `bandPart(): numLower (${t67}) must not be greater than the number of rows (${o80}).`), m96 = S5(t67 < 0 ? o80 : t67, "numLower", "bandPart")) : (c(t67.dtype === "int32", () => "bandPart(): numLower's dtype must be an int32."), m96 = G5(d11(t67, 0), o80, G8(t67, o80))), typeof r56 == "number" ? (c(r56 % 1 === 0, () => `bandPart(): numUpper must be an integer, got ${r56}.`), c(r56 <= a71, () => `bandPart(): numUpper (${r56}) must not be greater than the number of columns (${a71}).`), s84 = S5(r56 < 0 ? a71 : r56, "numUpper", "bandPart")) : (c(r56.dtype === "int32", () => "bandPart(): numUpper's dtype must be an int32."), s84 = G5(d11(r56, 0), a71, G8(r56, a71)));
  let u86 = h9(p35(0, o80, 1, "int32"), [-1, 1]), $37 = p35(0, a71, 1, "int32"), p103 = E16(u86, $37), h74 = g16(b15(p103, m96), h18(p103, g14(s84))), y43 = e13([o80, a71], e36.dtype);
  return h9(g21(g22(h9(e36, [-1, o80, a71])).map((k63) => G5(h74, k63, y43))), g72);
}
var X9 = u4({ bandPart_: M8 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/linalg/gram_schmidt.mjs
function b23(r56) {
  let i88;
  if (Array.isArray(r56)) {
    i88 = false, c(r56 != null && r56.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
    let t67 = r56[0].shape[0];
    for (let e36 = 1; e36 < r56.length; ++e36) c(r56[e36].shape[0] === t67, () => `Gram-Schmidt: Non-unique lengths found in the input vectors: (${r56[e36].shape[0]} vs. ${t67})`);
  } else i88 = true, r56 = N17(r56, r56.shape[0], 0).map((t67) => a23(t67, [0]));
  c(r56.length <= r56[0].shape[0], () => `Gram-Schmidt: Number of vectors (${r56.length}) exceeds number of dimensions (${r56[0].shape[0]}).`);
  let o80 = [], f85 = r56;
  for (let t67 = 0; t67 < r56.length; ++t67) o80.push(v3.tidy(() => {
    let e36 = f85[t67];
    if (t67 > 0) for (let m96 = 0; m96 < t67; ++m96) {
      let u86 = y8(T10(y8(o80[m96], e36)), o80[m96]);
      e36 = E16(e36, u86);
    }
    return D6(e36, z8(e36, "euclidean"));
  }));
  return i88 ? g21(o80, 0) : o80;
}
var D10 = u4({ gramSchmidt_: b23 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/linalg/qr.mjs
function S13(r56, h74 = false) {
  if (c(r56.rank >= 2, () => `qr() requires input tensor to have a rank >= 2, but got rank ${r56.rank}`), r56.rank === 2) return X10(r56, h74);
  {
    let e36 = r56.shape.slice(0, r56.shape.length - 2).reduce((c103, o80) => c103 * o80), m96 = g22(h9(r56, [e36, r56.shape[r56.shape.length - 2], r56.shape[r56.shape.length - 1]]), 0), s84 = [], t67 = [];
    m96.forEach((c103) => {
      let [o80, q25] = X10(c103, h74);
      s84.push(o80), t67.push(q25);
    });
    let a71 = h9(g21(s84, 0), r56.shape), n67 = h9(g21(t67, 0), r56.shape);
    return [a71, n67];
  }
}
function X10(r56, h74 = false) {
  return v3.tidy(() => {
    c(r56.shape.length === 2, () => `qr2d() requires a 2D Tensor, but got a ${r56.shape.length}D Tensor.`);
    let e36 = r56.shape[0], m96 = r56.shape[1], s84 = $9(e36), t67 = x11(r56), a71 = h22([[1]], [1, 1]), n67 = x11(a71), c103 = e36 >= m96 ? m96 : e36;
    for (let o80 = 0; o80 < c103; ++o80) {
      let q25 = t67, z32 = n67, B30 = s84;
      [n67, t67, s84] = v3.tidy(() => {
        let D42 = E10(t67, [o80, o80], [e36 - o80, 1]), b58 = z8(D42), y43 = E10(t67, [o80, o80], [1, 1]), v42 = G5(G6(y43, 0), h22([[-1]]), h22([[1]])), A35 = E16(y43, y8(v42, b58)), u86 = D6(D42, A35);
        u86.shape[0] === 1 ? n67 = x11(a71) : n67 = E9([a71, E10(u86, [1, 0], [u86.shape[0] - 1, u86.shape[1]])], 0);
        let C28 = g14(D6(N6(v42, A35), b58)), l80 = E10(t67, [o80, 0], [e36 - o80, m96]), T40 = y8(C28, n67), N58 = A10(n67);
        if (o80 === 0) t67 = E16(l80, N6(T40, N6(N58, l80)));
        else {
          let g72 = E16(l80, N6(T40, N6(N58, l80)));
          t67 = E9([E10(t67, [0, 0], [o80, m96]), g72], 0);
        }
        let P36 = A10(T40), d55 = E10(s84, [0, o80], [e36, s84.shape[1] - o80]);
        if (o80 === 0) s84 = E16(d55, N6(N6(d55, n67), P36));
        else {
          let g72 = E16(d55, N6(N6(d55, n67), P36));
          s84 = E9([E10(s84, [0, 0], [e36, o80]), g72], 1);
        }
        return [n67, t67, s84];
      }), E4([q25, z32, B30]);
    }
    return !h74 && e36 > m96 && (s84 = E10(s84, [0, 0], [e36, m96]), t67 = E10(t67, [0, 0], [m96, m96])), [s84, t67];
  });
}
var qr = u4({ qr_: S13 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/loss_ops_utils.mjs
var E24;
(function(N58) {
  N58[N58.NONE = 0] = "NONE", N58[N58.MEAN = 1] = "MEAN", N58[N58.SUM = 2] = "SUM", N58[N58.SUM_BY_NONZERO_WEIGHTS = 3] = "SUM_BY_NONZERO_WEIGHTS";
})(E24 || (E24 = {}));

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/losses/compute_weighted_loss.mjs
function W8(a71, u86, s84 = E24.SUM_BY_NONZERO_WEIGHTS) {
  let e36 = S5(a71, "losses", "computeWeightedLoss"), o80 = null;
  u86 != null && (o80 = S5(u86, "weights", "computeWeightedLoss"));
  let t67 = o80 == null ? e36 : y8(e36, o80);
  if (s84 === E24.NONE) return t67;
  if (s84 === E24.SUM) return T10(t67);
  if (s84 === E24.MEAN) {
    if (o80 == null) return E19(t67);
    {
      let i88 = e36.size / o80.size, n67 = D6(T10(t67), T10(o80));
      return i88 > 1 ? D6(n67, m21(i88)) : n67;
    }
  }
  if (s84 === E24.SUM_BY_NONZERO_WEIGHTS) {
    if (o80 == null) return D6(T10(t67), m21(e36.size));
    {
      let i88 = y8(o80, c26(e36.shape)), n67 = w12(T10(b18(i88, m21(0))), "float32");
      return D6(T10(t67), n67);
    }
  }
  throw Error(`Unknown reduction: ${s84}`);
}
var $21 = u4({ computeWeightedLoss_: W8 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/losses/absolute_difference.mjs
function h29(i88, f85, o80, n67 = E24.SUM_BY_NONZERO_WEIGHTS) {
  let r56 = S5(i88, "labels", "absoluteDifference"), t67 = S5(f85, "predictions", "absoluteDifference"), s84 = null;
  o80 != null && (s84 = S5(o80, "weights", "absoluteDifference")), k(r56.shape, t67.shape, "Error in absoluteDifference: ");
  let c103 = b9(E16(r56, t67));
  return $21(c103, s84, n67);
}
var g26 = u4({ absoluteDifference_: h29 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/losses/cosine_distance.mjs
function E25(r56, n67, c103, s84, m96 = E24.SUM_BY_NONZERO_WEIGHTS) {
  let t67 = S5(r56, "labels", "cosineDistance"), e36 = S5(n67, "predictions", "cosineDistance"), i88 = null;
  s84 != null && (i88 = S5(s84, "weights", "cosineDistance")), k(t67.shape, e36.shape, "Error in cosineDistance: ");
  let p103 = m21(1), a71 = E16(p103, T10(y8(t67, e36), c103, true));
  return $21(a71, i88, m96);
}
var v22 = u4({ cosineDistance_: E25 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/losses/hinge_loss.mjs
function _12(l80, c103, r56, h74 = E24.SUM_BY_NONZERO_WEIGHTS) {
  let o80 = S5(l80, "labels", "hingeLoss"), e36 = S5(c103, "predictions", "hingeLoss"), t67 = null;
  r56 != null && (t67 = S5(r56, "weights", "hingeLoss")), k(o80.shape, e36.shape, "Error in hingeLoss: ");
  let i88 = m21(1);
  o80 = E16(y8(m21(2), o80), i88);
  let f85 = s22(E16(i88, y8(o80, e36)));
  return $21(f85, t67, h74);
}
var W9 = u4({ hingeLoss_: _12 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/losses/huber_loss.mjs
function M9(u86, l80, r56, f85 = 1, h74 = E24.SUM_BY_NONZERO_WEIGHTS) {
  let s84 = S5(u86, "labels", "huberLoss"), t67 = S5(l80, "predictions", "huberLoss"), e36 = null;
  r56 != null && (e36 = S5(r56, "weights", "huberLoss")), k(s84.shape, t67.shape, "Error in huberLoss: ");
  let m96 = m21(f85), i88 = b9(E16(t67, s84)), n67 = G8(i88, m96), b58 = E16(i88, n67), d55 = T7(y8(m21(0.5), p24(n67)), y8(m96, b58));
  return $21(d55, e36, h74);
}
var Y5 = u4({ huberLoss_: M9 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/losses/log_loss.mjs
function M10(a71, g72, m96, u86 = 1e-7, L22 = E24.SUM_BY_NONZERO_WEIGHTS) {
  let o80 = S5(a71, "labels", "logLoss"), s84 = S5(g72, "predictions", "logLoss"), e36 = null;
  m96 != null && (e36 = S5(m96, "weights", "logLoss")), k(o80.shape, s84.shape, "Error in logLoss: ");
  let l80 = m21(1), i88 = m21(u86), d55 = g14(y8(o80, x29(T7(s84, i88)))), h74 = y8(E16(l80, o80), x29(T7(E16(l80, s84), i88))), S45 = E16(d55, h74);
  return $21(S45, e36, L22);
}
var U7 = u4({ logLoss_: M10 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/losses/mean_squared_error.mjs
function l28(s84, a71, e36, m96 = E24.SUM_BY_NONZERO_WEIGHTS) {
  let o80 = S5(s84, "labels", "meanSquaredError"), t67 = S5(a71, "predictions", "meanSquaredError"), n67 = null;
  e36 != null && (n67 = S5(e36, "weights", "meanSquaredError")), k(o80.shape, t67.shape, "Error in meanSquaredError: ");
  let i88 = T17(o80, t67);
  return $21(i88, n67, m96);
}
var $22 = u4({ meanSquaredError_: l28 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/losses/sigmoid_cross_entropy.mjs
function S14(m96, p103) {
  let t67 = S5(m96, "labels", "sigmoidCrossEntropyWithLogits"), o80 = S5(p103, "logits", "sigmoidCrossEntropyWithLogits");
  k(t67.shape, o80.shape, "Error in sigmoidCrossEntropyWithLogits: ");
  let n67 = s22(o80), s84 = y8(o80, t67), i88 = g13(u20(g14(b9(o80))));
  return T7(E16(n67, s84), i88);
}
function T22(m96, p103, t67, o80 = 0, n67 = E24.SUM_BY_NONZERO_WEIGHTS) {
  let s84 = S5(m96, "multiClassLabels", "sigmoidCrossEntropy"), i88 = S5(p103, "logits", "sigmoidCrossEntropy"), g72 = null;
  if (t67 != null && (g72 = S5(t67, "weights", "sigmoidCrossEntropy")), k(s84.shape, i88.shape, "Error in sigmoidCrossEntropy: "), o80 > 0) {
    let a71 = m21(o80), E44 = m21(1), h74 = m21(0.5);
    s84 = T7(y8(s84, E16(E44, a71)), y8(h74, a71));
  }
  let d55 = S14(s84, i88);
  return $21(d55, g72, n67);
}
var j8 = u4({ sigmoidCrossEntropy_: T22 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/losses/softmax_cross_entropy.mjs
function G12(p103, r56, o80 = -1) {
  if (o80 === -1 && (o80 = r56.rank - 1), o80 !== r56.rank - 1) throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${r56.rank} and dim was ${o80}`);
  return $10((n67, t67, e36) => {
    let i88 = z9(t67, [o80], true), s84 = E16(w12(t67, "float32"), i88);
    e36([n67, s84]);
    let l80 = g14(y8(s84, n67));
    return { value: T10(l80, [o80]), gradFunc: (u86, L22) => {
      let [y43, C28] = L22, S45 = m20(u86.shape, [o80]);
      return [y8(h9(u86, S45), E16(w12(y43, "float32"), u20(C28))), y8(h9(u86, S45), E16(u20(C28), w12(y43, "float32")))];
    } };
  })(p103, r56);
}
function M11(p103, r56, o80, f85 = 0, n67 = E24.SUM_BY_NONZERO_WEIGHTS) {
  let t67 = S5(p103, "onehotLabels", "softmaxCrossEntropy"), e36 = S5(r56, "logits", "softmaxCrossEntropy"), c103 = null;
  if (o80 != null && (c103 = S5(o80, "weights", "softmaxCrossEntropy")), k(t67.shape, e36.shape, "Error in softmaxCrossEntropy: "), f85 > 0) {
    let s84 = m21(f85), l80 = m21(1), g72 = m21(t67.shape[1]);
    t67 = T7(y8(t67, E16(l80, s84)), D6(s84, g72));
  }
  let i88 = G12(t67, e36);
  return $21(i88, c103, n67);
}
var ro2 = u4({ softmaxCrossEntropy_: M11 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sparse/sparse_fill_empty_rows.mjs
function m31(n67, p103, l80, i88) {
  let o80 = S5(n67, "indices", "sparseFillEmptyRows", "int32"), e36 = S5(p103, "values", "sparseFillEmptyRows"), t67 = S5(l80, "denseShape", "sparseFillEmptyRows", "int32"), a71 = S5(i88, "defaultValue", "sparseFillEmptyRows", e36.dtype);
  if (o80.rank !== 2) throw new Error(`Indices should be Tensor2D but received shape
        ${o80.shape}`);
  if (e36.rank !== 1) throw new Error(`Values should be Tensor1D but received shape ${e36.shape}`);
  if (t67.rank !== 1) throw new Error(`Dense shape should be Tensor1D but received shape ${t67.shape}`);
  if (a71.rank !== 0) throw new Error(`Default value should be a scalar but received shape ${a71.shape}`);
  let u86 = { indices: o80, values: e36, denseShape: t67, defaultValue: a71 }, s84 = v3.runKernel(Ht, u86);
  return { outputIndices: s84[0], outputValues: s84[1], emptyRowIndicator: s84[2], reverseIndexMap: s84[3] };
}
var y14 = u4({ sparseFillEmptyRows_: m31 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sparse/sparse_reshape.mjs
function d16(t67, o80, a71) {
  let e36 = S5(t67, "inputIndices", "sparseReshape", "int32"), s84 = S5(o80, "inputShape", "sparseReshape", "int32"), p103 = S5(a71, "newShape", "sparseReshape", "int32");
  if (e36.rank !== 2) throw new Error(`Input indices should be Tensor2D but received shape
        ${e36.shape}`);
  if (s84.rank !== 1) throw new Error(`Input shape should be Tensor1D but received shape ${s84.shape}`);
  if (p103.rank !== 1) throw new Error(`New shape should be Tensor1D but received shape ${p103.shape}`);
  let h74 = { inputIndices: e36, inputShape: s84, newShape: p103 }, n67 = v3.runKernel(Wt, h74);
  return { outputIndices: n67[0], outputShape: n67[1] };
}
var I15 = u4({ sparseReshape_: d16 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sparse/sparse_segment_mean.mjs
function c41(t67, a71, o80) {
  let s84 = S5(t67, "data", "sparseSegmentMean"), e36 = S5(a71, "indices", "sparseSegmentMean", "int32"), n67 = S5(o80, "segmentIds", "sparseSegmentMean", "int32");
  if (s84.rank < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (e36.rank !== 1) throw new Error(`Indices should be Tensor1D but received shape
          ${e36.shape}`);
  if (n67.rank !== 1) throw new Error(`Segment ids should be Tensor1D but received shape
          ${n67.shape}`);
  let i88 = { data: s84, indices: e36, segmentIds: n67 };
  return v3.runKernel(Kt, i88);
}
var S15 = u4({ sparseSegmentMean_: c41 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sparse/sparse_segment_sum.mjs
function u41(t67, o80, a71) {
  let n67 = S5(t67, "data", "sparseSegmentSum"), e36 = S5(o80, "indices", "sparseSegmentSum", "int32"), r56 = S5(a71, "segmentIds", "sparseSegmentSum", "int32");
  if (n67.rank < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (e36.rank !== 1) throw new Error(`Indices should be Tensor1D but received shape
         ${e36.shape}`);
  if (r56.rank !== 1) throw new Error(`Segment ids should be Tensor1D but received shape
         ${r56.shape}`);
  let m96 = { data: n67, indices: e36, segmentIds: r56 };
  return v3.runKernel(Xt, m96);
}
var f39 = u4({ sparseSegmentSum_: u41 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/string/string_n_grams.mjs
function w20(n67, o80, i88, e36, m96, p103, d55, f85) {
  let t67 = S5(n67, "data", "stringNGrams", "string");
  if (t67.dtype !== "string") throw new Error("Data must be of datatype string");
  if (t67.shape.length !== 1) throw new Error(`Data must be a vector, saw: ${t67.shape}`);
  let r56 = S5(o80, "dataSplits", "stringNGrams");
  if (r56.dtype !== "int32") throw new Error("Data splits must be of datatype int32");
  let c103 = { separator: i88, nGramWidths: e36, leftPad: m96, rightPad: p103, padWidth: d55, preserveShortSequences: f85 }, g72 = { data: t67, dataSplits: r56 }, s84 = v3.runKernel(Yt, g72, c103);
  return { nGrams: s84[0], nGramsSplits: s84[1] };
}
var y15 = u4({ stringNGrams_: w20 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/string/string_split.mjs
function m32(n67, o80, s84 = true) {
  let r56 = S5(n67, "input", "stringSplit", "string"), t67 = S5(o80, "delimiter", "stringSplit", "string");
  if (r56.rank !== 1) throw new Error(`Input should be Tensor1D but received shape ${r56.shape}`);
  if (t67.rank !== 0) throw new Error(`Delimiter should be a scalar but received shape ${t67.shape}`);
  let p103 = { skipEmpty: s84 }, l80 = { input: r56, delimiter: t67 }, i88 = v3.runKernel($t, l80, p103);
  return { indices: i88[0], values: i88[1], shape: i88[2] };
}
var S16 = u4({ stringSplit_: m32 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/string/string_to_hash_bucket_fast.mjs
function c42(r56, t67) {
  let o80 = S5(r56, "input", "stringToHashBucketFast", "string"), s84 = { numBuckets: t67 };
  if (t67 <= 0) throw new Error("Number of buckets must be at least 1");
  let n67 = { input: o80 };
  return v3.runKernel(oe, n67, s84);
}
var g27 = u4({ stringToHashBucketFast_: c42 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/string/static_regex_replace.mjs
function m33(t67, e36, r56, o80 = true) {
  let c103 = S5(t67, "input", "staticRegexReplace", "string"), n67 = { pattern: e36, rewrite: r56, replaceGlobal: o80 };
  return v3.runKernel(Jt, { x: c103 }, n67);
}
var g28 = u4({ staticRegexReplace_: m33 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/ops.mjs
var j9 = { fft: l24, ifft: l25, rfft: K8, irfft: G10 };
var $23 = { hammingWindow: p42, hannWindow: p43, frame: q10, stft: T20 };
var go2 = { flipLeftRight: c39, grayscaleToRGB: p45, resizeNearestNeighbor: y13, resizeBilinear: T21, rgbToGrayscale: h27, rotateWithOffset: l26, cropAndResize: k19, nonMaxSuppression: G11, nonMaxSuppressionAsync: l27, nonMaxSuppressionWithScore: V5, nonMaxSuppressionWithScoreAsync: N23, nonMaxSuppressionPadded: z11, nonMaxSuppressionPaddedAsync: b21, threshold: mt2, transform: x37 };
var bo2 = { bandPart: X9, gramSchmidt: D10, qr };
var Eo2 = { absoluteDifference: g26, computeWeightedLoss: $21, cosineDistance: v22, hingeLoss: W9, huberLoss: Y5, logLoss: U7, meanSquaredError: $22, sigmoidCrossEntropy: j8, softmaxCrossEntropy: ro2 };
var Co2 = { sparseFillEmptyRows: y14, sparseReshape: I15, sparseSegmentMean: S15, sparseSegmentSum: f39 };
var Oo2 = { stringNGrams: y15, stringSplit: S16, stringToHashBucketFast: g27, staticRegexReplace: g28 };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/serialization.mjs
var serialization_exports = {};
__export(serialization_exports, {
  Serializable: () => o11,
  SerializationMap: () => n14,
  getRegisteredName: () => N24,
  registerClass: () => f40
});
var m34 = /* @__PURE__ */ new Map();
var r11 = /* @__PURE__ */ new Map();
var o11 = class {
  getClassName() {
    return this.constructor.className;
  }
  static fromConfig(s84, t67) {
    return new s84(t67);
  }
};
var n14 = class e18 {
  constructor() {
    this.classNameMap = {};
  }
  static getMap() {
    return e18.instance == null && (e18.instance = new e18()), e18.instance;
  }
  static register(s84) {
    e18.getMap().classNameMap[s84.className] = [s84, s84.fromConfig];
  }
};
function f40(e36, s84, t67) {
  c(e36.className != null, () => "Class being registered does not have the static className property defined."), c(typeof e36.className == "string", () => "className is required to be a string, but got type " + typeof e36.className), c(e36.className.length > 0, () => "Class being registered has an empty-string as its className, which is disallowed."), typeof s84 > "u" && (s84 = "Custom"), typeof t67 > "u" && (t67 = e36.className);
  let c103 = t67, i88 = s84 + ">" + c103;
  return n14.register(e36), m34.set(i88, e36), r11.set(e36, i88), e36;
}
function N24(e36) {
  return r11.has(e36) ? r11.get(e36) : e36.className;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/optimizers/optimizer.mjs
var n15 = class extends o11 {
  minimize(t67, i88 = false, s84) {
    let { value: a71, grads: r56 } = this.computeGradients(t67, s84);
    if (s84 != null) {
      let m96 = s84.map((o80) => ({ name: o80.name, tensor: r56[o80.name] }));
      this.applyGradients(m96);
    } else this.applyGradients(r56);
    return E4(r56), i88 ? a71 : (a71.dispose(), null);
  }
  get iterations() {
    return this.iterations_ == null && (this.iterations_ = 0), this.iterations_;
  }
  incrementIterations() {
    this.iterations_ = this.iterations + 1;
  }
  computeGradients(t67, i88) {
    return N12(t67, i88);
  }
  dispose() {
    this.iterations_ != null && E4(this.iterations_);
  }
  async saveIterations() {
    return this.iterations_ == null && (this.iterations_ = 0), { name: "iter", tensor: m21(this.iterations_, "int32") };
  }
  async getWeights() {
    throw new Error("getWeights() is not implemented for this optimizer yet.");
  }
  async setWeights(t67) {
    throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`);
  }
  async extractIterations(t67) {
    return this.iterations_ = (await t67[0].tensor.data())[0], t67.slice(1);
  }
};
Object.defineProperty(n15, Symbol.hasInstance, { value: (e36) => e36.minimize != null && e36.computeGradients != null && e36.applyGradients != null });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/optimizers/adadelta_optimizer.mjs
var v23 = class extends n15 {
  static get className() {
    return "Adadelta";
  }
  constructor(a71, t67, s84 = null) {
    super(), this.learningRate = a71, this.rho = t67, this.epsilon = s84, this.accumulatedGrads = [], this.accumulatedUpdates = [], s84 == null && (this.epsilon = v3.backend.epsilon());
  }
  applyGradients(a71) {
    (Array.isArray(a71) ? a71.map((s84) => s84.name) : Object.keys(a71)).forEach((s84, e36) => {
      let c103 = v3.registeredVariables[s84], u86 = false;
      this.accumulatedGrads[e36] == null && (this.accumulatedGrads[e36] = { originalName: `${s84}/accum_grad`, variable: g4(() => k11(c103).variable(u86)) }), this.accumulatedUpdates[e36] == null && (this.accumulatedUpdates[e36] = { originalName: `${s84}/accum_var`, variable: g4(() => k11(c103).variable(u86)) });
      let l80 = Array.isArray(a71) ? a71[e36].tensor : a71[s84];
      if (l80 == null) return;
      let n67 = this.accumulatedGrads[e36].variable, o80 = this.accumulatedUpdates[e36].variable;
      g4(() => {
        let N58 = T7(y8(n67, this.rho), y8(p24(l80), 1 - this.rho)), d55 = y8(D6(q6(T7(o80, this.epsilon)), q6(T7(n67, this.epsilon))), l80), U24 = T7(y8(o80, this.rho), y8(p24(d55), 1 - this.rho));
        n67.assign(N58), o80.assign(U24);
        let y43 = T7(y8(d55, -this.learningRate), c103);
        c103.assign(y43);
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.accumulatedUpdates != null && (E4(this.accumulatedGrads.map((a71) => a71.variable)), E4(this.accumulatedUpdates.map((a71) => a71.variable)));
  }
  async getWeights() {
    let a71 = [...this.accumulatedGrads, ...this.accumulatedUpdates];
    return [await this.saveIterations()].concat(a71.map((t67) => ({ name: t67.originalName, tensor: t67.variable })));
  }
  async setWeights(a71) {
    a71 = await this.extractIterations(a71);
    let t67 = a71.length / 2, s84 = false;
    this.accumulatedGrads = a71.slice(0, t67).map((e36) => ({ originalName: e36.name, variable: e36.tensor.variable(s84) })), this.accumulatedUpdates = a71.slice(t67, t67 * 2).map((e36) => ({ originalName: e36.name, variable: e36.tensor.variable(s84) }));
  }
  getConfig() {
    return { learningRate: this.learningRate, rho: this.rho, epsilon: this.epsilon };
  }
  static fromConfig(a71, t67) {
    return new a71(t67.learningRate, t67.rho, t67.epsilon);
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/optimizers/adagrad_optimizer.mjs
var m35 = class extends n15 {
  static get className() {
    return "Adagrad";
  }
  constructor(a71, r56 = 0.1) {
    super(), this.learningRate = a71, this.initialAccumulatorValue = r56, this.accumulatedGrads = [];
  }
  applyGradients(a71) {
    (Array.isArray(a71) ? a71.map((t67) => t67.name) : Object.keys(a71)).forEach((t67, i88) => {
      let e36 = v3.registeredVariables[t67];
      this.accumulatedGrads[i88] == null && (this.accumulatedGrads[i88] = { originalName: `${t67}/accumulator`, variable: g4(() => c16(e36.shape, this.initialAccumulatorValue).variable(false)) });
      let s84 = Array.isArray(a71) ? a71[i88].tensor : a71[t67];
      if (s84 == null) return;
      let c103 = this.accumulatedGrads[i88].variable;
      g4(() => {
        let l80 = T7(c103, p24(s84));
        c103.assign(l80);
        let d55 = T7(y8(D6(s84, q6(T7(l80, v3.backend.epsilon()))), -this.learningRate), e36);
        e36.assign(d55);
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.accumulatedGrads != null && E4(this.accumulatedGrads.map((a71) => a71.variable));
  }
  async getWeights() {
    return [await this.saveIterations()].concat(this.accumulatedGrads.map((a71) => ({ name: a71.originalName, tensor: a71.variable })));
  }
  async setWeights(a71) {
    a71 = await this.extractIterations(a71);
    let r56 = false;
    this.accumulatedGrads = a71.map((t67) => ({ originalName: t67.name, variable: t67.tensor.variable(r56) }));
  }
  getConfig() {
    return { learningRate: this.learningRate, initialAccumulatorValue: this.initialAccumulatorValue };
  }
  static fromConfig(a71, r56) {
    return new a71(r56.learningRate, r56.initialAccumulatorValue);
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/optimizers/adam_optimizer.mjs
var y16 = class extends n15 {
  static get className() {
    return "Adam";
  }
  constructor(t67, a71, s84, e36 = null) {
    super(), this.learningRate = t67, this.beta1 = a71, this.beta2 = s84, this.epsilon = e36, this.accumulatedFirstMoment = [], this.accumulatedSecondMoment = [], g4(() => {
      this.accBeta1 = m21(a71).variable(), this.accBeta2 = m21(s84).variable();
    }), e36 == null && (this.epsilon = v3.backend.epsilon());
  }
  applyGradients(t67) {
    let a71 = Array.isArray(t67) ? t67.map((s84) => s84.name) : Object.keys(t67);
    g4(() => {
      let s84 = E16(1, this.accBeta1), e36 = E16(1, this.accBeta2);
      a71.forEach((c103, i88) => {
        let r56 = v3.registeredVariables[c103], u86 = false;
        this.accumulatedFirstMoment[i88] == null && (this.accumulatedFirstMoment[i88] = { originalName: `${c103}/m`, variable: g4(() => k11(r56).variable(u86)) }), this.accumulatedSecondMoment[i88] == null && (this.accumulatedSecondMoment[i88] = { originalName: `${c103}/v`, variable: g4(() => k11(r56).variable(u86)) });
        let l80 = Array.isArray(t67) ? t67[i88].tensor : t67[c103];
        if (l80 == null) return;
        let d55 = this.accumulatedFirstMoment[i88].variable, b58 = this.accumulatedSecondMoment[i88].variable, p103 = T7(y8(d55, this.beta1), y8(l80, 1 - this.beta1)), M30 = T7(y8(b58, this.beta2), y8(p24(l80), 1 - this.beta2)), N58 = D6(p103, s84), A35 = D6(M30, e36);
        d55.assign(p103), b58.assign(M30);
        let C28 = T7(y8(D6(N58, T7(q6(A35), this.epsilon)), -this.learningRate), r56);
        r56.assign(C28);
      }), this.accBeta1.assign(y8(this.accBeta1, this.beta1)), this.accBeta2.assign(y8(this.accBeta2, this.beta2));
    }), this.incrementIterations();
  }
  dispose() {
    this.accBeta1.dispose(), this.accBeta2.dispose(), this.accumulatedFirstMoment != null && E4(this.accumulatedFirstMoment.map((t67) => t67.variable)), this.accumulatedSecondMoment != null && E4(this.accumulatedSecondMoment.map((t67) => t67.variable));
  }
  async getWeights() {
    let t67 = [...this.accumulatedFirstMoment, ...this.accumulatedSecondMoment];
    return [await this.saveIterations()].concat(t67.map((a71) => ({ name: a71.originalName, tensor: a71.variable })));
  }
  async setWeights(t67) {
    t67 = await this.extractIterations(t67), g4(() => {
      this.accBeta1.assign(x22(this.beta1, this.iterations_ + 1)), this.accBeta2.assign(x22(this.beta2, this.iterations_ + 1));
    });
    let a71 = t67.length / 2, s84 = false;
    this.accumulatedFirstMoment = t67.slice(0, a71).map((e36) => ({ originalName: e36.name, variable: e36.tensor.variable(s84) })), this.accumulatedSecondMoment = t67.slice(a71, a71 * 2).map((e36) => ({ originalName: e36.name, variable: e36.tensor.variable(s84) }));
  }
  getConfig() {
    return { learningRate: this.learningRate, beta1: this.beta1, beta2: this.beta2, epsilon: this.epsilon };
  }
  static fromConfig(t67, a71) {
    return new t67(a71.learningRate, a71.beta1, a71.beta2, a71.epsilon);
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/optimizers/adamax_optimizer.mjs
var w21 = class extends n15 {
  static get className() {
    return "Adamax";
  }
  constructor(t67, e36, r56, o80 = null, a71 = 0) {
    super(), this.learningRate = t67, this.beta1 = e36, this.beta2 = r56, this.epsilon = o80, this.decay = a71, this.accumulatedFirstMoment = [], this.accumulatedWeightedInfNorm = [], g4(() => {
      this.iteration = m21(0).variable(), this.accBeta1 = m21(e36).variable();
    }), o80 == null && (this.epsilon = v3.backend.epsilon());
  }
  applyGradients(t67) {
    let e36 = Array.isArray(t67) ? t67.map((r56) => r56.name) : Object.keys(t67);
    g4(() => {
      let r56 = E16(1, this.accBeta1), o80 = D6(-this.learningRate, T7(y8(this.iteration, this.decay), 1));
      e36.forEach((a71, i88) => {
        let m96 = v3.registeredVariables[a71], h74 = false;
        this.accumulatedFirstMoment[i88] == null && (this.accumulatedFirstMoment[i88] = { originalName: `${a71}/m`, variable: k11(m96).variable(h74) }), this.accumulatedWeightedInfNorm[i88] == null && (this.accumulatedWeightedInfNorm[i88] = { originalName: `${a71}/v`, variable: k11(m96).variable(h74) });
        let c103 = Array.isArray(t67) ? t67[i88].tensor : t67[a71];
        if (c103 == null) return;
        let u86 = this.accumulatedFirstMoment[i88].variable, d55 = this.accumulatedWeightedInfNorm[i88].variable, p103 = T7(y8(u86, this.beta1), y8(c103, 1 - this.beta1)), I44 = y8(d55, this.beta2), v42 = b9(c103), f85 = E18(I44, v42);
        u86.assign(p103), d55.assign(f85);
        let M30 = T7(y8(D6(o80, r56), D6(p103, T7(f85, this.epsilon))), m96);
        m96.assign(M30);
      }), this.iteration.assign(T7(this.iteration, 1)), this.accBeta1.assign(y8(this.accBeta1, this.beta1));
    }), this.incrementIterations();
  }
  dispose() {
    this.accBeta1.dispose(), this.iteration.dispose(), this.accumulatedFirstMoment != null && E4(this.accumulatedFirstMoment.map((t67) => t67.variable)), this.accumulatedWeightedInfNorm != null && E4(this.accumulatedWeightedInfNorm.map((t67) => t67.variable));
  }
  async getWeights() {
    throw new Error("getWeights() is not implemented for Adamax yet.");
  }
  async setWeights(t67) {
    throw new Error("setWeights() is not implemented for Adamax yet.");
  }
  getConfig() {
    return { learningRate: this.learningRate, beta1: this.beta1, beta2: this.beta2, epsilon: this.epsilon, decay: this.decay };
  }
  static fromConfig(t67, e36) {
    return new t67(e36.learningRate, e36.beta1, e36.beta2, e36.epsilon, e36.decay);
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/optimizers/sgd_optimizer.mjs
var n16 = class extends n15 {
  static get className() {
    return "SGD";
  }
  constructor(t67) {
    super(), this.learningRate = t67, this.setLearningRate(t67);
  }
  applyGradients(t67) {
    (Array.isArray(t67) ? t67.map((r56) => r56.name) : Object.keys(t67)).forEach((r56, o80) => {
      let e36 = Array.isArray(t67) ? t67[o80].tensor : t67[r56];
      if (e36 == null) return;
      let i88 = v3.registeredVariables[r56];
      g4(() => {
        let a71 = T7(y8(this.c, e36), i88);
        i88.assign(a71);
      });
    }), this.incrementIterations();
  }
  setLearningRate(t67) {
    this.learningRate = t67, this.c != null && this.c.dispose(), this.c = N3(m21(-t67));
  }
  dispose() {
    this.c.dispose();
  }
  async getWeights() {
    return [await this.saveIterations()];
  }
  async setWeights(t67) {
    if (t67 = await this.extractIterations(t67), t67.length !== 0) throw new Error("SGD optimizer does not have settable weights.");
  }
  getConfig() {
    return { learningRate: this.learningRate };
  }
  static fromConfig(t67, s84) {
    return new t67(s84.learningRate);
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/optimizers/momentum_optimizer.mjs
var h30 = class extends n16 {
  static get className() {
    return "Momentum";
  }
  constructor(t67, e36, s84 = false) {
    super(t67), this.learningRate = t67, this.momentum = e36, this.useNesterov = s84, this.accumulations = [], this.m = m21(this.momentum);
  }
  applyGradients(t67) {
    (Array.isArray(t67) ? t67.map((s84) => s84.name) : Object.keys(t67)).forEach((s84, a71) => {
      let i88 = v3.registeredVariables[s84];
      this.accumulations[a71] == null && (this.accumulations[a71] = { originalName: `${s84}/momentum`, variable: g4(() => k11(i88).variable(false)) });
      let c103 = this.accumulations[a71].variable, n67 = Array.isArray(t67) ? t67[a71].tensor : t67[s84];
      n67 != null && g4(() => {
        let r56, u86 = T7(y8(this.m, c103), n67);
        this.useNesterov ? r56 = T7(y8(this.c, T7(n67, y8(u86, this.m))), i88) : r56 = T7(y8(this.c, u86), i88), c103.assign(u86), i88.assign(r56);
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.m.dispose(), this.accumulations != null && E4(this.accumulations.map((t67) => t67.variable));
  }
  setMomentum(t67) {
    this.momentum = t67;
  }
  async getWeights() {
    return [await this.saveIterations()].concat(this.accumulations.map((t67) => ({ name: t67.originalName, tensor: t67.variable })));
  }
  async setWeights(t67) {
    t67 = await this.extractIterations(t67);
    let e36 = false;
    this.accumulations = t67.map((s84) => ({ originalName: s84.name, variable: s84.tensor.variable(e36) }));
  }
  getConfig() {
    return { learningRate: this.learningRate, momentum: this.momentum, useNesterov: this.useNesterov };
  }
  static fromConfig(t67, e36) {
    return new t67(e36.learningRate, e36.momentum, e36.useNesterov);
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/optimizers/rmsprop_optimizer.mjs
var A11 = class extends n15 {
  static get className() {
    return "RMSProp";
  }
  constructor(e36, t67 = 0.9, s84 = 0, a71 = null, i88 = false) {
    if (super(), this.learningRate = e36, this.decay = t67, this.momentum = s84, this.epsilon = a71, this.accumulatedMeanSquares = [], this.accumulatedMoments = [], this.accumulatedMeanGrads = [], this.centered = i88, a71 == null && (this.epsilon = v3.backend.epsilon()), e36 == null) throw new Error("learningRate for RMSPropOptimizer must be defined.");
  }
  applyGradients(e36) {
    (Array.isArray(e36) ? e36.map((s84) => s84.name) : Object.keys(e36)).forEach((s84, a71) => {
      let i88 = v3.registeredVariables[s84], h74 = false;
      this.accumulatedMeanSquares[a71] == null && (this.accumulatedMeanSquares[a71] = { originalName: `${s84}/rms`, variable: g4(() => k11(i88).variable(h74)) }), this.accumulatedMoments[a71] == null && (this.accumulatedMoments[a71] = { originalName: `${s84}/momentum`, variable: g4(() => k11(i88).variable(h74)) }), this.accumulatedMeanGrads[a71] == null && this.centered && (this.accumulatedMeanGrads[a71] = { originalName: `${s84}/mg`, variable: g4(() => k11(i88).variable(h74)) });
      let c103 = Array.isArray(e36) ? e36[a71].tensor : e36[s84];
      if (c103 == null) return;
      let u86 = this.accumulatedMeanSquares[a71].variable, o80 = this.accumulatedMoments[a71].variable;
      g4(() => {
        let y43 = T7(y8(u86, this.decay), y8(p24(c103), 1 - this.decay));
        if (this.centered) {
          let m96 = this.accumulatedMeanGrads[a71].variable, l80 = T7(y8(m96, this.decay), y8(c103, 1 - this.decay)), p103 = D6(y8(c103, this.learningRate), q6(E16(y43, T7(p24(l80), this.epsilon)))), v42 = T7(y8(o80, this.momentum), p103);
          u86.assign(y43), m96.assign(l80), o80.assign(v42);
          let G30 = E16(i88, v42);
          i88.assign(G30);
        } else {
          let m96 = T7(y8(u86, this.decay), y8(p24(c103), 1 - this.decay)), l80 = T7(y8(o80, this.momentum), D6(y8(c103, this.learningRate), q6(T7(m96, this.epsilon))));
          u86.assign(m96), o80.assign(l80);
          let p103 = E16(i88, l80);
          i88.assign(p103);
        }
      });
    }), this.incrementIterations();
  }
  dispose() {
    this.accumulatedMeanSquares != null && E4(this.accumulatedMeanSquares.map((e36) => e36.variable)), this.accumulatedMeanGrads != null && this.centered && E4(this.accumulatedMeanGrads.map((e36) => e36.variable)), this.accumulatedMoments != null && E4(this.accumulatedMoments.map((e36) => e36.variable));
  }
  async getWeights() {
    let e36 = [...this.accumulatedMeanSquares, ...this.accumulatedMoments];
    return this.centered && e36.push(...this.accumulatedMeanGrads), [await this.saveIterations()].concat(e36.map((t67) => ({ name: t67.originalName, tensor: t67.variable })));
  }
  async setWeights(e36) {
    e36 = await this.extractIterations(e36);
    let t67 = this.centered ? e36.length / 3 : e36.length / 2, s84 = false;
    this.accumulatedMeanSquares = e36.slice(0, t67).map((a71) => ({ originalName: a71.name, variable: a71.tensor.variable(s84) })), this.accumulatedMoments = e36.slice(t67, t67 * 2).map((a71) => ({ originalName: a71.name, variable: a71.tensor.variable(s84) })), this.centered && (this.accumulatedMeanGrads = e36.slice(t67 * 2, t67 * 3).map((a71) => ({ originalName: a71.name, variable: a71.tensor.variable(s84) })));
  }
  getConfig() {
    return { learningRate: this.learningRate, decay: this.decay, momentum: this.momentum, epsilon: this.epsilon, centered: this.centered };
  }
  static fromConfig(e36, t67) {
    return new e36(t67.learningRate, t67.decay, t67.momentum, t67.epsilon, t67.centered);
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/optimizers/register_optimizers.mjs
var O8 = [v23, m35, y16, w21, h30, A11, n16];
function S17() {
  for (let r56 of O8) f40(r56);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/io.mjs
var io_exports = {};
__export(io_exports, {
  CompositeArrayBuffer: () => d4,
  browserFiles: () => T23,
  browserHTTPRequest: () => I16,
  concatenateArrayBuffers: () => J4,
  copyModel: () => $6,
  decodeWeights: () => N4,
  decodeWeightsStream: () => X4,
  encodeWeights: () => Z5,
  fromMemory: () => u43,
  fromMemorySync: () => i21,
  getLoadHandlers: () => i5,
  getModelArtifactsForJSON: () => ne2,
  getModelArtifactsForJSONSync: () => I7,
  getModelArtifactsInfoForJSON: () => re2,
  getSaveHandlers: () => g5,
  getWeightSpecs: () => oe2,
  http: () => w22,
  isHTTPScheme: () => u42,
  listModels: () => w11,
  loadWeights: () => C9,
  moveModel: () => I9,
  registerLoadRouter: () => l11,
  registerSaveRouter: () => u5,
  removeModel: () => S8,
  weightsLoaderFactory: () => M13,
  withSaveHandler: () => f41,
  withSaveHandlerSync: () => m36
});

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/browser_files.mjs
var R8 = "model";
var y17 = ".json";
var A12 = ".weights.bin";
function d17(s84) {
  return new Promise((e36) => setTimeout(e36)).then(s84);
}
var l29 = class s30 {
  constructor(e36) {
    if (!l().getBool("IS_BROWSER")) throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
    e36.startsWith(s30.URL_SCHEME) && (e36 = e36.slice(s30.URL_SCHEME.length)), (e36 == null || e36.length === 0) && (e36 = R8), this.modelJsonFileName = e36 + y17, this.weightDataFileName = e36 + A12;
  }
  async save(e36) {
    if (typeof document > "u") throw new Error("Browser downloads are not supported in this environment since `document` is not present");
    let o80 = d4.join(e36.weightData), i88 = globalThis.URL.createObjectURL(new Blob([o80], { type: "application/octet-stream" }));
    if (e36.modelTopology instanceof ArrayBuffer) throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
    {
      let a71 = [{ paths: ["./" + this.weightDataFileName], weights: e36.weightSpecs }], n67 = te2(e36, a71), t67 = globalThis.URL.createObjectURL(new Blob([JSON.stringify(n67)], { type: "application/json" })), r56 = this.modelJsonAnchor == null ? document.createElement("a") : this.modelJsonAnchor;
      if (r56.download = this.modelJsonFileName, r56.href = t67, await d17(() => r56.dispatchEvent(new MouseEvent("click"))), e36.weightData != null) {
        let h74 = this.weightDataAnchor == null ? document.createElement("a") : this.weightDataAnchor;
        h74.download = this.weightDataFileName, h74.href = i88, await d17(() => h74.dispatchEvent(new MouseEvent("click")));
      }
      return { modelArtifactsInfo: re2(e36) };
    }
  }
};
l29.URL_SCHEME = "downloads://";
var c43 = class {
  constructor(e36) {
    if (e36 == null || e36.length < 1) throw new Error(`When calling browserFiles, at least 1 file is required, but received ${e36}`);
    this.jsonFile = e36[0], this.weightsFiles = e36.slice(1);
  }
  async load() {
    return new Promise((e36, o80) => {
      let i88 = new FileReader();
      i88.onload = (a71) => {
        let n67 = JSON.parse(a71.target.result), t67 = n67.modelTopology;
        if (t67 == null) {
          o80(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));
          return;
        }
        if (n67.weightsManifest == null) {
          o80(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));
          return;
        }
        if (this.weightsFiles.length === 0) {
          e36({ modelTopology: t67 });
          return;
        }
        let h74 = ne2(n67, (f85) => this.loadWeights(f85));
        e36(h74);
      }, i88.onerror = (a71) => o80(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`), i88.readAsText(this.jsonFile);
    });
  }
  loadWeights(e36) {
    let o80 = [], i88 = [];
    for (let t67 of e36) o80.push(...t67.weights), i88.push(...t67.paths);
    let a71 = this.checkManifestAndWeightFiles(e36), n67 = i88.map((t67) => this.loadWeightsFile(t67, a71[t67]));
    return Promise.all(n67).then((t67) => [o80, t67]);
  }
  loadWeightsFile(e36, o80) {
    return new Promise((i88, a71) => {
      let n67 = new FileReader();
      n67.onload = (t67) => {
        let r56 = t67.target.result;
        i88(r56);
      }, n67.onerror = (t67) => a71(`Failed to weights data from file of path '${e36}'.`), n67.readAsArrayBuffer(o80);
    });
  }
  checkManifestAndWeightFiles(e36) {
    let o80 = [], i88 = this.weightsFiles.map((n67) => ee2(n67.name)), a71 = {};
    for (let n67 of e36) n67.paths.forEach((t67) => {
      let r56 = ee2(t67);
      if (o80.indexOf(r56) !== -1) throw new Error(`Duplicate file basename found in weights manifest: '${r56}'`);
      if (o80.push(r56), i88.indexOf(r56) === -1) throw new Error(`Weight file with basename '${r56}' is not provided.`);
      a71[t67] = this.weightsFiles[i88.indexOf(r56)];
    });
    if (o80.length !== this.weightsFiles.length) throw new Error(`Mismatch in the number of files in weights manifest (${o80.length}) and the number of weight files provided (${this.weightsFiles.length}).`);
    return a71;
  }
};
var S18 = (s84) => l().getBool("IS_BROWSER") && !Array.isArray(s84) && s84.startsWith(l29.URL_SCHEME) ? M12(s84.slice(l29.URL_SCHEME.length)) : null;
s6.registerSaveRouter(S18);
function M12(s84 = "model") {
  return new l29(s84);
}
function T23(s84) {
  return new c43(s84);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/progress.mjs
function h31(l80, g72, n67, u86) {
  s84(l80), n67 = n67 ?? 0, u86 = u86 ?? 1, b58(n67, u86);
  let t67 = 0, m96 = (e36) => (e36.then((r56) => {
    let f85 = n67 + ++t67 / l80.length * (u86 - n67);
    return g72(f85), r56;
  }), e36);
  function s84(e36) {
    c(e36 != null && Array.isArray(e36) && e36.length > 0, () => "promises must be a none empty array");
  }
  function b58(e36, r56) {
    c(e36 >= 0 && e36 <= 1, () => `Progress fraction must be in range [0, 1], but got startFraction ${e36}`), c(r56 >= 0 && r56 <= 1, () => `Progress fraction must be in range [0, 1], but got endFraction ${r56}`), c(r56 >= e36, () => `startFraction must be no more than endFraction, but got startFraction ${e36} and endFraction ${r56}`);
  }
  return Promise.all(l80.map(m96));
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/weights_loader.mjs
async function T24(f85, e36) {
  e36 == null && (e36 = {});
  let o80 = e36.fetchFunc == null ? l().platform.fetch : e36.fetchFunc, r56 = f85.map((l80) => o80(l80, e36.requestInit, { isBinary: true })), u86 = (e36.onProgress == null ? await Promise.all(r56) : await h31(r56, e36.onProgress, 0, 0.5)).map((l80) => l80.arrayBuffer());
  return e36.onProgress == null ? await Promise.all(u86) : await h31(u86, e36.onProgress, 0.5, 1);
}
function x38(f85, e36) {
  var o80;
  let r56 = e36.fetchFunc == null ? l().platform.fetch : e36.fetchFunc, a71 = 0, s84;
  return (o80 = e36.onProgress) === null || o80 === void 0 || o80.call(e36, 0), new ReadableStream({ pull: async (i88) => {
    for (var u86; a71 < f85.length; ) {
      s84 || (s84 = (await r56(f85[a71], e36.requestInit, { isBinary: true })).body.getReader());
      let { done: g72, value: F32 } = await s84.read();
      if (g72) {
        a71++, s84 = void 0, (u86 = e36.onProgress) === null || u86 === void 0 || u86.call(e36, a71 / f85.length);
        continue;
      }
      i88.enqueue(F32);
      return;
    }
    i88.close();
  } });
}
async function C9(f85, e36 = "", o80, r56) {
  return M13((i88) => T24(i88, { requestInit: r56 }))(f85, e36, o80);
}
function M13(f85) {
  return async (e36, o80 = "", r56) => {
    let a71 = e36.map(() => false), s84 = {}, i88 = r56 != null ? r56.map(() => false) : [], u86 = [];
    if (e36.forEach((t67, n67) => {
      let c103 = 0;
      t67.weights.forEach((h74) => {
        let m96 = "quantization" in h74 ? h74.quantization.dtype : h74.dtype, d55 = o8[m96] * q(h74.shape), p103 = () => {
          a71[n67] = true, s84[n67] == null && (s84[n67] = []), s84[n67].push({ manifestEntry: h74, groupOffset: c103, sizeBytes: d55 });
        };
        r56 != null ? r56.forEach((b58, E44) => {
          b58 === h74.name && (p103(), i88[E44] = true);
        }) : p103(), u86.push(h74.name), c103 += d55;
      });
    }), !i88.every((t67) => t67)) {
      let t67 = r56.filter((n67, c103) => !i88[c103]);
      throw new Error(`Could not find weights in manifest with names: ${t67.join(", ")}. 
Manifest JSON has weights with names: ${u86.join(", ")}.`);
    }
    let g72 = a71.reduce((t67, n67, c103) => (n67 && t67.push(c103), t67), []), F32 = [];
    g72.forEach((t67) => {
      e36[t67].paths.forEach((n67) => {
        let c103 = o80 + (o80.endsWith("/") ? "" : "/") + n67;
        F32.push(c103);
      });
    });
    let y43 = await f85(F32), l80 = {}, w45 = 0;
    return g72.forEach((t67) => {
      let n67 = e36[t67].paths.length, c103 = new d4(y43.slice(w45, w45 + n67));
      s84[t67].forEach((m96) => {
        let d55 = c103.slice(m96.groupOffset, m96.groupOffset + m96.sizeBytes), p103 = N4(d55, [m96.manifestEntry]);
        for (let b58 in p103) l80[b58] = p103[b58];
      }), w45 += n67;
    }), l80;
  };
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/http.mjs
var E26 = "application/octet-stream";
var M14 = "application/json";
var h32 = class {
  constructor(t67, e36) {
    if (this.DEFAULT_METHOD = "POST", e36 == null && (e36 = {}), this.weightPathPrefix = e36.weightPathPrefix, this.weightUrlConverter = e36.weightUrlConverter, e36.fetchFunc != null ? (c(typeof e36.fetchFunc == "function", () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)"), this.fetch = e36.fetchFunc) : this.fetch = l().platform.fetch, c(t67 != null && t67.length > 0, () => "URL path for http must not be null, undefined or empty."), Array.isArray(t67) && c(t67.length === 2, () => `URL paths for http must have a length of 2, (actual length is ${t67.length}).`), this.path = t67, e36.requestInit != null && e36.requestInit.body != null) throw new Error("requestInit is expected to have no pre-existing body, but has one.");
    this.requestInit = e36.requestInit || {}, this.loadOptions = e36;
  }
  async save(t67) {
    if (t67.modelTopology instanceof ArrayBuffer) throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
    let e36 = Object.assign({ method: this.DEFAULT_METHOD }, this.requestInit);
    e36.body = new FormData();
    let o80 = [{ paths: ["./model.weights.bin"], weights: t67.weightSpecs }], r56 = te2(t67, o80);
    if (e36.body.append("model.json", new Blob([JSON.stringify(r56)], { type: M14 }), "model.json"), t67.weightData != null) {
      let i88 = d4.join(t67.weightData);
      e36.body.append("model.weights.bin", new Blob([i88], { type: E26 }), "model.weights.bin");
    }
    let n67 = await this.fetch(this.path, e36);
    if (n67.ok) return { modelArtifactsInfo: re2(t67), responses: [n67] };
    throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${n67.status}.`);
  }
  async loadModelJSON() {
    let t67 = await this.fetch(this.path, this.requestInit);
    if (!t67.ok) throw new Error(`Request to ${this.path} failed with status code ${t67.status}. Please verify this URL points to the model JSON of the model to load.`);
    let e36;
    try {
      e36 = await t67.json();
    } catch {
      let i88 = `Failed to parse model JSON of response from ${this.path}.`;
      throw this.path.endsWith(".pb") ? i88 += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository." : i88 += " Please make sure the server is serving valid JSON for this request.", new Error(i88);
    }
    let o80 = e36.modelTopology, r56 = e36.weightsManifest;
    if (o80 == null && r56 == null) throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);
    return e36;
  }
  async load() {
    if (this.loadOptions.streamWeights) return this.loadStream();
    let t67 = await this.loadModelJSON();
    return ne2(t67, (e36) => this.loadWeights(e36));
  }
  async loadStream() {
    let t67 = await this.loadModelJSON(), e36 = await this.getWeightUrls(t67.weightsManifest), o80 = oe2(t67.weightsManifest), r56 = () => x38(e36, this.loadOptions);
    return Object.assign(Object.assign({}, t67), { weightSpecs: o80, getWeightStream: r56 });
  }
  async getWeightUrls(t67) {
    let e36 = Array.isArray(this.path) ? this.path[1] : this.path, [o80, r56] = R9(e36), n67 = this.weightPathPrefix || o80, i88 = [], l80 = [];
    for (let m96 of t67) for (let f85 of m96.paths) this.weightUrlConverter != null ? l80.push(this.weightUrlConverter(f85)) : i88.push(n67 + f85 + r56);
    return this.weightUrlConverter && i88.push(...await Promise.all(l80)), i88;
  }
  async loadWeights(t67) {
    let e36 = await this.getWeightUrls(t67), o80 = oe2(t67), r56 = await T24(e36, this.loadOptions);
    return [o80, r56];
  }
};
h32.URL_SCHEME_REGEX = /^https?:\/\//;
function R9(s84) {
  let t67 = s84.lastIndexOf("/"), e36 = s84.lastIndexOf("?"), o80 = s84.substring(0, t67), r56 = e36 > t67 ? s84.substring(e36) : "";
  return [o80 + "/", r56];
}
function u42(s84) {
  return s84.match(h32.URL_SCHEME_REGEX) != null;
}
var g29 = (s84, t67) => {
  if (typeof fetch > "u" && (t67 == null || t67.fetchFunc == null)) return null;
  {
    let e36 = true;
    if (Array.isArray(s84) ? e36 = s84.every((o80) => u42(o80)) : e36 = u42(s84), e36) return w22(s84, t67);
  }
  return null;
};
s6.registerSaveRouter(g29);
s6.registerLoadRouter(g29);
function w22(s84, t67) {
  return new h32(s84, t67);
}
function I16(s84, t67) {
  return w22(s84, t67);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/io/passthrough.mjs
var t5 = class {
  constructor(o80) {
    this.modelArtifacts = o80;
  }
  load() {
    return this.modelArtifacts;
  }
};
var n17 = class {
  constructor(o80) {
    this.saveHandler = o80;
  }
  save(o80) {
    return this.saveHandler(o80);
  }
};
var l30 = class {
  constructor(o80) {
    o80.load && (this.load = () => Promise.resolve(o80.load())), o80.save && (this.save = (r56) => Promise.resolve(o80.save(r56)));
  }
};
function u43(e36, o80, r56, a71) {
  let s84 = arguments;
  return new l30(i21(...s84));
}
function i21(e36, o80, r56, a71) {
  return arguments.length === 1 ? e36.modelTopology != null || e36.weightSpecs != null ? new t5(e36) : (console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."), new t5({ modelTopology: e36 })) : (console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."), new t5({ modelTopology: e36, weightSpecs: o80, weightData: r56, trainingConfig: a71 }));
}
function f41(e36) {
  return new n17(e36);
}
function m36(e36) {
  return new n17(e36);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/math.mjs
var math_exports = {};
__export(math_exports, {
  confusionMatrix: () => H6
});

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/confusion_matrix.mjs
function h33(a71, p103, t67) {
  let e36 = S5(a71, "labels", "confusionMatrix"), r56 = S5(p103, "predictions", "confusionMatrix");
  c(t67 == null || t67 > 0 && Number.isInteger(t67), () => `If provided, numClasses must be a positive integer, but got ${t67}`), c(e36.rank === 1, () => `Expected the rank of labels to be 1, but got ${e36.rank}`), c(r56.rank === 1, () => `Expected the rank of predictions to be 1, but got ${r56.rank}`), c(e36.shape[0] === r56.shape[0], () => `Mismatch in the number of examples: ${e36.shape[0]} vs. ${r56.shape[0]}. Labels and predictions should have the same number of elements.`), c(t67 > 0 && Number.isInteger(t67), () => `numClasses is required to be a positive integer, but got ${t67}`);
  let c103 = w15(w12(e36, "int32"), t67), u86 = w15(w12(r56, "int32"), t67), b58 = A10(c103), m96 = N6(b58, u86);
  return w12(m96, "int32");
}
var H6 = u4({ confusionMatrix_: h33 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/browser.mjs
var browser_exports = {};
__export(browser_exports, {
  draw: () => q11,
  fromPixels: () => z12,
  fromPixelsAsync: () => G13,
  toPixels: () => j10
});
var h34;
var v24 = false;
function k21(e36, n67 = 3) {
  if (n67 > 4) throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
  if (e36 == null) throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
  let t67 = false, r56 = false, i88 = false, d55 = false, u86 = false, c103 = false;
  if (e36.data instanceof Uint8Array) t67 = true;
  else if (typeof ImageData < "u" && e36 instanceof ImageData) r56 = true;
  else if (typeof HTMLVideoElement < "u" && e36 instanceof HTMLVideoElement) i88 = true;
  else if (typeof HTMLImageElement < "u" && e36 instanceof HTMLImageElement) d55 = true;
  else if (e36.getContext != null) u86 = true;
  else if (typeof ImageBitmap < "u" && e36 instanceof ImageBitmap) c103 = true;
  else throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${e36.constructor.name}`);
  if (w3(Se, v3.backendName) != null) {
    let p103 = { pixels: e36 }, w45 = { numChannels: n67 };
    return v3.runKernel(Se, p103, w45);
  }
  let [a71, o80] = i88 ? [e36.videoWidth, e36.videoHeight] : [e36.width, e36.height], s84;
  if (u86) s84 = e36.getContext("2d").getImageData(0, 0, a71, o80).data;
  else if (r56 || t67) s84 = e36.data;
  else if (d55 || i88 || c103) {
    if (h34 == null) if (typeof document > "u") if (typeof OffscreenCanvas < "u" && typeof OffscreenCanvasRenderingContext2D < "u") h34 = new OffscreenCanvas(1, 1).getContext("2d");
    else throw new Error("Cannot parse input in current context. Reason: OffscreenCanvas Context2D rendering is not supported.");
    else h34 = document.createElement("canvas").getContext("2d", { willReadFrequently: true });
    h34.canvas.width = a71, h34.canvas.height = o80, h34.drawImage(e36, 0, 0, a71, o80), s84 = h34.getImageData(0, 0, a71, o80).data;
  }
  let l80;
  if (n67 === 4) l80 = new Int32Array(s84);
  else {
    let p103 = a71 * o80;
    l80 = new Int32Array(p103 * n67);
    for (let w45 = 0; w45 < p103; w45++) for (let g72 = 0; g72 < n67; ++g72) l80[w45 * n67 + g72] = s84[w45 * 4 + g72];
  }
  return s28(l80, [o80, a71, n67], "int32");
}
function x39(e36) {
  return e36 != null && e36.data instanceof Uint8Array;
}
function $24() {
  return typeof globalThis < "u" && typeof ImageBitmap < "u" && globalThis.hasOwnProperty("createImageBitmap");
}
function H7(e36) {
  return e36 != null && e36.width !== 0 && e36.height !== 0;
}
function L4(e36) {
  return $24() && !(e36 instanceof ImageBitmap) && H7(e36) && !x39(e36);
}
async function G13(e36, n67 = 3) {
  let t67 = null;
  if (l().getBool("WRAP_TO_IMAGEBITMAP") && L4(e36)) {
    let r56;
    try {
      r56 = await createImageBitmap(e36, { premultiplyAlpha: "none" });
    } catch {
      r56 = null;
    }
    r56 != null && r56.width === e36.width && r56.height === e36.height ? t67 = r56 : t67 = e36;
  } else t67 = e36;
  return k21(t67, n67);
}
function M15(e36) {
  if (e36.rank !== 2 && e36.rank !== 3) throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${e36.rank}.`);
  let n67 = e36.rank === 2 ? 1 : e36.shape[2];
  if (n67 > 4 || n67 === 2) throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${n67}`);
  if (e36.dtype !== "float32" && e36.dtype !== "int32") throw new Error(`Unsupported type for toPixels: ${e36.dtype}. Please use float32 or int32 tensors.`);
}
function O9(e36) {
  let n67 = e36?.alpha || 1;
  if (n67 > 1 || n67 < 0) throw new Error(`Alpha value ${n67} is suppoed to be in range [0 - 1].`);
}
async function j10(e36, n67) {
  let t67 = S5(e36, "img", "toPixels");
  if (!(e36 instanceof o5)) {
    let a71 = t67;
    t67 = w12(a71, "int32"), a71.dispose();
  }
  M15(t67);
  let [r56, i88] = t67.shape.slice(0, 2), d55 = t67.rank === 2 ? 1 : t67.shape[2], u86 = await t67.data(), c103 = t67.dtype === "float32" ? 255 : 1, m96 = new Uint8ClampedArray(i88 * r56 * 4);
  for (let a71 = 0; a71 < r56 * i88; ++a71) {
    let o80 = [0, 0, 0, 255];
    for (let l80 = 0; l80 < d55; l80++) {
      let f85 = u86[a71 * d55 + l80];
      if (t67.dtype === "float32") {
        if (f85 < 0 || f85 > 1) throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${f85}.`);
      } else if (t67.dtype === "int32" && (f85 < 0 || f85 > 255)) throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${f85}.`);
      d55 === 1 ? (o80[0] = f85 * c103, o80[1] = f85 * c103, o80[2] = f85 * c103) : o80[l80] = f85 * c103;
    }
    let s84 = a71 * 4;
    m96[s84 + 0] = Math.round(o80[0]), m96[s84 + 1] = Math.round(o80[1]), m96[s84 + 2] = Math.round(o80[2]), m96[s84 + 3] = Math.round(o80[3]);
  }
  if (n67 != null) {
    v24 || w3(J2, v3.backendName) != null && (console.warn("tf.browser.toPixels is not efficient to draw tensor on canvas. Please try tf.browser.draw instead."), v24 = true), n67.width = i88, n67.height = r56;
    let a71 = n67.getContext("2d"), o80 = new ImageData(m96, i88, r56);
    a71.putImageData(o80, 0, 0);
  }
  return t67 !== e36 && t67.dispose(), m96;
}
function q11(e36, n67, t67) {
  let r56 = S5(e36, "img", "draw");
  if (!(e36 instanceof o5)) {
    let u86 = r56;
    r56 = w12(u86, "int32"), u86.dispose();
  }
  M15(r56), O9(t67?.imageOptions);
  let i88 = { image: r56 }, d55 = { canvas: n67, options: t67 };
  v3.runKernel(J2, i88, d55);
}
var z12 = u4({ fromPixels_: k21 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/gather_nd_util.mjs
var gather_nd_util_exports = {};
__export(gather_nd_util_exports, {
  prepareAndValidate: () => g30
});
function g30(r56, t67) {
  let n67 = r56.shape.length, s84 = t67.shape.length;
  if (n67 < 1) throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${n67}.`);
  if (s84 < 1) throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${s84}.`);
  if (t67.dtype !== "int32") throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${t67.dtype}.`);
  if (t67.shape[s84 - 1] > n67) throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${t67.shape[s84 - 1]} vs. ${n67}`);
  if (q(r56.shape) === 0) throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${r56.shape}.`);
  let h74 = t67.shape, o80 = h74[h74.length - 1], i88 = 1;
  for (let e36 = 0; e36 < h74.length - 1; ++e36) i88 *= h74[e36];
  let l80 = r56.shape, p103 = h74.slice();
  p103.pop();
  let a71 = 1;
  for (let e36 = o80; e36 < n67; ++e36) a71 *= l80[e36], p103.push(l80[e36]);
  let u86 = [...Y(r56.shape).map((e36) => e36 / a71), 1].slice(0, o80);
  return [p103, i88, a71, u86];
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/slice_util.mjs
var slice_util_exports = {};
__export(slice_util_exports, {
  assertParamsValid: () => z13,
  computeFlatOffset: () => j11,
  computeOutShape: () => C10,
  getNormalizedAxes: () => H8,
  isSliceContinous: () => K9,
  maskToAxes: () => B14,
  parseSliceParams: () => q12,
  sliceInfo: () => J6,
  startForAxis: () => W10,
  startIndicesWithElidedDims: () => O10,
  stopForAxis: () => L5,
  stopIndicesWithElidedDims: () => R10,
  stridesForAxis: () => X11,
  stridesWithElidedDims: () => T25
});
var y18 = -2;
var D11 = -1;
function z13(n67, e36, t67) {
  let r56 = n67.shape.length;
  c(r56 === e36.length, () => `Error in slice${r56}D: Length of begin ${e36} must match the rank of the array (${r56}).`), c(r56 === t67.length, () => `Error in slice${r56}D: Length of size ${t67} must match the rank of the array (${r56}).`);
  for (let i88 = 0; i88 < r56; ++i88) c(e36[i88] + t67[i88] <= n67.shape[i88], () => `Error in slice${r56}D: begin[${i88}] + size[${i88}] (${e36[i88] + t67[i88]}) would overflow input.shape[${i88}] (${n67.shape[i88]})`);
}
function B14(n67) {
  let e36 = [], t67 = 0;
  for (; n67 > 0; ) n67 & 1 && e36.push(t67), n67 /= 2, t67++;
  return e36;
}
function C10(n67, e36, t67) {
  let r56 = [];
  for (let i88 = 0; i88 < n67.length; i88++) r56[i88] = Math.ceil((e36[i88] - n67[i88]) / t67[i88]);
  return r56;
}
function T25(n67, e36, t67, r56) {
  let i88 = [...n67];
  for (let o80 = i88.length; o80 < r56.length; o80++) i88.push(1);
  for (let o80 = 0; o80 < t67; o80++) o80 === 0 ? i88[e36] = 1 : (i88.splice(e36, 0, 1), i88.pop());
  return i88;
}
function F6(n67, e36, t67) {
  return t67 <= n67 ? t67 : t67 - (e36 - 1);
}
function V6(n67, e36) {
  let t67 = [];
  for (let r56 = 0; r56 < n67; r56++) t67.push(e36 + r56);
  return t67;
}
function H8(n67, e36, t67, r56, i88, o80, f85, a71, u86) {
  let h74 = n67.length, x76 = new Array(h74), p103 = new Array(h74), s84 = new Array(h74);
  if (e36.length && t67 > 0) {
    let c103 = e36[0], A35 = t67 + 1;
    x76 = O10(f85, c103, A35, r56, n67), p103 = R10(a71, c103, A35, i88, n67), s84 = T25(o80, c103, A35, n67);
  } else for (let c103 = 0; c103 < h74; c103++) x76[c103] = W10(f85, r56, o80, n67, c103, u86), p103[c103] = L5(a71, i88, o80, n67, c103, u86), s84[c103] = X11(o80, c103, u86);
  return { begin: x76, end: p103, strides: s84 };
}
function O10(n67, e36, t67, r56, i88) {
  let o80 = [...i88], f85 = V6(t67, e36);
  for (let a71 = 0; a71 < o80.length; a71++) if (f85.indexOf(a71) > -1) o80[a71] = 0;
  else {
    let u86 = F6(e36, t67, a71), h74 = r56[u86];
    n67 & 1 << u86 && (h74 = 0), o80[a71] = h74;
  }
  return o80;
}
function R10(n67, e36, t67, r56, i88) {
  let o80 = [...i88], f85 = V6(t67, e36);
  for (let a71 = 0; a71 < o80.length; a71++) if (f85.indexOf(a71) > -1) o80[a71] = Number.MAX_SAFE_INTEGER;
  else {
    let u86 = F6(e36, t67, a71), h74 = r56[u86];
    n67 & 1 << u86 && (h74 = Number.MAX_SAFE_INTEGER), o80[a71] = h74;
  }
  for (let a71 = 0; a71 < o80.length; a71++) {
    let u86 = i88[a71];
    o80[a71] < 0 && (o80[a71] += u86), o80[a71] = F(0, o80[a71], i88[a71]);
  }
  return o80;
}
function X11(n67, e36, t67) {
  let r56 = n67[e36];
  return (t67 & 1 << e36 || r56 == null) && (r56 = 1), r56;
}
function W10(n67, e36, t67, r56, i88, o80) {
  let f85 = e36[i88], a71 = t67[i88] || 1;
  (n67 & 1 << i88 || o80 & 1 << i88 || f85 == null) && (a71 > 0 ? f85 = Number.MIN_SAFE_INTEGER : f85 = Number.MAX_SAFE_INTEGER);
  let u86 = r56[i88];
  return f85 < 0 && (f85 += u86), f85 = F(0, f85, u86 - 1), f85;
}
function L5(n67, e36, t67, r56, i88, o80) {
  let f85 = e36[i88], a71 = t67[i88] || 1;
  (n67 & 1 << i88 || o80 & 1 << i88 || f85 == null) && (a71 > 0 ? f85 = Number.MAX_SAFE_INTEGER : f85 = Number.MIN_SAFE_INTEGER);
  let u86 = r56[i88];
  return f85 < 0 && (f85 += u86), a71 > 0 ? f85 = F(0, f85, u86) : f85 = F(-1, f85, u86 - 1), f85;
}
function K9(n67, e36, t67) {
  let r56 = t67.length;
  for (let i88 = 0; i88 < t67.length; i88++) if (t67[i88] > 1) {
    r56 = i88;
    break;
  }
  for (let i88 = r56 + 1; i88 < t67.length; i88++) if (e36[i88] > 0 || t67[i88] !== n67[i88]) return false;
  return true;
}
function j11(n67, e36) {
  let t67 = n67.length > 0 ? n67[n67.length - 1] : 1;
  for (let r56 = 0; r56 < n67.length - 1; r56++) t67 += n67[r56] * e36[r56];
  return t67;
}
function q12(n67, e36, t67) {
  let r56, i88 = n67.shape.length;
  typeof e36 == "number" ? r56 = [e36, ...new Array(i88 - 1).fill(0)] : e36.length < i88 ? r56 = e36.concat(new Array(i88 - e36.length).fill(0)) : r56 = e36.slice(), r56.forEach((f85) => {
    c(f85 !== -1, () => "slice() does not support negative begin indexing.");
  });
  let o80;
  return t67 == null ? o80 = new Array(i88).fill(-1) : typeof t67 == "number" ? o80 = [t67, ...new Array(i88 - 1).fill(-1)] : t67.length < i88 ? o80 = t67.concat(new Array(i88 - t67.length).fill(-1)) : o80 = t67, o80 = o80.map((f85, a71) => f85 >= 0 ? f85 : (c(f85 === -1, () => `Negative size values should be exactly -1 but got ${f85} for the slice() size at index ${a71}.`), n67.shape[a71] - r56[a71])), [r56, o80];
}
function J6(n67, e36, t67, r56, i88, o80, f85, a71, u86) {
  let h74;
  if (r56 == null ? (h74 = new Array(e36.length), h74.fill(1)) : h74 = r56, f85 != null && f85 & f85 - 1) throw new Error("Multiple ellipses in slice is not allowed.");
  let x76 = false, p103 = { dims: h74.length, numAddAxisAfterEllipsis: 0, begin: e36.slice(), end: t67.slice(), strides: h74.slice(), beginMask: i88, endMask: o80, ellipsisMask: f85, newAxisMask: a71, shrinkAxisMask: u86 };
  for (let l80 = 0; l80 < p103.dims; l80++) x76 && 1 << l80 & a71 && p103.numAddAxisAfterEllipsis++, 1 << l80 & f85 && (x76 = true);
  x76 || (p103.ellipsisMask |= 1 << p103.dims, p103.dims++);
  let s84 = { dims: n67.length, beginMask: 0, endMask: 0, beginValid: false, endValid: false };
  v25(p103, s84);
  let c103 = true, A35 = true, k63 = true, E44 = [], I44 = [];
  for (let l80 = 0; l80 < n67.length; ++l80) {
    if (s84.strides[l80] === 0) throw Error(`strides[${l80}] must be non-zero`);
    let m96 = !!(s84.shrinkAxisMask & 1 << l80), d55 = n67[l80];
    if (d55 === -1) {
      E44.push(m96 ? 1 : -1);
      continue;
    }
    let N58 = [s84.beginMask & 1 << l80, s84.endMask & 1 << l80], $37 = [s84.strides[l80] > 0 ? 0 : -1, s84.strides[l80] > 0 ? d55 : d55 - 1];
    if (m96 && s84.strides[l80] <= 0) throw Error("only stride 1 allowed on non-range indexing.");
    k63 = k63 && s84.strides[l80] === 1;
    let M30 = !!(s84.beginMask & 1 << l80 && s84.endMask & 1 << l80);
    if (s84.beginValid && s84.endValid) {
      if (m96) {
        let G30 = s84.begin[l80] < 0 ? d55 + s84.begin[l80] : s84.begin[l80];
        if (s84.begin[l80] = G30, s84.end[l80] = s84.begin[l80] + 1, G30 < 0 || G30 >= d55) throw Error(`slice index ${s84.begin[l80]} of dimension ${l80} out of bounds.`);
      } else s84.begin[l80] = _13(s84.begin[l80], 0, s84.strides[l80], d55, N58, $37), s84.end[l80] = _13(s84.end[l80], 1, s84.strides[l80], d55, N58, $37);
      let b58 = s84.strides[l80] === 1 && s84.begin[l80] === 0 && s84.end[l80] === d55;
      c103 = c103 && b58, A35 = A35 && (l80 === 0 && s84.strides[l80] === 1 || b58);
    } else c103 = c103 && s84.strides[l80] === 1 && M30, A35 = A35 && (l80 === 0 && s84.strides[l80] === 1 || M30);
    let S45, w45 = false;
    if (s84.beginValid && s84.endValid ? (S45 = s84.end[l80] - s84.begin[l80], w45 = true) : m96 ? (S45 = 1, w45 = true) : M30 && d55 >= 0 && (s84.strides[l80] < 0 ? S45 = -d55 : S45 = d55, w45 = true), w45) {
      let b58;
      S45 === 0 || S45 < 0 != s84.strides[l80] < 0 ? b58 = 0 : b58 = Math.trunc(S45 / s84.strides[l80]) + (S45 % s84.strides[l80] !== 0 ? 1 : 0), E44.push(b58);
    } else E44.push(-1);
  }
  for (let l80 = 0; l80 < s84.finalShapeGatherIndices.length; ++l80) {
    let m96 = s84.finalShapeGatherIndices[l80];
    m96 >= 0 ? I44.push(E44[m96]) : m96 === y18 && I44.push(1);
  }
  return { finalShapeSparse: I44.filter((l80, m96) => s84.finalShapeGatherIndices[m96] !== y18), finalShape: I44, isIdentity: c103, sliceDim0: A35, isSimpleSlice: k63, begin: s84.begin, end: s84.end, strides: s84.strides };
}
function v25(n67, e36) {
  e36.beginMask = 0, e36.endMask = 0, e36.shrinkAxisMask = 0;
  let t67 = 0;
  e36.beginValid = n67.begin != null, e36.endValid = n67.end != null, e36.begin = new Array(e36.dims), e36.end = new Array(e36.dims), e36.strides = new Array(e36.dims), e36.finalShapeGatherIndices = [], e36.finalShapeGatherIndicesSparse = [], e36.inputShapeGatherIndicesSparse = new Array(e36.dims);
  for (let r56 = 0; r56 < n67.dims; r56++) if (1 << r56 & n67.ellipsisMask) {
    let i88 = Math.min(e36.dims - (n67.dims - r56) + 1 + n67.numAddAxisAfterEllipsis, e36.dims);
    for (; t67 < i88; t67++) e36.begin[t67] = 0, e36.end[t67] = 0, e36.strides[t67] = 1, e36.beginMask |= 1 << t67, e36.endMask |= 1 << t67, e36.finalShapeGatherIndices.push(t67), e36.finalShapeGatherIndicesSparse.push(-1), e36.inputShapeGatherIndicesSparse[t67] = r56;
  } else if (1 << r56 & n67.newAxisMask) e36.finalShapeGatherIndices.push(y18), e36.finalShapeGatherIndicesSparse.push(-1);
  else {
    if (t67 === e36.begin.length) throw Error(`Index out of range using input dim ${t67}; input has only ${e36.dims} dims, ${e36.begin.length}.`);
    n67.begin != null && (e36.begin[t67] = n67.begin[r56]), n67.end != null && (e36.end[t67] = n67.end[r56]), e36.strides[t67] = n67.strides[r56], n67.beginMask & 1 << r56 && (e36.beginMask |= 1 << t67), n67.endMask & 1 << r56 && (e36.endMask |= 1 << t67), n67.shrinkAxisMask & 1 << r56 ? (e36.finalShapeGatherIndices.push(D11), e36.finalShapeGatherIndicesSparse.push(-1), e36.shrinkAxisMask |= 1 << t67) : (e36.finalShapeGatherIndices.push(t67), e36.finalShapeGatherIndicesSparse.push(r56)), e36.inputShapeGatherIndicesSparse[t67] = r56, t67++;
  }
}
function _13(n67, e36, t67, r56, i88, o80) {
  if (i88[e36]) return t67 > 0 ? o80[e36] : o80[e36 + 1 & 1];
  {
    let f85 = n67 < 0 ? r56 + n67 : n67;
    return f85 < o80[0] ? o80[0] : f85 > o80[1] ? o80[1] : f85;
  }
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/version.mjs
var o12 = "4.22.0";

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/optimizers/optimizer_constructors.mjs
var i22 = class {
  static sgd(r56) {
    return new n16(r56);
  }
  static momentum(r56, t67, m96 = false) {
    return new h30(r56, t67, m96);
  }
  static rmsprop(r56, t67 = 0.9, m96 = 0, a71 = null, e36 = false) {
    return new A11(r56, t67, m96, a71, e36);
  }
  static adam(r56 = 1e-3, t67 = 0.9, m96 = 0.999, a71 = null) {
    return new y16(r56, t67, m96, a71);
  }
  static adadelta(r56 = 1e-3, t67 = 0.95, m96 = null) {
    return new v23(r56, t67, m96);
  }
  static adamax(r56 = 2e-3, t67 = 0.9, m96 = 0.999, a71 = null, e36 = 0) {
    return new w21(r56, t67, m96, a71, e36);
  }
  static adagrad(r56, t67 = 0.1) {
    return new m35(r56, t67);
  }
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/train.mjs
var o13 = i22;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/browser_util.mjs
var __setImmediate$ = (cb, ...args) => ({ $t: setTimeout(cb, 0, ...args), [Symbol.dispose]() {
  clearTimeout(this.t);
} });
var t6 = typeof requestAnimationFrame < "u" ? requestAnimationFrame : typeof __setImmediate$ < "u" ? __setImmediate$ : (e36) => e36();
function n18() {
  return new Promise((e36) => t6(() => e36()));
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/backends/backend_util.mjs
var backend_util_exports = {};
__export(backend_util_exports, {
  ERF_A1: () => t7,
  ERF_A2: () => c45,
  ERF_A3: () => e19,
  ERF_A4: () => n20,
  ERF_A5: () => p48,
  ERF_P: () => o18,
  PARALLELIZE_THRESHOLD: () => o15,
  RowPartitionType: () => u45,
  SELU_SCALE: () => o17,
  SELU_SCALEALPHA: () => L6,
  applyActivation: () => b20,
  assertAndGetBroadcastShape: () => u14,
  assertAxesAreInnerMostDims: () => h15,
  assertParamsConsistent: () => u44,
  assignToTypedArray: () => f45,
  axesAreInnerMostDims: () => p22,
  calculateShapes: () => m26,
  checkEinsumDimSizes: () => I17,
  checkPadOnDimRoundingMode: () => z5,
  combineLocations: () => c20,
  combineRaggedTensorToTensorShapes: () => f43,
  complexWithEvenIndex: () => s31,
  complexWithOddIndex: () => i24,
  computeConv2DInfo: () => V3,
  computeConv3DInfo: () => j6,
  computeDefaultPad: () => P5,
  computeDilation2DInfo: () => K6,
  computeOptimalWindowSize: () => p47,
  computeOutAndReduceShapes: () => l17,
  computeOutShape: () => f42,
  computePool2DInfo: () => Q5,
  computePool3DInfo: () => Y3,
  convertConv2DDataFormat: () => J5,
  decodeEinsumEquation: () => y19,
  eitherStridesOrDilationsAreOne: () => Z6,
  expandShapeToKeepDim: () => m20,
  exponent: () => u46,
  exponents: () => c46,
  fromStringArrayToUint8: () => n22,
  fromUint8ToStringArray: () => x40,
  getAxesPermutation: () => x21,
  getBroadcastDims: () => c17,
  getComplexWithIndex: () => g32,
  getEinsumComputePath: () => A13,
  getEinsumPermutation: () => $25,
  getFusedBiasGradient: () => $20,
  getFusedDyActivation: () => _11,
  getImageCenter: () => f44,
  getInnerMostAxes: () => a13,
  getPermuted: () => c44,
  getRaggedRank: () => i23,
  getReductionAxes: () => f15,
  getReshaped: () => o16,
  getReshapedPermuted: () => n19,
  getRowPartitionTypesHelper: () => S19,
  getSliceBeginCoords: () => l31,
  getSliceSize: () => g31,
  getSparseFillEmptyRowsIndicesDenseShapeMismatch: () => n21,
  getSparseFillEmptyRowsNegativeIndexErrorMessage: () => r12,
  getSparseFillEmptyRowsOutOfRangeIndexErrorMessage: () => t8,
  getSparseReshapeEmptyTensorZeroOutputDimErrorMessage: () => i25,
  getSparseReshapeInputOutputMismatchErrorMessage: () => h37,
  getSparseReshapeInputOutputMultipleErrorMessage: () => a27,
  getSparseReshapeMultipleNegativeOneOutputDimErrorMessage: () => p49,
  getSparseReshapeNegativeOutputDimErrorMessage: () => o19,
  getSparseSegmentReductionIndicesOutOfRangeErrorMessage: () => o20,
  getSparseSegmentReductionNegativeSegmentIdsErrorMessage: () => r13,
  getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage: () => s32,
  getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage: () => g33,
  getUndoAxesPermutation: () => d9,
  isIdentityPermutation: () => R11,
  log: () => l3,
  mergeRealAndImagArrays: () => l32,
  prepareAndValidate: () => g30,
  prepareSplitSize: () => y20,
  segment_util: () => segment_util_exports,
  shouldFuse: () => B9,
  slice_util: () => slice_util_exports,
  splitRealAndImagArrays: () => h35,
  stridesOrDilationsArePositive: () => _6,
  tupleValuesAreOne: () => R6,
  upcastType: () => c5,
  validateDefaultValueShape: () => o14,
  validateInput: () => $17,
  validateUpdateShape: () => k16,
  warn: () => t2
});

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/concat_util.mjs
function u44(e36, o80) {
  let t67 = e36[0].length;
  e36.forEach((a71, c103) => {
    c(a71.length === t67, () => `Error in concat${t67}D: rank of tensors[${c103}] must be the same as the rank of the rest (${t67})`);
  }), c(o80 >= 0 && o80 < t67, () => `Error in concat${t67}D: axis must be between 0 and ${t67 - 1}.`);
  let r56 = e36[0];
  e36.forEach((a71, c103) => {
    for (let n67 = 0; n67 < t67; n67++) c(n67 === o80 || a71[n67] === r56[n67], () => `Error in concat${t67}D: Shape of tensors[${c103}] (${a71}) does not match the shape of the rest (${r56}) along the non-concatenated axis ${c103}.`);
  });
}
function f42(e36, o80) {
  let t67 = e36[0].slice();
  for (let r56 = 1; r56 < e36.length; r56++) t67[o80] += e36[r56][o80];
  return t67;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/ragged_to_dense_util.mjs
var u45;
(function(n67) {
  n67[n67.FIRST_DIM_SIZE = 0] = "FIRST_DIM_SIZE", n67[n67.VALUE_ROWIDS = 1] = "VALUE_ROWIDS", n67[n67.ROW_LENGTHS = 2] = "ROW_LENGTHS", n67[n67.ROW_SPLITS = 3] = "ROW_SPLITS", n67[n67.ROW_LIMITS = 4] = "ROW_LIMITS", n67[n67.ROW_STARTS = 5] = "ROW_STARTS";
})(u45 || (u45 = {}));
function f43(n67, r56, e36) {
  let t67 = new Array();
  if (e36 == null && r56 == null) return t67;
  if (r56 == null) for (; t67.length < n67 + e36.length; ) t67.push(-1);
  else t67 = r56.slice();
  if (e36 == null) return t67;
  if (n67 + e36.length !== t67.length) throw new Error(`rt input.shape and shape=${r56} are incompatible: rt input.rank = ${n67 + e36.length}, but shape.rank = ${t67.length}`);
  for (let l80 = 1; l80 < e36.length; ++l80) {
    let s84 = e36[l80], I44 = t67[t67.length - e36.length + l80], _24 = t67[I44];
    if (s84 >= 0) if (_24 >= 0) {
      if (_24 !== s84) throw new Error(`rt input.shape and shape=${r56} are incompatible: rt input.shape[${l80 + n67}] = ${s84} but shape[${l80 + n67}] = ${_24}`);
    } else t67[I44] = s84;
  }
  return t67;
}
function S19(n67) {
  let r56 = { FIRST_DIM_SIZE: u45.FIRST_DIM_SIZE, VALUE_ROWIDS: u45.VALUE_ROWIDS, ROW_LENGTHS: u45.ROW_LENGTHS, ROW_SPLITS: u45.ROW_SPLITS, ROW_LIMITS: u45.ROW_LIMITS, ROW_STARTS: u45.ROW_STARTS }, e36 = [];
  for (let t67 of n67) if (t67 in r56) e36.push(r56[t67]);
  else break;
  return e36;
}
function i23(n67) {
  return n67.length === 0 ? 0 : n67[0] === u45.FIRST_DIM_SIZE ? n67.length - 1 : n67.length;
}
function o14(n67, r56) {
  if (n67 == null || r56 == null) return;
  let e36 = n67.length, t67 = r56.length;
  if (e36 >= t67) throw new Error(`defaultValue.shape=${n67} and ragged tensor flatValues.shape=${r56}, are incompatible: defaultValue.rank = ${e36} must be less than ragged tensor input flatValues.rank = ${t67})`);
  for (let l80 = 0; l80 < Math.min(e36, t67 - 1); ++l80) {
    let s84 = n67[l80], I44 = r56[l80 + 1];
    if (s84 >= 0 && I44 >= 0 && s84 !== 1 && s84 !== I44) throw new Error(`defaultValue.shape=${n67}, and ragged tensor input flatValues.shape=${r56} are incompatible: defaultValue.shape[${l80 - n67.length}] = ${s84} but ragged tensor input.flatValues.shape[${l80 - n67.length}] = ${I44}`);
  }
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/reduce_util.mjs
var o15 = 30;
function p47(t67) {
  return t67 <= o15 ? t67 : X(t67, Math.floor(Math.sqrt(t67)));
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/rotate_util.mjs
function f44(o80, t67, n67) {
  let e36 = n67 * (typeof o80 == "number" ? o80 : o80[0]), u86 = t67 * (typeof o80 == "number" ? o80 : o80[1]);
  return [e36, u86];
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/array_ops_util.mjs
function o16(t67, r56, f85, s84 = true) {
  let e36 = [];
  if (s84) e36 = e36.concat(r56.slice(0)), e36.push(t67[0] / f85), e36 = e36.concat(t67.slice(1));
  else {
    e36 = e36.concat(t67[0]);
    let u86 = r56.length;
    for (let i88 = 0; i88 < u86; ++i88) e36 = e36.concat([t67[i88 + 1] / r56[i88], r56[i88]]);
    e36 = e36.concat(t67.slice(u86 + 1));
  }
  return e36;
}
function c44(t67, r56, f85 = true) {
  let s84 = [];
  if (f85) {
    s84.push(r56);
    for (let e36 = r56 + 1; e36 < t67; ++e36) e36 <= 2 * r56 ? (s84.push(e36), s84.push(e36 - (r56 + 1))) : s84.push(e36);
  } else {
    let e36 = [], u86 = [];
    for (let i88 = 1; i88 < t67; ++i88) i88 >= r56 * 2 + 1 || i88 % 2 === 1 ? u86.push(i88) : e36.push(i88);
    s84.push(...e36), s84.push(0), s84.push(...u86);
  }
  return s84;
}
function n19(t67, r56, f85, s84 = true) {
  let e36 = [];
  s84 ? e36.push(t67[0] / f85) : e36.push(t67[0] * f85);
  for (let u86 = 1; u86 < t67.length; ++u86) u86 <= r56.length ? s84 ? e36.push(r56[u86 - 1] * t67[u86]) : e36.push(t67[u86] / r56[u86 - 1]) : e36.push(t67[u86]);
  return e36;
}
function l31(t67, r56) {
  let f85 = [0];
  for (let s84 = 0; s84 < r56; ++s84) f85.push(t67[s84][0]);
  return f85;
}
function g31(t67, r56, f85) {
  let s84 = t67.slice(0, 1);
  for (let e36 = 0; e36 < f85; ++e36) s84.push(t67[e36 + 1] - r56[e36][0] - r56[e36][1]);
  return s84;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/selu_util.mjs
var L6 = 1.7580993408473768;
var o17 = 1.0507009873554805;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/erf_util.mjs
var o18 = 0.3275911;
var t7 = 0.254829592;
var c45 = -0.284496736;
var e19 = 1.421413741;
var n20 = -1.453152027;
var p48 = 1.061405429;

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/backends/complex_util.mjs
function l32(t67, e36) {
  if (t67.length !== e36.length) throw new Error(`Cannot merge real and imag arrays of different lengths. real:${t67.length}, imag: ${e36.length}.`);
  let r56 = new Float32Array(t67.length * 2);
  for (let n67 = 0; n67 < r56.length; n67 += 2) r56[n67] = t67[n67 / 2], r56[n67 + 1] = e36[n67 / 2];
  return r56;
}
function h35(t67) {
  let e36 = new Float32Array(t67.length / 2), r56 = new Float32Array(t67.length / 2);
  for (let n67 = 0; n67 < t67.length; n67 += 2) e36[n67 / 2] = t67[n67], r56[n67 / 2] = t67[n67 + 1];
  return { real: e36, imag: r56 };
}
function s31(t67) {
  let e36 = Math.ceil(t67.length / 4), r56 = new Float32Array(e36), n67 = new Float32Array(e36);
  for (let o80 = 0; o80 < t67.length; o80 += 4) r56[Math.floor(o80 / 4)] = t67[o80], n67[Math.floor(o80 / 4)] = t67[o80 + 1];
  return { real: r56, imag: n67 };
}
function i24(t67) {
  let e36 = Math.floor(t67.length / 4), r56 = new Float32Array(e36), n67 = new Float32Array(e36);
  for (let o80 = 2; o80 < t67.length; o80 += 4) r56[Math.floor(o80 / 4)] = t67[o80], n67[Math.floor(o80 / 4)] = t67[o80 + 1];
  return { real: r56, imag: n67 };
}
function g32(t67, e36) {
  let r56 = t67[e36 * 2], n67 = t67[e36 * 2 + 1];
  return { real: r56, imag: n67 };
}
function f45(t67, e36, r56, n67) {
  t67[n67 * 2] = e36, t67[n67 * 2 + 1] = r56;
}
function c46(t67, e36) {
  let r56 = new Float32Array(t67 / 2), n67 = new Float32Array(t67 / 2);
  for (let o80 = 0; o80 < Math.ceil(t67 / 2); o80++) {
    let a71 = (e36 ? 2 : -2) * Math.PI * (o80 / t67);
    r56[o80] = Math.cos(a71), n67[o80] = Math.sin(a71);
  }
  return { real: r56, imag: n67 };
}
function u46(t67, e36, r56) {
  let n67 = (r56 ? 2 : -2) * Math.PI * (t67 / e36), o80 = Math.cos(n67), a71 = Math.sin(n67);
  return { real: o80, imag: a71 };
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/backends/einsum_util.mjs
var h36 = "->";
var E27 = /->/g;
var m37 = ",";
var d18 = "...";
function y19(i88, s84) {
  i88 = i88.replace(/\s/g, "");
  let n67 = (i88.length - i88.replace(E27, "").length) / h36.length;
  if (n67 < 1) throw new Error("Equations without an arrow are not supported.");
  if (n67 > 1) throw new Error(`Equation must contain exactly one arrow ("${h36}").`);
  let [o80, t67] = i88.split(h36);
  c(o80.indexOf(d18) === -1, () => `The ellipsis notation ("${d18}") is not supported yet.`);
  let p103 = o80.split(m37), e36 = p103.length;
  if (s84 !== e36) throw new Error(`Expected ${e36} input tensors, received ${s84}`);
  if (e36 > 2) throw new Error("Support for more than 2 input tensors is not implemented yet.");
  let l80 = [];
  for (let r56 = 0; r56 < t67.length; ++r56) {
    let u86 = t67[r56];
    if (!p103.some((x76) => x76.indexOf(u86) !== -1)) throw new Error(`Output subscripts contain the label ${u86} not present in the input subscripts.`);
    l80.indexOf(u86) === -1 && l80.push(u86);
  }
  for (let r56 = 0; r56 < o80.length; ++r56) {
    let u86 = o80[r56];
    l80.indexOf(u86) === -1 && u86 !== m37 && l80.push(u86);
  }
  let c103 = new Array(p103.length);
  for (let r56 = 0; r56 < e36; ++r56) {
    if (new Set(p103[r56].split("")).size !== p103[r56].length) throw new Error(`Found duplicate axes in input component ${p103[r56]}. Support for duplicate axes in input is not implemented yet.`);
    c103[r56] = [];
    for (let u86 = 0; u86 < p103[r56].length; ++u86) c103[r56].push(l80.indexOf(p103[r56][u86]));
  }
  let f85 = l80.length, w45 = t67.length, a71 = [];
  for (let r56 = w45; r56 < f85; ++r56) a71.push(r56);
  return { allDims: l80, summedDims: a71, idDims: c103 };
}
function $25(i88, s84) {
  let n67 = new Array(i88);
  n67.fill(-1);
  for (let t67 = 0; t67 < s84.length; ++t67) n67[s84[t67]] = t67;
  let o80 = [];
  for (let t67 = 0; t67 < i88; ++t67) n67[t67] === -1 && o80.push(t67);
  return n67 = n67.filter((t67) => t67 !== -1), { permutationIndices: n67, expandDims: o80 };
}
function I17(i88, s84, n67) {
  let o80 = new Array(i88);
  for (let t67 = 0; t67 < n67.length; ++t67) {
    let p103 = n67[t67].shape;
    for (let e36 = 0; e36 < s84[t67].length; ++e36) o80[s84[t67][e36]] === void 0 ? o80[s84[t67][e36]] = p103[e36] : c(o80[s84[t67][e36]] === p103[e36], () => `Expected dimension ${o80[s84[t67][e36]]} at axis ${e36} of input shaped ${JSON.stringify(p103)}, but got dimension ${p103[e36]}`);
  }
}
function A13(i88, s84) {
  let n67 = i88, o80 = [], t67 = 0;
  i88.length === 0 && n67.push(-1), t67 = i88.length + 1;
  for (let e36 = 0; e36 < t67; ++e36) o80.push([]);
  let p103 = [];
  for (let e36 = 0; e36 < n67.length; ++e36) {
    let l80 = n67[e36], c103 = O11(s84, l80);
    for (let f85 of c103) p103.indexOf(f85) === -1 && (o80[e36].push(f85), p103.push(f85));
  }
  return { path: n67, steps: o80 };
}
function R11(i88) {
  return i88.every((s84, n67) => s84 === n67);
}
function O11(i88, s84) {
  let n67 = [];
  for (let o80 = 0; o80 < i88.length; ++o80) (i88[o80].length === 0 || i88[o80].indexOf(s84) !== -1 || s84 === -1) && n67.push(o80);
  return n67;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/split_util.mjs
function y20(t67, e36, f85 = 0) {
  let a71 = [];
  if (typeof e36 == "number") c(t67.shape[f85] % e36 === 0, () => "Number of splits must evenly divide the axis."), a71 = new Array(e36).fill(t67.shape[f85] / e36);
  else {
    let d55 = e36.reduce((o80, s84) => (s84 === -1 && (o80 += 1), o80), 0);
    c(d55 <= 1, () => "There should be only one negative value in split array.");
    let r56 = e36.indexOf(-1);
    if (r56 !== -1) {
      let o80 = e36.reduce((s84, n67) => n67 > 0 ? s84 + n67 : s84);
      e36[r56] = t67.shape[f85] - o80;
    }
    c(t67.shape[f85] === e36.reduce((o80, s84) => o80 + s84), () => "The sum of sizes must match the size of the axis dimension."), a71 = e36;
  }
  return a71;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sparse/sparse_fill_empty_rows_util.mjs
function n21(e36) {
  return `Received SparseTensor with denseShape[0] = 0 but
  indices.shape[0] = ${e36}`;
}
function r12(e36, i88) {
  return `indices(${e36}, 0) is invalid: ${i88} < 0`;
}
function t8(e36, i88, s84) {
  return `indices(${e36}, 0) is invalid: ${i88} >= ${s84}`;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sparse/sparse_reshape_util.mjs
function p49(e36, t67) {
  return `only one output dimension may be -1, not both ${e36} and ${t67}`;
}
function o19(e36, t67) {
  return `size ${e36} must be non-negative, not ${t67}`;
}
function i25() {
  return "reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero";
}
function a27(e36, t67) {
  let r56 = q(e36), n67 = q(t67);
  return `Input to reshape is a SparseTensor with ${r56}
  dense values, but the requested shape requires a multiple of ${n67}. inputShape=${e36} outputShape= ${t67}`;
}
function h37(e36, t67) {
  let r56 = q(e36), n67 = q(t67);
  return `Input to reshape is a tensor with ${r56} dense values, but the requested shape has ${n67}. inputShape=${e36} outputShape=${t67}`;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/sparse/sparse_segment_reduction_util.mjs
function r13() {
  return "segment ids must be >= 0";
}
function s32() {
  return "segment ids are not increasing";
}
function g33(e36, n67) {
  return `Segment id ${e36} out of range [0, ${n67}), possibly because segmentIds input is not sorted.`;
}
function o20(e36, n67, t67) {
  return `Bad: indices[${e36}] == ${n67} out of range [0, ${t67})`;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/segment_util.mjs
var segment_util_exports = {};
__export(segment_util_exports, {
  collectGatherOpShapeInfo: () => c47,
  computeOutShape: () => O12,
  segOpComputeOptimalWindowSize: () => g34
});
function g34(o80, p103) {
  let r56 = false, t67;
  for (o80 <= o15 ? (t67 = o80, r56 = true) : t67 = X(o80, Math.floor(Math.sqrt(o80))); !r56; ) t67 > p103 || t67 === o80 ? r56 = true : t67 = X(o80, t67 + 1);
  return t67;
}
function O12(o80, p103, r56) {
  let t67 = [], h74 = o80.length;
  for (let s84 = 0; s84 < h74; s84++) s84 !== p103 ? t67.push(o80[s84]) : t67.push(r56);
  return t67;
}
function c47(o80, p103, r56, t67) {
  let h74 = p103.shape.length, s84 = o80.shape.length;
  if (t67 !== 0 && (t67 < -h74 || t67 > h74)) throw new Error(`Expect batchDims in the range of [-${h74}, ${h74}], but got ${t67}`);
  if (t67 < 0 && (t67 += h74), t67 > s84) throw new Error(`batchDims (${t67}) must be less than rank(x) (
    ${s84}).`);
  if (r56 < t67) throw new Error(`batchDims (${t67}) must be less than or equal to axis (${r56}).`);
  for (let e36 = 0; e36 < t67; ++e36) if (o80.shape[e36] !== p103.shape[e36]) throw new Error(`x.shape[${e36}]: ${o80.shape[e36]} should be equal to indices.shape[${e36}]: ${p103.shape[e36]}.`);
  let $37 = o80.shape[r56], l80 = [], n67 = 1, u86 = 1, f85 = 1;
  for (let e36 = 0; e36 < t67; ++e36) l80.push(o80.shape[e36]), n67 *= o80.shape[e36];
  for (let e36 = t67; e36 < r56; e36++) l80.push(o80.shape[e36]), u86 *= o80.shape[e36];
  for (let e36 = t67; e36 < h74; e36++) l80.push(p103.shape[e36]);
  for (let e36 = r56 + 1; e36 < s84; e36++) l80.push(o80.shape[e36]), f85 *= o80.shape[e36];
  return { batchSize: n67, sliceSize: f85, outerSize: u86, dimSize: $37, outputShape: l80 };
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/backends/backend_util.mjs
function x40(o80) {
  try {
    return o80.map((r56) => w5(r56));
  } catch (r56) {
    throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${r56}`);
  }
}
function n22(o80) {
  return o80.map((r56) => m4(r56));
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/backends/kernel_impls.mjs
var kernel_impls_exports = {};
__export(kernel_impls_exports, {
  nonMaxSuppressionV3Impl: () => B12,
  nonMaxSuppressionV4Impl: () => V4,
  nonMaxSuppressionV5Impl: () => O7,
  whereImpl: () => c37
});

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/tfjs-core.mjs
S17();

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/cpu_util.mjs
function i26(o80, e36) {
  Array.isArray(o80) || (o80 = [o80]), o80.forEach((r56) => {
    r56 != null && util_exports.assert(r56.dtype !== "complex64", () => `${e36} does not support complex64 tensors in the CPU backend.`);
  });
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/backend_cpu.mjs
var g35 = kernel_impls_exports.whereImpl;
var o21 = class l33 extends o {
  nextDataId() {
    return l33.nextDataId++;
  }
  constructor() {
    super(), this.blockSize = 48, this.firstUse = true, this.data = new n(this, k7());
  }
  write(e36, t67, r56) {
    this.firstUse && (this.firstUse = false, l().get("IS_NODE") && backend_util_exports.warn(`
============================
Hi, looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, visit https://github.com/tensorflow/tfjs-node for more details. 
============================`));
    let s84 = { id: this.nextDataId() };
    return this.data.set(s84, { values: e36, dtype: r56, refCount: 1 }), s84;
  }
  makeTensorInfo(e36, t67, r56) {
    let s84;
    if (t67 === "string" && r56 != null && r56.length > 0 && util_exports.isString(r56[0])) {
      let n67 = r56.map((h74) => util_exports.encodeString(h74));
      s84 = this.write(n67, e36, t67);
    } else s84 = this.write(r56, e36, t67);
    return { dataId: s84, shape: e36, dtype: t67 };
  }
  refCount(e36) {
    return this.data.has(e36) ? this.data.get(e36).refCount : 0;
  }
  incRef(e36) {
    let t67 = this.data.get(e36);
    t67.refCount++;
  }
  decRef(e36) {
    if (this.data.has(e36)) {
      let t67 = this.data.get(e36);
      t67.refCount--;
    }
  }
  move(e36, t67, r56, s84, n67) {
    this.data.set(e36, { values: t67, dtype: s84, refCount: n67 });
  }
  numDataIds() {
    return this.data.numDataIds();
  }
  async read(e36) {
    return this.readSync(e36);
  }
  readSync(e36) {
    let { dtype: t67, complexTensorInfos: r56 } = this.data.get(e36);
    if (t67 === "complex64") {
      let s84 = this.readSync(r56.real.dataId), n67 = this.readSync(r56.imag.dataId);
      return backend_util_exports.mergeRealAndImagArrays(s84, n67);
    }
    return util_exports.convertBackendValuesAndArrayBuffer(this.data.get(e36).values, t67);
  }
  bufferSync(e36) {
    let t67 = this.readSync(e36.dataId);
    if (e36.dtype === "string") try {
      let r56 = t67.map((s84) => util_exports.decodeString(s84));
      return i7(e36.shape, e36.dtype, r56);
    } catch {
      throw new Error("Failed to decode encoded string bytes into utf-8");
    }
    return i7(e36.shape, e36.dtype, t67);
  }
  makeOutput(e36, t67, r56) {
    return k7().makeTensorFromTensorInfo(this.makeTensorInfo(t67, r56, e36), this);
  }
  disposeData(e36, t67 = false) {
    if (this.data.has(e36)) {
      if (this.data.get(e36).refCount--, !t67 && this.data.get(e36).refCount > 0) return false;
      let { complexTensorInfos: r56 } = this.data.get(e36);
      r56 != null && (this.disposeData(r56.real.dataId, true), this.disposeData(r56.imag.dataId, true)), this.data.delete(e36);
    }
    return true;
  }
  disposeIntermediateTensorInfo(e36) {
    this.disposeData(e36.dataId);
  }
  async time(e36) {
    let t67 = util_exports.now();
    return e36(), { kernelMs: util_exports.now() - t67 };
  }
  memory() {
    return { unreliable: true, reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."] };
  }
  where(e36) {
    i26([e36], "where");
    let t67 = this.readSync(e36.dataId);
    return g35(e36.shape, t67);
  }
  dispose() {
  }
  floatPrecision() {
    return 32;
  }
  epsilon() {
    return super.epsilon();
  }
};
o21.nextDataId = 0;

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/shared.mjs
var shared_exports = {};
__export(shared_exports, {
  addImpl: () => l35,
  bincountImpl: () => m38,
  bincountReduceImpl: () => g36,
  bitwiseAndImpl: () => o23,
  castImpl: () => k22,
  ceilImpl: () => c49,
  concatImpl: () => v26,
  equalImpl: () => m40,
  expImpl: () => m41,
  expm1Impl: () => o24,
  floorDivImpl: () => i30,
  floorImpl: () => l38,
  gatherNdImpl: () => w23,
  gatherV2Impl: () => x41,
  greaterEqualImpl: () => n26,
  greaterImpl: () => m42,
  lessEqualImpl: () => m44,
  lessImpl: () => m43,
  linSpaceImpl: () => a31,
  logImpl: () => n27,
  maxImpl: () => u51,
  maximumImpl: () => a33,
  minimumImpl: () => o25,
  multiplyImpl: () => i34,
  negImpl: () => u53,
  notEqualImpl: () => t12,
  prodImpl: () => b24,
  raggedGatherImpl: () => A16,
  raggedRangeImpl: () => z16,
  raggedTensorToTensorImpl: () => O13,
  rangeImpl: () => S21,
  rsqrtImpl: () => m47,
  scatterImpl: () => a36,
  sigmoidImpl: () => a37,
  simpleAbsImpl: () => p50,
  sliceImpl: () => F8,
  sparseFillEmptyRowsImpl: () => D12,
  sparseReshapeImpl: () => z18,
  sparseSegmentReductionImpl: () => b26,
  sqrtImpl: () => c53,
  squaredDifferenceImpl: () => i37,
  staticRegexReplaceImpl: () => o26,
  stridedSliceImpl: () => p53,
  stringNGramsImpl: () => v27,
  stringSplitImpl: () => m49,
  stringToHashBucketFastImpl: () => g39,
  subImpl: () => a38,
  tileImpl: () => h39,
  topKImpl: () => z19,
  transposeImpl: () => S20,
  uniqueImpl: () => z20
});

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Abs.mjs
function p50(a71) {
  let e36 = new Float32Array(a71.length);
  for (let t67 = 0; t67 < a71.length; ++t67) e36[t67] = Math.abs(a71[t67]);
  return e36;
}
var u47 = (a71) => {
  let { x: e36 } = a71.inputs, t67 = a71.backend;
  i26(e36, "abs");
  let n67 = new Float32Array(util_exports.sizeFromShape(e36.shape)), s84 = t67.data.get(e36.dataId).values;
  return n67 = p50(s84), t67.makeOutput(n67, e36.shape, e36.dtype);
};
var i27 = { kernelName: o3, backendName: "cpu", kernelFunc: u47 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/utils/binary_impl.mjs
function z14(a71) {
  return (c103, s84, r56, i88, p103) => {
    let n67 = backend_util_exports.assertAndGetBroadcastShape(c103, s84), D42 = n67.length, I44 = util_exports.computeStrides(n67), S45 = util_exports.sizeFromShape(n67), o80 = util_exports.getTypedArrayFromDType(p103, S45), m96 = c103.length, g72 = s84.length, T40 = util_exports.computeStrides(c103), k63 = util_exports.computeStrides(s84), u86 = backend_util_exports.getBroadcastDims(c103, n67), h74 = backend_util_exports.getBroadcastDims(s84, n67);
    if (u86.length + h74.length === 0) for (let t67 = 0; t67 < o80.length; ++t67) o80[t67] = a71(r56[t67 % r56.length], i88[t67 % i88.length]);
    else for (let t67 = 0; t67 < o80.length; ++t67) {
      let f85 = util_exports.indexToLoc(t67, D42, I44), x76 = f85.slice(-m96);
      u86.forEach((l80) => x76[l80] = 0);
      let y43 = util_exports.locToIndex(x76, m96, T40), B30 = f85.slice(-g72);
      h74.forEach((l80) => B30[l80] = 0);
      let L22 = util_exports.locToIndex(B30, g72, k63);
      o80[t67] = a71(r56[y43], i88[L22]);
    }
    return [o80, n67];
  };
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Complex.mjs
function r14(t67) {
  let { inputs: s84, backend: e36 } = t67, { real: a71, imag: o80 } = s84, c103 = e36.data.get(a71.dataId).values, l80 = e36.data.get(o80.dataId).values, n67 = e36.makeTensorInfo(a71.shape, "complex64"), m96 = e36.data.get(n67.dataId);
  return m96.complexTensorInfos = { real: e36.makeTensorInfo(a71.shape, "float32", c103), imag: e36.makeTensorInfo(o80.shape, "float32", l80) }, n67;
}
var f46 = { kernelName: P2, backendName: "cpu", kernelFunc: r14 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/utils/zeros_impl.mjs
function f47(o80, r56, t67 = "float32") {
  if (t67 === "complex64") {
    let l80 = f47(o80, r56, "float32"), e36 = f47(o80, r56, "float32");
    return r14({ inputs: { real: l80, imag: e36 }, backend: o80 });
  }
  let i88 = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(r56), t67);
  return o80.makeTensorInfo(r56, t67, i88);
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Identity.mjs
function i28(e36) {
  let { inputs: n67, backend: d55 } = e36, { x: t67 } = n67;
  return d55.incRef(t67.dataId), { dataId: t67.dataId, shape: t67.shape, dtype: t67.dtype };
}
var o22 = { kernelName: mo, backendName: "cpu", kernelFunc: i28 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Real.mjs
function l34(n67) {
  let { inputs: t67, backend: e36 } = n67, { input: o80 } = t67, a71 = e36.data.get(o80.dataId).complexTensorInfos.real, r56 = e36.data.get(a71.dataId).values;
  return e36.makeTensorInfo(a71.shape, a71.dtype, r56);
}
var d19 = { kernelName: gt, backendName: "cpu", kernelFunc: l34 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Cast.mjs
function k22(s84, a71, e36, n67) {
  if (n67 === "int32") {
    let t67 = Int32Array.from(s84);
    return [a71, "int32", t67];
  }
  if (n67 === "bool") {
    let t67 = util_exports.toTypedArray([0], e36), [o80, p103] = z14((c103, l80) => c103 !== l80 ? 1 : 0)(a71, [], s84, t67, "bool");
    return [p103, "bool", o80];
  }
  throw new Error(`Error in Cast: failed to cast ${e36} to ${n67}`);
}
function u48(s84) {
  let { inputs: a71, backend: e36, attrs: n67 } = s84, { x: t67 } = a71, { dtype: o80 } = n67;
  if (o80 === "complex64") {
    if (t67.dtype === "complex64") return i28({ inputs: { x: t67 }, backend: e36 });
    let r56 = f47(e36, t67.shape, t67.dtype), i88 = u48({ inputs: { x: t67 }, backend: e36, attrs: { dtype: "float32" } }), I44 = r14({ inputs: { real: i88, imag: r56 }, backend: e36 });
    return e36.disposeIntermediateTensorInfo(r56), e36.disposeIntermediateTensorInfo(i88), I44;
  }
  if (t67.dtype === "complex64") {
    let r56 = l34({ inputs: { input: t67 }, backend: e36 }), i88 = u48({ inputs: { x: r56 }, backend: e36, attrs: { dtype: o80 } });
    return e36.disposeIntermediateTensorInfo(r56), i88;
  }
  if (!util_exports.hasEncodingLoss(t67.dtype, o80)) {
    let r56 = i28({ inputs: { x: t67 }, backend: e36 });
    return { dataId: r56.dataId, shape: r56.shape, dtype: o80 };
  }
  let p103 = e36.data.get(t67.dataId).values, [c103, l80, f85] = k22(p103, t67.shape, t67.dtype, o80);
  return e36.makeTensorInfo(c103, l80, f85);
}
var A14 = { kernelName: C2, backendName: "cpu", kernelFunc: u48 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/utils/binary_utils.mjs
function G14(V24, g72, I44, k63) {
  return I44 == null ? ({ inputs: T40, backend: b58 }) => {
    let { a: a71, b: e36 } = T40, t67 = b58;
    i26([a71, e36], V24);
    let r56 = t67.data.get(a71.dataId).values, l80 = t67.data.get(e36.dataId).values, o80 = a71.dtype === "string" ? backend_util_exports.fromUint8ToStringArray(r56) : r56, c103 = a71.dtype === "string" ? backend_util_exports.fromUint8ToStringArray(l80) : l80, d55 = k63 || a71.dtype, [y43, n67] = g72(a71.shape, e36.shape, o80, c103, d55);
    return t67.makeTensorInfo(n67, d55, y43);
  } : ({ inputs: T40, backend: b58 }) => {
    let { a: a71, b: e36 } = T40, t67 = b58;
    if (a71.dtype === "complex64" || e36.dtype === "complex64") {
      let r56 = u48({ inputs: { x: a71 }, backend: t67, attrs: { dtype: "complex64" } }), l80 = t67.data.get(r56.dataId), o80 = l80.complexTensorInfos.real, c103 = l80.complexTensorInfos.imag, d55 = t67.data.get(o80.dataId).values, y43 = t67.data.get(c103.dataId).values, n67 = u48({ inputs: { x: e36 }, backend: t67, attrs: { dtype: "complex64" } }), i88 = t67.data.get(n67.dataId), R26 = i88.complexTensorInfos.real, B30 = i88.complexTensorInfos.imag, A35 = t67.data.get(R26.dataId).values, S45 = t67.data.get(B30.dataId).values, [s84, f85, p103] = I44(a71.shape, e36.shape, d55, y43, A35, S45), u86 = t67.makeTensorInfo(p103, "float32", s84), h74 = t67.makeTensorInfo(p103, "float32", f85), D42 = r14({ inputs: { real: u86, imag: h74 }, backend: t67 });
      return t67.disposeIntermediateTensorInfo(r56), t67.disposeIntermediateTensorInfo(n67), t67.disposeIntermediateTensorInfo(u86), t67.disposeIntermediateTensorInfo(h74), D42;
    } else {
      let r56 = t67.data.get(a71.dataId).values, l80 = t67.data.get(e36.dataId).values, o80 = k63 || a71.dtype, [c103, d55] = g72(a71.shape, e36.shape, r56, l80, o80);
      return t67.makeTensorInfo(d55, o80, c103);
    }
  };
}
function N25(V24) {
  return (g72, I44, k63, T40, b58, a71) => {
    let e36 = backend_util_exports.assertAndGetBroadcastShape(g72, I44), t67 = util_exports.sizeFromShape(e36), r56 = e36.length, l80 = util_exports.computeStrides(e36), o80 = util_exports.getTypedArrayFromDType("float32", t67), c103 = util_exports.getTypedArrayFromDType("float32", t67), d55 = backend_util_exports.getBroadcastDims(g72, e36), y43 = backend_util_exports.getBroadcastDims(I44, e36), n67 = backend_util_exports.mergeRealAndImagArrays(k63, T40), i88 = backend_util_exports.mergeRealAndImagArrays(b58, a71), R26 = g72.length, B30 = util_exports.computeStrides(g72), A35 = I44.length, S45 = util_exports.computeStrides(I44);
    if (d55.length + y43.length === 0) for (let s84 = 0; s84 < o80.length; s84++) {
      let f85 = s84 % n67.length, p103 = s84 % i88.length, u86 = V24(n67[f85 * 2], n67[f85 * 2 + 1], i88[p103 * 2], i88[p103 * 2 + 1]);
      o80[s84] = u86.real, c103[s84] = u86.imag;
    }
    else for (let s84 = 0; s84 < o80.length; s84++) {
      let f85 = util_exports.indexToLoc(s84, r56, l80), p103 = f85.slice(-R26);
      d55.forEach((v42) => p103[v42] = 0);
      let u86 = util_exports.locToIndex(p103, R26, B30), h74 = f85.slice(-A35);
      y43.forEach((v42) => h74[v42] = 0);
      let D42 = util_exports.locToIndex(h74, A35, S45), C28 = V24(n67[u86 * 2], n67[u86 * 2 + 1], i88[D42 * 2], i88[D42 * 2 + 1]);
      o80[s84] = C28.real, c103[s84] = C28.imag;
    }
    return [o80, c103, e36];
  };
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Add.mjs
var l35 = z14((e36, r56) => e36 + r56);
var d20 = N25((e36, r56, o80, m96) => ({ real: e36 + o80, imag: r56 + m96 }));
var c48 = G14(r, l35, d20);
var s33 = { kernelName: r, backendName: "cpu", kernelFunc: c48 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Bincount_impl.mjs
function m38(r56, s84, u86, c103, i88) {
  let l80 = util_exports.sizeFromShape(c103), t67 = util_exports.makeZerosTypedArray(i88, u86);
  for (let e36 = 0; e36 < r56.length; e36++) {
    let n67 = r56[e36];
    if (n67 < 0) throw new Error("Input x must be non-negative!");
    n67 >= i88 || (l80 > 0 ? t67[n67] += s84[e36] : t67[n67] += 1);
  }
  return t67;
}
function g36(r56, s84, u86, c103 = false) {
  let i88 = r56.shape[0], l80 = r56.shape[1], t67 = i7([i88, u86], s84.dtype);
  for (let e36 = 0; e36 < i88; e36++) for (let n67 = 0; n67 < l80; n67++) {
    let o80 = r56.get(e36, n67);
    if (o80 < 0) throw new Error("Input x must be non-negative!");
    o80 >= u86 || (c103 ? t67.set(1, e36, o80) : s84.size > 0 ? t67.set(t67.get(e36, o80) + s84.get(e36, n67), e36, o80) : t67.set(t67.get(e36, o80) + 1, e36, o80));
  }
  return t67;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/BitwiseAnd.mjs
var o23 = z14((n67, r56) => n67 & r56);
var m39 = G14(A2, o23);
var s34 = { kernelName: A2, backendName: "cpu", kernelFunc: m39 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/utils/unary_impl.mjs
function p51(n67) {
  return (t67, o80, i88) => {
    let e36 = util_exports.getArrayFromDType(o80, t67.length);
    for (let r56 = 0; r56 < t67.length; ++r56) e36[r56] = n67(t67[r56], i88);
    return e36;
  };
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/utils/unary_utils.mjs
function A15(e36, n67, t67) {
  let o80 = p51(n67);
  return y21(e36, o80, t67);
}
function y21(e36, n67, t67) {
  return ({ inputs: o80, attrs: p103, backend: u86 }) => {
    let { x: r56 } = o80;
    i26(r56, e36);
    let c103 = u86, a71 = c103.data.get(r56.dataId).values, s84;
    if (r56.dtype === "string") {
      if (!Array.isArray(a71)) throw new Error("String tensor's value was not an instance of Array");
      s84 = backend_util_exports.fromUint8ToStringArray(a71);
    } else s84 = a71;
    let i88 = t67 || r56.dtype, l80 = n67(s84, i88, p103);
    return c103.makeTensorInfo(r56.shape, i88, l80);
  };
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Ceil.mjs
var c49 = p51((r56) => Math.ceil(r56));
var l36 = y21(v2, c49);
var i29 = { kernelName: v2, backendName: "cpu", kernelFunc: l36 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Concat_impl.mjs
function v26(f85, h74, r56, m96) {
  let s84 = util_exports.getArrayFromDType(r56, util_exports.sizeFromShape(h74));
  if (m96 && r56 !== "string") {
    let o80 = 0;
    f85.forEach((e36) => {
      let t67 = util_exports.sizeFromShape(e36.shape);
      s84.set(e36.vals, o80), o80 += t67;
    });
  } else {
    let o80 = 0;
    f85.forEach((e36) => {
      let t67 = r56 === "string" ? backend_util_exports.fromUint8ToStringArray(e36.vals) : e36.vals, n67 = 0;
      for (let a71 = 0; a71 < e36.shape[0]; ++a71) {
        let i88 = a71 * h74[1] + o80;
        for (let l80 = 0; l80 < e36.shape[1]; ++l80) s84[i88 + l80] = t67[n67++];
      }
      o80 += e36.shape[1];
    });
  }
  return s84;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Equal.mjs
var m40 = z14((r56, o80) => r56 === o80 ? 1 : 0);
var a28 = G14(eo, m40, null, "bool");
var u49 = { kernelName: eo, backendName: "cpu", kernelFunc: a28 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Exp.mjs
var m41 = p51((p103) => Math.exp(p103));
var n23 = y21(ro, m41, "float32");
var l37 = { kernelName: ro, backendName: "cpu", kernelFunc: n23 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Expm1.mjs
var o24 = p51((m96) => Math.expm1(m96));
var n24 = y21(so, o24);
var a29 = { kernelName: so, backendName: "cpu", kernelFunc: n24 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Floor.mjs
var l38 = p51((r56) => Math.floor(r56));
var n25 = y21(xo, l38);
var f48 = { kernelName: xo, backendName: "cpu", kernelFunc: n25 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/FloorDiv.mjs
var i30 = z14((r56, e36) => Math.floor(r56 / e36));
var t9 = G14(io, i30, null, "int32");
var f49 = { kernelName: io, backendName: "cpu", kernelFunc: t9 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/GatherNd_Impl.mjs
function w23(p103, d55, I44, f85, e36, o80, g72, i88, l80) {
  let u86 = i7([f85, o80], I44);
  for (let n67 = 0; n67 < f85; n67++) {
    let x76 = [], r56 = 0;
    for (let t67 = 0; t67 < e36; t67++) {
      let h74 = p103[n67 * e36 + t67];
      r56 += h74 * g72[t67], x76.push(h74);
    }
    if (r56 < 0 || r56 >= l80 / o80) throw new Error(`Invalid indices: ${x76} does not index into ${i88}`);
    for (let t67 = 0; t67 < o80; t67++) u86.values[n67 * o80 + t67] = d55.get(...d55.indexToLoc(r56 * o80 + t67));
  }
  return u86;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/GatherV2_impl.mjs
function x41(o80, s84, i88) {
  let e36 = i7(i88, o80.dtype);
  for (let n67 = 0; n67 < e36.size; ++n67) {
    let c103 = e36.indexToLoc(n67).slice(), l80 = c103[0], r56 = c103[2], d55 = s84.locToIndex([l80, r56]);
    c103[2] = s84.values[d55];
    let t67 = o80.locToIndex(c103);
    0 <= t67 && t67 < o80.values.length && (e36.values[n67] = o80.values[t67]);
  }
  return e36;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Greater.mjs
var m42 = z14((r56, o80) => r56 > o80 ? 1 : 0);
var a30 = G14(go, m42, null, "bool");
var i31 = { kernelName: go, backendName: "cpu", kernelFunc: a30 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/GreaterEqual.mjs
var n26 = z14((r56, o80) => r56 >= o80 ? 1 : 0);
var t10 = G14(Do, n26, null, "bool");
var u50 = { kernelName: Do, backendName: "cpu", kernelFunc: t10 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Less.mjs
var m43 = z14((r56, o80) => r56 < o80 ? 1 : 0);
var s35 = G14(Co, m43, null, "bool");
var i32 = { kernelName: Co, backendName: "cpu", kernelFunc: s35 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/LessEqual.mjs
var m44 = z14((l80, r56) => l80 <= r56 ? 1 : 0);
var s36 = G14(vo, m44, null, "bool");
var c50 = { kernelName: vo, backendName: "cpu", kernelFunc: s36 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/LinSpace_impl.mjs
function a31(t67, l80, r56) {
  let n67 = (l80 - t67) / (r56 - 1), e36 = util_exports.makeZerosTypedArray(r56, "float32");
  e36[0] = t67;
  for (let o80 = 1; o80 < e36.length; o80++) e36[o80] = e36[o80 - 1] + n67;
  return e36;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Log.mjs
var n27 = p51((r56) => Math.log(r56));
var l39 = y21(Po, n27);
var a32 = { kernelName: Po, backendName: "cpu", kernelFunc: l39 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Max_impl.mjs
function u51(f85, l80, p103, s84) {
  let o80 = util_exports.getTypedArrayFromDType(s84, util_exports.sizeFromShape(p103));
  for (let t67 = 0; t67 < o80.length; ++t67) {
    let n67 = t67 * l80, e36 = f85[n67];
    for (let r56 = 0; r56 < l80; ++r56) {
      let m96 = f85[n67 + r56];
      (Number.isNaN(m96) || m96 > e36) && (e36 = m96);
    }
    o80[t67] = e36;
  }
  return o80;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Maximum.mjs
var a33 = z14((e36, r56) => Math.max(e36, r56));
var i33 = G14(bo, a33);
var x42 = { kernelName: bo, backendName: "cpu", kernelFunc: i33 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Minimum.mjs
var o25 = z14((n67, e36) => Math.min(n67, e36));
var t11 = G14(Zo, o25);
var l40 = { kernelName: Zo, backendName: "cpu", kernelFunc: t11 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Multiply.mjs
var i34 = z14((e36, r56) => e36 * r56);
var c51 = N25((e36, r56, l80, p103) => ({ real: e36 * l80 - r56 * p103, imag: e36 * p103 + r56 * l80 }));
var u52 = G14(Qo, i34, c51);
var f50 = { kernelName: Qo, backendName: "cpu", kernelFunc: u52 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Neg.mjs
function u53(t67, o80, n67) {
  let e36 = util_exports.createScalarValue(-1, n67);
  return i34([], o80, e36, t67, n67);
}
function i35(t67) {
  let { inputs: o80, backend: n67 } = t67, { x: e36 } = o80;
  i26(e36, "neg");
  let r56 = n67.data.get(e36.dataId).values, [a71, p103] = u53(r56, e36.shape, e36.dtype);
  return n67.makeTensorInfo(p103, e36.dtype, a71);
}
var k23 = { kernelName: Yo, backendName: "cpu", kernelFunc: i35 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/NotEqual.mjs
var t12 = z14((e36, n67) => e36 !== n67 ? 1 : 0);
var m45 = G14($o, t12, null, "bool");
var u54 = { kernelName: $o, backendName: "cpu", kernelFunc: m45 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Transpose_impl.mjs
function S20(d55, n67, m96, p103, s84) {
  let c103 = n67.length, u86 = util_exports.sizeFromShape(n67), x76 = util_exports.computeStrides(n67), f85 = util_exports.computeStrides(s84), i88 = util_exports.getTypedArrayFromDType(m96, util_exports.sizeFromShape(s84));
  for (let e36 = 0; e36 < u86; ++e36) {
    let l80 = util_exports.indexToLoc(e36, c103, x76), r56 = new Array(l80.length);
    for (let o80 = 0; o80 < r56.length; o80++) r56[o80] = l80[p103[o80]];
    let g72 = util_exports.locToIndex(r56, c103, f85);
    i88[g72] = d55[e36];
  }
  return i88;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Transpose.mjs
function h38(o80) {
  let { inputs: r56, attrs: p103, backend: n67 } = o80, { x: t67 } = r56, { perm: a71 } = p103;
  i26(t67, "transpose");
  let c103 = t67.shape.length, e36 = new Array(c103);
  for (let s84 = 0; s84 < e36.length; s84++) e36[s84] = t67.shape[a71[s84]];
  let d55 = n67.data.get(t67.dataId).values, m96 = S20(d55, t67.shape, t67.dtype, a71, e36);
  return { dataId: n67.write(m96, e36, t67.dtype), shape: e36, dtype: t67.dtype };
}
var g37 = { kernelName: ce, backendName: "cpu", kernelFunc: h38 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Prod.mjs
function b24(d55, m96, s84, l80) {
  let [e36, f85] = backend_util_exports.computeOutAndReduceShapes(d55, l80), u86 = c5(m96, "int32"), n67 = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(e36), u86), r56 = util_exports.sizeFromShape(f85);
  for (let o80 = 0; o80 < n67.length; ++o80) {
    let p103 = o80 * r56, t67 = 1;
    for (let a71 = 0; a71 < r56; ++a71) t67 *= s84[p103 + a71];
    n67[o80] = t67;
  }
  return { outVals: n67, outShape: e36, outDtype: u86 };
}
function z15(d55) {
  let { inputs: m96, backend: s84, attrs: l80 } = d55, { x: e36 } = m96, { axis: f85, keepDims: u86 } = l80;
  i26(e36, "prod");
  let n67 = e36.shape.length, r56 = util_exports.parseAxisParam(f85, e36.shape), o80 = backend_util_exports.getAxesPermutation(r56, n67), p103 = r56, t67 = e36, a71 = [];
  o80 != null && (t67 = h38({ inputs: { x: e36 }, backend: s84, attrs: { perm: o80 } }), a71.push(t67), p103 = backend_util_exports.getInnerMostAxes(p103.length, n67));
  let k63 = s84.data.get(t67.dataId).values, { outVals: S45, outShape: h74, outDtype: g72 } = b24(t67.shape, t67.dtype, k63, p103), x76 = h74;
  return u86 && (x76 = backend_util_exports.expandShapeToKeepDim(h74, r56)), a71.forEach((I44) => s84.disposeIntermediateTensorInfo(I44)), s84.makeTensorInfo(x76, g72, S45);
}
var V7 = { kernelName: it, backendName: "cpu", kernelFunc: z15 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/RaggedGather_impl.mjs
function b25(l80, n67, t67) {
  l80.forEach((o80, s84) => {
    if (o80 < 0 || o80 >= t67) {
      let e36 = util_exports.indexToLoc(s84, n67.length, util_exports.computeStrides(n67)).join(",");
      throw new Error(`indices[${e36}] = ${o80} is not in [0, ${t67})`);
    }
  });
}
function R12(l80, n67) {
  for (let t67 = 0; t67 < l80.length; ++t67) {
    let o80 = l80[t67], s84 = t67 === l80.length - 1 ? n67 : l80[t67 + 1].length;
    if (o80.length === 0) throw new Error("Ragged splits may not be empty");
    if (o80[0] < 0) throw new Error("Ragged splits must be non-negative");
    if (o80[o80.length - 1] > s84) throw new Error("Ragged splits must not point past values");
    for (let e36 = 1; e36 < o80.length; ++e36) if (o80[e36 - 1] > o80[e36]) throw new Error("Ragged splits must be sorted in ascending order");
  }
}
function F7(l80, n67, t67, o80) {
  let s84 = [], e36 = 0, c103 = n67.length - 1 + t67.length, g72 = new Array(c103).fill(null).map(() => [0]);
  R12(t67, o80);
  let f85 = 1;
  for (let u86 = 0; u86 < n67.length - 1; ++u86) {
    f85 *= n67[u86];
    let i88 = n67[u86 + 1];
    for (let r56 = 1; r56 < f85 + 1; ++r56) g72[u86].push(r56 * i88);
  }
  for (let u86 = 0; u86 < l80.length; ++u86) {
    let i88 = l80[u86], r56 = l80[u86] + 1;
    for (let h74 = 0; h74 < t67.length; ++h74) {
      let w45 = t67[h74], m96 = h74 + n67.length - 1;
      if (m96 >= 0) {
        let v42 = g72[m96], y43 = v42[v42.length - 1] - w45[i88];
        for (let p103 = i88; p103 < r56; ++p103) g72[m96].push(w45[p103 + 1] + y43);
      }
      i88 = w45[i88], r56 = w45[r56];
    }
    r56 !== i88 && (s84.push([i88, r56]), e36 += r56 - i88);
  }
  return { outSplits: g72, valueSlices: s84, numValues: e36 };
}
function d21(l80) {
  let n67 = [];
  for (let t67 = 0; t67 < l80.length; ++t67) {
    let o80 = l80[t67].length, s84 = util_exports.getArrayFromDType("int32", o80);
    n67.push(s84), l80[t67].forEach((e36, c103) => s84[c103] = e36);
  }
  return n67;
}
function a34(l80, n67) {
  let t67 = l80.slice(0, n67);
  for (; t67.length < n67; ) t67.push(1);
  for (let o80 = n67; o80 < l80.length; o80++) t67[n67 - 1] *= l80[o80];
  return t67;
}
function j12(l80, n67, t67, o80, s84, e36) {
  let c103 = a34(n67, 2)[1], g72 = a34(e36, 2)[1], f85 = 0;
  for (let u86 of t67) for (let i88 = u86[0]; i88 < u86[1]; ++i88) {
    for (let r56 = 0; r56 < o80; ++r56) s84[f85 * g72 + r56] = l80[i88 * c103 + r56];
    ++f85;
  }
}
function k24(l80, n67, t67, o80, s84) {
  let e36 = n67.slice();
  e36[0] = s84;
  let c103 = util_exports.getArrayFromDType(t67, util_exports.sizeFromShape(e36)), g72 = l80.length, f85 = g72 === 0 ? 0 : g72 / n67[0];
  return j12(l80, n67, o80, f85, c103, e36), [c103, e36];
}
function A16(l80, n67, t67, o80, s84, e36, c103, g72) {
  if (l80.length === 0) throw new Error("paramsNestedSplits must be non empty");
  if (n67[0].length === 0) throw new Error("Split tensors must not be scalars");
  let f85 = n67[0][0] - 1;
  if (b25(e36, c103, f85), o80.length === 0) throw new Error("params.rank must be nonzero");
  let u86 = o80[0], { outSplits: i88, valueSlices: r56, numValues: h74 } = F7(e36, c103, l80, u86), w45 = d21(i88), m96 = k24(t67, o80, s84, r56, h74);
  return [w45, m96[0], m96[1]];
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/RaggedRange_impl.mjs
var E28 = 2147483647;
function z16(i88, f85, p103, m96, h74, a71, w45) {
  if (f85.length > 1) throw new Error("starts must be a scalar or vector");
  if (h74.length > 1) throw new Error("limits must be a scalar or vector");
  if (w45.length > 1) throw new Error("deltas must be a scalar or vector");
  let u86 = f85.length === 0, d55 = h74.length === 0, g72 = w45.length === 0, r56 = [];
  u86 || r56.push(f85[0]), d55 || r56.push(h74[0]), g72 || r56.push(w45[0]);
  for (let t67 = 1; t67 < r56.length; ++t67) if (r56[t67] !== r56[t67 - 1]) throw new Error("starts, limits, and deltas must have the same shape");
  let c103 = r56.length === 0 ? 1 : r56[0], e36 = util_exports.getArrayFromDType("int32", c103 + 1);
  e36[0] = 0;
  for (let t67 = 0; t67 < c103; ++t67) {
    let l80 = u86 ? i88[0] : i88[t67], n67 = d55 ? m96[0] : m96[t67], s84 = g72 ? a71[0] : a71[t67];
    if (s84 === 0) throw new Error("Requires delta != 0");
    let o80;
    if (s84 > 0 && n67 < l80 || s84 < 0 && n67 > l80) o80 = 0;
    else if (o80 = Math.ceil(Math.abs((n67 - l80) / s84)), o80 > E28) throw new Error(`Requires ((limit - start) / delta) <= ${E28}`);
    e36[t67 + 1] = e36[t67] + o80;
  }
  let y43 = e36[c103], b58 = util_exports.getArrayFromDType(p103, y43), D42 = 0;
  for (let t67 = 0; t67 < c103; ++t67) {
    let l80 = e36[t67 + 1] - e36[t67], n67 = u86 ? i88[0] : i88[t67], s84 = g72 ? a71[0] : a71[t67];
    for (let o80 = 0; o80 < l80; ++o80) b58[D42++] = n67, n67 += s84;
  }
  return [e36, b58];
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/RaggedTensorToTensor_impl.mjs
var p52 = backend_util_exports.RowPartitionType;
var P10 = class g38 {
  constructor(t67, e36, r56, n67, s84, i88, o80, a71, l80, h74) {
    this.shape = t67, this.shapeShape = e36, this.values = r56, this.valuesShape = n67, this.valuesDType = s84, this.defaultValue = i88, this.defaultValueShape = o80, this.rowPartitionValues = a71, this.rowPartitionValuesShapes = l80, this.rowPartitionTypes = backend_util_exports.getRowPartitionTypesHelper(h74), this.raggedRank = backend_util_exports.getRaggedRank(this.rowPartitionTypes);
  }
  getRowPartitionTypeByDimension(t67) {
    return this.rowPartitionTypes[0] === p52.FIRST_DIM_SIZE ? this.rowPartitionTypes[t67 + 1] : this.rowPartitionTypes[t67];
  }
  getRowPartitionTensor(t67) {
    return this.rowPartitionTypes[0] === p52.FIRST_DIM_SIZE ? this.rowPartitionValues[t67 + 1] : this.rowPartitionValues[t67];
  }
  getMaxWidth(t67) {
    let e36 = this.getRowPartitionTensor(t67 - 1);
    switch (this.getRowPartitionTypeByDimension(t67 - 1)) {
      case p52.VALUE_ROWIDS:
        return g38.getMaxWidthValueRowID(e36);
      case p52.ROW_SPLITS:
        return g38.getMaxWidthRowSplit(e36);
      default:
        throw new Error(`Cannot handle partition type ${p52[this.getRowPartitionTypeByDimension(t67 - 1)]}`);
    }
  }
  static getMaxWidthRowSplit(t67) {
    let e36 = t67.length;
    if (e36 === 0 || e36 === 1) return 0;
    let r56 = 0;
    for (let n67 = 0; n67 < e36 - 1; ++n67) {
      let s84 = t67[n67 + 1] - t67[n67];
      s84 > r56 && (r56 = s84);
    }
    return r56;
  }
  static getMaxWidthValueRowID(t67) {
    let e36 = t67.length;
    if (e36 === 0) return 0;
    let r56 = 0, n67 = t67[0], s84 = 0;
    for (let i88 = 1; i88 < e36; ++i88) {
      let o80 = t67[i88];
      o80 !== n67 && (n67 = o80, s84 = Math.max(i88 - r56, s84), r56 = i88);
    }
    return Math.max(e36 - r56, s84);
  }
  tensorShapeFromTensor(t67, e36, r56 = true) {
    if (e36.length === 0) {
      if (t67[0] === -1) return [];
      throw new Error("The only valid scalar shape tensor is the fully unknown shape specified as -1.");
    }
    return m46(t67, r56);
  }
  calculateOutputSize(t67) {
    let e36 = this.valuesShape, r56 = this.defaultValueShape;
    backend_util_exports.validateDefaultValueShape(r56, e36);
    let n67 = this.tensorShapeFromTensor(this.shape, this.shapeShape), i88 = backend_util_exports.combineRaggedTensorToTensorShapes(this.raggedRank, n67, e36);
    i88[0] < 0 && (i88[0] = t67);
    for (let o80 = 1; o80 <= this.raggedRank; ++o80) i88[o80] < 0 && (i88[o80] = this.getMaxWidth(o80));
    return i88;
  }
  calculateFirstParentOutputIndex(t67, e36, r56) {
    let n67 = Math.min(t67, r56), s84 = [], i88 = 0;
    for (let o80 = 0; o80 < n67; ++o80, i88 += e36) s84.push(i88);
    for (let o80 = n67; o80 < t67; ++o80) s84.push(-1);
    return util_exports.assert(s84.length === t67, () => "Final length of result must be equal to firstDimension."), s84;
  }
  calculateOutputIndexRowSplit(t67, e36, r56, n67) {
    let s84 = t67.length, i88 = [];
    for (let o80 = 0; o80 < s84 - 1; ++o80) {
      let a71 = t67[o80 + 1] - t67[o80], l80 = Math.min(n67, a71), h74 = e36[o80];
      h74 === -1 && (l80 = 0);
      for (let u86 = 0; u86 < l80; ++u86) i88.push(h74), h74 += r56;
      for (let u86 = 0; u86 < a71 - l80; ++u86) i88.push(-1);
    }
    if (s84 > 0 && i88.length !== t67[s84 - 1]) throw new Error("Invalid row split size.");
    return i88;
  }
  calculateOutputIndexValueRowID(t67, e36, r56, n67) {
    let s84 = t67.length, i88 = [];
    if (s84 === 0) return [];
    let o80 = 0, a71 = t67[0];
    if (a71 >= e36.length) throw new Error(`Got currentValueRowId=${a71}, which is not less than ${e36.length}`);
    let l80 = e36[a71];
    i88.push(l80);
    for (let h74 = 1; h74 < s84; ++h74) {
      let u86 = t67[h74];
      if (u86 === a71) l80 >= 0 && (++o80, o80 < n67 ? l80 += r56 : l80 = -1);
      else {
        if (o80 = 0, a71 = u86, u86 >= e36.length) throw new Error(`Got nextValueRowId=${u86} which is not less than ${e36.length}`);
        l80 = e36[u86];
      }
      i88.push(l80);
    }
    if (i88.length !== t67.length) throw new Error("Invalid row ids.");
    return i88;
  }
  calculateOutputIndex(t67, e36, r56, n67) {
    let s84 = this.getRowPartitionTensor(t67), i88 = this.getRowPartitionTypeByDimension(t67);
    switch (i88) {
      case p52.VALUE_ROWIDS:
        return this.calculateOutputIndexValueRowID(s84, e36, r56, n67);
      case p52.ROW_SPLITS:
        if (s84.length - 1 > e36.length) throw new Error(`Row partition size is greater than output size: ${s84.length - 1} > ${e36.length}`);
        return this.calculateOutputIndexRowSplit(s84, e36, r56, n67);
      default:
        throw new Error(`Unsupported partition type: ${p52[i88]}`);
    }
  }
  getFirstDimensionSize() {
    let t67 = this.rowPartitionValues[0];
    if (this.rowPartitionTypes.length === 0) throw new Error("No row_partition_types given.");
    let e36 = this.rowPartitionTypes[0];
    switch (e36) {
      case p52.FIRST_DIM_SIZE:
        return t67[0];
      case p52.VALUE_ROWIDS:
        throw new Error("Cannot handle VALUE_ROWIDS in first dimension.");
      case p52.ROW_SPLITS:
        return this.rowPartitionValuesShapes[0][0] - 1;
      default:
        throw new Error(`Cannot handle type ${p52[e36]}`);
    }
  }
  compute() {
    if (this.rowPartitionValues[0].length <= 0) throw new Error("Invalid first partition input. Tensor requires at least one element.");
    let e36 = this.getFirstDimensionSize(), r56 = this.calculateOutputSize(e36), n67 = new Array(this.raggedRank + 1);
    n67[n67.length - 1] = 1;
    for (let a71 = n67.length - 2; a71 >= 0; --a71) n67[a71] = n67[a71 + 1] * r56[a71 + 1];
    let s84 = m46(r56, false), i88 = util_exports.getArrayFromDType(this.valuesDType, util_exports.sizeFromShape(s84));
    if (n67[0] * r56[0] > 0) {
      let a71 = this.calculateFirstParentOutputIndex(e36, n67[0], r56[0]);
      for (let l80 = 1; l80 <= this.raggedRank; ++l80) a71 = this.calculateOutputIndex(l80 - 1, a71, n67[l80], r56[l80]);
      this.setOutput(this.raggedRank, a71, i88, s84);
    }
    return [s84, i88];
  }
  setOutput(t67, e36, r56, n67) {
    if (r56.length === 0) return;
    let s84 = this.values, i88 = r56, o80 = n67.slice();
    o80 = o80.slice(t67 + 1);
    let a71 = util_exports.sizeFromShape(o80), l80 = e36.length, h74 = this.defaultValue;
    if (h74.length !== a71 && h74.length !== 1) {
      let f85 = this.defaultValueShape;
      g4(() => {
        let w45 = h9(h74, f85);
        h74 = v10(w45, o80).dataSync();
      });
    }
    let u86 = 0, d55 = 0, c103 = 0;
    for (let f85 = 0; f85 <= l80; ++f85) {
      let w45 = f85 < l80 ? e36[f85] : -1;
      if (w45 === c103) {
        ++c103;
        continue;
      }
      if (d55 < c103) {
        let S45 = s84.subarray(u86 * a71), I44 = i88.subarray(d55 * a71), V24 = (c103 - d55) * a71;
        R13(I44, S45, V24);
      }
      if (f85 >= l80) {
        let S45 = r56.length;
        w45 = Math.floor(S45 / a71);
      }
      if (w45 > c103) if (this.defaultValue.length === 1) i88.subarray(c103 * a71, w45 * a71).fill(this.defaultValue[0]), c103 = w45;
      else for (; w45 > c103; ) {
        let S45 = i88.slice(c103 * a71);
        R13(S45, h74, a71), ++c103;
      }
      w45 < 0 ? (u86 = f85 + 1, d55 = c103) : (u86 = f85, d55 = c103, c103 = d55 + 1);
    }
  }
};
function R13(g72, t67, e36) {
  for (let r56 = 0; r56 < e36; r56++) g72[r56] = t67[r56];
}
function m46(g72, t67) {
  let e36 = [];
  for (let r56 of g72) {
    if (r56 < 0) {
      if (!t67) throw new Error(`Dimension ${r56} must be >= 0`);
      if (r56 < -1) throw new Error(`Dimension ${r56} must be >= -1`);
      r56 = -1;
    }
    e36.push(r56);
  }
  return e36;
}
function O13(g72, t67, e36, r56, n67, s84, i88, o80, a71, l80) {
  return new P10(g72, t67, e36, r56, n67, s84, i88, o80, a71, l80).compute();
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Range_impl.mjs
function S21(e36, i88, n67, o80) {
  let m96 = e36 === i88, g72 = e36 < i88 && n67 < 0, l80 = i88 < e36 && n67 > 1;
  if (m96 || g72 || l80) return util_exports.makeZerosTypedArray(0, o80);
  let u86 = Math.abs(Math.ceil((i88 - e36) / n67)), r56 = util_exports.makeZerosTypedArray(u86, o80);
  i88 < e36 && n67 === 1 && (n67 = -1), r56[0] = e36;
  for (let a71 = 1; a71 < r56.length; a71++) r56[a71] = r56[a71 - 1] + n67;
  return r56;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Rsqrt.mjs
var m47 = p51((t67) => 1 / Math.sqrt(t67));
var n28 = y21(Ft, m47);
var a35 = { kernelName: Ft, backendName: "cpu", kernelFunc: n28 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Scatter_impl.mjs
function a36(c103, e36, m96, v42, o80, l80, p103, I44, r56, h74) {
  let w45 = [v42 / o80, o80], B30 = c103.values, i88 = e36.values;
  if (v42 === 0) return i7(m96, e36.dtype);
  let t67 = r56 instanceof p8 ? r56 : i7(w45, e36.dtype);
  typeof r56 == "string" || typeof r56 == "number" ? t67.values.fill(r56) : typeof r56 == "boolean" && t67.values.fill(+r56);
  for (let f85 = 0; f85 < l80; f85++) {
    let y43 = [], s84 = 0;
    for (let n67 = 0; n67 < p103; n67++) {
      let x76 = B30[f85 * p103 + n67];
      y43.push(x76), s84 += x76 * I44[n67];
    }
    if (s84 < 0 || s84 >= v42 / o80) throw new Error(`Invalid indices: ${y43} does not index into ${m96}`);
    for (let n67 = 0; n67 < o80; n67++) h74 ? t67.values[s84 * o80 + n67] += i88[f85 * o80 + n67] : t67.values[s84 * o80 + n67] = e36.rank === 0 ? i88[0] : i88[f85 * o80 + n67];
  }
  return t67;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Sigmoid.mjs
var a37 = p51((e36) => 1 / (1 + Math.exp(-e36)));
var i36 = A15(wt, (e36) => 1 / (1 + Math.exp(-e36)));
var c52 = { kernelName: wt, backendName: "cpu", kernelFunc: i36 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Slice.mjs
function F8(o80, r56, s84, i88, t67) {
  let f85 = slice_util_exports.isSliceContinous(i88, r56, s84), a71 = util_exports.sizeFromShape(s84), u86 = util_exports.computeStrides(i88);
  if (f85) {
    let e36 = slice_util_exports.computeFlatOffset(r56, u86);
    return t67 === "string" ? o80.slice(e36, e36 + a71) : o80.subarray(e36, e36 + a71);
  }
  let c103 = t67 === "string" ? backend_util_exports.fromUint8ToStringArray(o80) : o80, m96 = i7(i88, t67, c103), n67 = i7(s84, t67);
  for (let e36 = 0; e36 < n67.size; ++e36) {
    let d55 = n67.indexToLoc(e36), x76 = d55.map((k63, b58) => k63 + r56[b58]);
    n67.set(m96.get(...x76), ...d55);
  }
  return t67 === "string" ? backend_util_exports.fromStringArrayToUint8(n67.values) : n67.values;
}
function I18(o80) {
  let { inputs: r56, backend: s84, attrs: i88 } = o80, { x: t67 } = r56, { begin: f85, size: a71 } = i88;
  i26(t67, "slice");
  let [u86, c103] = slice_util_exports.parseSliceParams(t67, f85, a71);
  slice_util_exports.assertParamsValid(t67, u86, c103);
  let m96 = s84.data.get(t67.dataId).values, n67 = F8(m96, u86, c103, t67.shape, t67.dtype);
  return s84.makeTensorInfo(c103, t67.dtype, n67);
}
var z17 = { kernelName: Et, backendName: "cpu", kernelFunc: I18 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SparseFillEmptyRows_impl.mjs
function D12(i88, A35, F32, R26, x76, C28, M30) {
  let u86 = A35[0], n67 = C28[0], p103 = new Array(n67), a71 = new Array(u86), e36 = A35[1];
  if (n67 === 0) {
    if (u86 !== 0) throw new Error(backend_util_exports.getSparseFillEmptyRowsIndicesDenseShapeMismatch(u86));
    let t67 = util_exports.getArrayFromDType(F32, 0), r56 = util_exports.getArrayFromDType(x76, 0);
    return [t67, [0, e36], r56, p103, a71];
  }
  let I44 = true, h74 = 0, s84 = new Array(n67).fill(0);
  for (let t67 = 0; t67 < u86; ++t67) {
    let r56 = i88[t67 * e36];
    if (r56 < 0) throw new Error(backend_util_exports.getSparseFillEmptyRowsNegativeIndexErrorMessage(t67, r56));
    if (r56 >= n67) throw new Error(backend_util_exports.getSparseFillEmptyRowsOutOfRangeIndexErrorMessage(t67, r56, n67));
    ++s84[r56], I44 = I44 && r56 >= h74, h74 = r56;
  }
  let d55 = true;
  for (let t67 = 0; t67 < n67; ++t67) {
    let r56 = s84[t67] === 0;
    p103[t67] = r56, d55 = d55 && !r56, s84[t67] = Math.max(s84[t67], 1), t67 > 0 && (s84[t67] += s84[t67 - 1]);
  }
  if (d55 && I44) {
    let t67 = i88, r56 = R26;
    for (let l80 = 0; l80 < u86; ++l80) a71[l80] = l80;
    return [t67, [u86, e36], r56, p103, a71];
  } else {
    let t67 = s84[n67 - 1], r56 = util_exports.getArrayFromDType(F32, t67 * e36), l80 = util_exports.getArrayFromDType(x76, t67), g72 = new Array(n67).fill(0);
    for (let o80 = 0; o80 < u86; ++o80) {
      let w45 = i88[o80 * e36], f85 = g72[w45], c103 = (w45 === 0 ? 0 : s84[w45 - 1]) + f85;
      g72[w45]++;
      for (let y43 = 0; y43 < e36; ++y43) r56[c103 * e36 + y43] = i88[o80 * e36 + y43];
      l80[c103] = R26[o80], a71[o80] = c103;
    }
    for (let o80 = 0; o80 < n67; ++o80) if (g72[o80] === 0) {
      let f85 = o80 === 0 ? 0 : s84[o80 - 1];
      r56[f85 * e36 + 0] = o80;
      for (let c103 = 1; c103 < e36; ++c103) r56[f85 * e36 + c103] = 0;
      l80[f85] = M30;
    }
    return [r56, [t67, e36], l80, p103, a71];
  }
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SparseReshape_impl.mjs
function z18(d55, E44, M30, n67, m96) {
  let f85 = util_exports.sizeFromShape(n67), h74 = E44[0], o80 = m96.length, s84 = [], l80 = 1, i88 = -1;
  for (let e36 = 0; e36 < o80; ++e36) {
    let r56 = m96[e36];
    if (r56 === -1) {
      if (i88 !== -1) throw new Error(backend_util_exports.getSparseReshapeMultipleNegativeOneOutputDimErrorMessage(i88, e36));
      i88 = e36, s84.push(1);
    } else {
      if (r56 < 0) throw new Error(backend_util_exports.getSparseReshapeNegativeOutputDimErrorMessage(e36, r56));
      l80 *= r56, s84.push(r56);
    }
  }
  if (i88 !== -1) {
    if (l80 <= 0) throw new Error(backend_util_exports.getSparseReshapeEmptyTensorZeroOutputDimErrorMessage());
    let e36 = Math.trunc(f85 / l80);
    if (l80 * e36 !== f85) throw new Error(backend_util_exports.getSparseReshapeInputOutputMultipleErrorMessage(n67, s84));
    s84[i88] = e36;
  }
  if (util_exports.sizeFromShape(s84) !== f85) throw new Error(backend_util_exports.getSparseReshapeInputOutputMismatchErrorMessage(n67, s84));
  let u86 = n67.length, c103 = [];
  if (u86 > 0) {
    c103[u86 - 1] = 1;
    for (let e36 = u86 - 2; e36 >= 0; --e36) c103[e36] = c103[e36 + 1] * n67[e36 + 1];
  }
  let p103 = [];
  if (o80 > 0) {
    p103[o80 - 1] = 1;
    for (let e36 = o80 - 2; e36 >= 0; --e36) p103[e36] = p103[e36 + 1] * s84[e36 + 1];
  }
  let w45 = util_exports.getArrayFromDType(M30, h74 * o80);
  for (let e36 = 0; e36 < h74; ++e36) {
    let r56 = 0;
    for (let t67 = 0; t67 < u86; ++t67) r56 += d55[e36 * u86 + t67] * c103[t67];
    for (let t67 = 0; t67 < o80; ++t67) w45[e36 * o80 + t67] = Math.trunc(r56 / p103[t67]), r56 %= p103[t67];
  }
  return [w45, [h74, o80], s84];
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SparseSegmentReduction_impl.mjs
function b26(E44, d55, R26, m96, S45, h74 = false, w45 = 0) {
  let g72 = m96.length, p103 = [d55[0], E44.length / d55[0]], r56 = p103[1], n67 = g72 > 0 ? S45[g72 - 1] + 1 : 0;
  if (n67 < 0) throw new Error(backend_util_exports.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
  let f85 = d55.slice();
  f85[0] = n67;
  let x76 = f85.reduce((s84, t67) => s84 * t67, 1), i88 = util_exports.getArrayFromDType(R26, x76);
  if (g72 === 0) return n67 > 0 && i88.fill(w45), [i88, f85];
  if (n67 <= 0) throw new Error(backend_util_exports.getSparseSegmentReductionNegativeSegmentIdsErrorMessage());
  let c103 = 0, o80 = 1, l80 = 0, e36 = S45[c103];
  for (; ; ) {
    let s84 = 0;
    if (o80 < g72) {
      if (s84 = S45[o80], e36 === s84) {
        ++o80;
        continue;
      }
      if (e36 >= s84) throw new Error(backend_util_exports.getSparseSegmentReductionNonIncreasingSegmentIdsErrorMessage());
    }
    if (e36 < 0 || e36 >= n67) throw new Error(backend_util_exports.getSparseSegmentReductionSegmentIdOutOfRangeErrorMessage(e36, n67));
    e36 > l80 && i88.fill(w45, l80 * r56, e36 * r56);
    for (let t67 = c103; t67 < o80; ++t67) {
      let I44 = m96[t67];
      if (I44 < 0 || I44 >= p103[0]) throw new Error(backend_util_exports.getSparseSegmentReductionIndicesOutOfRangeErrorMessage(t67, m96[t67], p103[0]));
      for (let a71 = 0; a71 < r56; a71++) i88[e36 * r56 + a71] += E44[I44 * r56 + a71];
    }
    if (h74) for (let t67 = 0; t67 < r56; t67++) i88[e36 * r56 + t67] /= o80 - c103;
    if (c103 = o80, ++o80, l80 = e36 + 1, e36 = s84, o80 > g72) break;
  }
  return l80 < n67 && i88.fill(w45, l80 * r56, n67 * r56), [i88, f85];
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Sqrt.mjs
var c53 = p51((r56) => Math.sqrt(r56));
var n29 = A15(yt, (r56) => Math.sqrt(r56));
var s37 = { kernelName: yt, backendName: "cpu", kernelFunc: n29 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SquaredDifference.mjs
var i37 = z14((n67, f85) => {
  let e36 = n67 - f85;
  return e36 * e36;
});
var t13 = G14(_t, i37);
var u55 = { kernelName: _t, backendName: "cpu", kernelFunc: t13 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/StaticRegexReplace.mjs
var o26 = p51((r56, t67) => {
  let { pattern: c103, replaceGlobal: a71, rewrite: p103 } = t67;
  return r56.replace(new RegExp(c103, a71 ? "g" : ""), p103);
});
var m48 = y21(Jt, o26);
var s38 = { kernelName: Jt, backendName: "cpu", kernelFunc: m48 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/StridedSlice_impl.mjs
function p53(i88, c103, l80, f85) {
  let t67 = i7(i88, c103.dtype);
  for (let o80 = 0; o80 < t67.size; o80++) {
    let n67 = t67.indexToLoc(o80), r56 = new Array(n67.length);
    for (let e36 = 0; e36 < r56.length; e36++) r56[e36] = n67[e36] * l80[e36] + f85[e36];
    t67.set(c103.get(...r56), ...n67);
  }
  return t67;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/StringNGrams_impl.mjs
var p54 = class {
  constructor(i88, e36, h74, d55, m96, s84) {
    this.separator = util_exports.encodeString(i88), this.nGramWidths = e36, this.leftPad = util_exports.encodeString(h74), this.rightPad = util_exports.encodeString(d55), this.padWidth = m96, this.preserveShort = s84;
  }
  getPadWidth(i88) {
    return Math.min(this.padWidth < 0 ? i88 - 1 : this.padWidth, i88 - 1);
  }
  getNumNGrams(i88, e36) {
    let h74 = this.getPadWidth(e36);
    return Math.max(0, i88 + 2 * h74 - e36 + 1);
  }
  createNGrams(i88, e36, h74, d55, m96, s84) {
    for (let o80 = 0; o80 < m96; ++o80) {
      let t67 = this.getPadWidth(s84), r56 = Math.max(0, t67 - o80), n67 = Math.max(0, t67 - (m96 - (o80 + 1))), c103 = s84 - (r56 + n67), f85 = e36 + (r56 > 0 ? 0 : o80 - t67), g72 = 0;
      g72 += r56 * this.leftPad.length;
      for (let a71 = 0; a71 < c103; ++a71) g72 += i88[f85 + a71].length;
      g72 += n67 * this.rightPad.length;
      let N58 = r56 + n67 + c103 - 1;
      g72 += N58 * this.separator.length, h74[d55 + o80] = new Uint8Array(g72);
      let P36 = h74[d55 + o80], S45 = 0, l80 = (a71) => a71.forEach((w45) => P36[S45++] = w45);
      for (let a71 = 0; a71 < r56; ++a71) l80(this.leftPad), l80(this.separator);
      for (let a71 = 0; a71 < c103 - 1; ++a71) l80(i88[f85 + a71]), l80(this.separator);
      if (c103 > 0) {
        l80(i88[f85 + c103 - 1]);
        for (let a71 = 0; a71 < n67; ++a71) l80(this.separator), l80(this.rightPad);
      } else {
        for (let a71 = 0; a71 < n67 - 1; ++a71) l80(this.rightPad), l80(this.separator);
        l80(this.rightPad);
      }
    }
  }
  compute(i88, e36) {
    let h74 = i88.length, d55 = e36.length;
    if (d55 > 0) {
      let t67 = e36[0];
      if (t67 !== 0) throw new Error(`First split value must be 0, got ${t67}`);
      for (let r56 = 1; r56 < d55; ++r56) {
        let n67 = e36[r56] >= t67;
        if (n67 = n67 && e36[r56] <= h74, !n67) throw new Error(`Invalid split value ${e36[r56]}, must be in [${t67}, ${h74}]`);
        t67 = e36[r56];
      }
      if (t67 !== h74) throw new Error(`Last split value must be data size. Expected ${h74}, got ${t67}`);
    }
    let m96 = d55 - 1, s84 = util_exports.getArrayFromDType("int32", d55);
    if (h74 === 0 || d55 === 0) {
      let t67 = new Array(h74);
      for (let r56 = 0; r56 <= m96; ++r56) s84[r56] = 0;
      return [t67, s84];
    }
    s84[0] = 0;
    for (let t67 = 1; t67 <= m96; ++t67) {
      let r56 = e36[t67] - e36[t67 - 1], n67 = 0;
      this.nGramWidths.forEach((c103) => {
        n67 += this.getNumNGrams(r56, c103);
      }), this.preserveShort && r56 > 0 && n67 === 0 && (n67 = 1), s84[t67] = s84[t67 - 1] + n67;
    }
    let o80 = new Array(s84[m96]);
    for (let t67 = 0; t67 < m96; ++t67) {
      let r56 = e36[t67], n67 = s84[t67];
      if (this.nGramWidths.forEach((c103) => {
        let f85 = e36[t67 + 1] - e36[t67], g72 = this.getNumNGrams(f85, c103);
        this.createNGrams(i88, r56, o80, n67, g72, c103), n67 += g72;
      }), this.preserveShort && n67 === s84[t67]) {
        let c103 = e36[t67 + 1] - e36[t67];
        if (c103 === 0) continue;
        let f85 = c103 + 2 * this.padWidth;
        this.createNGrams(i88, r56, o80, n67, 1, f85);
      }
    }
    return [o80, s84];
  }
};
function v27(G30, i88, e36, h74, d55, m96, s84, o80) {
  return new p54(e36, h74, d55, m96, s84, o80).compute(G30, i88);
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/StringSplit_impl.mjs
function y22(e36, h74, f85, o80) {
  if (!e36.length) return;
  if (h74.length === 0) {
    for (let n67 = 0; n67 < e36.length; ++n67) o80.push(e36.subarray(n67, n67 + 1));
    return;
  }
  if (h74.length === 1) {
    let n67 = h74[0], t67 = e36.indexOf(n67);
    for (; t67 !== -1; ) {
      let a71 = e36.subarray(0, t67);
      (!f85 || a71.length !== 0) && o80.push(a71), e36 = e36.subarray(t67 + 1), t67 = e36.indexOf(n67);
    }
    (!f85 || e36.length !== 0) && o80.push(e36);
    return;
  }
  let l80 = 0;
  for (let n67 = 0; n67 < e36.length + 1; n67++) if (n67 === e36.length || h74.indexOf(e36[n67]) !== -1) {
    let t67 = e36.subarray(l80, n67);
    (!f85 || t67.length !== 0) && o80.push(t67), l80 = n67 + 1;
  }
}
function m49(e36, h74, f85) {
  let o80 = e36.length, l80 = [], n67 = 0, t67 = 0, a71 = new Array(o80);
  for (let i88 = 0; i88 < o80; ++i88) {
    let c103 = l80.length;
    y22(e36[i88], h74, f85, l80);
    let g72 = l80.length - c103;
    a71[i88] = g72, n67 += g72, t67 = Math.max(t67, g72);
  }
  let u86 = util_exports.getArrayFromDType("int32", n67 * 2), p103 = new Array(n67), s84 = [o80, t67], r56 = 0;
  for (let i88 = 0; i88 < o80; ++i88) for (let c103 = 0; c103 < a71[i88]; ++c103) u86[r56 * 2] = i88, u86[r56 * 2 + 1] = c103, p103[r56] = l80[r56], ++r56;
  return [u86, p103, s84];
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/StringToHashBucketFast_impl.mjs
function g39(o80, n67) {
  let r56 = util_exports.getArrayFromDType("int32", o80.length);
  for (let t67 = 0; t67 < o80.length; ++t67) r56[t67] = util_exports.fingerPrint64(o80[t67]).modulo(n67).getLowBitsUnsigned();
  return r56;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Sub.mjs
var a38 = z14((e36, r56) => e36 - r56);
var c54 = N25((e36, r56, o80, m96) => ({ real: e36 - o80, imag: r56 - m96 }));
var i38 = G14(te, a38, c54);
var x43 = { kernelName: te, backendName: "cpu", kernelFunc: i38 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Tile_impl.mjs
function h39(n67, a71) {
  let t67 = new Array(n67.rank);
  for (let e36 = 0; e36 < t67.length; e36++) t67[e36] = n67.shape[e36] * a71[e36];
  let r56 = i7(t67, n67.dtype);
  for (let e36 = 0; e36 < r56.values.length; ++e36) {
    let s84 = r56.indexToLoc(e36), l80 = new Array(n67.rank);
    for (let o80 = 0; o80 < l80.length; o80++) l80[o80] = s84[o80] % n67.shape[o80];
    let c103 = n67.locToIndex(l80);
    r56.values[e36] = n67.values[c103];
  }
  return r56;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/TopK_impl.mjs
var m50 = (n67, e36) => {
  let o80 = e36.value - n67.value;
  return o80 === 0 ? n67.index - e36.index : o80;
};
function A17(n67, e36, o80 = 0, t67 = n67.length - 1) {
  for (; t67 > o80; ) {
    if (t67 - o80 > 600) {
      let c103 = t67 - o80 + 1, w45 = e36 - o80 + 1, d55 = Math.log(c103), i88 = 0.5 * Math.exp(2 * d55 / 3), a71 = 0.5 * Math.sqrt(d55 * i88 * (c103 - i88) / c103) * Math.sign(w45 - c103 / 2), M30 = Math.max(o80, Math.floor(e36 - w45 * i88 / c103 + a71)), v42 = Math.min(t67, Math.floor(e36 + (c103 - w45) * i88 / c103 + a71));
      A17(n67, e36, M30, v42);
    }
    let h74 = n67[e36], l80 = o80, s84 = t67;
    for (util_exports.swap(n67, o80, e36), m50(n67[t67], h74) > 0 && util_exports.swap(n67, o80, t67); l80 < s84; ) {
      for (util_exports.swap(n67, l80, s84), l80++, s84--; m50(n67[l80], h74) < 0; ) l80 = l80 + 1;
      for (; m50(n67[s84], h74) > 0; ) s84 = s84 - 1;
    }
    m50(n67[o80], h74) === 0 ? util_exports.swap(n67, o80, s84) : (s84 = s84 + 1, util_exports.swap(n67, s84, t67)), s84 <= e36 && (o80 = s84 + 1), e36 <= s84 && (t67 = s84 - 1);
  }
}
function z19(n67, e36, o80, t67, h74) {
  let l80 = e36[e36.length - 1], [s84, c103] = [n67.length / l80, l80], w45 = util_exports.getTypedArrayFromDType(o80, s84 * t67), d55 = util_exports.getTypedArrayFromDType("int32", s84 * t67);
  for (let a71 = 0; a71 < s84; a71++) {
    let M30 = a71 * c103, v42 = n67.subarray(M30, M30 + c103), p103 = new Array(v42.length);
    v42.forEach((u86, b58) => p103[b58] = { value: u86, index: b58 }), t67 < p103.length && (A17(p103, t67), p103 = p103.slice(0, t67)), h74 && p103.sort(m50);
    let T40 = a71 * t67, I44 = w45.subarray(T40, T40 + t67), g72 = d55.subarray(T40, T40 + t67);
    for (let u86 = 0; u86 < t67; u86++) I44[u86] = p103[u86].value, g72[u86] = p103[u86].index;
  }
  let i88 = e36.slice();
  return i88[i88.length - 1] = t67, [i7(i88, o80, w45), i7(i88, "int32", d55)];
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Unique_impl.mjs
function z20(p103, S45, o80, x76) {
  let s84 = util_exports.parseAxisParam(S45, o80)[0], e36 = [1, o80[0], 1];
  for (let t67 = 0; t67 < s84; t67++) e36[0] *= o80[t67];
  e36[1] = o80[s84];
  for (let t67 = s84 + 1; t67 < o80.length; t67++) e36[2] *= o80[t67];
  let r56 = /* @__PURE__ */ new Map(), l80 = new Int32Array(o80[s84]), g72 = new p8(e36, x76, p103), a71 = [], d55 = e36[0] === 1 && e36[2] === 1;
  for (let t67 = 0; t67 < o80[s84]; t67++) {
    let u86;
    if (d55) u86 = p103[t67].toString();
    else {
      let n67 = [];
      for (let f85 = 0; f85 < e36[0]; f85++) for (let m96 = 0; m96 < e36[2]; m96++) n67.push(g72.get(f85, t67, m96));
      u86 = n67.join(",");
    }
    let i88 = r56.get(u86);
    if (i88 != null) l80[t67] = i88;
    else {
      let n67 = r56.size;
      r56.set(u86, n67), l80[t67] = n67, a71.push(t67);
    }
  }
  let c103 = e36.slice();
  c103[1] = r56.size;
  let w45 = new p8(c103, x76);
  a71.forEach((t67, u86) => {
    for (let i88 = 0; i88 < e36[0]; i88++) for (let n67 = 0; n67 < e36[2]; n67++) w45.set(g72.get(i88, t67, n67), i88, u86, n67);
  });
  let I44 = o80.slice();
  return I44[s84] = c103[1], { outputValues: w45.values, outputShape: I44, indices: l80 };
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/version.mjs
var o27 = "4.22.0";

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/base.mjs
R3("cpu", () => new o21(), 1);

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Elu.mjs
var o28 = A15($2, (e36) => e36 >= 0 ? e36 : Math.exp(e36) - 1);
var c55 = { kernelName: $2, backendName: "cpu", kernelFunc: o28 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/LeakyRelu.mjs
function k25(r56) {
  let { inputs: s84, backend: o80, attrs: p103 } = r56, { x: t67 } = s84, { alpha: c103 } = p103;
  i26([t67], "leakyRelu");
  let u86 = util_exports.sizeFromShape(t67.shape), a71 = o80.data.get(t67.dataId).values, n67 = util_exports.getTypedArrayFromDType("float32", u86);
  for (let e36 = 0; e36 < a71.length; e36++) n67[e36] = a71[e36] < 0 ? c103 * a71[e36] : a71[e36];
  return o80.makeTensorInfo(t67.shape, "float32", n67);
}
var d22 = { kernelName: No, backendName: "cpu", kernelFunc: k25 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Prelu.mjs
var d23 = z14((e36, t67) => e36 < 0 ? t67 * e36 : e36);
function f51(e36) {
  let { inputs: t67, backend: a71 } = e36, { x: r56, alpha: o80 } = t67;
  i26([r56, o80], "prelu");
  let n67 = a71.data.get(r56.dataId).values, l80 = a71.data.get(o80.dataId).values, [p103, s84] = d23(r56.shape, o80.shape, n67, l80, "float32");
  return a71.makeTensorInfo(s84, "float32", p103);
}
var h40 = { kernelName: xt, backendName: "cpu", kernelFunc: f51 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Relu.mjs
var o29 = A15(mt, (r56) => Math.max(0, r56));
var u56 = { kernelName: mt, backendName: "cpu", kernelFunc: o29 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Relu6.mjs
var o30 = A15(Nt, (r56) => Math.min(Math.max(0, r56), 6));
var a39 = { kernelName: Nt, backendName: "cpu", kernelFunc: o30 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/utils/fused_utils.mjs
function P11(e36, u86, r56, l80, p103) {
  if (r56 === "linear") return i28({ inputs: { x: u86 }, backend: e36 });
  if (r56 === "relu") return o29({ inputs: { x: u86 }, backend: e36 });
  if (r56 === "elu") return o28({ inputs: { x: u86 }, backend: e36 });
  if (r56 === "relu6") return o30({ inputs: { x: u86 }, backend: e36 });
  if (r56 === "prelu") return f51({ inputs: { x: u86, alpha: l80 }, backend: e36 });
  if (r56 === "leakyrelu") return k25({ inputs: { x: u86 }, backend: e36, attrs: { alpha: p103 } });
  if (r56 === "sigmoid") return i36({ inputs: { x: u86 }, backend: e36 });
  throw new Error(`Activation ${r56} has not been implemented for the CPU backend.`);
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Reshape.mjs
function f52(h74) {
  let { inputs: r56, backend: o80, attrs: c103 } = h74, { x: e36 } = r56, { shape: m96 } = c103, n67 = util_exports.sizeFromShape(e36.shape), a71 = util_exports.inferFromImplicitShape(m96, n67), p103 = util_exports.sizeFromShape(a71);
  util_exports.assert(n67 === p103, () => `The new shape (${a71}) has ${p103} elements and the old shape (${e36.shape}) has ${n67} elements. The new shape and old shape must have the same number of elements.`), o80.incRef(e36.dataId);
  let t67 = o80.data.get(e36.dataId);
  if (t67.complexTensorInfos != null) {
    let d55 = t67.complexTensorInfos.real, i88 = t67.complexTensorInfos.imag;
    d55.shape = a71, i88.shape = a71;
  }
  return { dataId: e36.dataId, shape: a71, dtype: e36.dtype };
}
var x44 = { kernelName: Rt, backendName: "cpu", kernelFunc: f52 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/BatchMatMul.mjs
function rt3(F32) {
  let { inputs: N58, backend: s84, attrs: y43 } = F32, { a: t67, b: e36 } = N58, { transposeA: o80, transposeB: n67 } = y43;
  i26([t67, e36], "matMul");
  let l80 = t67.shape.length, u86 = e36.shape.length, d55 = o80 ? t67.shape[l80 - 2] : t67.shape[l80 - 1], m96 = n67 ? e36.shape[u86 - 1] : e36.shape[u86 - 2], $37 = o80 ? t67.shape[l80 - 1] : t67.shape[l80 - 2], z32 = n67 ? e36.shape[u86 - 2] : e36.shape[u86 - 1], C28 = t67.shape.slice(0, -2), R26 = e36.shape.slice(0, -2), b58 = util_exports.sizeFromShape(C28), S45 = util_exports.sizeFromShape(R26), w45 = broadcast_util_exports.assertAndGetBroadcastShape(t67.shape.slice(0, -2), e36.shape.slice(0, -2)).concat([$37, z32]);
  util_exports.assert(d55 === m96, () => `Error in matMul: inner shapes (${d55}) and (${m96}) of Tensors with shapes ${t67.shape} and ${e36.shape} and transposeA=${o80} and transposeB=${n67} must match.`);
  let E44 = o80 ? [b58, d55, $37] : [b58, $37, d55], G30 = n67 ? [S45, z32, m96] : [S45, m96, z32], a71 = f52({ inputs: { x: t67 }, backend: s84, attrs: { shape: E44 } }), p103 = f52({ inputs: { x: e36 }, backend: s84, attrs: { shape: G30 } }), v42 = o80 ? a71.shape[1] : a71.shape[2], f85 = o80 ? a71.shape[2] : a71.shape[1], r56 = n67 ? p103.shape[1] : p103.shape[2], O21 = Math.max(b58, S45), _24 = s84.data.get(a71.dataId).values, q25 = s84.data.get(p103.dataId).values, k63 = util_exports.computeStrides(a71.shape), B30 = util_exports.computeStrides(p103.shape), [H18, J17, K21] = o80 ? [k63[0], 1, k63[1]] : [k63[0], k63[1], 1], [L22, P36, Q13] = n67 ? [1, B30[1], B30[0]] : [B30[1], 1, B30[0]], U24 = f85 * r56, V24 = i7([O21, f85, r56], a71.dtype), W15 = V24.values, c103 = s84.blockSize;
  for (let h74 = 0; h74 < O21; h74++) {
    let X20 = h74 % b58, Y14 = h74 % S45;
    for (let M30 = 0; M30 < f85; M30 += c103) {
      let Z16 = Math.min(M30 + c103, f85);
      for (let I44 = 0; I44 < r56; I44 += c103) {
        let tt3 = Math.min(I44 + c103, r56);
        for (let D42 = 0; D42 < v42; D42 += c103) {
          let et5 = Math.min(D42 + c103, v42);
          for (let x76 = M30; x76 < Z16; x76++) for (let A35 = I44; A35 < tt3; A35++) {
            let T40 = 0;
            for (let g72 = D42; g72 < et5; g72++) {
              let st7 = _24[X20 * H18 + x76 * J17 + g72 * K21], at7 = q25[g72 * L22 + A35 * P36 + Y14 * Q13];
              T40 += st7 * at7;
            }
            W15[h74 * U24 + (x76 * r56 + A35)] += T40;
          }
        }
      }
    }
  }
  return s84.disposeIntermediateTensorInfo(a71), s84.disposeIntermediateTensorInfo(p103), s84.makeTensorInfo(w45, V24.dtype, V24.values);
}
var dt2 = { kernelName: R2, backendName: "cpu", kernelFunc: rt3 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/_FusedMatMul.mjs
function R14(r56) {
  let { inputs: u86, backend: e36, attrs: p103 } = r56, { a: c103, b: l80, bias: s84, preluActivationWeights: m96 } = u86, { transposeA: f85, transposeB: d55, activation: n67, leakyreluAlpha: M30 } = p103, t67, o80, i88, a71 = [];
  t67 = rt3({ inputs: { a: c103, b: l80 }, attrs: { transposeA: f85, transposeB: d55 }, backend: e36 }), s84 && (o80 = c48({ inputs: { a: t67, b: s84 }, backend: e36 }), a71.push(t67), t67 = o80), n67 && (i88 = P11(e36, t67, n67, m96, M30), a71.push(t67), t67 = i88);
  for (let b58 of a71) e36.disposeIntermediateTensorInfo(b58);
  return t67;
}
var I19 = { kernelName: De, backendName: "cpu", kernelFunc: R14 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Acos.mjs
var n30 = A15(t, (e36) => Math.acos(e36));
var t14 = { kernelName: t, backendName: "cpu", kernelFunc: n30 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Acosh.mjs
var n31 = A15(e2, (e36) => Math.acosh(e36));
var t15 = { kernelName: e2, backendName: "cpu", kernelFunc: n31 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/AddN.mjs
function m51(d55) {
  let { inputs: n67, backend: s84 } = d55, t67 = n67;
  i26(n67, "addN");
  let c103 = t67.map((e36) => s84.data.get(e36.dataId).values), o80 = i7(t67[0].shape, t67[0].dtype), r56 = o80.values;
  for (let e36 = 0; e36 < t67.length; e36++) {
    let l80 = c103[e36];
    for (let a71 = 0; a71 < r56.length; a71++) r56[a71] += l80[a71];
  }
  return s84.makeTensorInfo(o80.shape, o80.dtype, o80.values);
}
var k26 = { kernelName: n4, backendName: "cpu", kernelFunc: m51 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/All.mjs
function F9(g72) {
  let { inputs: A35, backend: t67, attrs: k63 } = g72, { x: s84 } = A35, { axis: I44, keepDims: S45 } = k63;
  i26(s84, "all");
  let h74 = util_exports.parseAxisParam(I44, s84.shape), n67 = h74, l80 = backend_util_exports.getAxesPermutation(n67, s84.shape.length), e36 = s84;
  l80 != null && (e36 = h38({ inputs: { x: s84 }, backend: t67, attrs: { perm: l80 } }), n67 = backend_util_exports.getInnerMostAxes(n67.length, s84.shape.length)), backend_util_exports.assertAxesAreInnerMostDims("all", n67, e36.shape.length);
  let [i88, T40] = backend_util_exports.computeOutAndReduceShapes(e36.shape, n67), f85 = util_exports.sizeFromShape(T40), c103 = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(i88), e36.dtype), x76 = t67.data.get(e36.dataId).values;
  for (let a71 = 0; a71 < c103.length; ++a71) {
    let r56 = a71 * f85, u86 = x76[r56];
    for (let d55 = 0; d55 < f85; ++d55) {
      let y43 = x76[r56 + d55];
      u86 = u86 && y43;
    }
    c103[a71] = u86;
  }
  l80 != null && t67.disposeIntermediateTensorInfo(e36);
  let m96 = t67.makeTensorInfo(i88, e36.dtype, c103);
  if (S45) {
    let a71 = backend_util_exports.expandShapeToKeepDim(i88, h74), r56 = f52({ inputs: { x: m96 }, backend: t67, attrs: { shape: a71 } });
    return t67.disposeIntermediateTensorInfo(m96), r56;
  }
  return m96;
}
var R15 = { kernelName: s3, backendName: "cpu", kernelFunc: F9 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Any.mjs
function F10(g72) {
  let { inputs: y43, backend: t67, attrs: A35 } = g72, { x: s84 } = y43, { axis: k63, keepDims: I44 } = A35;
  i26(s84, "any");
  let h74 = util_exports.parseAxisParam(k63, s84.shape), a71 = h74, i88 = backend_util_exports.getAxesPermutation(a71, s84.shape.length), e36 = s84;
  i88 != null && (e36 = h38({ inputs: { x: s84 }, backend: t67, attrs: { perm: i88 } }), a71 = backend_util_exports.getInnerMostAxes(a71.length, s84.shape.length)), backend_util_exports.assertAxesAreInnerMostDims("any", a71, e36.shape.length);
  let [l80, S45] = backend_util_exports.computeOutAndReduceShapes(e36.shape, a71), f85 = util_exports.sizeFromShape(S45), c103 = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(l80), e36.dtype), x76 = t67.data.get(e36.dataId).values;
  for (let n67 = 0; n67 < c103.length; ++n67) {
    let r56 = n67 * f85, u86 = x76[r56];
    for (let d55 = 0; d55 < f85; ++d55) {
      let T40 = x76[r56 + d55];
      u86 = u86 || T40;
    }
    c103[n67] = u86;
  }
  i88 != null && t67.disposeIntermediateTensorInfo(e36);
  let m96 = t67.makeTensorInfo(l80, e36.dtype, c103);
  if (I44) {
    let n67 = backend_util_exports.expandShapeToKeepDim(l80, h74), r56 = f52({ inputs: { x: m96 }, backend: t67, attrs: { shape: n67 } });
    return t67.disposeIntermediateTensorInfo(m96), r56;
  }
  return m96;
}
var R16 = { kernelName: p2, backendName: "cpu", kernelFunc: F10 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ArgMax.mjs
function F11(A35) {
  let { inputs: I44, backend: n67, attrs: k63 } = A35, { x: a71 } = I44, { axis: M30 } = k63;
  i26(a71, "argMax");
  let e36 = util_exports.parseAxisParam(M30, a71.shape), c103 = backend_util_exports.getAxesPermutation(e36, a71.shape.length), t67 = a71, m96 = [];
  c103 != null && (t67 = h38({ inputs: { x: a71 }, backend: n67, attrs: { perm: c103 } }), m96.push(t67), e36 = backend_util_exports.getInnerMostAxes(e36.length, t67.shape.length)), e36 = [e36[0]], backend_util_exports.assertAxesAreInnerMostDims("argMax", e36, t67.shape.length);
  let [l80, S45] = backend_util_exports.computeOutAndReduceShapes(t67.shape, e36), z32 = util_exports.sizeFromShape(l80), i88 = util_exports.makeZerosTypedArray(z32, "int32"), u86 = util_exports.sizeFromShape(S45), x76 = n67.data.get(t67.dataId).values;
  for (let s84 = 0; s84 < i88.length; ++s84) {
    let h74 = s84 * u86, d55 = x76[h74], f85 = 0;
    for (let o80 = 0; o80 < u86; ++o80) {
      let g72 = x76[h74 + o80];
      g72 > d55 && (d55 = g72, f85 = o80);
    }
    i88[s84] = f85;
  }
  return m96.forEach((s84) => n67.disposeIntermediateTensorInfo(s84)), n67.makeTensorInfo(l80, "int32", i88);
}
var P12 = { kernelName: c3, backendName: "cpu", kernelFunc: F11 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ArgMin.mjs
function F12(A35) {
  let { inputs: I44, backend: o80, attrs: k63 } = A35, { x: s84 } = I44, { axis: M30 } = k63;
  i26(s84, "argMin");
  let e36 = util_exports.parseAxisParam(M30, s84.shape), c103 = backend_util_exports.getAxesPermutation(e36, s84.shape.length), t67 = s84, m96 = [];
  c103 != null && (t67 = h38({ inputs: { x: s84 }, backend: o80, attrs: { perm: c103 } }), m96.push(t67), e36 = backend_util_exports.getInnerMostAxes(e36.length, t67.shape.length)), e36 = [e36[0]], backend_util_exports.assertAxesAreInnerMostDims("argMin", e36, t67.shape.length);
  let [l80, S45] = backend_util_exports.computeOutAndReduceShapes(t67.shape, e36), z32 = util_exports.sizeFromShape(l80), p103 = util_exports.makeZerosTypedArray(z32, "int32"), u86 = util_exports.sizeFromShape(S45), h74 = o80.data.get(t67.dataId).values;
  for (let n67 = 0; n67 < p103.length; ++n67) {
    let d55 = n67 * u86, f85 = h74[d55], g72 = 0;
    for (let a71 = 0; a71 < u86; ++a71) {
      let x76 = h74[d55 + a71];
      x76 < f85 && (f85 = x76, g72 = a71);
    }
    p103[n67] = g72;
  }
  return m96.forEach((n67) => o80.disposeIntermediateTensorInfo(n67)), o80.makeTensorInfo(l80, "int32", p103);
}
var P13 = { kernelName: a4, backendName: "cpu", kernelFunc: F12 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Asin.mjs
var o31 = A15(x2, (e36) => Math.asin(e36));
var t16 = { kernelName: x2, backendName: "cpu", kernelFunc: o31 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Asinh.mjs
var o32 = A15(i, (e36) => Math.asinh(e36));
var t17 = { kernelName: i, backendName: "cpu", kernelFunc: o32 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Atan.mjs
var t18 = A15(l2, (a71) => Math.atan(a71));
var c56 = { kernelName: l2, backendName: "cpu", kernelFunc: t18 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Atan2.mjs
var o33 = z14((e36, a71) => Math.atan2(e36, a71));
var m52 = G14(u, o33);
var l41 = { kernelName: u, backendName: "cpu", kernelFunc: m52 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Atanh.mjs
var t19 = A15(d2, (a71) => Math.atanh(a71));
var c57 = { kernelName: d2, backendName: "cpu", kernelFunc: t19 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/utils/pool_utils.mjs
function st3(Y14, i88, b58, e36, t67, p103) {
  let N58 = t67.strideHeight, O21 = t67.strideWidth, V24 = t67.dilationHeight, w45 = t67.dilationWidth, g72 = t67.effectiveFilterHeight, F32 = t67.effectiveFilterWidth, E44 = t67.padInfo.top, _24 = t67.padInfo.left, k63 = p103 === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY, m96 = i7(t67.outShape, b58), l80 = m96.values, s84 = t67.outShape[1] * t67.outShape[2] * t67.outShape[3], u86 = t67.outShape[2] * t67.outShape[3], x76 = t67.outShape[3];
  for (let c103 = 0; c103 < t67.batchSize; ++c103) {
    let W15 = c103 * s84, n67 = c103 * e36[0];
    for (let r56 = 0; r56 < t67.inChannels; ++r56) for (let f85 = 0; f85 < t67.outHeight; ++f85) {
      let o80 = f85 * N58 - E44, H18 = Math.max(0, o80), M30 = Math.min(t67.inHeight, g72 + o80), h74 = W15 + f85 * u86;
      for (let d55 = 0; d55 < t67.outWidth; ++d55) {
        let a71 = d55 * O21 - _24, C28 = Math.max(0, a71), P36 = Math.min(t67.inWidth, F32 + a71), S45 = k63, R26 = 0, D42 = 0;
        for (let T40 = H18; T40 < M30; T40 += V24) {
          let j22 = n67 + T40 * e36[1];
          for (let B30 = C28; B30 < P36; B30 += w45) {
            let L22 = j22 + B30 * e36[2], z32 = Y14[L22 + r56];
            p103 === "max" && z32 > S45 ? S45 = z32 : p103 === "avg" && (R26 += z32, D42++);
          }
          if (isNaN(S45)) break;
        }
        let y43 = h74 + d55 * x76 + r56;
        l80[y43] = p103 === "avg" ? R26 / D42 : S45;
      }
    }
  }
  return m96;
}
function ht3(Y14, i88, b58, e36, t67 = false, p103 = false) {
  let N58 = i7(e36.outShape, "int32"), O21 = e36.strideHeight, V24 = e36.strideWidth, w45 = e36.dilationHeight, g72 = e36.dilationWidth, F32 = e36.effectiveFilterHeight, E44 = e36.effectiveFilterWidth, _24 = e36.padInfo.top, k63 = e36.padInfo.left, m96 = i7(i88, b58, Y14);
  for (let l80 = 0; l80 < e36.batchSize; ++l80) for (let s84 = 0; s84 < e36.inChannels; ++s84) for (let u86 = 0; u86 < e36.outHeight; ++u86) {
    let x76 = u86 * O21 - _24, c103 = x76;
    for (; c103 < 0; ) c103 += w45;
    let W15 = Math.min(e36.inHeight, F32 + x76);
    for (let n67 = 0; n67 < e36.outWidth; ++n67) {
      let r56 = n67 * V24 - k63, f85 = r56;
      for (; f85 < 0; ) f85 += g72;
      let o80 = Math.min(e36.inWidth, E44 + r56), H18 = Number.NEGATIVE_INFINITY, M30 = -1;
      for (let h74 = c103; h74 < W15; h74 += w45) {
        let d55 = h74 - x76;
        for (let a71 = f85; a71 < o80; a71 += g72) {
          let C28 = a71 - r56, P36 = m96.get(l80, h74, a71, s84);
          P36 > H18 && (H18 = P36, t67 ? M30 = p103 ? ((l80 * e36.inHeight + h74) * e36.inWidth + a71) * e36.inChannels + s84 : (h74 * e36.inWidth + a71) * e36.inChannels + s84 : M30 = d55 * E44 + C28);
        }
      }
      N58.set(M30, l80, u86, n67, s84);
    }
  }
  return N58;
}
function at3(Y14, i88, b58, e36, t67, p103) {
  let N58 = t67.strideDepth, O21 = t67.strideHeight, V24 = t67.strideWidth, w45 = t67.dilationDepth, g72 = t67.dilationHeight, F32 = t67.dilationWidth, E44 = t67.effectiveFilterDepth, _24 = t67.effectiveFilterHeight, k63 = t67.effectiveFilterWidth, m96 = t67.padInfo.front, l80 = t67.padInfo.top, s84 = t67.padInfo.left, u86 = p103 === "max" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY, x76 = i7(t67.outShape, b58), c103 = x76.values, W15 = t67.outShape[1] * t67.outShape[2] * t67.outShape[3] * t67.outShape[4], n67 = t67.outShape[2] * t67.outShape[3] * t67.outShape[4], r56 = t67.outShape[3] * t67.outShape[4], f85 = t67.outShape[4];
  for (let o80 = 0; o80 < t67.batchSize; ++o80) {
    let H18 = o80 * W15, M30 = o80 * e36[0];
    for (let h74 = 0; h74 < t67.inChannels; ++h74) for (let d55 = 0; d55 < t67.outDepth; ++d55) {
      let a71 = d55 * N58 - m96, C28 = a71;
      for (; C28 < 0; ) C28 += w45;
      let P36 = Math.min(t67.inDepth, E44 + a71), S45 = H18 + d55 * n67;
      for (let R26 = 0; R26 < t67.outHeight; ++R26) {
        let D42 = R26 * O21 - l80, y43 = D42;
        for (; y43 < 0; ) y43 += g72;
        let T40 = Math.min(t67.inHeight, _24 + D42), j22 = S45 + R26 * r56;
        for (let B30 = 0; B30 < t67.outWidth; ++B30) {
          let L22 = B30 * V24 - s84, z32 = L22;
          for (; z32 < 0; ) z32 += F32;
          let Z16 = Math.min(t67.inWidth, k63 + L22), $37 = j22 + B30 * f85, A35 = u86, U24 = 0, X20 = 0;
          for (let q25 = C28; q25 < P36; q25 += w45) {
            let v42 = M30 + q25 * e36[1];
            for (let J17 = y43; J17 < T40; J17 += g72) {
              let tt3 = v42 + J17 * e36[2];
              for (let K21 = z32; K21 < Z16; K21 += F32) {
                let et5 = tt3 + K21 * e36[3], Q13 = Y14[et5 + h74];
                if (p103 === "max" && Q13 > A35 ? A35 = Q13 : p103 === "avg" && (U24 += Q13, X20++), isNaN(A35)) break;
              }
              if (isNaN(A35)) break;
            }
            if (isNaN(A35)) break;
          }
          let I44 = $37 + h74;
          c103[I44] = p103 === "avg" ? U24 / Math.max(X20, 1) : A35;
        }
      }
    }
  }
  return x76;
}
function lt4(Y14, i88) {
  let b58 = i7(i88.outShape, "int32"), e36 = i88.strideDepth, t67 = i88.strideHeight, p103 = i88.strideWidth, N58 = i88.dilationDepth, O21 = i88.dilationHeight, V24 = i88.dilationWidth, w45 = i88.effectiveFilterDepth, g72 = i88.effectiveFilterHeight, F32 = i88.effectiveFilterWidth, E44 = i88.padInfo.front, _24 = i88.padInfo.top, k63 = i88.padInfo.left;
  for (let m96 = 0; m96 < i88.batchSize; ++m96) for (let l80 = 0; l80 < i88.inChannels; ++l80) for (let s84 = 0; s84 < i88.outDepth; ++s84) {
    let u86 = s84 * e36 - E44, x76 = u86;
    for (; x76 < 0; ) x76 += N58;
    let c103 = Math.min(i88.inDepth, w45 + u86);
    for (let W15 = 0; W15 < i88.outHeight; ++W15) {
      let n67 = W15 * t67 - _24, r56 = n67;
      for (; r56 < 0; ) r56 += O21;
      let f85 = Math.min(i88.inHeight, g72 + n67);
      for (let o80 = 0; o80 < i88.outWidth; ++o80) {
        let H18 = o80 * p103 - k63, M30 = H18;
        for (; M30 < 0; ) M30 += V24;
        let h74 = Math.min(i88.inWidth, F32 + H18), d55 = Number.NEGATIVE_INFINITY, a71 = -1;
        for (let C28 = x76; C28 < c103; C28 += N58) {
          let P36 = C28 - u86;
          for (let S45 = r56; S45 < f85; S45 += O21) {
            let R26 = S45 - n67;
            for (let D42 = M30; D42 < h74; D42 += V24) {
              let y43 = D42 - H18, T40 = Y14.get(m96, C28, S45, D42, l80);
              T40 >= d55 && (d55 = T40, a71 = P36 * g72 * F32 + R26 * g72 + y43);
            }
          }
        }
        b58.set(a71, m96, s84, W15, o80, l80);
      }
    }
  }
  return b58;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/AvgPool.mjs
function b27(l80) {
  let { inputs: d55, backend: o80, attrs: p103 } = l80, { x: t67 } = d55;
  i26(t67, "avgPool");
  let { filterSize: u86, strides: s84, pad: c103, dimRoundingMode: m96 } = p103, i88 = 1;
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(s84, i88), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${s84} and dilations '${i88}'`);
  let e36 = backend_util_exports.computePool2DInfo(t67.shape, u86, s84, i88, c103, m96), r56;
  if (e36.filterWidth === 1 && e36.filterHeight === 1 && util_exports.arraysEqual(e36.inShape, e36.outShape)) r56 = i28({ inputs: { x: t67 }, backend: o80 });
  else {
    let f85 = o80.data.get(t67.dataId).values, g72 = util_exports.computeStrides(t67.shape), h74 = st3(f85, t67.shape, t67.dtype, g72, e36, "avg");
    r56 = o80.makeTensorInfo(e36.outShape, t67.dtype, h74.values);
  }
  return r56;
}
var N26 = { kernelName: S2, backendName: "cpu", kernelFunc: b27 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/AvgPool3D.mjs
function x45(a71) {
  let { inputs: n67, backend: t67, attrs: s84 } = a71, { x: o80 } = n67, { filterSize: r56, strides: p103, pad: c103, dimRoundingMode: d55, dataFormat: l80 } = s84;
  i26(o80, "avgPool3d");
  let u86 = backend_util_exports.computePool3DInfo(o80.shape, r56, p103, 1, c103, d55, l80), i88 = t67.data.get(o80.dataId).values, e36 = at3(i88, o80.shape, o80.dtype, util_exports.computeStrides(o80.shape), u86, "avg");
  return t67.makeTensorInfo(e36.shape, "float32", e36.values);
}
var I20 = { kernelName: D2, backendName: "cpu", kernelFunc: x45 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/AvgPool3DGrad.mjs
function V8(C28) {
  let { inputs: H18, backend: u86, attrs: W15 } = C28, { dy: D42, input: s84 } = H18, { filterSize: x76, strides: F32, pad: b58, dimRoundingMode: w45 } = W15;
  i26([D42, s84], "avgPool3DGrad");
  let t67 = backend_util_exports.computePool3DInfo(s84.shape, x76, F32, 1, b58, w45), k63 = t67.strideDepth, I44 = t67.strideHeight, P36 = t67.strideWidth, M30 = t67.filterDepth, R26 = t67.filterHeight, G30 = t67.filterWidth, N58 = t67.dilationDepth, S45 = t67.dilationHeight, z32 = t67.dilationWidth, g72 = t67.effectiveFilterDepth, v42 = t67.effectiveFilterHeight, m96 = t67.effectiveFilterWidth, T40 = g72 - 1 - t67.padInfo.front, A35 = m96 - 1 - t67.padInfo.left, B30 = v42 - 1 - t67.padInfo.top, n67 = i7(s84.shape, "float32"), L22 = 1 / (M30 * R26 * G30), _24 = u86.bufferSync(D42);
  for (let r56 = 0; r56 < t67.batchSize; ++r56) for (let d55 = 0; d55 < t67.inChannels; ++d55) for (let f85 = 0; f85 < t67.inDepth; ++f85) for (let l80 = 0; l80 < t67.inHeight; ++l80) for (let c103 = 0; c103 < t67.inWidth; ++c103) {
    let j22 = f85 - T40, q25 = l80 - B30, E44 = c103 - A35, y43 = 0;
    for (let h74 = 0; h74 < g72; h74 += N58) {
      let e36 = (j22 + h74) / k63;
      if (!(e36 < 0 || e36 >= t67.outDepth || Math.floor(e36) !== e36)) for (let a71 = 0; a71 < v42; a71 += S45) {
        let o80 = (q25 + a71) / I44;
        if (!(o80 < 0 || o80 >= t67.outHeight || Math.floor(o80) !== o80)) for (let p103 = 0; p103 < m96; p103 += z32) {
          let i88 = (E44 + p103) / P36;
          if (i88 < 0 || i88 >= t67.outWidth || Math.floor(i88) !== i88) continue;
          let J17 = _24.get(r56, e36, o80, i88, d55);
          y43 += J17;
        }
      }
    }
    n67.set(y43 * L22, r56, f85, l80, c103, d55);
  }
  return u86.makeTensorInfo(n67.shape, n67.dtype, n67.values);
}
var Z7 = { kernelName: m, backendName: "cpu", kernelFunc: V8 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/AvgPoolGrad.mjs
function j13(W15) {
  let { inputs: m96, backend: f85, attrs: C28 } = W15, { dy: a71, input: h74 } = m96, p103 = h74;
  i26([a71, h74], "avgPoolGrad");
  let { filterSize: x76, strides: y43, pad: b58 } = C28, t67 = backend_util_exports.computePool2DInfo(p103.shape, x76, y43, 1, b58), k63 = t67.strideHeight, I44 = t67.strideWidth, P36 = t67.filterHeight, F32 = t67.filterWidth, G30 = t67.dilationHeight, R26 = t67.dilationWidth, g72 = t67.effectiveFilterHeight, u86 = t67.effectiveFilterWidth, M30 = u86 - 1 - t67.padInfo.left, N58 = g72 - 1 - t67.padInfo.top, i88 = i7(p103.shape, "float32"), w45 = 1 / (P36 * F32), z32 = f85.data.get(a71.dataId).values, D42 = i7(a71.shape, "float32", z32);
  for (let n67 = 0; n67 < t67.batchSize; ++n67) for (let d55 = 0; d55 < t67.inChannels; ++d55) for (let r56 = 0; r56 < t67.inHeight; ++r56) for (let s84 = 0; s84 < t67.inWidth; ++s84) {
    let S45 = r56 - N58, T40 = s84 - M30, v42 = 0;
    for (let c103 = 0; c103 < g72; c103 += G30) {
      let e36 = (S45 + c103) / k63;
      if (!(e36 < 0 || e36 >= t67.outHeight || Math.floor(e36) !== e36)) for (let l80 = 0; l80 < u86; l80 += R26) {
        let o80 = (T40 + l80) / I44;
        if (o80 < 0 || o80 >= t67.outWidth || Math.floor(o80) !== o80) continue;
        let A35 = D42.get(n67, e36, o80, d55);
        v42 += A35;
      }
    }
    i88.set(v42 * w45, n67, r56, s84, d55);
  }
  return f85.makeTensorInfo(i88.shape, i88.dtype, i88.values);
}
var J7 = { kernelName: g2, backendName: "cpu", kernelFunc: j13 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/BatchNorm.mjs
function L7(k63) {
  let { inputs: q25, backend: a71, attrs: N58 } = k63, { x: s84, scale: t67, offset: e36, mean: n67, variance: o80 } = q25;
  util_exports.assert(n67.shape.length === o80.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks."), util_exports.assert(e36 == null || n67.shape.length === e36.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks."), util_exports.assert(t67 == null || n67.shape.length === t67.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks."), i26([s84, n67, o80, t67, e36], "batchNorm");
  let { varianceEpsilon: r56 } = N58;
  r56 == null && (r56 = 1e-3);
  let h74 = a71.data.get(s84.dataId).values, u86 = a71.data.get(n67.dataId).values, f85 = a71.data.get(o80.dataId).values, p103 = t67 ? a71.data.get(t67.dataId).values : new Float32Array([1]), v42 = e36 ? a71.data.get(e36.dataId).values : new Float32Array([0]), V24 = new Float32Array(h74.length), I44 = v42.length, b58 = p103.length, x76 = f85.length, F32 = u86.length, i88 = 0, c103 = 0, d55 = 0, g72 = 0;
  for (let l80 = 0; l80 < h74.length; ++l80) V24[l80] = v42[i88++] + (h74[l80] - u86[c103++]) * p103[d55++] / Math.sqrt(f85[g72++] + r56), i88 >= I44 && (i88 = 0), c103 >= F32 && (c103 = 0), d55 >= b58 && (d55 = 0), g72 >= x76 && (g72 = 0);
  return a71.makeTensorInfo(s84.shape, s84.dtype, V24);
}
var A18 = { kernelName: lo, backendName: "cpu", kernelFunc: L7 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/BatchToSpaceND.mjs
function D13(h74) {
  let { inputs: u86, backend: e36, attrs: l80 } = h74, { x: o80 } = u86, { blockShape: t67, crops: n67 } = l80;
  i26([o80], "batchToSpaceND");
  let r56 = t67.reduce((T40, b58) => T40 * b58), p103 = backend_util_exports.getReshaped(o80.shape, t67, r56), g72 = backend_util_exports.getPermuted(p103.length, t67.length), a71 = backend_util_exports.getReshapedPermuted(o80.shape, t67, r56), f85 = backend_util_exports.getSliceBeginCoords(n67, t67.length), x76 = backend_util_exports.getSliceSize(a71, n67, t67.length), c103 = f52({ inputs: { x: o80 }, backend: e36, attrs: { shape: p103 } }), i88 = h38({ inputs: { x: c103 }, backend: e36, attrs: { perm: g72 } }), d55 = f52({ inputs: { x: i88 }, backend: e36, attrs: { shape: a71 } }), S45 = I18({ inputs: { x: d55 }, backend: e36, attrs: { begin: f85, size: x76 } });
  return e36.disposeIntermediateTensorInfo(c103), e36.disposeIntermediateTensorInfo(i88), e36.disposeIntermediateTensorInfo(d55), S45;
}
var _14 = { kernelName: h3, backendName: "cpu", kernelFunc: D13 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Bincount.mjs
function l42(o80) {
  let { inputs: a71, backend: n67, attrs: s84 } = o80, { x: c103, weights: t67 } = a71, { size: e36 } = s84, i88 = n67.data.get(c103.dataId).values, r56 = n67.data.get(t67.dataId).values, u86 = m38(i88, r56, t67.dtype, t67.shape, e36);
  return n67.makeTensorInfo([e36], t67.dtype, u86);
}
var f53 = { kernelName: M2, backendName: "cpu", kernelFunc: l42 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/BroadcastArgs.mjs
function m53(r56) {
  let { inputs: s84, backend: a71 } = r56, { s0: e36, s1: n67 } = s84, o80 = a71.data.get(e36.dataId).values, c103 = a71.data.get(n67.dataId).values, t67 = backend_util_exports.assertAndGetBroadcastShape(Array.from(o80), Array.from(c103));
  return a71.makeTensorInfo([t67.length], "int32", Int32Array.from(t67));
}
var f54 = { kernelName: N2, backendName: "cpu", kernelFunc: m53 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ClipByValue.mjs
var a40 = A15(F2, (l80, r56) => {
  let e36 = r56;
  return l80 > e36.clipValueMax ? e36.clipValueMax : l80 < e36.clipValueMin ? e36.clipValueMin : l80;
});
var i39 = { kernelName: F2, backendName: "cpu", kernelFunc: a40 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ComplexAbs.mjs
var x46 = (o80) => {
  let { x: t67 } = o80.inputs, a71 = o80.backend, s84 = new Float32Array(util_exports.sizeFromShape(t67.shape)), n67 = a71.data.get(t67.dataId), c103 = n67.complexTensorInfos.real, r56 = n67.complexTensorInfos.imag, l80 = a71.data.get(c103.dataId).values, p103 = a71.data.get(r56.dataId).values;
  for (let e36 = 0; e36 < l80.length; e36++) {
    let m96 = l80[e36], d55 = p103[e36];
    s84[e36] = Math.hypot(m96, d55);
  }
  return a71.makeOutput(s84, t67.shape, "float32");
};
var f55 = { kernelName: T2, backendName: "cpu", kernelFunc: x46 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Imag.mjs
function s39(n67) {
  let { inputs: t67, backend: a71 } = n67, { input: o80 } = t67, e36 = a71.data.get(o80.dataId).complexTensorInfos.imag, m96 = a71.data.get(e36.dataId).values;
  return a71.makeTensorInfo(e36.shape, e36.dtype, m96);
}
var r15 = { kernelName: ho, backendName: "cpu", kernelFunc: s39 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Concat.mjs
function h41(d55) {
  let { inputs: s84, backend: t67, attrs: l80 } = d55, { axis: I44 } = l80, o80 = util_exports.parseAxisParam(I44, s84[0].shape)[0], x76 = s84.map((e36) => e36.shape);
  backend_util_exports.assertParamsConsistent(x76, o80);
  let p103 = backend_util_exports.computeOutShape(s84.map((e36) => e36.shape), o80);
  if (util_exports.sizeFromShape(p103) === 0) return t67.makeTensorInfo(p103, s84[0].dtype, []);
  let a71 = s84.filter((e36) => util_exports.sizeFromShape(e36.shape) > 0);
  if (a71.length === 1) return i28({ inputs: { x: a71[0] }, backend: t67 });
  if (a71[0].dtype === "complex64") {
    let e36 = a71.map((n67) => l34({ inputs: { input: n67 }, backend: t67 })), u86 = a71.map((n67) => s39({ inputs: { input: n67 }, backend: t67 })), i88 = h41({ inputs: e36, backend: t67, attrs: { axis: o80 } }), f85 = h41({ inputs: u86, backend: t67, attrs: { axis: o80 } }), C28 = r14({ inputs: { real: i88, imag: f85 }, backend: t67 });
    return e36.forEach((n67) => t67.disposeIntermediateTensorInfo(n67)), u86.forEach((n67) => t67.disposeIntermediateTensorInfo(n67)), t67.disposeIntermediateTensorInfo(i88), t67.disposeIntermediateTensorInfo(f85), C28;
  }
  let r56 = a71.map((e36) => {
    let i88 = [-1, util_exports.sizeFromShape(e36.shape.slice(o80))];
    return f52({ inputs: { x: e36 }, backend: t67, attrs: { shape: i88 } });
  }), S45 = r56.map((e36) => ({ vals: t67.data.get(e36.dataId).values, shape: e36.shape }));
  p103 = backend_util_exports.computeOutShape(r56.map((e36) => e36.shape), 1);
  let g72 = r56[0].shape[0] === 1, k63 = v26(S45, p103, s84[0].dtype, g72), T40 = backend_util_exports.computeOutShape(a71.map((e36) => e36.shape), o80), y43 = t67.makeTensorInfo(T40, s84[0].dtype, k63);
  return r56.forEach((e36) => t67.disposeIntermediateTensorInfo(e36)), y43;
}
var q13 = { kernelName: L2, backendName: "cpu", kernelFunc: h41 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Conv2D.mjs
function at4(v42) {
  let { inputs: w45, backend: h74, attrs: O21 } = v42, { x: n67, filter: i88 } = w45, { strides: H18, pad: I44, dataFormat: R26, dilations: W15, dimRoundingMode: k63 } = O21;
  i26([n67, i88], "conv2d");
  let D42 = backend_util_exports.convertConv2DDataFormat(R26), t67 = backend_util_exports.computeConv2DInfo(n67.shape, i88.shape, H18, W15, I44, k63, false, D42), b58 = t67.filterHeight, F32 = t67.filterWidth, V24 = t67.dilationHeight, B30 = t67.dilationWidth, L22 = t67.padInfo.left, N58 = t67.padInfo.top, o80 = t67.dataFormat === "channelsLast", e36 = new p8(t67.outShape, n67.dtype), s84 = util_exports.computeStrides(n67.shape), x76 = util_exports.computeStrides(i88.shape), T40 = s84[0], z32 = o80 ? s84[1] : s84[2], M30 = o80 ? s84[2] : 1, _24 = o80 ? 1 : s84[1], $37 = e36.strides[0], j22 = o80 ? e36.strides[1] : e36.strides[2], q25 = o80 ? e36.strides[2] : 1, A35 = o80 ? 1 : e36.strides[1], E44 = h74.data.get(n67.dataId).values, G30 = h74.data.get(i88.dataId).values, m96 = e36.values;
  for (let a71 = 0; a71 < t67.batchSize; ++a71) {
    let J17 = a71 * T40, K21 = a71 * $37;
    for (let c103 = 0; c103 < t67.outHeight; ++c103) {
      let P36 = K21 + c103 * j22, Q13 = c103 * t67.strideHeight - N58;
      for (let d55 = 0; d55 < b58; ++d55) {
        let p103 = Q13 + d55 * V24;
        if (p103 < 0 || p103 >= t67.inHeight) continue;
        let U24 = d55 * x76[0], X20 = J17 + p103 * z32;
        for (let r56 = 0; r56 < t67.outWidth; ++r56) {
          let Y14 = P36 + r56 * q25, Z16 = r56 * t67.strideWidth - L22;
          for (let f85 = 0; f85 < F32; ++f85) {
            let u86 = Z16 + f85 * B30;
            if (u86 < 0 || u86 >= t67.inWidth) continue;
            let tt3 = U24 + f85 * x76[1], et5 = X20 + u86 * M30, S45 = tt3;
            for (let C28 = 0; C28 < t67.inChannels; ++C28) {
              let ot6 = E44[et5 + C28 * _24];
              for (let l80 = 0; l80 < t67.outChannels; ++l80) m96[Y14 + l80 * A35] += ot6 * G30[S45 + l80];
              S45 += t67.outChannels;
            }
          }
        }
      }
    }
  }
  return h74.makeTensorInfo(e36.shape, e36.dtype, m96);
}
var rt4 = { kernelName: k2, backendName: "cpu", kernelFunc: at4 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Conv2DBackpropFilter.mjs
function A19(F32) {
  let { inputs: B30, backend: p103, attrs: I44 } = F32, { x: n67, dy: i88 } = B30, { strides: D42, pad: R26, dataFormat: b58, dimRoundingMode: w45, filterShape: W15 } = I44;
  i26([n67, i88], "conv2dBackpropFilter");
  let H18 = backend_util_exports.convertConv2DDataFormat(b58), t67 = backend_util_exports.computeConv2DInfo(n67.shape, W15, D42, 1, R26, w45, false, H18), { strideHeight: f85, strideWidth: h74, filterHeight: N58, filterWidth: P36 } = t67, S45 = t67.dataFormat === "channelsLast", l80 = new p8(t67.filterShape, "float32"), m96 = t67.padInfo.left, u86 = t67.padInfo.top, L22 = p103.data.get(n67.dataId).values, T40 = p103.data.get(i88.dataId).values, x76 = new p8(n67.shape, n67.dtype, L22), y43 = new p8(i88.shape, i88.dtype, T40);
  for (let e36 = 0; e36 < N58; ++e36) {
    let V24 = Math.max(0, Math.ceil((u86 - e36) / f85)), z32 = Math.min(t67.outHeight, (t67.inHeight + u86 - e36) / f85);
    for (let o80 = 0; o80 < P36; ++o80) {
      let _24 = Math.max(0, Math.ceil((m96 - o80) / h74)), $37 = Math.min(t67.outWidth, (t67.inWidth + m96 - o80) / h74);
      for (let s84 = 0; s84 < t67.inChannels; ++s84) for (let r56 = 0; r56 < t67.outChannels; ++r56) {
        let C28 = 0;
        for (let a71 = 0; a71 < t67.batchSize; ++a71) for (let c103 = V24; c103 < z32; ++c103) {
          let v42 = e36 + c103 * f85 - u86;
          for (let d55 = _24; d55 < $37; ++d55) {
            let M30 = o80 + d55 * h74 - m96;
            S45 ? C28 += x76.get(a71, v42, M30, s84) * y43.get(a71, c103, d55, r56) : C28 += x76.get(a71, s84, v42, M30) * y43.get(a71, r56, c103, d55);
          }
        }
        l80.set(C28, e36, o80, s84, r56);
      }
    }
  }
  return p103.makeTensorInfo(l80.shape, l80.dtype, l80.values);
}
var J8 = { kernelName: G2, backendName: "cpu", kernelFunc: A19 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Conv2DBackpropInput.mjs
function mt3(g72) {
  let { inputs: R26, backend: p103, attrs: B30 } = g72, { dy: h74, filter: s84 } = R26, { inputShape: w45, strides: D42, pad: b58, dataFormat: F32, dimRoundingMode: H18 } = B30;
  i26([h74, s84], "conv2dBackpropInput");
  let W15 = util_exports.computeStrides(s84.shape), o80 = util_exports.computeStrides(h74.shape), u86 = backend_util_exports.convertConv2DDataFormat(F32), n67 = backend_util_exports.computeConv2DInfo(w45, s84.shape, D42, 1, b58, H18, false, u86), t67 = new p8(n67.inShape, "float32"), N58 = t67.values, O21 = p103.data.get(h74.dataId).values, P36 = p103.data.get(s84.dataId).values, [V24, L22, T40] = W15, { batchSize: z32, filterHeight: x76, filterWidth: m96, inChannels: _24, inHeight: $37, inWidth: j22, outChannels: q25, outHeight: A35, outWidth: E44, strideHeight: C28, strideWidth: S45 } = n67;
  u86 = n67.dataFormat;
  let G30 = x76 - 1 - n67.padInfo.top, J17 = m96 - 1 - n67.padInfo.left, e36 = u86 === "channelsLast", K21 = t67.strides[0], Q13 = e36 ? t67.strides[1] : t67.strides[2], U24 = e36 ? t67.strides[2] : 1, X20 = e36 ? 1 : t67.strides[1], Y14 = o80[0], Z16 = e36 ? o80[1] : o80[2], tt3 = e36 ? o80[2] : 1, et5 = e36 ? 1 : o80[1];
  for (let a71 = 0; a71 < z32; ++a71) for (let c103 = 0; c103 < _24; ++c103) for (let r56 = 0; r56 < $37; ++r56) {
    let y43 = r56 - G30, ot6 = Math.max(0, Math.ceil(y43 / C28)), nt5 = Math.min(A35, (x76 + y43) / C28);
    for (let d55 = 0; d55 < j22; ++d55) {
      let v42 = d55 - J17, st7 = Math.max(0, Math.ceil(v42 / S45)), at7 = Math.min(E44, (m96 + v42) / S45), I44 = 0;
      for (let i88 = ot6; i88 < nt5; ++i88) {
        let rt8 = i88 * C28 - y43;
        for (let l80 = st7; l80 < at7; ++l80) {
          let dt5 = l80 * S45 - v42, it4 = Y14 * a71 + Z16 * i88 + tt3 * l80, lt6 = V24 * (x76 - 1 - rt8) + L22 * (m96 - 1 - dt5) + T40 * c103;
          for (let f85 = 0; f85 < q25; ++f85) {
            let ft6 = O21[it4 + et5 * f85], pt3 = P36[lt6 + f85];
            I44 += ft6 * pt3;
          }
        }
      }
      let ct4 = K21 * a71 + Q13 * r56 + U24 * d55 + X20 * c103;
      N58[ct4] = I44;
    }
  }
  return p103.makeTensorInfo(t67.shape, t67.dtype, t67.values);
}
var yt2 = { kernelName: E2, backendName: "cpu", kernelFunc: mt3 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Conv3D.mjs
function ft3(D42) {
  let { inputs: g72, backend: p103, attrs: k63 } = D42, { x: o80, filter: n67 } = g72, { strides: F32, pad: I44, dilations: S45 } = k63;
  i26([o80, n67], "conv3d");
  let t67 = backend_util_exports.computeConv3DInfo(o80.shape, n67.shape, F32, S45, I44), { filterDepth: b58, filterHeight: H18, filterWidth: W15, dilationDepth: R26, dilationHeight: V24, dilationWidth: N58, padInfo: h74 } = t67, T40 = h74.front, z32 = h74.left, B30 = h74.top, e36 = new p8(t67.outShape, o80.dtype), L22 = p103.data.get(o80.dataId).values, _24 = p103.data.get(n67.dataId).values, j22 = e36.values, u86 = util_exports.computeStrides(o80.shape), x76 = util_exports.computeStrides(n67.shape);
  for (let s84 = 0; s84 < t67.batchSize; ++s84) {
    let q25 = s84 * u86[0], A35 = s84 * e36.strides[0];
    for (let f85 = 0; f85 < t67.outDepth; ++f85) {
      let E44 = A35 + f85 * e36.strides[1], G30 = f85 * t67.strideDepth - T40;
      for (let i88 = 0; i88 < b58; ++i88) {
        let C28 = G30 + i88 * R26;
        if (C28 < 0 || C28 >= t67.inDepth) continue;
        let J17 = i88 * x76[0], K21 = q25 + C28 * u86[1];
        for (let c103 = 0; c103 < t67.outHeight; ++c103) {
          let M30 = E44 + c103 * e36.strides[2], P36 = c103 * t67.strideHeight - B30;
          for (let r56 = 0; r56 < H18; ++r56) {
            let O21 = P36 + r56 * V24;
            if (O21 < 0 || O21 >= t67.inHeight) continue;
            let Q13 = J17 + r56 * x76[1], U24 = K21 + O21 * u86[2];
            for (let a71 = 0; a71 < t67.outWidth; ++a71) {
              let X20 = M30 + a71 * t67.outChannels, Y14 = a71 * t67.strideWidth - z32;
              for (let d55 = 0; d55 < W15; ++d55) {
                let m96 = Y14 + d55 * N58;
                if (m96 < 0 || m96 >= t67.inWidth) continue;
                let Z16 = Q13 + d55 * x76[2], $37 = U24 + m96 * t67.inChannels, v42 = Z16;
                for (let y43 = 0; y43 < t67.inChannels; ++y43) {
                  let tt3 = L22[$37 + y43];
                  for (let l80 = 0; l80 < t67.outChannels; ++l80) j22[X20 + l80] += tt3 * _24[v42 + l80];
                  v42 += t67.outChannels;
                }
              }
            }
          }
        }
      }
    }
  }
  return p103.makeTensorInfo(e36.shape, e36.dtype, e36.values);
}
var rt5 = { kernelName: f3, backendName: "cpu", kernelFunc: ft3 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Conv3DBackpropFilterV2.mjs
function yt3(O21) {
  let { inputs: F32, backend: p103, attrs: k63 } = O21, { x: c103, dy: h74 } = F32, { strides: v42, pad: D42, filterShape: g72 } = k63;
  i26([c103, h74], "conv3dBackpropFilterV2");
  let I44 = util_exports.computeStrides(c103.shape), V24 = util_exports.computeStrides(h74.shape), t67 = backend_util_exports.computeConv3DInfo(c103.shape, g72, v42, 1, D42), x76 = t67.strideDepth, u86 = t67.strideHeight, y43 = t67.strideWidth, H18 = t67.filterDepth, R26 = t67.filterHeight, W15 = t67.filterWidth, n67 = new p8(t67.filterShape, "float32"), b58 = n67.values, [B30, P36, N58, T40] = n67.strides, z32 = p103.data.get(h74.dataId).values, [_24, j22, q25, A35] = V24, E44 = p103.data.get(c103.dataId).values, [G30, J17, K21, L22] = I44, S45 = t67.padInfo.front, m96 = t67.padInfo.left, M30 = t67.padInfo.top;
  for (let e36 = 0; e36 < H18; ++e36) {
    let Q13 = Math.max(0, Math.ceil((S45 - e36) / x76)), U24 = Math.min(t67.outDepth, (t67.inDepth + S45 - e36) / x76), X20 = e36 * B30;
    for (let o80 = 0; o80 < R26; ++o80) {
      let Y14 = Math.max(0, Math.ceil((M30 - o80) / u86)), Z16 = Math.min(t67.outHeight, (t67.inHeight + M30 - o80) / u86), $37 = o80 * P36 + X20;
      for (let s84 = 0; s84 < W15; ++s84) {
        let tt3 = Math.max(0, Math.ceil((m96 - s84) / y43)), et5 = Math.min(t67.outWidth, (t67.inWidth + m96 - s84) / y43), ot6 = s84 * N58 + $37;
        for (let a71 = 0; a71 < t67.inChannels; ++a71) {
          let st7 = a71 * T40 + ot6;
          for (let f85 = 0; f85 < t67.outChannels; ++f85) {
            let w45 = 0;
            for (let i88 = 0; i88 < t67.batchSize; ++i88) {
              let nt5 = i88 * G30, ct4 = i88 * _24;
              for (let r56 = Q13; r56 < U24; ++r56) {
                let at7 = (e36 + r56 * x76 - S45) * J17 + nt5, ft6 = r56 * j22 + ct4;
                for (let d55 = Y14; d55 < Z16; ++d55) {
                  let it4 = (o80 + d55 * u86 - M30) * K21 + at7, rt8 = d55 * q25 + ft6;
                  for (let l80 = tt3; l80 < et5; ++l80) {
                    let dt5 = (s84 + l80 * y43 - m96) * L22 + it4, lt6 = l80 * A35 + rt8;
                    w45 += E44[dt5 + a71] * z32[lt6 + f85];
                  }
                }
              }
            }
            b58[st7 + f85] = w45;
          }
        }
      }
    }
  }
  return p103.makeTensorInfo(n67.shape, n67.dtype, n67.values);
}
var Ot2 = { kernelName: I2, backendName: "cpu", kernelFunc: yt3 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Conv3DBackpropInputV2.mjs
function vt2(D42) {
  let { inputs: F32, backend: f85, attrs: V24 } = D42, { dy: p103, filter: h74 } = F32, { pad: R26, strides: b58, inputShape: w45 } = V24;
  i26([p103], "conv3dBackpropInputV2");
  let B30 = util_exports.computeStrides(p103.shape), H18 = util_exports.computeStrides(h74.shape), t67 = backend_util_exports.computeConv3DInfo(w45, h74.shape, b58, 1, R26), o80 = new p8(t67.inShape, "float32"), P36 = o80.values, [W15, N58, O21, T40] = o80.strides, z32 = f85.data.get(p103.dataId).values, [_24, j22, q25, A35] = B30, E44 = f85.data.get(h74.dataId).values, [G30, J17, K21, L22] = H18, { batchSize: Q13, filterDepth: u86, filterHeight: x76, filterWidth: S45, inChannels: U24, inDepth: X20, inHeight: Y14, inWidth: Z16, outChannels: $37, outDepth: tt3, outHeight: ot6, outWidth: et5, strideDepth: m96, strideHeight: y43, strideWidth: C28 } = t67, nt5 = u86 - 1 - t67.padInfo.front, st7 = x76 - 1 - t67.padInfo.top, at7 = S45 - 1 - t67.padInfo.left;
  for (let e36 = 0; e36 < Q13; ++e36) for (let n67 = 0; n67 < U24; ++n67) for (let s84 = 0; s84 < X20; ++s84) {
    let M30 = s84 - nt5, ct4 = Math.max(0, Math.ceil(M30 / m96)), rt8 = Math.min(tt3, (u86 + M30) / m96);
    for (let a71 = 0; a71 < Y14; ++a71) {
      let I44 = a71 - st7, dt5 = Math.max(0, Math.ceil(I44 / y43)), it4 = Math.min(ot6, (x76 + I44) / y43);
      for (let c103 = 0; c103 < Z16; ++c103) {
        let k63 = c103 - at7, lt6 = Math.max(0, Math.ceil(k63 / C28)), ft6 = Math.min(et5, (S45 + k63) / C28), v42 = 0;
        for (let r56 = ct4; r56 < rt8; ++r56) {
          let pt3 = r56 * m96 - M30;
          for (let d55 = dt5; d55 < it4; ++d55) {
            let ht7 = d55 * y43 - I44;
            for (let i88 = lt6; i88 < ft6; ++i88) {
              let ut4 = i88 * C28 - k63, xt3 = _24 * e36 + j22 * r56 + q25 * d55 + A35 * i88, St4 = G30 * (u86 - 1 - pt3) + J17 * (x76 - 1 - ht7) + K21 * (S45 - 1 - ut4) + L22 * n67;
              for (let l80 = 0; l80 < $37; ++l80) {
                let mt6 = z32[xt3 + l80], yt6 = E44[St4 + l80];
                v42 += mt6 * yt6;
              }
            }
          }
        }
        P36[W15 * e36 + N58 * s84 + O21 * a71 + T40 * c103 + n67] = v42;
      }
    }
  }
  return f85.makeTensorInfo(o80.shape, o80.dtype, o80.values);
}
var Ft3 = { kernelName: q2, backendName: "cpu", kernelFunc: vt2 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Cos.mjs
var r16 = A15(w2, (e36) => Math.cos(e36));
var m54 = { kernelName: w2, backendName: "cpu", kernelFunc: r16 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Cosh.mjs
var r17 = A15(V2, (e36) => Math.cosh(e36));
var m55 = { kernelName: V2, backendName: "cpu", kernelFunc: r17 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/CropAndResize.mjs
function $26(Y14) {
  let { inputs: j22, backend: S45, attrs: q25 } = Y14, { image: z32, boxes: C28, boxInd: D42 } = j22, { cropSize: E44, method: G30, extrapolationValue: L22 } = q25, [J17, y43, u86, h74] = z32.shape, H18 = C28.shape[0], [x76, l80] = E44, i88 = i7([H18, x76, l80, h74], "float32"), M30 = S45.data.get(C28.dataId).values, K21 = S45.data.get(D42.dataId).values, b58 = S45.data.get(z32.dataId).values, t67 = util_exports.computeStrides(z32.shape), o80 = util_exports.computeStrides(i88.shape);
  for (let d55 = 0; d55 < H18; d55++) {
    let k63 = d55 * 4, V24 = M30[k63], g72 = M30[k63 + 1], N58 = M30[k63 + 2], A35 = M30[k63 + 3], m96 = K21[d55];
    if (m96 >= J17) continue;
    let O21 = x76 > 1 ? (N58 - V24) * (y43 - 1) / (x76 - 1) : 0, W15 = l80 > 1 ? (A35 - g72) * (u86 - 1) / (l80 - 1) : 0;
    for (let r56 = 0; r56 < x76; r56++) {
      let I44 = x76 > 1 ? V24 * (y43 - 1) + r56 * O21 : 0.5 * (V24 + N58) * (y43 - 1);
      if (I44 < 0 || I44 > y43 - 1) {
        for (let e36 = 0; e36 < l80; e36++) for (let a71 = 0; a71 < h74; a71++) {
          let v42 = a71 + e36 * o80[2] + r56 * o80[1] + d55 * o80[0];
          i88.values[v42] = L22;
        }
        continue;
      }
      if (G30 === "bilinear") {
        let e36 = Math.floor(I44), a71 = Math.ceil(I44), v42 = I44 - e36;
        for (let f85 = 0; f85 < l80; f85++) {
          let n67 = l80 > 1 ? g72 * (u86 - 1) + f85 * W15 : 0.5 * (g72 + A35) * (u86 - 1);
          if (n67 < 0 || n67 > u86 - 1) {
            for (let s84 = 0; s84 < h74; s84++) {
              let c103 = s84 + f85 * o80[2] + r56 * o80[1] + d55 * o80[0];
              i88.values[c103] = L22;
            }
            continue;
          }
          let p103 = Math.floor(n67), R26 = Math.ceil(n67), w45 = n67 - p103;
          for (let s84 = 0; s84 < h74; s84++) {
            let c103 = s84 + p103 * t67[2] + e36 * t67[1] + m96 * t67[0], B30 = b58[c103];
            c103 = s84 + R26 * t67[2] + e36 * t67[1] + m96 * t67[0];
            let P36 = b58[c103];
            c103 = s84 + p103 * t67[2] + a71 * t67[1] + m96 * t67[0];
            let F32 = b58[c103];
            c103 = s84 + R26 * t67[2] + a71 * t67[1] + m96 * t67[0];
            let Q13 = b58[c103], T40 = B30 + (P36 - B30) * w45, U24 = F32 + (Q13 - F32) * w45;
            c103 = s84 + f85 * o80[2] + r56 * o80[1] + d55 * o80[0], i88.values[c103] = T40 + (U24 - T40) * v42;
          }
        }
      } else for (let e36 = 0; e36 < l80; ++e36) {
        let a71 = l80 > 1 ? g72 * (u86 - 1) + e36 * W15 : 0.5 * (g72 + A35) * (u86 - 1);
        if (a71 < 0 || a71 > u86 - 1) {
          for (let n67 = 0; n67 < h74; n67++) {
            let p103 = n67 + e36 * o80[2] + r56 * o80[1] + d55 * o80[0];
            i88.values[p103] = L22;
          }
          continue;
        }
        let v42 = Math.round(a71), f85 = Math.round(I44);
        for (let n67 = 0; n67 < h74; n67++) {
          let p103 = n67 + v42 * t67[2] + f85 * t67[1] + m96 * t67[0], R26 = n67 + e36 * o80[2] + r56 * o80[1] + d55 * o80[0];
          i88.values[R26] = b58[p103];
        }
      }
    }
  }
  return S45.makeTensorInfo(i88.shape, i88.dtype, i88.values);
}
var ot3 = { kernelName: z2, backendName: "cpu", kernelFunc: $26 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Cumprod.mjs
function N27(I44) {
  let { inputs: v42, backend: n67, attrs: A35 } = I44, { x: r56 } = v42, { axis: T40, exclusive: d55, reverse: b58 } = A35;
  i26(r56, "cumprod");
  let a71 = backend_util_exports.getAxesPermutation([T40], r56.shape.length), t67 = r56;
  a71 != null && (t67 = h38({ inputs: { x: r56 }, backend: n67, attrs: { perm: a71 } }));
  let x76 = backend_util_exports.getInnerMostAxes(1, r56.shape.length)[0];
  if (x76 !== t67.shape.length - 1) throw new Error(`backend.cumprod in CPU expects an inner-most axis=${t67.shape.length - 1} but got axis=${x76}`);
  let h74 = c5(t67.dtype, "int32"), o80 = util_exports.makeOnesTypedArray(util_exports.sizeFromShape(t67.shape), h74), p103 = n67.data.get(t67.dataId).values, c103 = t67.shape[t67.shape.length - 1], f85 = b58 ? (s84, e36) => s84 + c103 - e36 - 1 : (s84, e36) => s84 + e36;
  for (let s84 = 0; s84 < p103.length; s84 += c103) for (let e36 = 0; e36 < c103; e36++) {
    let i88 = f85(s84, e36);
    if (e36 === 0) o80[i88] = d55 ? 1 : p103[i88];
    else {
      let m96 = f85(s84, e36 - 1);
      o80[i88] = d55 ? p103[m96] * o80[m96] : p103[i88] * o80[m96];
    }
  }
  let u86 = n67.makeTensorInfo(t67.shape, h74, o80);
  if (a71 != null) {
    let s84 = backend_util_exports.getUndoAxesPermutation(a71), e36 = h38({ inputs: { x: u86 }, backend: n67, attrs: { perm: s84 } });
    return n67.disposeIntermediateTensorInfo(u86), n67.disposeIntermediateTensorInfo(t67), e36;
  }
  return u86;
}
var D14 = { kernelName: y3, backendName: "cpu", kernelFunc: N27 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Cumsum.mjs
function N28(I44) {
  let { inputs: v42, backend: n67, attrs: A35 } = I44, { x: r56 } = v42, { axis: T40, exclusive: d55, reverse: b58 } = A35;
  i26(r56, "cumsum");
  let a71 = backend_util_exports.getAxesPermutation([T40], r56.shape.length), t67 = r56;
  a71 != null && (t67 = h38({ inputs: { x: r56 }, backend: n67, attrs: { perm: a71 } }));
  let x76 = backend_util_exports.getInnerMostAxes(1, r56.shape.length)[0];
  if (x76 !== t67.shape.length - 1) throw new Error(`backend.cumsum in CPU expects an inner-most axis=${t67.shape.length - 1} but got axis=${x76}`);
  let h74 = c5(t67.dtype, "int32"), o80 = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(t67.shape), h74), i88 = n67.data.get(t67.dataId).values, p103 = t67.shape[t67.shape.length - 1], f85 = b58 ? (s84, e36) => s84 + p103 - e36 - 1 : (s84, e36) => s84 + e36;
  for (let s84 = 0; s84 < i88.length; s84 += p103) for (let e36 = 0; e36 < p103; e36++) {
    let u86 = f85(s84, e36);
    if (e36 === 0) o80[u86] = d55 ? 0 : i88[u86];
    else {
      let c103 = f85(s84, e36 - 1);
      o80[u86] = d55 ? i88[c103] + o80[c103] : i88[u86] + o80[c103];
    }
  }
  let m96 = n67.makeTensorInfo(t67.shape, h74, o80);
  if (a71 != null) {
    let s84 = backend_util_exports.getUndoAxesPermutation(a71), e36 = h38({ inputs: { x: m96 }, backend: n67, attrs: { perm: s84 } });
    return n67.disposeIntermediateTensorInfo(m96), n67.disposeIntermediateTensorInfo(t67), e36;
  }
  return m96;
}
var D15 = { kernelName: b2, backendName: "cpu", kernelFunc: N28 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/DenseBincount.mjs
function h42(r56) {
  let { inputs: c103, backend: e36, attrs: i88 } = r56, { x: t67, weights: n67 } = c103, { size: o80, binaryOutput: p103 } = i88;
  if (t67.shape.length === 1) {
    let a71 = e36.data.get(t67.dataId).values, u86 = e36.data.get(n67.dataId).values, s84 = m38(a71, u86, n67.dtype, n67.shape, o80);
    return e36.makeTensorInfo([o80], n67.dtype, s84);
  } else if (t67.shape.length === 2) {
    let a71 = e36.bufferSync(t67), u86 = e36.bufferSync(n67), s84 = g36(a71, u86, o80, p103);
    return e36.makeTensorInfo(s84.shape, n67.dtype, s84.values);
  }
  throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${t67.shape.length}.`);
}
var b28 = { kernelName: U2, backendName: "cpu", kernelFunc: h42 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/DepthToSpace.mjs
function y23(k63) {
  let { inputs: x76, backend: i88, attrs: D42 } = k63, { x: o80 } = x76, { blockSize: t67, dataFormat: h74 } = D42;
  util_exports.assert(h74 === "NHWC", () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${h74}`);
  let a71 = o80.shape[0], d55 = o80.shape[1], f85 = o80.shape[2], l80 = o80.shape[3], c103 = d55 * t67, p103 = f85 * t67, e36 = l80 / (t67 * t67), H18 = i88.data.get(o80.dataId).values, m96 = new Float32Array(a71 * c103 * p103 * e36), S45 = 0;
  for (let r56 = 0; r56 < a71; ++r56) for (let n67 = 0; n67 < c103; ++n67) {
    let W15 = Math.floor(n67 / t67), b58 = n67 % t67;
    for (let s84 = 0; s84 < p103; ++s84) {
      let T40 = Math.floor(s84 / t67), g72 = s84 % t67, C28 = (b58 * t67 + g72) * e36;
      for (let u86 = 0; u86 < e36; ++u86) {
        let F32 = u86 + C28 + l80 * (T40 + f85 * (W15 + d55 * r56));
        m96[S45++] = H18[F32];
      }
    }
  }
  return i88.makeTensorInfo([a71, c103, p103, e36], o80.dtype, m96);
}
var M16 = { kernelName: O2, backendName: "cpu", kernelFunc: y23 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/DepthwiseConv2dNative.mjs
function Z8(S45) {
  let { inputs: b58, backend: l80, attrs: k63 } = S45, { x: s84, filter: o80 } = b58, { strides: h74, pad: I44, dilations: H18, dimRoundingMode: R26 } = k63;
  i26([s84, o80], "depthwiseConv2DNative");
  let m96 = util_exports.computeStrides(s84.shape), w45 = util_exports.computeStrides(o80.shape), n67 = H18;
  n67 == null && (n67 = [1, 1]), util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(h74, n67), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${h74} and dilations '${n67}'`);
  let t67 = backend_util_exports.computeConv2DInfo(s84.shape, o80.shape, h74, n67, I44, R26, true), { filterHeight: W15, filterWidth: D42, dilationHeight: V24, dilationWidth: T40, padInfo: O21 } = t67, $37 = O21.left, E44 = O21.top, p103 = t67.outChannels / t67.inChannels, e36 = new p8(t67.outShape, s84.dtype), M30 = l80.data.get(s84.dataId).values, q25 = l80.data.get(o80.dataId).values, z32 = e36.values;
  for (let i88 = 0; i88 < t67.batchSize; ++i88) {
    let A35 = i88 * m96[0], B30 = i88 * e36.strides[0];
    for (let r56 = 0; r56 < t67.outHeight; ++r56) {
      let F32 = B30 + r56 * e36.strides[1], G30 = r56 * t67.strideHeight - E44;
      for (let a71 = 0; a71 < W15; ++a71) {
        let u86 = G30 + a71 * V24;
        if (u86 < 0 || u86 >= t67.inHeight) continue;
        let L22 = a71 * w45[0], _24 = A35 + u86 * m96[1];
        for (let d55 = 0; d55 < t67.outWidth; ++d55) {
          let j22 = F32 + d55 * e36.strides[2], J17 = d55 * t67.strideWidth - $37;
          for (let f85 = 0; f85 < D42; ++f85) {
            let C28 = J17 + f85 * T40;
            if (C28 < 0 || C28 >= t67.inWidth) continue;
            let K21 = L22 + f85 * w45[1], P36 = _24 + C28 * t67.inChannels, y43 = j22, g72 = K21;
            for (let v42 = 0; v42 < t67.inChannels; ++v42) {
              let Q13 = M30[P36 + v42];
              for (let c103 = 0; c103 < p103; ++c103) z32[y43 + c103] += Q13 * q25[g72 + c103];
              y43 += p103, g72 += p103;
            }
          }
        }
      }
    }
  }
  return l80.makeTensorInfo(e36.shape, e36.dtype, e36.values);
}
var st4 = { kernelName: H2, backendName: "cpu", kernelFunc: Z8 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/DepthwiseConv2dNativeBackpropFilter.mjs
function G15(x76) {
  let { inputs: y43, backend: l80, attrs: g72 } = x76, { x: n67, dy: s84 } = y43, { strides: k63, dilations: w45, pad: B30, dimRoundingMode: I44, filterShape: N58 } = g72;
  i26([n67, s84], "depthwiseConv2dNativeBackpropFilter");
  let t67 = backend_util_exports.computeConv2DInfo(n67.shape, N58, k63, w45, B30, I44, true), { strideHeight: p103, strideWidth: h74, filterHeight: R26, filterWidth: b58 } = t67, i88 = new p8(t67.filterShape, "float32"), f85 = t67.padInfo.left, u86 = t67.padInfo.top, C28 = t67.outChannels / t67.inChannels, F32 = l80.data.get(n67.dataId).values, W15 = new p8(n67.shape, n67.dtype, F32), H18 = l80.data.get(s84.dataId).values, P36 = new p8(s84.shape, s84.dtype, H18);
  for (let e36 = 0; e36 < R26; ++e36) {
    let S45 = Math.max(0, Math.ceil((u86 - e36) / p103)), D42 = Math.min(t67.outHeight, (t67.inHeight + u86 - e36) / p103);
    for (let o80 = 0; o80 < b58; ++o80) {
      let T40 = Math.max(0, Math.ceil((f85 - o80) / h74)), V24 = Math.min(t67.outWidth, (t67.inWidth + f85 - o80) / h74);
      for (let a71 = 0; a71 < t67.outChannels; ++a71) {
        let v42 = Math.trunc(a71 / C28), z32 = a71 % C28, M30 = 0;
        for (let d55 = 0; d55 < t67.batchSize; ++d55) for (let c103 = S45; c103 < D42; ++c103) {
          let _24 = e36 + c103 * p103 - u86;
          for (let r56 = T40; r56 < V24; ++r56) {
            let j22 = o80 + r56 * h74 - f85;
            M30 += W15.get(d55, _24, j22, v42) * P36.get(d55, c103, r56, a71);
          }
        }
        i88.set(M30, e36, o80, v42, z32);
      }
    }
  }
  return l80.makeTensorInfo(i88.shape, i88.dtype, i88.values);
}
var L8 = { kernelName: W2, backendName: "cpu", kernelFunc: G15 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/DepthwiseConv2dNativeBackpropInput.mjs
function ht4(I44) {
  let { inputs: k63, backend: p103, attrs: g72 } = I44, { dy: l80, filter: o80 } = k63, { strides: w45, dilations: N58, pad: R26, dimRoundingMode: b58, inputShape: B30 } = g72;
  i26([l80, o80], "depthwiseConv2DNativeBackpropInput");
  let H18 = util_exports.computeStrides(l80.shape), W15 = util_exports.computeStrides(o80.shape), n67 = backend_util_exports.computeConv2DInfo(B30, o80.shape, w45, N58, R26, b58, true), t67 = new p8(n67.inShape, "float32"), D42 = t67.values, [P36, V24, O21] = t67.strides, T40 = p103.data.get(l80.dataId).values, [z32, F32, _24] = H18, j22 = p103.data.get(o80.dataId).values, [q25, A35, E44] = W15, { batchSize: G30, filterHeight: f85, filterWidth: h74, inChannels: S45, inHeight: J17, inWidth: K21, outChannels: L22, outHeight: Q13, outWidth: U24, strideHeight: u86, strideWidth: x76 } = n67, X20 = f85 - 1 - n67.padInfo.top, Y14 = h74 - 1 - n67.padInfo.left, v42 = L22 / S45;
  for (let s84 = 0; s84 < G30; ++s84) for (let e36 = 0; e36 < S45; ++e36) for (let a71 = 0; a71 < J17; ++a71) {
    let m96 = a71 - X20, Z16 = Math.max(0, Math.ceil(m96 / u86)), $37 = Math.min(Q13, (f85 + m96) / u86);
    for (let d55 = 0; d55 < K21; ++d55) {
      let C28 = d55 - Y14, tt3 = Math.max(0, Math.ceil(C28 / x76)), et5 = Math.min(U24, (h74 + C28) / x76), y43 = 0;
      for (let i88 = Z16; i88 < $37; ++i88) {
        let ot6 = i88 * u86 - m96;
        for (let c103 = tt3; c103 < et5; ++c103) {
          let nt5 = c103 * x76 - C28, st7 = z32 * s84 + F32 * i88 + _24 * c103, at7 = q25 * (f85 - 1 - ot6) + A35 * (h74 - 1 - nt5) + E44 * e36;
          for (let r56 = 0; r56 < v42; ++r56) {
            let dt5 = e36 * v42 + r56, it4 = T40[st7 + dt5], ct4 = j22[at7 + r56];
            y43 += it4 * ct4;
          }
        }
      }
      D42[P36 * s84 + V24 * a71 + O21 * d55 + e36] = y43;
    }
  }
  return p103.makeTensorInfo(t67.shape, t67.dtype, t67.values);
}
var mt4 = { kernelName: K2, backendName: "cpu", kernelFunc: ht4 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Diag.mjs
function f56(c103) {
  let { inputs: u86, backend: o80 } = c103, { x: e36 } = u86, a71 = util_exports.sizeFromShape(e36.shape), s84 = o80.data.get(e36.dataId).values, n67 = i7([a71, a71], e36.dtype), p103 = n67.values;
  for (let t67 = 0; t67 < s84.length; t67++) p103[t67 * a71 + t67] = s84[t67];
  let r56 = [...e36.shape, ...e36.shape];
  return o80.makeTensorInfo(r56, n67.dtype, n67.values);
}
var h43 = { kernelName: X2, backendName: "cpu", kernelFunc: f56 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Dilation2D.mjs
var X12 = { kernelName: Z2, backendName: "cpu", kernelFunc: ({ inputs: m96, backend: x76, attrs: y43 }) => {
  let { x: e36, filter: a71 } = m96, { strides: k63, pad: S45, dilations: D42 } = y43, r56 = x76, H18 = r56.data.get(e36.dataId).values, N58 = e36.shape.length, T40 = r56.data.get(a71.dataId).values, W15 = a71.shape.length, { batchSize: b58, inHeight: w45, inWidth: F32, inChannels: R26, outHeight: V24, outWidth: v42, padInfo: f85, strideHeight: z32, strideWidth: A35, filterHeight: B30, filterWidth: C28, dilationHeight: E44, dilationWidth: _24, outShape: o80 } = backend_util_exports.computeDilation2DInfo(e36.shape, a71.shape, k63, S45, "NHWC", D42), O21 = util_exports.sizeFromShape(o80), G30 = o80.length, I44 = util_exports.getArrayFromDType(e36.dtype, O21);
  for (let i88 = 0; i88 < b58; ++i88) for (let d55 = 0; d55 < V24; ++d55) {
    let M30 = d55 * z32 - f85.top;
    for (let s84 = 0; s84 < v42; ++s84) {
      let j22 = s84 * A35 - f85.left;
      for (let n67 = 0; n67 < R26; ++n67) {
        let p103 = Number.MIN_SAFE_INTEGER;
        for (let l80 = 0; l80 < B30; ++l80) {
          let h74 = M30 + l80 * E44;
          if (h74 >= 0 && h74 < w45) for (let c103 = 0; c103 < C28; ++c103) {
            let u86 = j22 + c103 * _24;
            if (u86 >= 0 && u86 < F32) {
              let J17 = util_exports.locToIndex([i88, h74, u86, n67], N58, util_exports.computeStrides(e36.shape)), K21 = util_exports.locToIndex([l80, c103, n67], W15, util_exports.computeStrides(a71.shape)), g72 = H18[J17] + T40[K21];
              g72 > p103 && (p103 = g72);
            }
          }
        }
        let q25 = util_exports.locToIndex([i88, d55, s84, n67], G30, util_exports.computeStrides(o80));
        I44[q25] = p103;
      }
    }
  }
  return { dataId: r56.write(util_exports.toTypedArray(I44, e36.dtype), o80, e36.dtype), shape: o80, dtype: e36.dtype };
} };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Dilation2DBackpropFilter.mjs
var K10 = { kernelName: j2, backendName: "cpu", kernelFunc: ({ inputs: b58, backend: w45, attrs: A35 }) => {
  let { x: r56, filter: t67, dy: h74 } = b58, { strides: H18, pad: W15, dilations: $37 } = A35, i88 = w45, v42 = util_exports.toNestedArray(r56.shape, i88.data.get(r56.dataId).values), x76 = util_exports.toNestedArray(t67.shape, i88.data.get(t67.dataId).values), { batchSize: B30, inHeight: D42, inWidth: E44, inChannels: F32, outHeight: C28, outWidth: M30, padInfo: f85, strideHeight: S45, strideWidth: T40, filterHeight: _24, filterWidth: O21, dilationHeight: z32, dilationWidth: G30, outShape: p103 } = backend_util_exports.computeDilation2DInfo(r56.shape, t67.shape, H18, W15, "NHWC", $37);
  util_exports.assert(h74.rank === p103.length, () => `Error in ${j2}, dy must have the same rank as output ${p103.length}, but got ${h74.rank}`);
  let R26 = util_exports.toNestedArray(p103, i88.data.get(h74.dataId).values), g72 = util_exports.makeZerosNestedTypedArray(t67.shape, t67.dtype);
  for (let n67 = 0; n67 < B30; ++n67) for (let s84 = 0; s84 < C28; ++s84) {
    let V24 = s84 * S45 - f85.top;
    for (let l80 = 0; l80 < M30; ++l80) {
      let Z16 = l80 * T40 - f85.left;
      for (let e36 = 0; e36 < F32; ++e36) {
        let y43 = Number.MIN_SAFE_INTEGER, k63 = 0, I44 = 0;
        for (let o80 = 0; o80 < _24; ++o80) {
          let c103 = V24 + o80 * z32;
          if (c103 >= 0 && c103 < D42) for (let d55 = 0; d55 < O21; ++d55) {
            let u86 = Z16 + d55 * G30;
            if (u86 >= 0 && u86 < E44) {
              let N58 = v42[n67][c103][u86][e36] + x76[o80][d55][e36];
              N58 > y43 && (y43 = N58, k63 = o80, I44 = d55);
            }
          }
        }
        g72[k63][I44][e36] += R26[n67][s84][l80][e36];
      }
    }
  }
  return { dataId: i88.write(util_exports.toTypedArray(g72, r56.dtype), t67.shape, t67.dtype), shape: t67.shape, dtype: t67.dtype };
} };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Dilation2DBackpropInput.mjs
var K11 = { kernelName: _2, backendName: "cpu", kernelFunc: ({ inputs: A35, backend: H18, attrs: W15 }) => {
  let { x: t67, filter: h74, dy: c103 } = A35, { strides: $37, pad: v42, dilations: x76 } = W15, o80 = H18, B30 = util_exports.toNestedArray(t67.shape, o80.data.get(t67.dataId).values), D42 = util_exports.toNestedArray(h74.shape, o80.data.get(h74.dataId).values), { batchSize: E44, inHeight: C28, inWidth: M30, inChannels: S45, outHeight: T40, outWidth: _24, padInfo: y43, strideHeight: F32, strideWidth: O21, filterHeight: z32, filterWidth: G30, dilationHeight: R26, dilationWidth: V24, outShape: u86 } = backend_util_exports.computeDilation2DInfo(t67.shape, h74.shape, $37, v42, "NHWC", x76);
  util_exports.assert(c103.rank === u86.length, () => `Error in ${_2}, dy must have the same rank as output ${u86.length}, but got ${c103.rank}`);
  let Z16 = util_exports.toNestedArray(u86, o80.data.get(c103.dataId).values), I44 = util_exports.makeZerosNestedTypedArray(t67.shape, t67.dtype);
  for (let n67 = 0; n67 < E44; ++n67) for (let d55 = 0; d55 < T40; ++d55) {
    let f85 = d55 * F32 - y43.top;
    for (let r56 = 0; r56 < _24; ++r56) {
      let g72 = r56 * O21 - y43.left;
      for (let e36 = 0; e36 < S45; ++e36) {
        let k63 = Number.MIN_SAFE_INTEGER, N58 = f85 < 0 ? 0 : f85, m96 = g72 < 0 ? 0 : g72;
        for (let i88 = 0; i88 < z32; ++i88) {
          let s84 = f85 + i88 * R26;
          if (s84 >= 0 && s84 < C28) for (let l80 = 0; l80 < G30; ++l80) {
            let p103 = g72 + l80 * V24;
            if (p103 >= 0 && p103 < M30) {
              let b58 = B30[n67][s84][p103][e36] + D42[i88][l80][e36];
              b58 > k63 && (k63 = b58, N58 = s84, m96 = p103);
            }
          }
        }
        I44[n67][N58][m96][e36] += Z16[n67][d55][r56][e36];
      }
    }
  }
  return { dataId: o80.write(util_exports.toTypedArray(I44, t67.dtype), t67.shape, t67.dtype), shape: t67.shape, dtype: t67.dtype };
} };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Draw.mjs
function D16(g72) {
  let { inputs: m96, backend: b58, attrs: v42 } = g72, { image: e36 } = m96, { canvas: u86, options: x76 } = v42, { contextOptions: o80, imageOptions: p103 } = x76 || {}, y43 = p103?.alpha || 1, h74 = o80?.contextType || "2d";
  if (h74 !== "2d") throw new Error(`Context type ${o80.contextType} is not supported by the CPU backend.`);
  let w45 = u86.getContext(h74, o80?.contextAttributes || {});
  if (w45 == null) throw new Error(`Could not get the context with ${h74} type.`);
  let [r56, s84] = e36.shape.slice(0, 2), f85 = e36.shape.length === 2 ? 1 : e36.shape[2], T40 = b58.data.get(e36.dataId).values, i88 = e36.dtype === "float32" ? 255 : 1, a71 = new Uint8ClampedArray(s84 * r56 * 4);
  for (let c103 = 0; c103 < r56 * s84; ++c103) {
    let n67 = [0, 0, 0, 255 * y43];
    for (let l80 = 0; l80 < f85; l80++) {
      let t67 = T40[c103 * f85 + l80];
      if (e36.dtype === "float32") {
        if (t67 < 0 || t67 > 1) throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${t67}.`);
      } else if (e36.dtype === "int32" && (t67 < 0 || t67 > 255)) throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${t67}.`);
      f85 === 1 ? (n67[0] = t67 * i88, n67[1] = t67 * i88, n67[2] = t67 * i88) : n67[l80] = t67 * i88;
    }
    let d55 = c103 * 4;
    a71[d55 + 0] = Math.round(n67[0]), a71[d55 + 1] = Math.round(n67[1]), a71[d55 + 2] = Math.round(n67[2]), a71[d55 + 3] = Math.round(n67[3]);
  }
  u86.width = s84, u86.height = r56;
  let C28 = new ImageData(a71, s84, r56);
  return w45.putImageData(C28, 0, 0), e36;
}
var M17 = { kernelName: J2, backendName: "cpu", kernelFunc: D16 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Sum.mjs
function P14(I44) {
  let { inputs: g72, backend: e36, attrs: S45 } = I44, { x: r56 } = g72, { axis: k63, keepDims: A35 } = S45;
  i26(r56, "sum");
  let t67;
  r56.dtype === "bool" ? t67 = u48({ inputs: { x: r56 }, backend: e36, attrs: { dtype: "int32" } }) : t67 = i28({ inputs: { x: r56 }, backend: e36 });
  let c103 = t67.shape.length, i88 = util_exports.parseAxisParam(k63, t67.shape), m96 = backend_util_exports.getAxesPermutation(i88, c103), p103 = i88, s84 = t67;
  m96 != null && (s84 = h38({ inputs: { x: t67 }, backend: e36, attrs: { perm: m96 } }), p103 = backend_util_exports.getInnerMostAxes(p103.length, c103)), backend_util_exports.assertAxesAreInnerMostDims("sum", p103, s84.shape.length);
  let [y43, T40] = backend_util_exports.computeOutAndReduceShapes(s84.shape, p103), b58 = backend_util_exports.upcastType(s84.dtype, "int32"), o80 = f47(e36, y43, b58), d55 = util_exports.sizeFromShape(T40), f85 = e36.data.get(o80.dataId).values, D42 = e36.data.get(s84.dataId).values;
  for (let n67 = 0; n67 < f85.length; ++n67) {
    let u86 = n67 * d55, h74 = 0;
    for (let l80 = 0; l80 < d55; ++l80) h74 += D42[u86 + l80];
    f85[n67] = h74;
  }
  if (A35) {
    let n67 = backend_util_exports.expandShapeToKeepDim(o80.shape, i88), u86 = o80;
    o80 = f52({ inputs: { x: o80 }, backend: e36, attrs: { shape: n67 } }), e36.disposeIntermediateTensorInfo(u86);
  }
  return e36.disposeIntermediateTensorInfo(t67), m96 != null && e36.disposeIntermediateTensorInfo(s84), o80;
}
var $27 = { kernelName: bt, backendName: "cpu", kernelFunc: P14 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Einsum.mjs
function N29(x76) {
  let { inputs: D42, backend: n67, attrs: E44 } = x76, { equation: I44 } = E44, m96 = D42, { allDims: r56, summedDims: b58, idDims: u86 } = backend_util_exports.decodeEinsumEquation(I44, m96.length);
  backend_util_exports.checkEinsumDimSizes(r56.length, u86, m96);
  let { path: f85, steps: h74 } = backend_util_exports.getEinsumComputePath(b58, u86), d55 = h74.length, t67 = null, p103 = r56.length, i88 = [];
  for (let s84 = 0; s84 < d55; ++s84) {
    for (let a71 of h74[s84]) {
      let { permutationIndices: g72, expandDims: k63 } = backend_util_exports.getEinsumPermutation(p103, u86[a71]), e36;
      backend_util_exports.isIdentityPermutation(g72) ? e36 = m96[a71] : (e36 = h38({ inputs: { x: m96[a71] }, backend: n67, attrs: { perm: g72 } }), i88.push(e36));
      let l80 = e36.shape.slice();
      for (let c103 = 0; c103 < k63.length; ++c103) l80.splice(k63[c103], 0, 1);
      util_exports.arraysEqual(e36.shape, l80) || (e36 = f52({ inputs: { x: e36 }, backend: n67, attrs: { shape: l80 } }), i88.push(e36)), t67 === null ? t67 = e36 : (t67 = u52({ inputs: { a: e36, b: t67 }, backend: n67 }), i88.push(t67));
    }
    s84 < d55 - 1 && (f85[s84] >= 0 && (t67 = P14({ inputs: { x: t67 }, backend: n67, attrs: { axis: f85[s84] - (r56.length - p103), keepDims: false } }), i88.push(t67)), p103--);
  }
  for (let s84 of i88) s84 !== t67 && n67.disposeIntermediateTensorInfo(s84);
  return t67;
}
var v28 = { kernelName: Y2, backendName: "cpu", kernelFunc: N29 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/EluGrad.mjs
function m56(u86) {
  let { inputs: d55, backend: t67 } = u86, { dy: n67, y: a71 } = d55;
  i26([n67, a71], "eluGrad");
  let o80 = new Float32Array(util_exports.sizeFromShape(a71.shape)), r56 = t67.data.get(a71.dataId).values, s84 = t67.data.get(n67.dataId).values;
  for (let e36 = 0; e36 < r56.length; ++e36) {
    let l80 = r56[e36];
    l80 >= 0 ? o80[e36] = s84[e36] : o80[e36] = s84[e36] * (l80 + 1);
  }
  return t67.makeTensorInfo(a71.shape, "float32", o80);
}
var g40 = { kernelName: oo, backendName: "cpu", kernelFunc: m56 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Erf.mjs
var s40 = backend_util_exports.ERF_P;
var F13 = backend_util_exports.ERF_A1;
var p55 = backend_util_exports.ERF_A2;
var E29 = backend_util_exports.ERF_A3;
var _15 = backend_util_exports.ERF_A4;
var f57 = backend_util_exports.ERF_A5;
var m57 = A15(to, (c103) => {
  let r56 = Math.sign(c103), o80 = Math.abs(c103), t67 = 1 / (1 + s40 * o80);
  return r56 * (1 - ((((f57 * t67 + _15) * t67 + E29) * t67 + p55) * t67 + F13) * t67 * Math.exp(-o80 * o80));
});
var i40 = { kernelName: to, backendName: "cpu", kernelFunc: m57 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ExpandDims.mjs
function l43(p103) {
  let { inputs: a71, backend: r56, attrs: o80 } = p103, { input: t67 } = a71, { dim: e36 } = o80, n67 = t67.shape.length, s84 = t67.shape.slice(), i88 = e36;
  return e36 < 0 && (util_exports.assert(-(n67 + 1) <= e36, () => `Axis must be in the interval [${-(n67 + 1)}, ${n67}]`), i88 = n67 + e36 + 1), s84.splice(i88, 0, 1), f52({ inputs: { x: t67 }, backend: r56, attrs: { shape: s84 } });
}
var x47 = { kernelName: no, backendName: "cpu", kernelFunc: l43 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/RealDiv.mjs
var m58 = z14((r56, n67) => r56 / n67);
var l44 = G14(Q2, m58);
var c58 = { kernelName: Q2, backendName: "cpu", kernelFunc: l44 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/utils/fft_utils.mjs
function Ao2(n67, s84, e36) {
  let i88 = n67.shape, o80 = i88[0], t67 = i88[1], I44 = e36.data.get(n67.dataId), a71 = I44.complexTensorInfos.real, r56 = I44.complexTensorInfos.imag, m96 = [o80, t67], g72 = util_exports.sizeFromShape(m96), d55 = util_exports.getTypedArrayFromDType("float32", g72), T40 = util_exports.getTypedArrayFromDType("float32", g72);
  for (let l80 = 0; l80 < o80; l80++) {
    let $37 = I18({ inputs: { x: a71 }, backend: e36, attrs: { begin: [l80, 0], size: [1, t67] } }), R26 = I18({ inputs: { x: r56 }, backend: e36, attrs: { begin: [l80, 0], size: [1, t67] } }), y43 = r14({ inputs: { real: $37, imag: R26 }, backend: e36 }), { real: F32, imag: A35 } = lo2(y43, s84, e36), C28 = backend_util_exports.mergeRealAndImagArrays(F32, A35);
    for (let h74 = 0; h74 < t67; h74++) {
      let V24 = backend_util_exports.getComplexWithIndex(C28, h74);
      d55[l80 * t67 + h74] = V24.real, T40[l80 * t67 + h74] = V24.imag;
    }
    e36.disposeIntermediateTensorInfo($37), e36.disposeIntermediateTensorInfo(R26), e36.disposeIntermediateTensorInfo(y43);
  }
  let b58 = e36.makeTensorInfo(m96, "float32", d55), p103 = e36.makeTensorInfo(m96, "float32", T40), x76 = r14({ inputs: { real: b58, imag: p103 }, backend: e36 });
  return e36.disposeIntermediateTensorInfo(b58), e36.disposeIntermediateTensorInfo(p103), x76;
}
function lo2(n67, s84, e36) {
  let i88 = util_exports.sizeFromShape(n67.shape), o80 = e36.data.get(n67.dataId), t67 = e36.data.get(o80.complexTensorInfos.real.dataId).values, I44 = e36.data.get(o80.complexTensorInfos.imag.dataId).values;
  if (fo2(i88)) {
    let a71 = E30(t67, I44, i88, s84, e36), r56 = [n67.shape[0], n67.shape[1]];
    if (s84) {
      let m96 = e36.makeTensorInfo(r56, "float32", a71.real), g72 = e36.makeTensorInfo(r56, "float32", a71.imag), d55 = e36.makeTensorInfo([], "float32", util_exports.createScalarValue(i88, "float32")), T40 = i28({ inputs: { x: d55 }, backend: e36 }), b58 = c58.kernelFunc({ inputs: { a: m96, b: d55 }, backend: e36 }), p103 = c58.kernelFunc({ inputs: { a: g72, b: T40 }, backend: e36 }), x76 = e36.data.get(b58.dataId).values, l80 = e36.data.get(p103.dataId).values;
      return e36.disposeIntermediateTensorInfo(m96), e36.disposeIntermediateTensorInfo(g72), e36.disposeIntermediateTensorInfo(d55), e36.disposeIntermediateTensorInfo(T40), e36.disposeIntermediateTensorInfo(b58), e36.disposeIntermediateTensorInfo(p103), { real: x76, imag: l80 };
    }
    return a71;
  } else {
    let a71 = backend_util_exports.mergeRealAndImagArrays(t67, I44), r56 = go3(a71, i88, s84);
    return backend_util_exports.splitRealAndImagArrays(r56);
  }
}
function fo2(n67) {
  return (n67 & n67 - 1) === 0;
}
function E30(n67, s84, e36, i88, o80) {
  if (e36 === 1) return { real: n67, imag: s84 };
  let t67 = backend_util_exports.mergeRealAndImagArrays(n67, s84), I44 = e36 / 2, a71 = backend_util_exports.complexWithEvenIndex(t67), r56 = a71.real, m96 = a71.imag, g72 = [r56.length], d55 = o80.makeTensorInfo(g72, "float32", r56), T40 = o80.makeTensorInfo(g72, "float32", m96), b58 = r14({ inputs: { real: d55, imag: T40 }, backend: o80 }), p103 = backend_util_exports.complexWithOddIndex(t67), x76 = p103.real, l80 = p103.imag, $37 = [x76.length], R26 = o80.makeTensorInfo($37, "float32", x76), y43 = o80.makeTensorInfo($37, "float32", l80), F32 = r14({ inputs: { real: R26, imag: y43 }, backend: o80 }), A35 = E30(r56, m96, I44, i88, o80), C28 = A35.real, h74 = A35.imag, V24 = [C28.length], M30 = o80.makeTensorInfo(V24, "float32", C28), _24 = o80.makeTensorInfo(V24, "float32", h74), D42 = r14({ inputs: { real: M30, imag: _24 }, backend: o80 }), j22 = E30(x76, l80, I44, i88, o80), q25 = j22.real, no3 = j22.imag, z32 = [q25.length], G30 = o80.makeTensorInfo(z32, "float32", q25), H18 = o80.makeTensorInfo(z32, "float32", no3), J17 = r14({ inputs: { real: G30, imag: H18 }, backend: o80 }), P36 = backend_util_exports.exponents(e36, i88), K21 = [P36.real.length], L22 = o80.makeTensorInfo(K21, "float32", P36.real), N58 = o80.makeTensorInfo(K21, "float32", P36.imag), Q13 = r14({ inputs: { real: L22, imag: N58 }, backend: o80 }), W15 = u52({ inputs: { a: Q13, b: J17 }, backend: o80 }), O21 = c48({ inputs: { a: D42, b: W15 }, backend: o80 }), w45 = i38({ inputs: { a: D42, b: W15 }, backend: o80 }), U24 = l34({ inputs: { input: O21 }, backend: o80 }), X20 = l34({ inputs: { input: w45 }, backend: o80 }), Y14 = s39({ inputs: { input: O21 }, backend: o80 }), Z16 = s39({ inputs: { input: w45 }, backend: o80 }), u86 = h41({ inputs: [U24, X20], backend: o80, attrs: { axis: 0 } }), c103 = h41({ inputs: [Y14, Z16], backend: o80, attrs: { axis: 0 } }), so3 = o80.data.get(u86.dataId).values, ao3 = o80.data.get(c103.dataId).values;
  return o80.disposeIntermediateTensorInfo(d55), o80.disposeIntermediateTensorInfo(T40), o80.disposeIntermediateTensorInfo(b58), o80.disposeIntermediateTensorInfo(R26), o80.disposeIntermediateTensorInfo(y43), o80.disposeIntermediateTensorInfo(F32), o80.disposeIntermediateTensorInfo(M30), o80.disposeIntermediateTensorInfo(_24), o80.disposeIntermediateTensorInfo(D42), o80.disposeIntermediateTensorInfo(G30), o80.disposeIntermediateTensorInfo(H18), o80.disposeIntermediateTensorInfo(J17), o80.disposeIntermediateTensorInfo(L22), o80.disposeIntermediateTensorInfo(N58), o80.disposeIntermediateTensorInfo(Q13), o80.disposeIntermediateTensorInfo(W15), o80.disposeIntermediateTensorInfo(O21), o80.disposeIntermediateTensorInfo(w45), o80.disposeIntermediateTensorInfo(U24), o80.disposeIntermediateTensorInfo(Y14), o80.disposeIntermediateTensorInfo(X20), o80.disposeIntermediateTensorInfo(Z16), o80.disposeIntermediateTensorInfo(u86), o80.disposeIntermediateTensorInfo(c103), { real: so3, imag: ao3 };
}
function go3(n67, s84, e36) {
  let i88 = new Float32Array(s84 * 2);
  for (let o80 = 0; o80 < s84; o80++) {
    let t67 = 0, I44 = 0;
    for (let a71 = 0; a71 < s84; a71++) {
      let r56 = backend_util_exports.exponent(o80 * a71, s84, e36), m96 = backend_util_exports.getComplexWithIndex(n67, a71);
      t67 += m96.real * r56.real - m96.imag * r56.imag, I44 += m96.real * r56.imag + m96.imag * r56.real;
    }
    e36 && (t67 /= s84, I44 /= s84), backend_util_exports.assignToTypedArray(i88, t67, I44, o80);
  }
  return i88;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/FFT.mjs
function d24(r56) {
  let { inputs: i88, backend: e36 } = r56, { input: t67 } = i88, a71 = util_exports.sizeFromShape(t67.shape), n67 = t67.shape[t67.shape.length - 1], c103 = a71 / n67, s84 = f52({ inputs: { x: t67 }, backend: e36, attrs: { shape: [c103, n67] } }), o80 = Ao2(s84, false, e36), f85 = f52({ inputs: { x: o80 }, backend: e36, attrs: { shape: t67.shape } });
  return e36.disposeIntermediateTensorInfo(s84), e36.disposeIntermediateTensorInfo(o80), f85;
}
var F14 = { kernelName: po, backendName: "cpu", kernelFunc: d24 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Fill.mjs
function a41(e36) {
  let { backend: n67, attrs: t67 } = e36, { shape: r56, value: i88, dtype: s84 } = t67, l80 = s84 || util_exports.inferDtype(i88), f85 = util_exports.getArrayFromDType(l80, util_exports.sizeFromShape(r56));
  return p56(f85, i88, l80), n67.makeTensorInfo(r56, l80, f85);
}
var u57 = { kernelName: co, backendName: "cpu", kernelFunc: a41 };
function p56(e36, n67, t67) {
  e36.fill(n67);
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/FlipLeftRight.mjs
var N30 = { kernelName: ao, backendName: "cpu", kernelFunc: ({ inputs: y43, attrs: w45, backend: I44 }) => {
  let { image: t67 } = y43, d55 = I44, p103 = util_exports.getTypedArrayFromDType(t67.dtype, util_exports.sizeFromShape(t67.shape)), [b58, f85, e36, o80] = t67.shape, l80 = d55.data.get(t67.dataId).values;
  for (let n67 = 0; n67 < b58; n67++) {
    let i88 = n67 * e36 * f85 * o80;
    for (let c103 = 0; c103 < f85; c103++) {
      let h74 = c103 * (e36 * o80);
      for (let a71 = 0; a71 < e36; a71++) {
        let k63 = a71 * o80;
        for (let s84 = 0; s84 < o80; s84++) {
          let r56 = Math.round(e36 - a71 - 1), u86 = i88 + h74 + k63 + s84, m96 = l80[u86];
          if (r56 >= 0 && r56 < e36) {
            let x76 = r56 * o80, F32 = i88 + h74 + x76 + s84;
            m96 = l80[F32];
          }
          p103[u86] = m96;
        }
      }
    }
  }
  return { dataId: d55.write(p103, t67.shape, t67.dtype), shape: t67.shape, dtype: t67.dtype };
} };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/FusedConv2D.mjs
function A20(f85) {
  let { inputs: m96, backend: e36, attrs: c103 } = f85, { x: h74, filter: I44, bias: s84, preluActivationWeights: n67 } = m96, { strides: v42, pad: C28, dataFormat: i88, dilations: b58, dimRoundingMode: g72, activation: a71, leakyreluAlpha: p103 } = c103, t67 = at4({ inputs: { x: h74, filter: I44 }, backend: e36, attrs: { strides: v42, pad: C28, dataFormat: i88, dilations: b58, dimRoundingMode: g72 } });
  if (s84) {
    let r56 = t67;
    if (i88 === "NCHW" && s84.shape.length === 1 && s84.shape[0] !== 1) {
      let o80 = f52({ inputs: { x: s84 }, backend: e36, attrs: { shape: [s84.shape[0], 1, 1] } });
      t67 = c48({ inputs: { a: t67, b: o80 }, backend: e36 }), e36.disposeIntermediateTensorInfo(o80);
    } else t67 = c48({ inputs: { a: t67, b: s84 }, backend: e36 });
    e36.disposeIntermediateTensorInfo(r56);
  }
  if (a71) {
    let r56 = t67;
    if (i88 === "NCHW" && a71 === "prelu" && n67.shape.length === 1 && n67.shape[0] !== 1) {
      let o80 = f52({ inputs: { x: n67 }, backend: e36, attrs: { shape: [n67.shape[0], 1, 1] } });
      t67 = P11(e36, t67, a71, o80, p103), e36.disposeIntermediateTensorInfo(o80);
    } else t67 = P11(e36, t67, a71, n67, p103);
    e36.disposeIntermediateTensorInfo(r56);
  }
  return t67;
}
var y24 = { kernelName: me, backendName: "cpu", kernelFunc: A20 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/FusedDepthwiseConv2D.mjs
function w24(s84) {
  let { inputs: r56, backend: e36, attrs: a71 } = s84, { x: d55, filter: p103, bias: i88, preluActivationWeights: u86 } = r56, { strides: l80, pad: c103, dataFormat: m96, dilations: f85, dimRoundingMode: v42, activation: n67, leakyreluAlpha: h74 } = a71, t67 = Z8({ inputs: { x: d55, filter: p103 }, backend: e36, attrs: { strides: l80, pad: c103, dataFormat: m96, dilations: f85, dimRoundingMode: v42 } });
  if (i88) {
    let o80 = t67;
    t67 = c48({ inputs: { a: t67, b: i88 }, backend: e36 }), e36.disposeIntermediateTensorInfo(o80);
  }
  if (n67) {
    let o80 = t67;
    t67 = P11(e36, t67, n67, u86, h74), e36.disposeIntermediateTensorInfo(o80);
  }
  return t67;
}
var F15 = { kernelName: Re, backendName: "cpu", kernelFunc: w24 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/GatherNd.mjs
function N31(o80) {
  let { inputs: c103, backend: t67 } = o80, { params: e36, indices: a71 } = c103, i88 = util_exports.sizeFromShape(e36.shape), n67 = a71.shape, p103 = n67[n67.length - 1], [s84, r56, d55, u86] = backend_util_exports.prepareAndValidate(e36, a71);
  if (r56 === 0) return t67.makeTensorInfo(s84, e36.dtype, []);
  let m96 = t67.data.get(a71.dataId).values, l80 = t67.bufferSync(e36), f85 = w23(m96, l80, e36.dtype, r56, p103, d55, u86, e36.shape, i88);
  return t67.makeTensorInfo(s84, e36.dtype, f85.values);
}
var I21 = { kernelName: So, backendName: "cpu", kernelFunc: N31 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/GatherV2.mjs
function G16(x76) {
  let { inputs: b58, backend: t67, attrs: z32 } = x76, { x: s84, indices: n67 } = b58, { axis: I44, batchDims: r56 } = z32;
  i26([s84, n67], "gatherV2");
  let c103 = util_exports.parseAxisParam(I44, s84.shape)[0], p103 = t67.data.get(n67.dataId).values, h74 = s84.shape[c103];
  for (let a71 = 0; a71 < p103.length; ++a71) {
    let i88 = p103[a71];
    util_exports.assert(i88 <= h74 - 1 && i88 >= 0, () => `GatherV2: the index value ${i88} is not in [0, ${h74 - 1}]`);
  }
  let u86 = r56;
  r56 == null && (u86 = 0);
  let f85 = util_exports.sizeFromShape(n67.shape), e36 = backend_util_exports.segment_util.collectGatherOpShapeInfo(s84, n67, c103, u86), l80 = f52({ inputs: { x: s84 }, backend: t67, attrs: { shape: [e36.batchSize, e36.outerSize, e36.dimSize, e36.sliceSize] } }), m96 = f52({ inputs: { x: n67 }, backend: t67, attrs: { shape: [e36.batchSize, f85 / e36.batchSize] } }), g72 = [e36.batchSize, e36.outerSize, f85 / e36.batchSize, e36.sliceSize], V24 = t67.bufferSync(m96), k63 = t67.bufferSync(l80), d55 = x41(k63, V24, g72);
  return t67.disposeIntermediateTensorInfo(l80), t67.disposeIntermediateTensorInfo(m96), t67.makeTensorInfo(e36.outputShape, d55.dtype, d55.values);
}
var C11 = { kernelName: uo, backendName: "cpu", kernelFunc: G16 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/IFFT.mjs
function d25(r56) {
  let { inputs: p103, backend: e36 } = r56, { input: t67 } = p103, a71 = util_exports.sizeFromShape(t67.shape), n67 = t67.shape[t67.shape.length - 1], c103 = a71 / n67, s84 = f52({ inputs: { x: t67 }, backend: e36, attrs: { shape: [c103, n67] } }), o80 = Ao2(s84, true, e36), u86 = f52({ inputs: { x: o80 }, backend: e36, attrs: { shape: t67.shape } });
  return e36.disposeIntermediateTensorInfo(s84), e36.disposeIntermediateTensorInfo(o80), u86;
}
var x48 = { kernelName: Ro, backendName: "cpu", kernelFunc: d25 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/IsFinite.mjs
var o34 = A15(Mo, (i88) => Number.isFinite(i88) ? 1 : 0, "bool");
var m59 = { kernelName: Mo, backendName: "cpu", kernelFunc: o34 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/IsInf.mjs
var r18 = A15(Ao, (e36) => Math.abs(e36) === 1 / 0 ? 1 : 0, "bool");
var i41 = { kernelName: Ao, backendName: "cpu", kernelFunc: r18 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/IsNaN.mjs
var r19 = A15(Bo, (n67) => Number.isNaN(n67) ? 1 : 0, "bool");
var m60 = { kernelName: Bo, backendName: "cpu", kernelFunc: r19 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/LinSpace.mjs
function m61(e36) {
  let { backend: t67, attrs: o80 } = e36, { start: a71, stop: c103, num: r56 } = o80, n67 = a31(a71, c103, r56);
  return t67.makeTensorInfo([n67.length], "float32", n67);
}
var f58 = { kernelName: Fo, backendName: "cpu", kernelFunc: m61 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Log1p.mjs
var r20 = A15(To, (e36) => Math.log1p(e36));
var c59 = { kernelName: To, backendName: "cpu", kernelFunc: r20 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/LogicalAnd.mjs
var c60 = z14((n67, e36) => n67 && e36);
var i42 = G14(Lo, c60, null, "bool");
var t20 = { kernelName: Lo, backendName: "cpu", kernelFunc: i42 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/LogicalNot.mjs
var r21 = A15(ko, (e36) => e36 ? 0 : 1, "bool");
var t21 = { kernelName: ko, backendName: "cpu", kernelFunc: r21 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/LogicalOr.mjs
var c61 = z14((o80, e36) => o80 || e36);
var i43 = G14(Go, c61, null, "bool");
var t22 = { kernelName: Go, backendName: "cpu", kernelFunc: i43 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/LRN.mjs
function F16(i88) {
  let { inputs: h74, backend: a71, attrs: f85 } = i88, { x: e36 } = h74, { depthRadius: o80, bias: d55, alpha: x76, beta: N58 } = f85;
  i26(e36, "LRN");
  let r56 = e36.shape[3], b58 = r56 - 1, c103 = a71.data.get(e36.dataId).values, u86 = util_exports.sizeFromShape(e36.shape), l80 = new Float32Array(u86);
  function k63(t67) {
    let n67 = t67 % r56, s84 = t67 - n67 + Math.max(0, n67 - o80), R26 = t67 - n67 + Math.min(n67 + o80, b58), m96 = 0;
    for (; s84 <= R26; s84++) {
      let p103 = c103[s84];
      m96 += p103 * p103;
    }
    return m96;
  }
  for (let t67 = 0; t67 < u86; t67++) {
    let n67 = k63(t67), s84 = c103[t67] * Math.pow(d55 + x76 * n67, -N58);
    l80[t67] = s84;
  }
  return a71.makeTensorInfo(e36.shape, e36.dtype, l80);
}
var S22 = { kernelName: qo, backendName: "cpu", kernelFunc: F16 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/LRNGrad.mjs
function z21(k63) {
  let { inputs: N58, backend: o80, attrs: x76 } = k63, { x: d55, y: g72, dy: a71 } = N58, { depthRadius: c103, bias: R26, alpha: l80, beta: p103 } = x76;
  i26(a71, "LRNGrad");
  let i88 = util_exports.sizeFromShape(a71.shape), u86 = a71.shape[3], b58 = o80.data.get(a71.dataId).values, h74 = o80.data.get(d55.dataId).values, G30 = o80.data.get(g72.dataId).values, m96 = new Float32Array(i88), I44 = i88;
  for (let e36 = 0; e36 < I44; e36++) {
    let s84 = e36 % u86, f85 = e36 - s84 + Math.max(0, s84 - c103), y43 = e36 - s84 + Math.min(u86, s84 + c103 + 1), n67 = 0;
    for (let t67 = f85; t67 < y43; t67++) n67 += Math.pow(h74[t67], 2);
    n67 = l80 * n67 + R26;
    for (let t67 = f85; t67 < y43; t67++) {
      let r56 = -2 * l80 * p103 * h74[t67] * G30[e36] / n67;
      e36 === t67 && (r56 += Math.pow(n67, -p103)), r56 *= b58[e36], m96[t67] += r56;
    }
  }
  return o80.makeTensorInfo(a71.shape, d55.dtype, m96);
}
var L9 = { kernelName: wo, backendName: "cpu", kernelFunc: z21 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Max.mjs
function z22(l80) {
  let { inputs: h74, backend: f85, attrs: S45 } = l80, { x: e36 } = h74, { reductionIndices: A35, keepDims: g72 } = S45, i88 = f85, t67 = e36.shape, s84 = t67.length, d55 = util_exports.parseAxisParam(A35, t67), a71 = d55, m96 = backend_util_exports.getAxesPermutation(a71, s84), c103 = i88.data.get(e36.dataId).values;
  if (m96 != null) {
    let n67 = new Array(s84);
    for (let p103 = 0; p103 < n67.length; p103++) n67[p103] = t67[m96[p103]];
    c103 = S20(c103, t67, e36.dtype, m96, n67), a71 = backend_util_exports.getInnerMostAxes(a71.length, s84), t67 = n67;
  }
  i26(e36, "max"), backend_util_exports.assertAxesAreInnerMostDims("max", a71, s84);
  let [r56, k63] = backend_util_exports.computeOutAndReduceShapes(t67, a71), I44 = util_exports.sizeFromShape(k63), y43 = u51(c103, I44, r56, e36.dtype), w45 = i88.write(y43, r56, e36.dtype), x76 = r56;
  return g72 && (x76 = backend_util_exports.expandShapeToKeepDim(r56, d55)), { dataId: w45, shape: x76, dtype: e36.dtype };
}
var B15 = { kernelName: yo, backendName: "cpu", kernelFunc: z22 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/MaxPool.mjs
function g41(l80) {
  let { inputs: d55, backend: o80, attrs: p103 } = l80, { x: t67 } = d55;
  i26(t67, "maxPool");
  let { filterSize: m96, strides: s84, pad: u86, dimRoundingMode: c103 } = p103, i88 = 1;
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(s84, i88), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${s84} and dilations '${i88}'`);
  let e36 = backend_util_exports.computePool2DInfo(t67.shape, m96, s84, i88, u86, c103), r56;
  if (e36.filterWidth === 1 && e36.filterHeight === 1 && util_exports.arraysEqual(e36.inShape, e36.outShape)) r56 = i28({ inputs: { x: t67 }, backend: o80 });
  else {
    let f85 = o80.data.get(t67.dataId).values, x76 = util_exports.computeStrides(t67.shape), h74 = st3(f85, t67.shape, t67.dtype, x76, e36, "max");
    r56 = o80.makeTensorInfo(e36.outShape, t67.dtype, h74.values);
  }
  return r56;
}
var N32 = { kernelName: zo, backendName: "cpu", kernelFunc: g41 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/MaxPool3D.mjs
function h44(a71) {
  let { inputs: n67, backend: t67, attrs: s84 } = a71, { x: o80 } = n67, { filterSize: r56, strides: m96, pad: p103, dimRoundingMode: c103, dataFormat: d55 } = s84;
  i26(o80, "maxPool3d");
  let l80 = backend_util_exports.computePool3DInfo(o80.shape, r56, m96, 1, p103, c103, d55), u86 = t67.data.get(o80.dataId).values, e36 = at3(u86, o80.shape, o80.dtype, util_exports.computeStrides(o80.shape), l80, "max");
  return t67.makeTensorInfo(e36.shape, "float32", e36.values);
}
var g42 = { kernelName: Oo, backendName: "cpu", kernelFunc: h44 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/MaxPool3DGrad.mjs
function Y6(C28) {
  let { inputs: b58, backend: D42, attrs: v42 } = C28, { dy: g72, input: c103 } = b58, { filterSize: F32, strides: H18, pad: W15, dimRoundingMode: k63 } = v42;
  i26([g72, c103], "maxPool3DGrad");
  let t67 = backend_util_exports.computePool3DInfo(c103.shape, F32, H18, 1, W15, k63), w45 = D42.bufferSync(c103), I44 = lt4(w45, t67), M30 = t67.strideDepth, R26 = t67.strideHeight, G30 = t67.strideWidth, S45 = t67.dilationDepth, B30 = t67.dilationHeight, N58 = t67.dilationWidth, x76 = t67.effectiveFilterDepth, d55 = t67.effectiveFilterHeight, i88 = t67.effectiveFilterWidth, z32 = x76 - 1 - t67.padInfo.front, T40 = i88 - 1 - t67.padInfo.left, L22 = d55 - 1 - t67.padInfo.top, f85 = i7(c103.shape, "float32"), _24 = D42.bufferSync(g72);
  for (let r56 = 0; r56 < t67.batchSize; ++r56) for (let s84 = 0; s84 < t67.inChannels; ++s84) for (let a71 = 0; a71 < t67.inDepth; ++a71) for (let l80 = 0; l80 < t67.inHeight; ++l80) for (let h74 = 0; h74 < t67.inWidth; ++h74) {
    let j22 = a71 - z32, q25 = l80 - L22, A35 = h74 - T40, y43 = 0;
    for (let p103 = 0; p103 < x76; p103 += S45) {
      let o80 = (j22 + p103) / M30;
      if (!(o80 < 0 || o80 >= t67.outDepth || Math.floor(o80) !== o80)) for (let u86 = 0; u86 < d55; u86 += B30) {
        let e36 = (q25 + u86) / R26;
        if (!(e36 < 0 || e36 >= t67.outHeight || Math.floor(e36) !== e36)) for (let m96 = 0; m96 < i88; m96 += N58) {
          let n67 = (A35 + m96) / G30;
          if (n67 < 0 || n67 >= t67.outWidth || Math.floor(n67) !== n67) continue;
          let E44 = x76 * d55 * i88 - 1 - I44.get(r56, o80, e36, n67, s84), J17 = p103 * d55 * i88 + u86 * i88 + m96, P36 = E44 === J17 ? 1 : 0;
          if (P36 === 0) continue;
          let K21 = _24.get(r56, o80, e36, n67, s84);
          y43 += K21 * P36;
        }
      }
    }
    f85.set(y43, r56, a71, l80, h74, s84);
  }
  return D42.makeTensorInfo(f85.shape, f85.dtype, f85.values);
}
var ot4 = { kernelName: Ho, backendName: "cpu", kernelFunc: Y6 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/MaxPoolGrad.mjs
function K12(y43) {
  let { inputs: v42, backend: p103, attrs: C28 } = y43, { dy: m96, input: x76, output: H18 } = v42, o80 = x76;
  i26([x76, H18], "maxPoolGrad");
  let { filterSize: W15, strides: k63, pad: I44, dimRoundingMode: b58 } = C28, t67 = backend_util_exports.computePool2DInfo(o80.shape, W15, k63, 1, I44, b58), F32 = p103.data.get(o80.dataId).values, R26 = i7(t67.outShape, o80.dtype, ht3(F32, o80.shape, o80.dtype, t67).values), G30 = t67.strideHeight, M30 = t67.strideWidth, N58 = t67.dilationHeight, S45 = t67.dilationWidth, h74 = t67.effectiveFilterHeight, s84 = t67.effectiveFilterWidth, w45 = s84 - 1 - t67.padInfo.left, z32 = h74 - 1 - t67.padInfo.top, d55 = i7(o80.shape, "float32"), B30 = p103.data.get(m96.dataId).values, D42 = i7(m96.shape, "float32", B30);
  for (let i88 = 0; i88 < t67.batchSize; ++i88) for (let a71 = 0; a71 < t67.inChannels; ++a71) for (let c103 = 0; c103 < t67.inHeight; ++c103) for (let r56 = 0; r56 < t67.inWidth; ++r56) {
    let T40 = c103 - z32, L22 = r56 - w45, g72 = 0;
    for (let f85 = 0; f85 < h74; f85 += N58) {
      let e36 = (T40 + f85) / G30;
      if (!(e36 < 0 || e36 >= t67.outHeight || Math.floor(e36) !== e36)) for (let l80 = 0; l80 < s84; l80 += S45) {
        let n67 = (L22 + l80) / M30;
        if (n67 < 0 || n67 >= t67.outWidth || Math.floor(n67) !== n67) continue;
        let V24 = h74 * s84 - 1 - R26.get(i88, e36, n67, a71), _24 = f85 * s84 + l80, P36 = V24 === _24 ? 1 : 0;
        if (P36 === 0) continue;
        let j22 = D42.get(i88, e36, n67, a71);
        g72 += j22 * P36;
      }
    }
    d55.set(g72, i88, c103, r56, a71);
  }
  return p103.makeTensorInfo(d55.shape, d55.dtype, d55.values);
}
var X13 = { kernelName: Uo, backendName: "cpu", kernelFunc: K12 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/MaxPoolWithArgmax_impl.mjs
function x49(t67, o80, m96, i88, s84) {
  let r56 = util_exports.computeStrides(o80), l80 = st3(t67, o80, m96, r56, s84, "max"), n67 = ht3(t67, o80, m96, s84, true, i88);
  return [l80.values, n67.values];
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/MaxPoolWithArgmax.mjs
var A21 = { kernelName: Wo, backendName: "cpu", kernelFunc: ({ inputs: a71, attrs: p103, backend: d55 }) => {
  let { x: t67 } = a71, { filterSize: n67, strides: r56, pad: s84, includeBatchInIndex: c103 } = p103, o80 = d55;
  i26(t67, "MaxPoolWithArgmax");
  let i88 = o80.data.get(t67.dataId).values, e36 = backend_util_exports.computePool2DInfo(t67.shape, n67, r56, [1, 1], s84), [m96, l80] = x49(i88, t67.shape, t67.dtype, c103, e36), x76 = o80.write(m96, e36.outShape, t67.dtype), h74 = o80.write(l80, e36.outShape, t67.dtype);
  return [{ dataId: x76, shape: e36.outShape, dtype: t67.dtype }, { dataId: h74, shape: e36.outShape, dtype: "int32" }];
} };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Mean.mjs
function F17(p103) {
  let { inputs: i88, backend: e36, attrs: u86 } = p103, { x: t67 } = i88, { axis: o80, keepDims: m96 } = u86, d55 = util_exports.parseAxisParam(o80, t67.shape), f85 = backend_util_exports.computeOutAndReduceShapes(t67.shape, d55)[1], h74 = util_exports.sizeFromShape(f85), s84 = [], n67 = e36.makeTensorInfo([], "float32", new Float32Array([h74]));
  s84.push(n67);
  let a71 = u48({ inputs: { x: t67 }, backend: e36, attrs: { dtype: "float32" } });
  s84.push(a71);
  let r56 = l44({ inputs: { a: a71, b: n67 }, backend: e36 });
  s84.push(r56);
  let l80 = P14({ inputs: { x: r56 }, backend: e36, attrs: { axis: o80, keepDims: m96 } });
  return s84.forEach((x76) => e36.disposeIntermediateTensorInfo(x76)), l80;
}
var g43 = { kernelName: Ko, backendName: "cpu", kernelFunc: F17 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Min.mjs
function D17(A35) {
  let { inputs: k63, backend: t67, attrs: I44 } = A35, { x: s84 } = k63, { axis: S45, keepDims: N58 } = I44;
  i26(s84, "min");
  let f85 = util_exports.parseAxisParam(S45, s84.shape), o80 = f85, i88 = backend_util_exports.getAxesPermutation(o80, s84.shape.length), e36 = s84;
  i88 != null && (e36 = h38({ inputs: { x: s84 }, backend: t67, attrs: { perm: i88 } }), o80 = backend_util_exports.getInnerMostAxes(o80.length, s84.shape.length)), backend_util_exports.assertAxesAreInnerMostDims("min", o80, e36.shape.length);
  let [m96, T40] = backend_util_exports.computeOutAndReduceShapes(e36.shape, o80), x76 = util_exports.sizeFromShape(T40), c103 = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(m96), e36.dtype), g72 = t67.data.get(e36.dataId).values;
  for (let n67 = 0; n67 < c103.length; ++n67) {
    let r56 = n67 * x76, u86 = g72[r56];
    for (let d55 = 0; d55 < x76; ++d55) {
      let h74 = g72[r56 + d55];
      (Number.isNaN(h74) || h74 < u86) && (u86 = h74);
    }
    c103[n67] = u86;
  }
  i88 != null && t67.disposeIntermediateTensorInfo(e36);
  let l80 = t67.makeTensorInfo(m96, e36.dtype, c103);
  if (N58) {
    let n67 = backend_util_exports.expandShapeToKeepDim(m96, f85), r56 = f52({ inputs: { x: l80 }, backend: t67, attrs: { shape: n67 } });
    return t67.disposeIntermediateTensorInfo(l80), r56;
  }
  return l80;
}
var R17 = { kernelName: Xo, backendName: "cpu", kernelFunc: D17 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/MirrorPad.mjs
function b29(f85) {
  let { inputs: x76, backend: c103, attrs: h74 } = f85, { x: s84 } = x76, { paddings: a71, mode: y43 } = h74;
  i26(s84, "mirrorPad");
  let n67 = a71.map((o80, e36) => o80[0] + s84.shape[e36] + o80[1]), d55 = a71.map((o80) => o80[0]), p103 = a71.map((o80, e36) => o80[0] + s84.shape[e36]), i88 = y43 === "reflect" ? 0 : 1, S45 = c103.data.get(s84.dataId).values, g72 = s84.shape.length, k63 = util_exports.computeStrides(s84.shape), m96 = util_exports.sizeFromShape(n67), l80 = n67.length, I44 = util_exports.computeStrides(n67), u86 = util_exports.getTypedArrayFromDType(s84.dtype, m96);
  for (let o80 = 0; o80 < m96; o80++) {
    let e36 = util_exports.indexToLoc(o80, l80, I44);
    for (let t67 = 0; t67 < l80; t67++) e36[t67] < d55[t67] ? e36[t67] = d55[t67] * 2 - e36[t67] - i88 : e36[t67] >= p103[t67] && (e36[t67] = (p103[t67] - 1) * 2 - e36[t67] + i88);
    e36 = e36.map((t67, T40) => t67 - d55[T40]);
    let P36 = util_exports.locToIndex(e36, g72, k63);
    u86[o80] = S45[P36];
  }
  return { dataId: c103.write(u86, n67, s84.dtype), shape: n67, dtype: s84.dtype };
}
var V9 = { kernelName: _o, backendName: "cpu", kernelFunc: b29 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Mod.mjs
var p57 = z14((o80, r56) => {
  let e36 = o80 % r56;
  return o80 < 0 && r56 < 0 || o80 >= 0 && r56 >= 0 ? e36 : (e36 + r56) % r56;
});
var c62 = G14(jo, p57);
var s41 = { kernelName: jo, backendName: "cpu", kernelFunc: c62 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Softmax.mjs
function R18(u86) {
  let { inputs: x76, backend: s84, attrs: l80 } = u86, { logits: t67 } = x76, { dim: I44 } = l80, o80 = t67.shape.length, e36 = I44;
  if (e36 === -1 && (e36 = o80 - 1), e36 !== o80 - 1) throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${o80} and dim was ${e36}`);
  let n67 = util_exports.parseAxisParam([e36], t67.shape), a71 = z22({ inputs: { x: t67 }, backend: s84, attrs: { reductionIndices: n67, keepDims: false } }), r56 = backend_util_exports.expandShapeToKeepDim(a71.shape, n67), p103 = f52({ inputs: { x: a71 }, backend: s84, attrs: { shape: r56 } }), m96 = i38({ inputs: { a: t67, b: p103 }, backend: s84 }), i88 = n23({ inputs: { x: m96 }, backend: s84 }), d55 = P14({ inputs: { x: i88 }, backend: s84, attrs: { axis: n67, keepDims: false } }), f85 = f52({ inputs: { x: d55 }, backend: s84, attrs: { shape: r56 } }), h74 = l44({ inputs: { a: i88, b: f85 }, backend: s84 });
  return s84.disposeIntermediateTensorInfo(a71), s84.disposeIntermediateTensorInfo(p103), s84.disposeIntermediateTensorInfo(m96), s84.disposeIntermediateTensorInfo(i88), s84.disposeIntermediateTensorInfo(d55), s84.disposeIntermediateTensorInfo(f85), h74;
}
var F18 = { kernelName: Ot, backendName: "cpu", kernelFunc: R18 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Multinomial.mjs
function T26(k63) {
  let { inputs: I44, backend: o80, attrs: S45 } = k63, { logits: r56 } = I44, { numSamples: i88, seed: v42, normalized: l80 } = S45;
  i26(r56, "multinomial");
  let n67 = l80 ? r56 : R18({ inputs: { logits: r56 }, backend: o80, attrs: { dim: -1 } }), c103 = n67.shape[0], f85 = n67.shape[1], p103 = o80.data.get(n67.dataId).values, d55 = [c103, i88], m96 = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(d55), "int32");
  for (let s84 = 0; s84 < c103; ++s84) {
    let u86 = s84 * f85, e36 = new Float32Array(f85 - 1);
    e36[0] = p103[u86];
    for (let t67 = 1; t67 < e36.length; ++t67) e36[t67] = e36[t67 - 1] + p103[u86 + t67];
    let x76 = qn(v42.toString()), b58 = s84 * i88;
    for (let t67 = 0; t67 < i88; ++t67) {
      let y43 = x76();
      m96[b58 + t67] = e36.length;
      for (let a71 = 0; a71 < e36.length; a71++) if (y43 < e36[a71]) {
        m96[b58 + t67] = a71;
        break;
      }
    }
  }
  return l80 || o80.disposeIntermediateTensorInfo(n67), o80.makeTensorInfo(d55, "int32", m96);
}
var w25 = { kernelName: Jo, backendName: "cpu", kernelFunc: T26 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/NonMaxSuppressionV3.mjs
var x50 = kernel_impls_exports.nonMaxSuppressionV3Impl;
function S23(o80) {
  let { inputs: t67, backend: n67, attrs: a71 } = o80, { boxes: e36, scores: r56 } = t67, { maxOutputSize: p103, iouThreshold: c103, scoreThreshold: i88 } = a71;
  i26(e36, "NonMaxSuppression");
  let u86 = n67.data.get(e36.dataId).values, l80 = n67.data.get(r56.dataId).values, { selectedIndices: s84 } = x50(u86, l80, p103, c103, i88);
  return n67.makeTensorInfo([s84.length], "int32", new Int32Array(s84));
}
var M18 = { kernelName: ot, backendName: "cpu", kernelFunc: S23 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/NonMaxSuppressionV4.mjs
var S24 = kernel_impls_exports.nonMaxSuppressionV4Impl;
function M19(s84) {
  let { inputs: t67, backend: n67, attrs: a71 } = s84, { boxes: e36, scores: r56 } = t67, { maxOutputSize: p103, iouThreshold: u86, scoreThreshold: i88, padToMaxOutputSize: c103 } = a71;
  i26(e36, "NonMaxSuppressionPadded");
  let d55 = n67.data.get(e36.dataId).values, l80 = n67.data.get(r56.dataId).values, { selectedIndices: o80, validOutputs: m96 } = S24(d55, l80, p103, u86, i88, c103);
  return [n67.makeTensorInfo([o80.length], "int32", new Int32Array(o80)), n67.makeTensorInfo([], "int32", new Int32Array([m96]))];
}
var h45 = { kernelName: tt, backendName: "cpu", kernelFunc: M19 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/NonMaxSuppressionV5.mjs
var g44 = kernel_impls_exports.nonMaxSuppressionV5Impl;
function N33(t67) {
  let { inputs: a71, backend: o80, attrs: r56 } = t67, { boxes: s84, scores: c103 } = a71, { maxOutputSize: l80, iouThreshold: p103, scoreThreshold: i88, softNmsSigma: u86 } = r56;
  i26(s84, "NonMaxSuppressionWithScore");
  let m96 = o80.data.get(s84.dataId).values, d55 = o80.data.get(c103.dataId).values, x76 = l80, S45 = p103, h74 = i88, V24 = u86, { selectedIndices: e36, selectedScores: n67 } = g44(m96, d55, x76, S45, h74, V24);
  return [o80.makeTensorInfo([e36.length], "int32", new Int32Array(e36)), o80.makeTensorInfo([n67.length], "float32", new Float32Array(n67))];
}
var b30 = { kernelName: et, backendName: "cpu", kernelFunc: N33 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/OneHot.mjs
function h46(i88) {
  let { inputs: c103, backend: s84, attrs: l80 } = i88, { indices: o80 } = c103, { dtype: p103, depth: t67, onValue: d55, offValue: f85 } = l80;
  i26(o80, "oneHot");
  let r56 = util_exports.sizeFromShape(o80.shape), n67 = new Float32Array(r56 * t67);
  n67.fill(f85);
  let a71 = s84.data.get(o80.dataId).values;
  for (let e36 = 0; e36 < r56; ++e36) a71[e36] >= 0 && a71[e36] < t67 && (n67[e36 * t67 + a71[e36]] = d55);
  return s84.makeTensorInfo([...o80.shape, t67], p103, n67);
}
var F19 = { kernelName: nt, backendName: "cpu", kernelFunc: h46 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ZerosLike.mjs
function r22(p103) {
  let { inputs: m96, backend: e36 } = p103, { x: t67 } = m96;
  if (t67.dtype === "string") throw new Error("zerosLike is not supported for string tensors");
  if (t67.dtype === "complex64") {
    let o80 = l34({ inputs: { input: t67 }, backend: e36 }), n67 = r22({ inputs: { x: o80 }, backend: e36 }), s84 = s39({ inputs: { input: t67 }, backend: e36 }), i88 = r22({ inputs: { x: s84 }, backend: e36 }), a71 = r14({ inputs: { real: n67, imag: i88 }, backend: e36 });
    return e36.disposeIntermediateTensorInfo(o80), e36.disposeIntermediateTensorInfo(n67), e36.disposeIntermediateTensorInfo(s84), e36.disposeIntermediateTensorInfo(i88), a71;
  } else return a41({ backend: e36, attrs: { shape: t67.shape, value: 0, dtype: t67.dtype } });
}
var L10 = { kernelName: de, backendName: "cpu", kernelFunc: r22 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/OnesLike.mjs
function i44(p103) {
  let { inputs: m96, backend: e36 } = p103, { x: t67 } = m96;
  if (t67.dtype === "string") throw new Error("onesLike is not supported for string tensors");
  if (t67.dtype === "complex64") {
    let o80 = l34({ inputs: { input: t67 }, backend: e36 }), n67 = i44({ inputs: { x: o80 }, backend: e36 }), r56 = s39({ inputs: { input: t67 }, backend: e36 }), s84 = r22({ inputs: { x: r56 }, backend: e36 }), a71 = r14({ inputs: { real: n67, imag: s84 }, backend: e36 });
    return e36.disposeIntermediateTensorInfo(o80), e36.disposeIntermediateTensorInfo(n67), e36.disposeIntermediateTensorInfo(r56), e36.disposeIntermediateTensorInfo(s84), a71;
  } else return a41({ backend: e36, attrs: { shape: t67.shape, value: 1, dtype: t67.dtype } });
}
var h47 = { kernelName: rt, backendName: "cpu", kernelFunc: i44 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Pack.mjs
function l45(c103) {
  let { inputs: t67, backend: e36, attrs: i88 } = c103, { axis: n67 } = i88;
  if (t67.length === 1) return l43({ inputs: { input: t67[0] }, backend: e36, attrs: { dim: n67 } });
  let d55 = t67[0].shape, m96 = t67[0].dtype;
  t67.forEach((s84) => {
    util_exports.assertShapesMatch(d55, s84.shape, "All tensors passed to stack must have matching shapes"), util_exports.assert(m96 === s84.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  let a71 = [], u86 = t67.map((s84) => {
    let o80 = l43({ inputs: { input: s84 }, backend: e36, attrs: { dim: n67 } });
    return a71.push(o80), o80;
  }), h74 = h41({ inputs: u86, backend: e36, attrs: { axis: n67 } });
  return a71.forEach((s84) => e36.disposeIntermediateTensorInfo(s84)), h74;
}
var T27 = { kernelName: st, backendName: "cpu", kernelFunc: l45 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/PadV2.mjs
function C12(p103) {
  let { inputs: i88, backend: a71, attrs: u86 } = p103, { x: t67 } = i88, { paddings: r56, constantValue: c103 } = u86;
  i26(t67, "pad");
  let s84 = r56.map((e36, d55) => e36[0] + t67.shape[d55] + e36[1]), l80 = r56.map((e36) => e36[0]), m96 = a71.data.get(t67.dataId).values, x76 = util_exports.sizeFromShape(t67.shape), h74 = t67.shape.length, S45 = util_exports.computeStrides(t67.shape), f85 = util_exports.sizeFromShape(s84), y43 = s84.length, g72 = util_exports.computeStrides(s84), n67 = util_exports.getTypedArrayFromDType(t67.dtype, f85);
  c103 !== 0 && n67.fill(c103);
  for (let e36 = 0; e36 < x76; e36++) {
    let k63 = util_exports.indexToLoc(e36, h74, S45).map((V24, z32) => V24 + l80[z32]), I44 = util_exports.locToIndex(k63, y43, g72);
    n67[I44] = m96[e36];
  }
  return { dataId: a71.write(n67, s84, t67.dtype), shape: s84, dtype: t67.dtype };
}
var v29 = { kernelName: pt, backendName: "cpu", kernelFunc: C12 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Pow.mjs
var m62 = z14((e36, r56) => Math.pow(e36, r56));
var t23 = G14(at, m62);
var l46 = { kernelName: at, backendName: "cpu", kernelFunc: t23 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/RaggedGather.mjs
function I22(o80) {
  let { inputs: p103, backend: t67, attrs: r56 } = o80, { paramsNestedSplits: s84, paramsDenseValues: a71, indices: n67 } = p103, { outputRaggedRank: d55 } = r56, u86 = s84.map((e36) => t67.data.get(e36.dataId).values), c103 = s84.map((e36) => e36.shape), m96 = t67.data.get(a71.dataId).values, l80 = t67.data.get(n67.dataId).values, [g72, i88, h74] = A16(u86, c103, m96, a71.shape, a71.dtype, l80, n67.shape, d55), k63 = g72.map((e36) => t67.makeTensorInfo([e36.length], "int32", e36)), N58 = t67.makeTensorInfo(h74, a71.dtype, i88);
  return k63.concat([N58]);
}
var G17 = { kernelName: lt, backendName: "cpu", kernelFunc: I22 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/RaggedRange.mjs
function f59(o80) {
  let { inputs: r56, backend: e36 } = o80, { starts: t67, limits: a71, deltas: s84 } = r56, g72 = e36.data.get(t67.dataId).values, l80 = e36.data.get(a71.dataId).values, c103 = e36.data.get(s84.dataId).values, [n67, d55] = z16(g72, t67.shape, t67.dtype, l80, a71.shape, c103, s84.shape), p103 = e36.makeTensorInfo([n67.length], "int32", n67), i88 = e36.makeTensorInfo([d55.length], t67.dtype, d55);
  return [p103, i88];
}
var h48 = { kernelName: dt, backendName: "cpu", kernelFunc: f59 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/RaggedTensorToTensor.mjs
function I23(r56) {
  let { inputs: d55, backend: e36, attrs: p103 } = r56, { shape: o80, values: a71, defaultValue: s84, rowPartitionTensors: n67 } = d55, { rowPartitionTypes: u86 } = p103, c103 = e36.data.get(o80.dataId).values, l80 = e36.data.get(a71.dataId).values, T40 = e36.data.get(s84.dataId).values, g72 = n67.map((t67) => e36.data.get(t67.dataId).values), i88 = n67.map((t67) => t67.shape), [m96, h74] = O13(c103, o80.shape, l80, a71.shape, a71.dtype, T40, s84.shape, g72, i88, u86);
  return e36.makeTensorInfo(m96, a71.dtype, h74);
}
var P15 = { kernelName: ut, backendName: "cpu", kernelFunc: I23 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Range.mjs
function g45(t67) {
  let { backend: r56, attrs: o80 } = t67, { start: a71, stop: s84, dtype: e36, step: c103 } = o80, n67 = S21(a71, s84, c103, e36);
  return r56.makeTensorInfo([n67.length], e36, n67);
}
var l47 = { kernelName: St, backendName: "cpu", kernelFunc: g45 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Reciprocal.mjs
var o35 = A15(Dt, (e36) => 1 / e36);
var a42 = { kernelName: Dt, backendName: "cpu", kernelFunc: o35 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ResizeBilinear.mjs
function Y7(H18) {
  let { inputs: V24, backend: g72, attrs: W15 } = H18, { images: i88 } = V24, { alignCorners: r56, halfPixelCenters: w45, size: y43 } = W15;
  i26(i88, "resizeBilinear");
  let t67 = util_exports.computeStrides(i88.shape), [e36, o80] = y43, [h74, m96, p103, d55] = i88.shape, a71 = g72.data.get(i88.dataId).values, C28 = new Float32Array(util_exports.sizeFromShape([h74, e36, o80, d55])), b58 = [r56 && e36 > 1 ? m96 - 1 : m96, r56 && o80 > 1 ? p103 - 1 : p103], z32 = [r56 && e36 > 1 ? e36 - 1 : e36, r56 && o80 > 1 ? o80 - 1 : o80], A35 = 0, F32 = b58[0] / z32[0], x76 = b58[1] / z32[1];
  for (let l80 = 0; l80 < h74; l80++) for (let f85 = 0; f85 < e36; f85++) {
    let n67;
    w45 ? n67 = F32 * (f85 + 0.5) - 0.5 : n67 = F32 * f85;
    let M30 = Math.max(0, Math.floor(n67)), P36 = n67 - M30, T40 = Math.min(m96 - 1, Math.ceil(n67)), O21 = l80 * t67[0] + M30 * t67[1], S45 = l80 * t67[0] + T40 * t67[1];
    for (let u86 = 0; u86 < o80; u86++) {
      let c103;
      w45 ? c103 = x76 * (u86 + 0.5) - 0.5 : c103 = x76 * u86;
      let R26 = Math.max(0, Math.floor(c103)), k63 = c103 - R26, v42 = Math.min(p103 - 1, Math.ceil(c103)), j22 = O21 + R26 * t67[2], q25 = S45 + R26 * t67[2], D42 = O21 + v42 * t67[2], E44 = S45 + v42 * t67[2];
      for (let s84 = 0; s84 < d55; s84++) {
        let B30 = a71[j22 + s84], I44 = a71[q25 + s84], G30 = a71[D42 + s84], J17 = a71[E44 + s84], L22 = B30 + (G30 - B30) * k63, K21 = I44 + (J17 - I44) * k63, Q13 = L22 + (K21 - L22) * P36;
        C28[A35++] = Q13;
      }
    }
  }
  return g72.makeTensorInfo([h74, e36, o80, d55], "float32", C28);
}
var $28 = { kernelName: At, backendName: "cpu", kernelFunc: Y7 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ResizeBilinearGrad.mjs
function U8(T40) {
  let { inputs: B30, backend: u86, attrs: G30 } = T40, { images: f85, dy: d55 } = B30, { alignCorners: i88 } = G30;
  i26([d55, f85], "resizeBilinearGrad");
  let e36 = util_exports.computeStrides(f85.shape), [p103, o80, s84, x76] = f85.shape, [, n67, r56] = d55.shape, c103 = new Float32Array(p103 * o80 * s84 * x76), b58 = [i88 && n67 > 1 ? o80 - 1 : o80, i88 && r56 > 1 ? s84 - 1 : s84], v42 = [i88 && n67 > 1 ? n67 - 1 : n67, i88 && r56 > 1 ? r56 - 1 : r56], N58 = b58[0] / v42[0], w45 = b58[1] / v42[1], F32 = u86.data.get(d55.dataId).values, H18 = 0;
  for (let l80 = 0; l80 < p103; l80++) {
    let I44 = l80 * e36[0];
    for (let h74 = 0; h74 < n67; h74++) {
      let m96 = h74 * N58, O21 = Math.floor(m96), V24 = Math.min(Math.ceil(m96), o80 - 1), y43 = I44 + O21 * e36[1], z32 = I44 + V24 * e36[1], R26 = m96 - O21, M30 = 1 - R26;
      for (let C28 = 0; C28 < r56; C28++) {
        let D42 = C28 * w45, L22 = Math.floor(D42), S45 = Math.min(Math.ceil(D42), s84 - 1), g72 = D42 - L22, k63 = 1 - g72, W15 = y43 + L22 * e36[2], A35 = y43 + S45 * e36[2], X20 = z32 + L22 * e36[2], Y14 = z32 + S45 * e36[2], j22 = M30 * k63, q25 = M30 * g72, E44 = R26 * k63, J17 = R26 * g72;
        for (let t67 = 0; t67 < x76; t67++) {
          let a71 = F32[H18++];
          c103[W15 + t67] += a71 * j22, c103[A35 + t67] += a71 * q25, c103[X20 + t67] += a71 * E44, c103[Y14 + t67] += a71 * J17;
        }
      }
    }
  }
  return u86.makeTensorInfo([p103, s84, o80, x76], "float32", c103);
}
var $29 = { kernelName: Bt, backendName: "cpu", kernelFunc: U8 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ResizeNearestNeighbor.mjs
function T28(R26) {
  let { inputs: S45, backend: N58, attrs: k63 } = R26, { images: s84 } = S45, { alignCorners: o80, halfPixelCenters: r56, size: v42 } = k63;
  i26(s84, "resizeNearestNeighbor");
  let c103 = util_exports.computeStrides(s84.shape), [e36, t67] = v42, [i88, f85, l80, u86] = s84.shape, O21 = N58.data.get(s84.dataId).values, g72 = new Float32Array(i88 * e36 * t67 * u86), b58 = [o80 && e36 > 1 ? f85 - 1 : f85, o80 && t67 > 1 ? l80 - 1 : l80], z32 = [o80 && e36 > 1 ? e36 - 1 : e36, o80 && t67 > 1 ? t67 - 1 : t67], w45 = b58[0] / z32[0], C28 = b58[1] / z32[1], F32 = 0;
  for (let h74 = 0; h74 < i88; h74++) {
    let I44 = h74 * c103[0];
    for (let n67 = 0; n67 < e36; n67++) {
      let M30 = r56 ? w45 * (n67 + 0.5) : w45 * n67, m96 = Math.min(f85 - 1, o80 ? Math.round(M30) : Math.floor(M30));
      r56 && (m96 = Math.max(0, m96));
      let y43 = I44 + m96 * c103[1];
      for (let a71 = 0; a71 < t67; a71++) {
        let x76 = r56 ? C28 * (a71 + 0.5) : C28 * a71, d55 = Math.min(l80 - 1, o80 ? Math.round(x76) : Math.floor(x76));
        r56 && (d55 = Math.max(0, d55));
        let H18 = y43 + d55 * c103[2];
        for (let p103 = 0; p103 < u86; p103++) {
          let V24 = O21[H18 + p103];
          g72[F32++] = V24;
        }
      }
    }
  }
  return N58.makeTensorInfo([i88, e36, t67, u86], s84.dtype, g72);
}
var B16 = { kernelName: ht, backendName: "cpu", kernelFunc: T28 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ResizeNearestNeighborGrad.mjs
function U9(W15) {
  let { inputs: D42, backend: y43, attrs: L22 } = W15, { images: e36, dy: i88 } = D42, { alignCorners: t67 } = L22;
  i26([i88, e36], "resizeNearestNeighborGrad");
  let l80 = util_exports.computeStrides(e36.shape), g72 = util_exports.computeStrides(i88.shape), [N58, o80, s84, M30] = e36.shape, [, r56, n67] = i88.shape, C28 = new Float32Array(N58 * o80 * s84 * M30), A35 = y43.data.get(i88.dataId).values, S45 = [t67 && r56 > 1 ? o80 - 1 : o80, t67 && n67 > 1 ? s84 - 1 : s84], b58 = [t67 && r56 > 1 ? r56 - 1 : r56, t67 && n67 > 1 ? n67 - 1 : n67], R26 = S45[0] / b58[0], w45 = S45[1] / b58[1], x76 = 1 / R26, z32 = 1 / w45, k63 = Math.ceil(x76) * 2 + 2, v42 = Math.ceil(z32) * 2 + 2;
  for (let u86 = 0; u86 < N58; u86++) {
    let O21 = u86 * l80[0];
    for (let c103 = 0; c103 < o80; c103++) {
      let T40 = O21 + c103 * l80[1], V24 = Math.floor(c103 * x76), X20 = Math.floor(V24 - k63 / 2);
      for (let a71 = 0; a71 < s84; a71++) {
        let Y14 = T40 + a71 * l80[2], j22 = Math.floor(a71 * z32), q25 = Math.floor(j22 - v42 / 2);
        for (let f85 = 0; f85 < M30; f85++) {
          let F32 = 0;
          for (let p103 = 0; p103 < k63; p103++) {
            let h74 = p103 + X20;
            if (h74 < 0 || h74 >= r56) continue;
            let B30 = O21 + h74 * g72[1], G30 = h74 * R26, E44 = Math.min(o80 - 1, t67 ? Math.round(G30) : Math.floor(G30));
            if (c103 === E44) for (let m96 = 0; m96 < v42; m96++) {
              let d55 = m96 + q25;
              if (d55 < 0 || d55 >= n67) continue;
              let J17 = B30 + d55 * g72[2], H18 = d55 * w45, K21 = Math.min(s84 - 1, t67 ? Math.round(H18) : Math.floor(H18));
              a71 === K21 && (F32 += A35[J17 + f85]);
            }
          }
          C28[Y14 + f85] = F32;
        }
      }
    }
  }
  return y43.makeTensorInfo(e36.shape, e36.dtype, C28);
}
var $30 = { kernelName: Mt, backendName: "cpu", kernelFunc: U9 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Reverse.mjs
function y25(i88) {
  let { inputs: a71, backend: s84, attrs: p103 } = i88, { x: e36 } = a71, { dims: f85 } = p103;
  i26(e36, "reverse");
  let u86 = e36.shape.length, m96 = util_exports.parseAxisParam(f85, e36.shape);
  if (u86 === 0) return i28({ inputs: { x: e36 }, backend: s84 });
  let t67 = new p8(e36.shape, e36.dtype), l80 = s84.bufferSync(e36);
  for (let o80 = 0; o80 < t67.size; o80++) {
    let c103 = t67.indexToLoc(o80), n67 = c103.slice();
    m96.forEach((r56) => n67[r56] = e36.shape[r56] - 1 - n67[r56]), t67.set(l80.get(...n67), ...c103);
  }
  return s84.makeTensorInfo(t67.shape, t67.dtype, t67.values);
}
var L11 = { kernelName: Ct, backendName: "cpu", kernelFunc: y25 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/RotateWithOffset.mjs
var _16 = { kernelName: ge, backendName: "cpu", kernelFunc: ({ inputs: C28, attrs: M30, backend: V24 }) => {
  let { image: t67 } = C28, { radians: h74, fillValue: l80, center: W15 } = M30, m96 = V24, g72 = util_exports.getTypedArrayFromDType(t67.dtype, util_exports.sizeFromShape(t67.shape)), [y43, s84, o80, a71] = t67.shape, [i88, p103] = backend_util_exports.getImageCenter(W15, s84, o80), N58 = 255, O21 = Math.sin(h74), I44 = Math.cos(h74), R26 = m96.data.get(t67.dataId).values;
  for (let u86 = 0; u86 < y43; u86++) {
    let b58 = u86 * o80 * s84 * a71;
    for (let r56 = 0; r56 < s84; r56++) {
      let T40 = r56 * (o80 * a71);
      for (let d55 = 0; d55 < o80; d55++) {
        let X20 = d55 * a71;
        for (let e36 = 0; e36 < a71; e36++) {
          let k63 = [y43, r56, d55, e36], x76 = k63[2], F32 = k63[1], c103 = (x76 - i88) * I44 - (F32 - p103) * O21, n67 = (x76 - i88) * O21 + (F32 - p103) * I44;
          c103 = Math.round(c103 + i88), n67 = Math.round(n67 + p103);
          let f85 = l80;
          if (typeof l80 != "number" && (e36 === 3 ? f85 = N58 : f85 = l80[e36]), c103 >= 0 && c103 < o80 && n67 >= 0 && n67 < s84) {
            let v42 = n67 * (o80 * a71), z32 = c103 * a71, A35 = b58 + v42 + z32 + e36;
            f85 = R26[A35];
          }
          let Y14 = b58 + T40 + X20 + e36;
          g72[Y14] = f85;
        }
      }
    }
  }
  return { dataId: m96.write(g72, t67.shape, t67.dtype), shape: t67.shape, dtype: t67.dtype };
} };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Round.mjs
var t24 = A15(vt, (e36) => {
  let r56 = Math.floor(e36);
  return e36 - r56 < 0.5 ? Math.floor(e36) : e36 - r56 > 0.5 ? Math.ceil(e36) : r56 % 2 === 0 ? r56 : r56 + 1;
});
var a43 = { kernelName: vt, backendName: "cpu", kernelFunc: t24 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/ScatterNd.mjs
function y26(u86) {
  let { inputs: o80, backend: e36, attrs: a71 } = u86, { indices: n67, updates: s84 } = o80, { shape: t67 } = a71, { sliceRank: r56, numUpdates: i88, sliceSize: p103, strides: d55, outputSize: f85 } = backend_util_exports.calculateShapes(s84, n67, t67), m96 = true, l80 = e36.bufferSync(n67), k63 = e36.bufferSync(s84), c103 = a36(l80, k63, t67, f85, p103, i88, r56, d55, 0, m96);
  return e36.makeTensorInfo(t67, c103.dtype, c103.values);
}
var h49 = { kernelName: Pt, backendName: "cpu", kernelFunc: y26 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SearchSorted_impl.mjs
function d26(l80, r56) {
  let o80 = 0, e36 = l80.length, t67 = 0;
  for (; o80 < e36; ) t67 = Math.floor((o80 + e36) / 2), l80[t67] < r56 ? o80 = t67 + 1 : e36 = t67;
  return e36;
}
function s42(l80, r56) {
  let o80 = 0, e36 = l80.length, t67 = 0;
  for (; o80 < e36; ) t67 = Math.floor((o80 + e36) / 2), l80[t67] <= r56 ? o80 = t67 + 1 : e36 = t67;
  return e36;
}
function m63(l80, r56, o80, e36, t67, p103) {
  let c103 = util_exports.getArrayFromDType("int32", o80 * t67);
  for (let i88 = 0; i88 < o80; ++i88) {
    let h74 = l80.slice(i88 * e36, (i88 + 1) * e36), n67 = i88 * t67;
    for (let f85 = 0; f85 < t67; ++f85) c103[n67 + f85] = p103 === "left" ? d26(h74, r56[f85 + n67]) : s42(h74, r56[f85 + n67]);
  }
  return c103;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SearchSorted.mjs
function m64(o80) {
  let { inputs: s84, backend: e36, attrs: n67 } = o80, { sortedSequence: t67, values: a71 } = s84, { side: r56 } = n67, c103 = e36.data.get(t67.dataId).values, d55 = e36.data.get(a71.dataId).values, u86 = m63(c103, d55, t67.shape[0], t67.shape[1], a71.shape[1], r56);
  return e36.makeTensorInfo(a71.shape, "int32", u86);
}
var S25 = { kernelName: Lt, backendName: "cpu", kernelFunc: m64 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Select.mjs
function x51(u86) {
  let { inputs: m96, backend: s84 } = u86, { condition: a71, t: e36, e: n67 } = m96;
  i26([a71, e36, n67], "select");
  let c103 = a71.shape.length, p103 = s84.data.get(a71.dataId).values, f85 = s84.data.get(e36.dataId).values, h74 = s84.data.get(n67.dataId).values, r56 = c5(e36.dtype, n67.dtype), o80 = util_exports.makeZerosTypedArray(util_exports.sizeFromShape(e36.shape), r56), d55 = 0, g72 = c103 === 0 || c103 > 1 || e36.shape.length === 1 ? 1 : util_exports.sizeFromShape(e36.shape.slice(1));
  for (let t67 = 0; t67 < p103.length; t67++) for (let i88 = 0; i88 < g72; i88++) p103[t67] === 1 ? o80[d55++] = f85[t67] : o80[d55++] = h74[t67];
  return s84.makeTensorInfo(e36.shape, r56, o80);
}
var N34 = { kernelName: kt, backendName: "cpu", kernelFunc: x51 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Selu.mjs
var c63 = backend_util_exports.SELU_SCALEALPHA;
var l48 = backend_util_exports.SELU_SCALE;
var o36 = A15(Gt, (e36) => e36 >= 0 ? l48 * e36 : c63 * (Math.exp(e36) - 1));
var s43 = { kernelName: Gt, backendName: "cpu", kernelFunc: o36 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Sign.mjs
var o37 = A15(qt, (e36) => e36 < 0 ? -1 : e36 > 0 ? 1 : 0);
var u58 = { kernelName: qt, backendName: "cpu", kernelFunc: o37 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Sin.mjs
var o38 = A15(ft, (e36) => Math.sin(e36));
var c64 = { kernelName: ft, backendName: "cpu", kernelFunc: o38 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Sinh.mjs
var o39 = A15(It, (e36) => Math.sinh(e36));
var c65 = { kernelName: It, backendName: "cpu", kernelFunc: o39 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Softplus.mjs
var p58 = 11920928955078125e-23;
var n32 = Math.log(p58) + 2;
var a44 = A15(Vt, (o80) => {
  let l80 = o80 > -n32, r56 = o80 < n32, t67 = Math.exp(o80), e36;
  return r56 ? e36 = t67 : l80 ? e36 = o80 : e36 = Math.log(1 + t67), e36;
});
var m65 = { kernelName: Vt, backendName: "cpu", kernelFunc: a44 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SpaceToBatchND.mjs
function P16(i88) {
  let { inputs: l80, backend: e36, attrs: m96 } = i88, { x: n67 } = l80, { blockShape: t67, paddings: f85 } = m96;
  i26([n67], "spaceToBatchND");
  let o80 = util_exports.sizeFromShape(t67), p103 = [[0, 0]];
  p103.push(...f85);
  for (let h74 = 1 + t67.length; h74 < n67.shape.length; ++h74) p103.push([0, 0]);
  let s84 = v29.kernelFunc({ inputs: { x: n67 }, backend: e36, attrs: { paddings: p103, constantValue: 0 } }), r56 = backend_util_exports.getReshaped(s84.shape, t67, o80, false), g72 = backend_util_exports.getPermuted(r56.length, t67.length, false), I44 = backend_util_exports.getReshapedPermuted(s84.shape, t67, o80, false), d55 = f52({ inputs: { x: s84 }, backend: e36, attrs: { shape: r56 } }), c103 = h38({ inputs: { x: d55 }, backend: e36, attrs: { perm: g72 } }), R26 = f52({ inputs: { x: c103 }, backend: e36, attrs: { shape: I44 } });
  return e36.disposeIntermediateTensorInfo(s84), e36.disposeIntermediateTensorInfo(d55), e36.disposeIntermediateTensorInfo(c103), R26;
}
var q14 = { kernelName: zt, backendName: "cpu", kernelFunc: P16 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SparseFillEmptyRows.mjs
function g46(l80) {
  let { inputs: d55, backend: e36 } = l80, { indices: a71, values: t67, denseShape: s84, defaultValue: n67 } = d55;
  if (s84.shape.length !== 1) throw new Error(`Dense shape must be a vector, saw:
        ${s84.shape}`);
  if (a71.shape.length !== 2) throw new Error(`Indices must be a matrix, saw:
        ${a71.shape}`);
  if (t67.shape.length !== 1) throw new Error(`Values must be a vector, saw:
        ${t67.shape}`);
  if (n67.shape.length !== 0) throw new Error(`Default value must be a scalar, saw:
        ${n67.shape}`);
  let u86 = e36.data.get(a71.dataId).values, h74 = e36.data.get(t67.dataId).values, i88 = e36.data.get(s84.dataId).values, m96 = e36.data.get(n67.dataId).values[0], [c103, r56, w45, o80, p103] = D12(u86, a71.shape, a71.dtype, h74, t67.dtype, i88, m96);
  return [e36.makeTensorInfo(r56, a71.dtype, c103), e36.makeTensorInfo([r56[0]], t67.dtype, w45), e36.makeTensorInfo([o80.length], "bool", new Uint8Array(o80.map((f85) => Number(f85)))), e36.makeTensorInfo([p103.length], a71.dtype, new Int32Array(p103))];
}
var k27 = { kernelName: Ht, backendName: "cpu", kernelFunc: g46 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SparseReshape.mjs
function m66(n67) {
  let { inputs: p103, backend: a71 } = n67, { inputIndices: e36, inputShape: r56, newShape: t67 } = p103;
  if (e36.shape.length !== 2) throw new Error(`Input indices should be a matrix but received shape
        ${e36.shape}`);
  if (r56.shape.length !== 1) throw new Error(`Input shape should be a vector but received shape
        ${r56.shape}`);
  if (t67.shape.length !== 1) throw new Error(`Target shape should be a vector but received shape ${t67.shape}`);
  let o80 = Array.from(a71.data.get(r56.dataId).values), h74 = a71.data.get(e36.dataId).values, d55 = Array.from(a71.data.get(t67.dataId).values), [i88, c103, s84] = z18(h74, e36.shape, e36.dtype, o80, d55);
  return [a71.makeTensorInfo(c103, e36.dtype, i88), a71.makeTensorInfo([s84.length], t67.dtype, new Int32Array(s84))];
}
var g47 = { kernelName: Wt, backendName: "cpu", kernelFunc: m66 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SparseSegmentMean.mjs
function m67(n67) {
  let { inputs: r56, backend: a71 } = n67, { data: e36, indices: t67, segmentIds: s84 } = r56;
  if (e36.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (t67.shape.length !== 1) throw new Error(`Indices should be a vector but received shape
          ${t67.shape}`);
  if (s84.shape.length !== 1) throw new Error(`Segment ids should be a vector but received shape
          ${s84.shape}`);
  if (t67.shape[0] !== s84.shape[0]) throw new Error("segmentIds and indices should have same size.");
  let o80 = a71.data.get(e36.dataId).values, d55 = a71.data.get(t67.dataId).values, p103 = a71.data.get(s84.dataId).values, [i88, c103] = b26(o80, e36.shape, e36.dtype, d55, p103, true);
  return a71.makeTensorInfo(c103, e36.dtype, i88);
}
var f60 = { kernelName: Kt, backendName: "cpu", kernelFunc: m67 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SparseSegmentSum.mjs
function m68(n67) {
  let { inputs: r56, backend: t67 } = n67, { data: e36, indices: a71, segmentIds: s84 } = r56;
  if (e36.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (a71.shape.length !== 1) throw new Error(`Indices should be a vector but received shape
         ${a71.shape}`);
  if (s84.shape.length !== 1) throw new Error(`Segment ids should be a vector but received shape
         ${s84.shape}`);
  if (a71.shape[0] !== s84.shape[0]) throw new Error("segmentIds and indices should have same size.");
  let o80 = t67.data.get(e36.dataId).values, d55 = t67.data.get(a71.dataId).values, p103 = t67.data.get(s84.dataId).values, [i88, c103] = b26(o80, e36.shape, e36.dtype, d55, p103);
  return t67.makeTensorInfo(c103, e36.dtype, i88);
}
var S26 = { kernelName: Xt, backendName: "cpu", kernelFunc: m68 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SparseToDense.mjs
function V10(S45) {
  let { inputs: m96, backend: e36, attrs: y43 } = S45, { sparseIndices: k63, sparseValues: t67, defaultValue: c103 } = m96, { outputShape: u86 } = y43, { sliceRank: o80, numUpdates: d55, sliceSize: r56, strides: l80, outputSize: f85 } = backend_util_exports.calculateShapes(t67, k63, u86), p103 = false, i88 = e36.bufferSync(k63), n67;
  switch (t67.dtype) {
    case "bool": {
      let a71 = e36.bufferSync(t67), s84 = !!e36.data.get(c103.dataId).values[0];
      n67 = a36(i88, a71, u86, f85, r56, d55, o80, l80, s84, p103);
      break;
    }
    case "float32": {
      let a71 = e36.bufferSync(t67), s84 = e36.data.get(c103.dataId).values[0];
      n67 = a36(i88, a71, u86, f85, r56, d55, o80, l80, s84, p103);
      break;
    }
    case "int32": {
      let a71 = e36.bufferSync(t67), s84 = e36.data.get(c103.dataId).values[0];
      n67 = a36(i88, a71, u86, f85, r56, d55, o80, l80, s84, p103);
      break;
    }
    case "string": {
      let a71 = e36.bufferSync(t67), s84 = util_exports.decodeString(e36.data.get(c103.dataId).values[0]);
      n67 = a36(i88, a71, u86, f85, r56, d55, o80, l80, s84, p103);
      break;
    }
    default:
      throw new Error(`Unsupported type ${t67.dtype}`);
  }
  return e36.makeTensorInfo(u86, n67.dtype, n67.values);
}
var h50 = { kernelName: Zt, backendName: "cpu", kernelFunc: V10 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/SplitV.mjs
function b31(r56) {
  let { inputs: p103, backend: c103, attrs: o80 } = r56, { x: t67 } = p103, { numOrSizeSplits: a71, axis: l80 } = o80, e36 = util_exports.parseAxisParam(l80, t67.shape)[0], m96 = backend_util_exports.prepareSplitSize(t67, a71, e36), s84 = new Array(t67.shape.length).fill(0), u86 = t67.shape.slice();
  return m96.map((i88) => {
    let n67 = [...u86];
    n67[e36] = i88;
    let S45 = I18({ inputs: { x: t67 }, backend: c103, attrs: { begin: s84, size: n67 } });
    return s84[e36] += i88, S45;
  });
}
var V11 = { kernelName: Ut, backendName: "cpu", kernelFunc: b31 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Square.mjs
var h51 = { kernelName: jt, backendName: "cpu", kernelFunc: ({ inputs: s84, backend: c103 }) => {
  let { x: e36 } = s84, n67 = c103;
  i26(e36, "square");
  let a71 = n67.data.get(e36.dataId).values, o80 = new Float32Array(a71.length);
  for (let t67 = 0; t67 < a71.length; ++t67) {
    let r56 = a71[t67];
    o80[t67] = r56 * r56;
  }
  return { dataId: n67.write(o80, e36.shape, e36.dtype), shape: e36.shape, dtype: e36.dtype };
} };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Step.mjs
var p59 = A15(ue, (e36, t67) => {
  let n67 = t67;
  return isNaN(e36) ? NaN : e36 > 0 ? 1 : n67.alpha;
});
var c66 = { kernelName: ue, backendName: "cpu", kernelFunc: p59 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/StridedSlice.mjs
function w26(c103) {
  let { inputs: d55, backend: s84, attrs: m96 } = c103, { x: e36 } = d55, { begin: u86, end: f85, strides: h74, beginMask: S45, endMask: k63, ellipsisMask: g72, newAxisMask: b58, shrinkAxisMask: x76 } = m96;
  i26(e36, "stridedSlice");
  let { finalShapeSparse: I44, finalShape: n67, isIdentity: M30, sliceDim0: $37, isSimpleSlice: y43, begin: r56, end: N58, strides: o80 } = slice_util_exports.sliceInfo(e36.shape, u86, f85, h74, S45, k63, g72, b58, x76), i88;
  if (M30) i88 = f52({ inputs: { x: e36 }, backend: s84, attrs: { shape: n67 } });
  else if ($37 || y43) {
    util_exports.assert(e36.shape.length >= 1, () => `Input must have rank at least 1, got: ${e36.shape.length}`);
    let a71 = slice_util_exports.computeOutShape(r56, N58, o80), t67 = I18({ inputs: { x: e36 }, backend: s84, attrs: { begin: r56, size: a71 } });
    i88 = f52({ inputs: { x: t67 }, backend: s84, attrs: { shape: n67 } }), s84.disposeIntermediateTensorInfo(t67);
  } else {
    let a71 = s84.bufferSync(e36), t67 = p53(I44, a71, o80, r56);
    i88 = s84.makeTensorInfo(n67, t67.dtype, t67.values);
  }
  return i88;
}
var j14 = { kernelName: Qt, backendName: "cpu", kernelFunc: w26 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/StringNGrams.mjs
function k28(r56) {
  let { inputs: s84, backend: t67, attrs: e36 } = r56, { separator: o80, nGramWidths: d55, leftPad: i88, rightPad: m96, padWidth: p103, preserveShortSequences: c103 } = e36, { data: g72, dataSplits: a71 } = s84, l80 = t67.data.get(g72.dataId).values, u86 = t67.data.get(a71.dataId).values, [n67, f85] = v27(l80, u86, o80, d55, i88, m96, p103, c103);
  return [t67.makeTensorInfo([n67.length], "string", n67), t67.makeTensorInfo(a71.shape, "int32", f85)];
}
var I24 = { kernelName: Yt, backendName: "cpu", kernelFunc: k28 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/StringSplit.mjs
function h52(a71) {
  let { inputs: i88, backend: t67, attrs: o80 } = a71, { skipEmpty: p103 } = o80, { input: e36, delimiter: n67 } = i88;
  if (e36.dtype !== "string") throw new Error("Input must be of datatype string");
  if (e36.shape.length !== 1) throw new Error(`Input must be a vector, got shape: ${e36.shape}`);
  if (n67.shape.length !== 0) throw new Error(`Delimiter must be a scalar, got shape: ${n67.shape}`);
  let l80 = t67.data.get(e36.dataId).values, m96 = t67.data.get(n67.dataId).values[0], [u86, r56, c103] = m49(l80, m96, p103), s84 = r56.length;
  return [t67.makeTensorInfo([s84, 2], "int32", u86), t67.makeTensorInfo([s84], "string", r56), t67.makeTensorInfo([2], "int32", new Int32Array(c103))];
}
var k29 = { kernelName: $t, backendName: "cpu", kernelFunc: h52 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/StringToHashBucketFast.mjs
function p60(s84) {
  let { inputs: o80, backend: n67, attrs: r56 } = s84, { numBuckets: e36 } = r56, { input: t67 } = o80;
  if (t67.dtype !== "string") throw new Error("Input must be of datatype string");
  if (e36 <= 0) throw new Error("Number of buckets must be at least 1");
  let a71 = n67.data.get(t67.dataId).values, u86 = g39(a71, e36);
  return n67.makeTensorInfo(t67.shape, "int32", u86);
}
var f61 = { kernelName: oe, backendName: "cpu", kernelFunc: p60 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Tan.mjs
var t25 = A15(ee, (e36) => Math.tan(e36));
var c67 = { kernelName: ee, backendName: "cpu", kernelFunc: t25 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Tanh.mjs
var t26 = A15(re, (e36) => Math.tanh(e36));
var c68 = { kernelName: re, backendName: "cpu", kernelFunc: t26 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/TensorScatterUpdate.mjs
function y27(o80) {
  let { inputs: a71, backend: e36 } = o80, { tensor: t67, indices: n67, updates: s84 } = a71, { sliceRank: r56, numUpdates: u86, sliceSize: p103, strides: f85, outputSize: i88 } = backend_util_exports.calculateShapes(s84, n67, t67.shape), d55 = false, l80 = e36.bufferSync(n67), m96 = e36.bufferSync(s84), S45 = e36.bufferSync(t67), c103 = a36(l80, m96, t67.shape, i88, p103, u86, r56, f85, S45, d55);
  return e36.makeTensorInfo(t67.shape, c103.dtype, c103.values);
}
var I25 = { kernelName: Tt, backendName: "cpu", kernelFunc: y27 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Tile.mjs
function l49(n67) {
  let { inputs: r56, backend: t67, attrs: s84 } = n67, { x: o80 } = r56, { reps: p103 } = s84;
  i26(o80, "tile");
  let e36 = h39(t67.bufferSync(o80), p103);
  return t67.makeTensorInfo(e36.shape, e36.dtype, e36.values);
}
var k30 = { kernelName: ne, backendName: "cpu", kernelFunc: l49 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/TopK.mjs
function u59(p103) {
  let { inputs: s84, backend: e36, attrs: n67 } = p103, { x: o80 } = s84, { k: r56, sorted: l80 } = n67;
  i26(o80, "topk");
  let c103 = e36.data.get(o80.dataId).values, [t67, a71] = z19(c103, o80.shape, o80.dtype, r56, l80);
  return [e36.makeTensorInfo(t67.shape, t67.dtype, t67.values), e36.makeTensorInfo(a71.shape, a71.dtype, a71.values)];
}
var x52 = { kernelName: se, backendName: "cpu", kernelFunc: u59 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Transform.mjs
function K13(r56) {
  let { inputs: o80, attrs: t67, backend: n67 } = r56, { image: s84, transforms: i88 } = o80, { interpolation: f85, fillMode: c103, fillValue: e36, outputShape: p103 } = t67, [d55, a71, u86, I44] = s84.shape, [m96, v42] = p103 ?? [a71, u86], y43 = [d55, m96, v42, I44], z32 = util_exports.computeStrides(s84.shape), E44 = z32[0], N58 = z32[1], O21 = z32[2], T40 = util_exports.computeStrides(y43), D42 = T40[0], R26 = T40[1], W15 = T40[2], w45 = util_exports.getTypedArrayFromDType(s84.dtype, util_exports.sizeFromShape(y43));
  w45.fill(e36);
  let $37 = n67.data.get(s84.dataId).values, X20 = n67.data.get(i88.dataId).values;
  for (let h74 = 0; h74 < d55; ++h74) {
    let l80 = i88.shape[0] === 1 ? X20 : X20.subarray(h74 * 8, h74 * 8 + 8);
    for (let M30 = 0; M30 < m96; ++M30) for (let b58 = 0; b58 < v42; ++b58) for (let k63 = 0; k63 < I44; ++k63) {
      let S45, Y14 = l80[6] * b58 + l80[7] * M30 + 1;
      if (Y14 === 0) continue;
      let q25 = (l80[0] * b58 + l80[1] * M30 + l80[2]) / Y14, B30 = (l80[3] * b58 + l80[4] * M30 + l80[5]) / Y14, j22 = A22(q25, u86, c103), x76 = A22(B30, a71, c103);
      switch (f85) {
        case "nearest":
          S45 = Z9($37, a71, u86, E44, N58, O21, h74, x76, j22, k63, e36);
          break;
        case "bilinear":
          S45 = _17($37, a71, u86, E44, N58, O21, h74, x76, j22, k63, e36);
          break;
        default:
          throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${f85}`);
      }
      let G30 = h74 * D42 + M30 * R26 + b58 * W15 + k63;
      w45[G30] = S45;
    }
    return n67.makeTensorInfo(y43, s84.dtype, w45);
  }
  return { dataId: n67.write(w45, y43, s84.dtype), shape: s84.shape, dtype: s84.dtype };
}
var V12 = { kernelName: pe, backendName: "cpu", kernelFunc: K13 };
function A22(r56, o80, t67) {
  switch (t67) {
    case "reflect":
      return L12(r56, o80);
    case "wrap":
      return P17(r56, o80);
    case "nearest":
      return U10(r56, o80);
    case "constant":
    default:
      return Q6(r56, o80);
  }
}
function L12(r56, o80) {
  let t67 = r56;
  if (t67 < 0) if (o80 <= 1) t67 = 0;
  else {
    let n67 = 2 * o80;
    t67 < n67 && (t67 = n67 * Math.trunc(-t67 / n67) + t67), t67 = t67 < -o80 ? t67 + n67 : -t67 - 1;
  }
  else if (t67 > o80 - 1) if (o80 <= 1) t67 = 0;
  else {
    let n67 = 2 * o80;
    t67 -= n67 * Math.trunc(t67 / n67), t67 >= o80 && (t67 = n67 - t67 - 1);
  }
  return util_exports.clamp(0, t67, o80 - 1);
}
function P17(r56, o80) {
  let t67 = r56;
  if (t67 < 0) if (o80 <= 1) t67 = 0;
  else {
    let n67 = o80 - 1;
    t67 += o80 * (Math.trunc(-t67 / n67) + 1);
  }
  else if (t67 > o80 - 1) if (o80 <= 1) t67 = 0;
  else {
    let n67 = o80 - 1;
    t67 -= o80 * Math.trunc(t67 / n67);
  }
  return util_exports.clamp(0, t67, o80 - 1);
}
function Q6(r56, o80) {
  return r56;
}
function U10(r56, o80) {
  return util_exports.clamp(0, r56, o80 - 1);
}
function F20(r56, o80, t67, n67, s84, i88, f85, c103, e36, p103, d55) {
  let a71 = f85 * n67 + c103 * s84 + e36 * i88 + p103;
  return 0 <= c103 && c103 < o80 && 0 <= e36 && e36 < t67 ? r56[a71] : d55;
}
function Z9(r56, o80, t67, n67, s84, i88, f85, c103, e36, p103, d55) {
  let a71 = Math.round(c103), u86 = Math.round(e36);
  return F20(r56, o80, t67, n67, s84, i88, f85, a71, u86, p103, d55);
}
function _17(r56, o80, t67, n67, s84, i88, f85, c103, e36, p103, d55) {
  let a71 = Math.floor(c103), u86 = Math.floor(e36), I44 = a71 + 1, m96 = u86 + 1, v42 = (m96 - e36) * F20(r56, o80, t67, n67, s84, i88, f85, a71, u86, p103, d55) + (e36 - u86) * F20(r56, o80, t67, n67, s84, i88, f85, a71, m96, p103, d55), y43 = (m96 - e36) * F20(r56, o80, t67, n67, s84, i88, f85, I44, u86, p103, d55) + (e36 - u86) * F20(r56, o80, t67, n67, s84, i88, f85, I44, m96, p103, d55);
  return (I44 - c103) * v42 + (c103 - a71) * y43;
}

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Unique.mjs
function l50(o80) {
  let { inputs: u86, attrs: a71, backend: t67 } = o80, { axis: s84 } = a71, { x: e36 } = u86;
  i26(e36, "unique");
  let r56 = t67.data.get(e36.dataId).values, { outputValues: i88, outputShape: p103, indices: n67 } = z20(r56, s84, e36.shape, e36.dtype);
  return [t67.makeTensorInfo(p103, e36.dtype, i88), t67.makeTensorInfo([n67.length], "int32", n67)];
}
var x53 = { kernelName: ae, backendName: "cpu", kernelFunc: l50 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/Unpack.mjs
function g48(l80) {
  let { inputs: u86, backend: s84, attrs: f85 } = l80, { value: n67 } = u86, { axis: t67 } = f85;
  t67 < 0 && (t67 += n67.shape.length);
  let o80 = n67.shape.length, h74 = n67.shape[t67], a71 = new Array(o80 - 1), m96 = 0;
  for (let e36 = 0; e36 < o80; e36++) e36 !== t67 && (a71[m96++] = n67.shape[e36]);
  let p103 = new Array(o80).fill(0), c103 = n67.shape.slice();
  c103[t67] = 1;
  let r56 = new Array(h74);
  for (let e36 = 0; e36 < r56.length; e36++) {
    p103[t67] = e36;
    let i88 = I18({ inputs: { x: n67 }, backend: s84, attrs: { begin: p103, size: c103 } });
    r56[e36] = f52({ inputs: { x: i88 }, backend: s84, attrs: { shape: a71 } }), s84.disposeIntermediateTensorInfo(i88);
  }
  return r56;
}
var A23 = { kernelName: xe, backendName: "cpu", kernelFunc: g48 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/kernels/UnsortedSegmentSum.mjs
function E31(d55) {
  let { inputs: f85, backend: s84, attrs: g72 } = d55, { x: o80, segmentIds: r56 } = f85, { numSegments: h74 } = g72;
  i26(o80, "unsortedSegmentSum");
  let k63 = o80.shape.length, x76 = r56.shape.length, a71 = [], e36 = [], S45 = k63 - x76, m96 = r56;
  for (let t67 = 0; t67 < S45; ++t67) {
    let n67 = l43({ inputs: { input: m96 }, backend: s84, attrs: { dim: t67 + 1 } });
    m96 = n67, e36.push(n67);
  }
  for (let t67 = 0; t67 < h74; ++t67) {
    let n67 = util_exports.createScalarValue(t67, "int32"), u86 = s84.makeTensorInfo([], "int32", n67), p103 = a28({ inputs: { a: u86, b: m96 }, backend: s84 }), i88 = u48({ inputs: { x: p103 }, backend: s84, attrs: { dtype: "float32" } }), c103 = u52({ inputs: { a: i88, b: o80 }, backend: s84 }), l80 = P14({ inputs: { x: c103 }, backend: s84, attrs: { axis: 0, keepDims: false } });
    a71.push(l80), e36.push(u86), e36.push(p103), e36.push(i88), e36.push(c103), e36.push(l80);
  }
  let I44 = l45({ inputs: a71, backend: s84, attrs: { axis: 0 } });
  return e36.forEach((t67) => s84.disposeIntermediateTensorInfo(t67)), I44;
}
var B17 = { kernelName: ie, backendName: "cpu", kernelFunc: E31 };

// https://esm.sh/@tensorflow/tfjs-backend-cpu@4.22.0/denonext/dist/register_all_kernels.mjs
var li = [I19, i27, t14, t15, s33, k26, R15, R16, P12, P13, t16, t17, c56, l41, c57, N26, I20, Z7, J7, dt2, A18, _14, f53, s34, f54, A14, i29, i39, f46, f55, q13, rt4, J8, yt2, rt5, Ot2, Ft3, m54, m55, ot3, D14, D15, b28, M16, st4, L8, mt4, h43, X12, K10, K11, M17, v28, c55, g40, u49, i40, l37, x47, a29, F14, u57, N30, f48, f49, y24, F15, I21, C11, i31, u50, o22, x48, r15, m59, i41, m60, d22, i32, c50, f58, a32, c59, t20, t21, t22, S22, L9, B15, x42, N32, g42, ot4, X13, A21, g43, R17, l40, V9, s41, w25, f50, k23, M18, h45, b30, u54, F19, h47, T27, v29, l46, h40, V7, G17, h48, P15, l47, d19, c58, a42, u56, a39, x44, $28, $29, B16, $30, L11, _16, a43, a35, h49, S25, N34, s43, c52, u58, c64, c65, z17, F18, m65, q14, k27, g47, f60, S26, h50, V11, s37, h51, u55, s38, c66, j14, I24, k29, f61, x43, $27, c67, c68, I25, k30, x52, V12, g37, x53, A23, B17, L10];
for (let o80 of li) p3(o80);

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/webgl_util.mjs
var webgl_util_exports = {};
__export(webgl_util_exports, {
  assertNotComplex: () => be,
  bindCanvasToFramebuffer: () => ne3,
  bindColorTextureToFramebuffer: () => oe3,
  bindTextureToProgramUniformSampler: () => te3,
  bindTextureUnit: () => w27,
  bindVertexBufferToProgramAttribute: () => J9,
  callAndCheck: () => o41,
  canBeRepresented: () => H9,
  createFragmentShader: () => V13,
  createFramebuffer: () => K14,
  createProgram: () => q15,
  createStaticIndexBuffer: () => Y8,
  createStaticVertexBuffer: () => p61,
  createTexture: () => Z10,
  createVertexShader: () => z23,
  getBatchDim: () => N36,
  getExtensionOrThrow: () => y28,
  getFramebufferErrorMessage: () => h53,
  getMaxTexturesInShader: () => Fe,
  getNumChannels: () => j15,
  getProgramUniformLocation: () => re3,
  getProgramUniformLocationOrThrow: () => ee3,
  getRowsCols: () => O15,
  getShapeAs3D: () => fe,
  getTextureShapeFromLogicalShape: () => Ee,
  getWebGLDisjointQueryTimerVersion: () => Re2,
  getWebGLErrorMessage: () => D18,
  getWebGLMaxTextureSize: () => ce2,
  hasExtension: () => F21,
  isCapableOfRenderingToFloatTexture: () => _e,
  isDownloadFloatTextureEnabled: () => me2,
  isReshapeFree: () => ae2,
  isWebGLFenceEnabled: () => Ae,
  isWebGLVersionEnabled: () => xe2,
  linkProgram: () => $31,
  logShaderSourceAndInfoLog: () => X14,
  resetMaxTextureSize: () => se2,
  resetMaxTexturesInShader: () => Te,
  unbindColorTextureFromFramebuffer: () => ue2,
  unbindTextureUnit: () => g49,
  validateFramebuffer: () => ie4,
  validateProgram: () => k31,
  validateTextureSize: () => Q7
});

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/canvas_util.mjs
var n33 = {};
var o40 = { alpha: false, antialias: false, premultipliedAlpha: false, preserveDrawingBuffer: false, depth: false, stencil: false, failIfMajorPerformanceCaveat: true };
function d27(t67, l80) {
  n33[t67] = l80;
}
function f62(t67, l80) {
  if (!(t67 in n33) || l80 != null) {
    let a71 = i45(t67, l80);
    if (a71 !== null) n33[t67] = a71;
    else return console.log("Could not get context for WebGL version", t67), null;
  }
  let e36 = n33[t67];
  return e36 == null || e36.isContextLost() ? (delete n33[t67], f62(t67)) : (e36.disable(e36.DEPTH_TEST), e36.disable(e36.STENCIL_TEST), e36.disable(e36.BLEND), e36.disable(e36.DITHER), e36.disable(e36.POLYGON_OFFSET_FILL), e36.disable(e36.SAMPLE_COVERAGE), e36.enable(e36.SCISSOR_TEST), e36.enable(e36.CULL_FACE), e36.cullFace(e36.BACK), n33[t67]);
}
function c69(t67) {
  if (!l().getBool("IS_SAFARI") && typeof OffscreenCanvas < "u" && t67 === 2) return new OffscreenCanvas(300, 150);
  if (typeof document < "u") return document.createElement("canvas");
  throw new Error("Cannot create a canvas in this context");
}
function i45(t67, l80) {
  if (t67 !== 1 && t67 !== 2) throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");
  let e36 = l80 ?? c69(t67);
  return e36.addEventListener("webglcontextlost", (a71) => {
    a71.preventDefault(), delete n33[t67];
  }, false), l().getBool("SOFTWARE_WEBGL_ENABLED") && (o40.failIfMajorPerformanceCaveat = false), t67 === 1 ? e36.getContext("webgl", o40) || e36.getContext("experimental-webgl", o40) : e36.getContext("webgl2", o40);
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/tex_util.mjs
var L13;
(function(t67) {
  t67[t67.DENSE = 0] = "DENSE", t67[t67.SHARED_BATCH = 1] = "SHARED_BATCH";
})(L13 || (L13 = {}));
var R19;
(function(t67) {
  t67[t67.RENDER = 0] = "RENDER", t67[t67.UPLOAD = 1] = "UPLOAD", t67[t67.PIXELS = 2] = "PIXELS", t67[t67.DOWNLOAD = 3] = "DOWNLOAD";
})(R19 || (R19 = {}));
var S27;
(function(t67) {
  t67[t67.UNPACKED_FLOAT16 = 0] = "UNPACKED_FLOAT16", t67[t67.UNPACKED_FLOAT32 = 1] = "UNPACKED_FLOAT32", t67[t67.PACKED_4X1_UNSIGNED_BYTE = 2] = "PACKED_4X1_UNSIGNED_BYTE", t67[t67.PACKED_2X2_FLOAT32 = 3] = "PACKED_2X2_FLOAT32", t67[t67.PACKED_2X2_FLOAT16 = 4] = "PACKED_2X2_FLOAT16";
})(S27 || (S27 = {}));
function N35(t67, o80) {
  return [o80, t67];
}
function m69(t67, o80) {
  return t67 * o80;
}
function C13(t67) {
  let o80 = util_exports.sizeFromShape(t67), r56 = Math.ceil(o80 / 4);
  return util_exports.sizeToSquarishShape(r56);
}
function O14(t67, o80) {
  return [Math.max(1, Math.ceil(o80 / 2)), Math.max(1, Math.ceil(t67 / 2))];
}
function c70(t67, o80) {
  let [r56, e36] = O14(t67, o80);
  return r56 * e36 * 4;
}
function G18(t67, o80) {
  let r56 = t67, e36, a71, n67, A35, i88, F32, l80, E44, D42, _24;
  return l().getNumber("WEBGL_VERSION") === 2 ? (e36 = r56.R32F, a71 = r56.R16F, n67 = r56.RGBA16F, A35 = r56.RGBA32F, i88 = r56.RED, l80 = 4, E44 = 1, D42 = r56.HALF_FLOAT, _24 = r56.FLOAT, F32 = r56.RGBA8) : (e36 = t67.RGBA, a71 = t67.RGBA, n67 = t67.RGBA, A35 = r56.RGBA, i88 = t67.RGBA, l80 = 4, E44 = 4, D42 = o80 != null ? o80.HALF_FLOAT_OES : null, _24 = t67.FLOAT, F32 = t67.RGBA), { internalFormatFloat: e36, internalFormatHalfFloat: a71, internalFormatPackedHalfFloat: n67, internalFormatPackedFloat: A35, textureFormatFloat: i88, downloadTextureFormat: F32, downloadUnpackNumChannels: l80, defaultNumChannels: E44, textureTypeHalfFloat: D42, textureTypeFloat: _24 };
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/webgl_util.mjs
function o41(e36, r56) {
  let t67 = r56();
  return l().getBool("DEBUG") && I26(e36), t67;
}
function I26(e36) {
  let r56 = e36.getError();
  if (r56 !== e36.NO_ERROR) throw new Error("WebGL Error: " + D18(e36, r56));
}
var l51 = 596e-10;
var C14 = 65504;
function H9(e36) {
  return !!(l().getBool("WEBGL_RENDER_FLOAT32_ENABLED") || e36 === 0 || l51 < Math.abs(e36) && Math.abs(e36) < C14);
}
function D18(e36, r56) {
  switch (r56) {
    case e36.NO_ERROR:
      return "NO_ERROR";
    case e36.INVALID_ENUM:
      return "INVALID_ENUM";
    case e36.INVALID_VALUE:
      return "INVALID_VALUE";
    case e36.INVALID_OPERATION:
      return "INVALID_OPERATION";
    case e36.INVALID_FRAMEBUFFER_OPERATION:
      return "INVALID_FRAMEBUFFER_OPERATION";
    case e36.OUT_OF_MEMORY:
      return "OUT_OF_MEMORY";
    case e36.CONTEXT_LOST_WEBGL:
      return "CONTEXT_LOST_WEBGL";
    default:
      return `Unknown error code ${r56}`;
  }
}
function y28(e36, r56) {
  return s44(e36, () => e36.getExtension(r56), 'Extension "' + r56 + '" not supported on this browser.');
}
function z23(e36, r56) {
  let t67 = s44(e36, () => e36.createShader(e36.VERTEX_SHADER), "Unable to create vertex WebGLShader.");
  if (o41(e36, () => e36.shaderSource(t67, r56)), o41(e36, () => e36.compileShader(t67)), e36.getShaderParameter(t67, e36.COMPILE_STATUS) === false) throw console.log(e36.getShaderInfoLog(t67)), new Error("Failed to compile vertex shader.");
  return t67;
}
function V13(e36, r56) {
  let t67 = s44(e36, () => e36.createShader(e36.FRAGMENT_SHADER), "Unable to create fragment WebGLShader.");
  if (o41(e36, () => e36.shaderSource(t67, r56)), o41(e36, () => e36.compileShader(t67)), l().get("ENGINE_COMPILE_ONLY")) return t67;
  if (e36.getShaderParameter(t67, e36.COMPILE_STATUS) === false) throw X14(r56, e36.getShaderInfoLog(t67)), new Error("Failed to compile fragment shader.");
  return t67;
}
var P18 = /ERROR: [0-9]+:([0-9]+):/g;
function X14(e36, r56) {
  let t67 = P18.exec(r56);
  if (t67 == null) {
    console.log(`Couldn't parse line number in error: ${r56}`), console.log(e36);
    return;
  }
  let n67 = +t67[1], i88 = e36.split(`
`), u86 = i88.length.toString().length + 2, f85 = i88.map((x76, B30) => util_exports.rightPad((B30 + 1).toString(), u86) + x76), E44 = 0;
  for (let x76 = 0; x76 < f85.length; x76++) E44 = Math.max(f85[x76].length, E44);
  let T40 = f85.slice(0, n67 - 1), _24 = f85.slice(n67 - 1, n67), d55 = f85.slice(n67);
  console.log(T40.join(`
`)), console.log(r56.split(`
`)[0]), console.log(`%c ${util_exports.rightPad(_24[0], E44)}`, "border:1px solid red; background-color:#e3d2d2; color:#a61717"), console.log(d55.join(`
`));
}
function q15(e36) {
  return s44(e36, () => e36.createProgram(), "Unable to create WebGLProgram.");
}
function $31(e36, r56) {
  if (o41(e36, () => e36.linkProgram(r56)), !l().get("ENGINE_COMPILE_ONLY") && e36.getProgramParameter(r56, e36.LINK_STATUS) === false) throw console.log(e36.getProgramInfoLog(r56)), new Error("Failed to link vertex and fragment shaders.");
}
function k31(e36, r56) {
  if (o41(e36, () => e36.validateProgram(r56)), e36.getProgramParameter(r56, e36.VALIDATE_STATUS) === false) throw console.log(e36.getProgramInfoLog(r56)), new Error("Shader program validation failed.");
}
function p61(e36, r56) {
  let t67 = s44(e36, () => e36.createBuffer(), "Unable to create WebGLBuffer");
  return o41(e36, () => e36.bindBuffer(e36.ARRAY_BUFFER, t67)), o41(e36, () => e36.bufferData(e36.ARRAY_BUFFER, r56, e36.STATIC_DRAW)), t67;
}
function Y8(e36, r56) {
  let t67 = s44(e36, () => e36.createBuffer(), "Unable to create WebGLBuffer");
  return o41(e36, () => e36.bindBuffer(e36.ELEMENT_ARRAY_BUFFER, t67)), o41(e36, () => e36.bufferData(e36.ELEMENT_ARRAY_BUFFER, r56, e36.STATIC_DRAW)), t67;
}
function j15() {
  return l().getNumber("WEBGL_VERSION") === 2 ? 1 : 4;
}
function Z10(e36) {
  return s44(e36, () => e36.createTexture(), "Unable to create WebGLTexture.");
}
function Q7(e36, r56) {
  let t67 = l().getNumber("WEBGL_MAX_TEXTURE_SIZE");
  if (e36 <= 0 || r56 <= 0) {
    let n67 = `[${e36}x${r56}]`;
    throw new Error("Requested texture size " + n67 + " is invalid.");
  }
  if (e36 > t67 || r56 > t67) {
    let n67 = `[${e36}x${r56}]`, i88 = `[${t67}x${t67}]`;
    throw new Error("Requested texture size " + n67 + " greater than WebGL maximum on this browser / GPU " + i88 + ".");
  }
}
function K14(e36) {
  return s44(e36, () => e36.createFramebuffer(), "Unable to create WebGLFramebuffer.");
}
function J9(e36, r56, t67, n67, i88, u86, f85) {
  let E44 = e36.getAttribLocation(r56, t67);
  return E44 === -1 ? false : (o41(e36, () => e36.bindBuffer(e36.ARRAY_BUFFER, n67)), o41(e36, () => e36.vertexAttribPointer(E44, i88, e36.FLOAT, false, u86, f85)), o41(e36, () => e36.enableVertexAttribArray(E44)), true);
}
function w27(e36, r56, t67) {
  L14(e36, t67), o41(e36, () => e36.activeTexture(e36.TEXTURE0 + t67)), o41(e36, () => e36.bindTexture(e36.TEXTURE_2D, r56));
}
function g49(e36, r56) {
  L14(e36, r56), o41(e36, () => e36.activeTexture(e36.TEXTURE0 + r56)), o41(e36, () => e36.bindTexture(e36.TEXTURE_2D, null));
}
function ee3(e36, r56, t67) {
  return s44(e36, () => e36.getUniformLocation(r56, t67), 'uniform "' + t67 + '" not present in program.');
}
function re3(e36, r56, t67) {
  return e36.getUniformLocation(r56, t67);
}
function te3(e36, r56, t67, n67) {
  o41(e36, () => w27(e36, r56, n67)), o41(e36, () => e36.uniform1i(t67, n67));
}
function ne3(e36) {
  o41(e36, () => e36.bindFramebuffer(e36.FRAMEBUFFER, null)), o41(e36, () => e36.viewport(0, 0, e36.canvas.width, e36.canvas.height)), o41(e36, () => e36.scissor(0, 0, e36.canvas.width, e36.canvas.height));
}
function oe3(e36, r56, t67) {
  o41(e36, () => e36.bindFramebuffer(e36.FRAMEBUFFER, t67)), o41(e36, () => e36.framebufferTexture2D(e36.FRAMEBUFFER, e36.COLOR_ATTACHMENT0, e36.TEXTURE_2D, r56, 0));
}
function ue2(e36, r56) {
  o41(e36, () => e36.bindFramebuffer(e36.FRAMEBUFFER, r56)), o41(e36, () => e36.framebufferTexture2D(e36.FRAMEBUFFER, e36.COLOR_ATTACHMENT0, e36.TEXTURE_2D, null, 0));
}
function ie4(e36) {
  let r56 = e36.checkFramebufferStatus(e36.FRAMEBUFFER);
  if (r56 !== e36.FRAMEBUFFER_COMPLETE) throw new Error("Error binding framebuffer: " + h53(e36, r56));
}
function h53(e36, r56) {
  switch (r56) {
    case e36.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";
    case e36.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";
    case e36.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:
      return "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";
    case e36.FRAMEBUFFER_UNSUPPORTED:
      return "FRAMEBUFFER_UNSUPPORTED";
    default:
      return `unknown error ${r56}`;
  }
}
function s44(e36, r56, t67) {
  let n67 = o41(e36, () => r56());
  if (n67 == null) throw new Error(t67);
  return n67;
}
function L14(e36, r56) {
  let t67 = e36.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1, n67 = r56 + e36.TEXTURE0;
  if (n67 < e36.TEXTURE0 || n67 > t67) {
    let i88 = `[gl.TEXTURE0, gl.TEXTURE${t67}]`;
    throw new Error(`textureUnit must be in ${i88}.`);
  }
}
function N36(e36, r56 = 2) {
  return util_exports.sizeFromShape(e36.slice(0, e36.length - r56));
}
function O15(e36) {
  if (e36.length === 0) throw Error("Cannot get rows and columns of an empty shape array.");
  return [e36.length > 1 ? e36[e36.length - 2] : 1, e36[e36.length - 1]];
}
function fe(e36) {
  let r56 = [1, 1, 1];
  return e36.length === 0 || e36.length === 1 && e36[0] === 1 || (r56 = [N36(e36), ...O15(e36)]), r56;
}
function Ee(e36, r56 = false) {
  let t67 = l().getNumber("WEBGL_MAX_TEXTURE_SIZE"), n67 = l().getNumber("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE");
  n67 === 1 / 0 && l().getBool("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE") && (n67 = t67 / 2), r56 && (t67 = t67 * 2, n67 = n67 * 2, e36 = e36.map((E44, T40) => T40 >= e36.length - 2 ? util_exports.nearestLargerEven(e36[T40]) : e36[T40]), e36.length === 1 && (e36 = [2, e36[0]])), e36.length !== 2 && (e36 = util_exports.squeezeShape(e36).newShape);
  let i88 = util_exports.sizeFromShape(e36), u86 = null;
  e36.length <= 1 && i88 <= t67 ? u86 = [1, i88] : e36.length === 2 && e36[0] <= t67 && e36[1] <= t67 ? u86 = e36 : e36.length === 3 && e36[0] * e36[1] <= t67 && e36[2] <= t67 ? u86 = [e36[0] * e36[1], e36[2]] : e36.length === 3 && e36[0] <= t67 && e36[1] * e36[2] <= t67 ? u86 = [e36[0], e36[1] * e36[2]] : e36.length === 4 && e36[0] * e36[1] * e36[2] <= t67 && e36[3] <= t67 ? u86 = [e36[0] * e36[1] * e36[2], e36[3]] : e36.length === 4 && e36[0] <= t67 && e36[1] * e36[2] * e36[3] <= t67 && (u86 = [e36[0], e36[1] * e36[2] * e36[3]]);
  let f85 = u86 != null && Math.max(...u86) > n67 && Math.min(...u86) <= (r56 ? 2 : 1) && Math.min(...u86) > 0;
  if (u86 == null || f85) if (r56) {
    let E44 = N36(e36), T40 = 2, _24 = 2;
    e36.length && ([T40, _24] = O15(e36)), i88 = E44 * (T40 / 2) * (_24 / 2), u86 = util_exports.sizeToSquarishShape(i88).map((d55) => d55 * 2);
  } else u86 = util_exports.sizeToSquarishShape(i88);
  return u86;
}
function m70(e36) {
  return e36 % 2 === 0;
}
function ae2(e36, r56) {
  if (e36 = e36.slice(-2), r56 = r56.slice(-2), util_exports.arraysEqual(e36, r56) || !e36.length || !r56.length || e36[0] === 0 || e36[1] === 0 || r56[0] === 0 || r56[1] === 0) return true;
  if (e36.length !== r56.length) {
    let t67 = e36[e36.length - 1], n67 = r56[r56.length - 1];
    if (t67 === n67 || m70(t67) && m70(n67) && (e36[0] === 1 || r56[0] === 1)) return true;
  }
  return e36[1] === r56[1] && m70(e36[0]) && m70(r56[0]);
}
var A24;
var b32;
function ce2(e36) {
  if (A24 == null) {
    let r56 = f62(e36);
    A24 = r56.getParameter(r56.MAX_TEXTURE_SIZE);
  }
  return A24;
}
function se2() {
  A24 = null;
}
function Te() {
  b32 = null;
}
function Fe(e36) {
  if (b32 == null) {
    let r56 = f62(e36);
    b32 = r56.getParameter(r56.MAX_TEXTURE_IMAGE_UNITS);
  }
  return Math.min(16, b32);
}
function Re2(e36) {
  if (e36 === 0) return 0;
  let r56, t67 = f62(e36);
  return F21(t67, "EXT_disjoint_timer_query_webgl2") && e36 === 2 ? r56 = 2 : F21(t67, "EXT_disjoint_timer_query") ? r56 = 1 : r56 = 0, r56;
}
function F21(e36, r56) {
  return e36.getExtension(r56) != null;
}
function xe2(e36) {
  try {
    if (f62(e36) != null) return true;
  } catch (r56) {
    return console.log("Error when getting WebGL context: ", r56), false;
  }
  return false;
}
function _e(e36) {
  if (e36 === 0) return false;
  let r56 = f62(e36);
  if (e36 === 1) {
    if (!F21(r56, "OES_texture_float")) return false;
  } else if (!F21(r56, "EXT_color_buffer_float")) return false;
  return U11(r56);
}
function me2(e36) {
  if (e36 === 0) return false;
  let r56 = f62(e36);
  if (e36 === 1) {
    if (!F21(r56, "OES_texture_float") || !F21(r56, "WEBGL_color_buffer_float")) return false;
  } else {
    if (F21(r56, "EXT_color_buffer_float")) return U11(r56);
    let n67 = "EXT_color_buffer_half_float";
    if (F21(r56, n67)) {
      let i88 = r56.getExtension(n67);
      return S28(r56, i88);
    }
    return false;
  }
  return U11(r56);
}
function U11(e36) {
  let r56 = G18(e36), t67 = e36.createTexture();
  e36.bindTexture(e36.TEXTURE_2D, t67), e36.texImage2D(e36.TEXTURE_2D, 0, r56.internalFormatFloat, 1, 1, 0, r56.textureFormatFloat, r56.textureTypeFloat, null);
  let u86 = e36.createFramebuffer();
  e36.bindFramebuffer(e36.FRAMEBUFFER, u86), e36.framebufferTexture2D(e36.FRAMEBUFFER, e36.COLOR_ATTACHMENT0, e36.TEXTURE_2D, t67, 0);
  let f85 = e36.checkFramebufferStatus(e36.FRAMEBUFFER) === e36.FRAMEBUFFER_COMPLETE;
  return e36.bindTexture(e36.TEXTURE_2D, null), e36.bindFramebuffer(e36.FRAMEBUFFER, null), e36.deleteTexture(t67), e36.deleteFramebuffer(u86), f85;
}
function S28(e36, r56) {
  let t67 = G18(e36, r56), n67 = e36.createTexture();
  e36.bindTexture(e36.TEXTURE_2D, n67), e36.texImage2D(e36.TEXTURE_2D, 0, t67.internalFormatHalfFloat, 1, 1, 0, t67.textureFormatFloat, t67.textureTypeHalfFloat, null);
  let f85 = e36.createFramebuffer();
  e36.bindFramebuffer(e36.FRAMEBUFFER, f85), e36.framebufferTexture2D(e36.FRAMEBUFFER, e36.COLOR_ATTACHMENT0, e36.TEXTURE_2D, n67, 0);
  let E44 = e36.checkFramebufferStatus(e36.FRAMEBUFFER) === e36.FRAMEBUFFER_COMPLETE;
  return e36.bindTexture(e36.TEXTURE_2D, null), e36.bindFramebuffer(e36.FRAMEBUFFER, null), e36.deleteTexture(n67), e36.deleteFramebuffer(f85), E44;
}
function Ae(e36) {
  return e36 !== 2 ? false : f62(e36).fenceSync != null;
}
function be(e36, r56) {
  Array.isArray(e36) || (e36 = [e36]), e36.forEach((t67) => {
    t67 != null && util_exports.assert(t67.dtype !== "complex64", () => `${r56} does not support complex64 tensors in the WebGL backend.`);
  });
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/flags_webgl.mjs
var E32 = l();
E32.registerFlag("HAS_WEBGL", () => E32.getNumber("WEBGL_VERSION") > 0);
E32.registerFlag("WEBGL_VERSION", () => xe2(2) ? 2 : xe2(1) ? 1 : 0);
E32.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS", () => false);
E32.registerFlag("WEBGL_BUFFER_SUPPORTED", () => E32.get("WEBGL_VERSION") === 2);
E32.registerFlag("WEBGL_CPU_FORWARD", () => true);
E32.registerFlag("WEBGL_FORCE_F16_TEXTURES", () => false);
E32.registerFlag("WEBGL_PACK", () => E32.getBool("HAS_WEBGL"));
E32.registerFlag("WEBGL_PACK_NORMALIZATION", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_PACK_CLIP", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_PACK_DEPTHWISECONV", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_PACK_BINARY_OPERATIONS", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_PACK_UNARY_OPERATIONS", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_PACK_REDUCE", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_LAZILY_UNPACK", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_CONV_IM2COL", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_PACK_CONV2DTRANSPOSE", () => E32.getBool("WEBGL_PACK"));
E32.registerFlag("WEBGL_MAX_TEXTURE_SIZE", () => ce2(E32.getNumber("WEBGL_VERSION")));
E32.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER", () => Fe(E32.getNumber("WEBGL_VERSION")));
E32.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION", () => {
  let e36 = E32.getNumber("WEBGL_VERSION");
  return e36 === 0 ? 0 : Re2(e36);
});
E32.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE", () => E32.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 && !device_util_exports.isMobile());
E32.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE", () => _e(E32.getNumber("WEBGL_VERSION")));
E32.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED", () => E32.getBool("WEBGL_FORCE_F16_TEXTURES") ? false : E32.getBool("WEBGL_RENDER_FLOAT32_CAPABLE"));
E32.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED", () => me2(E32.getNumber("WEBGL_VERSION")));
E32.registerFlag("WEBGL_FENCE_API_ENABLED", () => Ae(E32.getNumber("WEBGL_VERSION")));
E32.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM", () => E32.getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? 4 : 0);
E32.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD", () => -1, (e36) => {
  if (typeof e36 != "number") throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be a number but got ${e36}.`);
  if (e36 < 0 && e36 !== -1) throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${e36}.`);
});
E32.registerFlag("WEBGL_FLUSH_THRESHOLD", () => device_util_exports.isMobile() ? 1 : -1, (e36) => {
  if (typeof e36 != "number") throw new Error(`WEBGL_FLUSH_THRESHOLD must be a number but got ${e36}.`);
  if (e36 < 0 && e36 !== -1) throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${e36}.`);
});
E32.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD", () => 128);
E32.registerFlag("WEBGL_USE_SHAPES_UNIFORMS", () => false);
E32.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD", () => 1e5);
E32.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD", () => 128);
E32.registerFlag("WEBGL_EXP_CONV", () => false);
E32.registerFlag("SOFTWARE_WEBGL_ENABLED", () => E32.getBool("IS_TEST"));
E32.registerFlag("WEBGL_MAX_SIZE_FOR_NARROW_TEXTURE", () => 1 / 0);
E32.registerFlag("WEBGL_AUTO_SQUARIFY_NARROW_TEXTURE_SHAPE", () => false);
E32.registerFlag("WEBGL2_ISNAN_CUSTOM", () => false);
E32.registerFlag("ENGINE_COMPILE_ONLY", () => false);

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/glsl_version.mjs
function c71() {
  let e36, n67, t67, a71, l80, u86, o80, v42, i88, r56;
  return l().getNumber("WEBGL_VERSION") === 2 ? (e36 = "#version 300 es", n67 = "in", t67 = "out", a71 = "in", l80 = "texture", u86 = "outputColor", o80 = "out vec4 outputColor;", v42 = l().getBool("WEBGL2_ISNAN_CUSTOM") ? `
      bool isnan_custom(float val) {
        uint floatToUint = floatBitsToUint(val);
        return (floatToUint & 0x7fffffffu) > 0x7f800000u;
      }

      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan_custom(val.x),
          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));
      }

      #define isnan(value) isnan_custom(value)
    ` : "", i88 = "", r56 = `
      #define round(value) newRound(value)
      int newRound(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 newRound(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `) : (e36 = "", n67 = "attribute", t67 = "varying", a71 = "varying", l80 = "texture2D", u86 = "gl_FragColor", o80 = "", v42 = `
      #define isnan(value) isnan_custom(value)
      bool isnan_custom(float val) {
        return (val > 0. || val < 1. || val == 0.) ? false : true;
      }
      bvec4 isnan_custom(vec4 val) {
        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));
      }
    `, i88 = `
      uniform float INFINITY;

      bool isinf(float val) {
        return abs(val) == INFINITY;
      }
      bvec4 isinf(vec4 val) {
        return equal(abs(val), vec4(INFINITY));
      }
    `, r56 = `
      int round(float value) {
        return int(floor(value + 0.5));
      }

      ivec4 round(vec4 value) {
        return ivec4(floor(value + vec4(0.5)));
      }
    `), { version: e36, attribute: n67, varyingVs: t67, varyingFs: a71, texture2D: l80, output: u86, defineOutput: o80, defineSpecialNaN: v42, defineSpecialInf: i88, defineRound: r56 };
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/shader_compiler_util.mjs
function p62(e36, i88, o80 = "index") {
  let c103 = util_exports.computeStrides(i88);
  return c103.map((r56, t67) => {
    let n67 = `int ${e36[t67]} = ${o80} / ${r56}`, l80 = t67 === c103.length - 1 ? `int ${e36[t67 + 1]} = ${o80} - ${e36[t67]} * ${r56}` : `index -= ${e36[t67]} * ${r56}`;
    return `${n67}; ${l80};`;
  }).join("");
}
function h54(e36, i88, o80 = "index") {
  let c103 = util_exports.computeStrides(i88);
  return c103.map((r56, t67) => {
    let n67 = `int ${e36[t67]} = ${o80} / outShapeStrides[${t67}]`, l80 = t67 === c103.length - 1 ? `int ${e36[t67 + 1]} = ${o80} - ${e36[t67]} * outShapeStrides[${t67}]` : `index -= ${e36[t67]} * outShapeStrides[${t67}]`;
    return `${n67}; ${l80};`;
  }).join("");
}
function u60(e36, i88) {
  let o80 = e36.length, c103 = e36.map((t67) => `${i88}[${t67}]`), r56 = new Array(o80 - 1);
  r56[o80 - 2] = c103[o80 - 1];
  for (let t67 = o80 - 3; t67 >= 0; --t67) r56[t67] = `(${r56[t67 + 1]} * ${c103[t67 + 1]})`;
  return r56;
}
function g50(e36, i88, o80 = "index") {
  let c103 = e36.map((t67, n67) => n67), r56 = u60(c103, i88);
  return r56.map((t67, n67) => {
    let l80 = `int ${e36[n67]} = ${o80} / ${r56[n67]}`, $37 = n67 === r56.length - 1 ? `int ${e36[n67 + 1]} = ${o80} - ${e36[n67]} * ${r56[n67]}` : `index -= ${e36[n67]} * ${r56[n67]}`;
    return `${l80}; ${$37};`;
  }).join("");
}
function d28(e36) {
  let i88 = util_exports.computeStrides(e36).map((o80) => o80.toString());
  return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * ${i88[0]} + coords.y * ${i88[1]} + coords.z;
  }
`;
}
function v30() {
  return `
  int getFlatIndex(ivec3 coords) {
    return coords.x * outShapeStrides[0] + coords.y * outShapeStrides[1] + coords.z;
  }
`;
}
var S29 = `
  const float FLOAT_MAX = 1.70141184e38;
  const float FLOAT_MIN = 1.17549435e-38;

  lowp vec4 encode_float(highp float v) {
    if (isnan(v)) {
      return vec4(255, 255, 255, 255);
    }

    highp float av = abs(v);

    if(av < FLOAT_MIN) {
      return vec4(0.0, 0.0, 0.0, 0.0);
    } else if(v > FLOAT_MAX) {
      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;
    } else if(v < -FLOAT_MAX) {
      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;
    }

    highp vec4 c = vec4(0,0,0,0);

    highp float e = floor(log2(av));
    highp float m = exp2(fract(log2(av))) - 1.0;

    c[2] = floor(128.0 * m);
    m -= c[2] / 128.0;
    c[1] = floor(32768.0 * m);
    m -= c[1] / 32768.0;
    c[0] = floor(8388608.0 * m);

    highp float ebias = e + 127.0;
    c[3] = floor(ebias / 2.0);
    ebias -= c[3] * 2.0;
    c[2] += floor(ebias) * 128.0;

    c[3] += 128.0 * step(0.0, -v);

    return c / 255.0;
  }
`;

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/shader_compiler.mjs
var { getBroadcastDims: O16 } = backend_util_exports;
function fe2(e36, n67, r56) {
  let t67 = [];
  if (e36.forEach((a71) => {
    let h74 = util_exports.sizeFromShape(a71.shapeInfo.logicalShape);
    if (a71.shapeInfo.isUniform ? t67.push(`uniform float ${a71.name}${h74 > 1 ? `[${h74}]` : ""};`) : (t67.push(`uniform sampler2D ${a71.name};`), t67.push(`uniform int offset${a71.name};`)), r56.enableShapeUniforms) {
      let { uniformShape: v42 } = he(r56.packedInputs, a71.shapeInfo.logicalShape, a71.shapeInfo.texShape);
      switch (v42.length) {
        case 1:
          t67.push(`uniform int ${a71.name}Shape;`);
          break;
        case 2:
          t67.push(`uniform ivec2 ${a71.name}Shape;`);
          break;
        case 3:
          t67.push(`uniform ivec3 ${a71.name}Shape;`);
          break;
        case 4:
          t67.push(`uniform ivec4 ${a71.name}Shape;`);
          break;
        default:
          break;
      }
      t67.push(`uniform ivec2 ${a71.name}TexShape;`);
    }
  }), r56.enableShapeUniforms) {
    switch (n67.logicalShape.length) {
      case 1:
        t67.push("uniform int outShape;");
        break;
      case 2:
        t67.push("uniform ivec2 outShape;"), t67.push("uniform int outShapeStrides;");
        break;
      case 3:
        t67.push("uniform ivec3 outShape;"), t67.push("uniform ivec2 outShapeStrides;");
        break;
      case 4:
        t67.push("uniform ivec4 outShape;"), t67.push("uniform ivec3 outShapeStrides;");
        break;
      default:
        break;
    }
    t67.push("uniform ivec2 outTexShape;");
  }
  r56.customUniforms && r56.customUniforms.forEach((a71) => {
    t67.push(`uniform ${a71.type} ${a71.name}${a71.arrayIndex ? `[${a71.arrayIndex}]` : ""};`);
  });
  let o80 = t67.join(`
`), c103 = e36.map((a71) => U12(a71, n67, r56.packedInputs, r56.enableShapeUniforms)).join(`
`), i88 = n67.texShape, u86 = c71(), s84 = z24(u86), l80, x76, d55 = M20(u86);
  return n67.isPacked ? (l80 = P19(n67.logicalShape, i88, r56.enableShapeUniforms), x76 = L15(u86)) : (l80 = E33(n67.logicalShape, i88, r56.enableShapeUniforms), x76 = A25(u86)), r56.packedInputs && (d55 += _18), [d55, s84, x76, o80, l80, c103, r56.userCode].join(`
`);
}
function w28(e36, n67 = false) {
  let r56 = e36.shapeInfo.logicalShape;
  switch (r56.length) {
    case 0:
      return te4(e36, n67);
    case 1:
      return re4(e36, n67);
    case 2:
      return ce3(e36, n67);
    case 3:
      return ae3(e36, n67);
    case 4:
      return se3(e36, n67);
    case 5:
      return le2(e36);
    case 6:
      return xe3(e36);
    default:
      throw new Error(`${r56.length}-D input sampling is not yet supported`);
  }
}
function D19(e36, n67) {
  switch (e36.shapeInfo.logicalShape.length) {
    case 0:
      return ee4(e36);
    case 1:
      return ne4(e36, n67);
    case 2:
      return oe4(e36, n67);
    case 3:
      return ie5(e36, n67);
    default:
      return ue3(e36, n67);
  }
}
function U12(e36, n67, r56 = false, t67) {
  let o80 = "";
  r56 ? o80 += D19(e36, t67) : o80 += w28(e36, t67);
  let c103 = e36.shapeInfo.logicalShape, i88 = n67.logicalShape;
  return c103.length <= i88.length && (r56 ? o80 += pe2(e36, n67) : o80 += de2(e36, n67)), o80;
}
function P19(e36, n67, r56) {
  switch (e36.length) {
    case 0:
      return I27();
    case 1:
      return j16(e36, n67, r56);
    case 2:
      return Y9(e36, n67, r56);
    case 3:
      return G19(e36, n67, r56);
    default:
      return J10(e36, n67, r56);
  }
}
function E33(e36, n67, r56) {
  switch (e36.length) {
    case 0:
      return I27();
    case 1:
      return H10(e36, n67, r56);
    case 2:
      return Z11(e36, n67, r56);
    case 3:
      return X15(e36, n67, r56);
    case 4:
      return K15(e36, n67, r56);
    case 5:
      return W11(e36, n67);
    case 6:
      return Q8(e36, n67);
    default:
      throw new Error(`${e36.length}-D output sampling is not yet supported`);
  }
}
function z24(e36) {
  return `
    float sampleTexture(sampler2D textureSampler, vec2 uv) {
      return ${e36.texture2D}(textureSampler, uv).r;
    }
  `;
}
function A25(e36) {
  return `
    void setOutput(float val) {
      ${e36.output} = vec4(val, 0, 0, 0);
    }
  `;
}
function L15(e36) {
  return `
    void setOutput(vec4 val) {
      ${e36.output} = val;
    }
  `;
}
function M20(e36) {
  return `${e36.version}
    precision highp float;
    precision highp int;
    precision highp sampler2D;
    ${e36.varyingFs} vec2 resultUV;
    ${e36.defineOutput}
    const vec2 halfCR = vec2(0.5, 0.5);

    struct ivec5
    {
      int x;
      int y;
      int z;
      int w;
      int u;
    };

    struct ivec6
    {
      int x;
      int y;
      int z;
      int w;
      int u;
      int v;
    };

    uniform float NAN;
    ${e36.defineSpecialNaN}
    ${e36.defineSpecialInf}
    ${e36.defineRound}

    int imod(int x, int y) {
      return x - y * (x / y);
    }

    int idiv(int a, int b, float sign) {
      int res = a / b;
      int mod = imod(a, b);
      if (sign < 0. && mod != 0) {
        res -= 1;
      }
      return res;
    }

    //Based on the work of Dave Hoskins
    //https://www.shadertoy.com/view/4djSRW
    #define HASHSCALE1 443.8975
    float random(float seed){
      vec2 p = resultUV * seed;
      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);
      p3 += dot(p3, p3.yzx + 19.19);
      return fract((p3.x + p3.y) * p3.z);
    }

    ${B18}
    ${b33}
    ${q16}
  `;
}
var B18 = `
vec2 uvFromFlat(int texNumR, int texNumC, int index) {
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
vec2 packedUVfrom1D(int texNumR, int texNumC, int index) {
  int texelIndex = index / 2;
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var b33 = `
vec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,
  int texNumC, int row, int col) {
  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = texelIndex / texNumC;
  int texC = texelIndex - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var q16 = `
vec2 packedUVfrom3D(int texNumR, int texNumC,
    int texelsInBatch, int texelsInLogicalRow, int b,
    int row, int col) {
  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);
  int texR = index / texNumC;
  int texC = index - texR * texNumC;
  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);
}
`;
var _18 = `
  float getChannel(vec4 frag, vec2 innerDims) {
    vec2 modCoord = mod(innerDims, 2.);
    return modCoord.x == 0. ?
      (modCoord.y == 0. ? frag.r : frag.g) :
      (modCoord.y == 0. ? frag.b : frag.a);
  }
  float getChannel(vec4 frag, int dim) {
    float modCoord = mod(float(dim), 2.);
    return modCoord == 0. ? frag.r : frag.g;
  }
`;
function I27() {
  return `
    int getOutputCoords() {
      return 0;
    }
  `;
}
function j16(e36, n67, r56) {
  let t67 = [Math.ceil(n67[0] / 2), Math.ceil(n67[1] / 2)];
  return t67[0] === 1 ? r56 ? `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));
      }
    ` : `
      int getOutputCoords() {
        return 2 * int(resultUV.x * ${t67[1]}.0);
      }
    ` : t67[1] === 1 ? r56 ? `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));
      }
    ` : `
      int getOutputCoords() {
        return 2 * int(resultUV.y * ${t67[0]}.0);
      }
    ` : r56 ? `
    int getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);
    }
  ` : `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${t67[0]}, ${t67[1]}));
      return 2 * (resTexRC.x * ${t67[1]} + resTexRC.y);
    }
  `;
}
function H10(e36, n67, r56) {
  return n67[0] === 1 ? r56 ? `
      int getOutputCoords() {
        return int(resultUV.x * float(outTexShape[1]));
      }
    ` : `
      int getOutputCoords() {
        return int(resultUV.x * ${n67[1]}.0);
      }
    ` : n67[1] === 1 ? r56 ? `
      int getOutputCoords() {
        return int(resultUV.y * float(outTexShape[0]));
      }
    ` : `
      int getOutputCoords() {
        return int(resultUV.y * ${n67[0]}.0);
      }
    ` : r56 ? `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(outTexShape[0], outTexShape[1]));
      return resTexRC.x * outTexShape[1] + resTexRC.y;
    }
  ` : `
    int getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${n67[0]}, ${n67[1]}));
      return resTexRC.x * ${n67[1]} + resTexRC.y;
    }
  `;
}
function G19(e36, n67, r56) {
  if (r56) return `
    ivec3 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));
      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;

      int b = index / texelsInBatch;
      index -= b * texelsInBatch;

      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec3(b, r, c);
    }
  `;
  let t67 = [Math.ceil(n67[0] / 2), Math.ceil(n67[1] / 2)], o80 = Math.ceil(e36[2] / 2), c103 = o80 * Math.ceil(e36[1] / 2);
  return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${t67[0]}, ${t67[1]}));
      int index = resTexRC.x * ${t67[1]} + resTexRC.y;

      int b = index / ${c103};
      index -= b * ${c103};

      int r = 2 * (index / ${o80});
      int c = imod(index, ${o80}) * 2;

      return ivec3(b, r, c);
    }
  `;
}
function X15(e36, n67, r56) {
  if (r56) return `
  ivec3 getOutputCoords() {
    ivec2 resTexRC = ivec2(resultUV.yx *
                           vec2(outTexShape[0], outTexShape[1]));
    int index = resTexRC.x * outTexShape[1] + resTexRC.y;
    ${h54(["r", "c", "d"], e36)}
    return ivec3(r, c, d);
  }
`;
  let t67 = p62(["r", "c", "d"], e36);
  return `
    ivec3 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${n67[0]}, ${n67[1]}));
      int index = resTexRC.x * ${n67[1]} + resTexRC.y;
      ${t67}
      return ivec3(r, c, d);
    }
  `;
}
function J10(e36, n67, r56) {
  if (r56) return `
    ivec4 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));
      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;

      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));
      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));
      int texelsInBatchN = texelsInBatch * outShape[1];

      int b2 = index / texelsInBatchN;
      index -= b2 * texelsInBatchN;

      int b = index / texelsInBatch;
      index -= b * texelsInBatch;

      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec4(b2, b, r, c);
    }
  `;
  let t67 = [Math.ceil(n67[0] / 2), Math.ceil(n67[1] / 2)], o80 = Math.ceil(e36[e36.length - 1] / 2), c103 = o80 * Math.ceil(e36[e36.length - 2] / 2), i88 = c103, u86 = "", s84 = "b, r, c";
  for (let l80 = 2; l80 < e36.length - 1; l80++) i88 *= e36[e36.length - l80 - 1], u86 = `
      int b${l80} = index / ${i88};
      index -= b${l80} * ${i88};
    ` + u86, s84 = `b${l80}, ` + s84;
  return `
    ivec${e36.length} getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${t67[0]}, ${t67[1]}));
      int index = resTexRC.x * ${t67[1]} + resTexRC.y;

      ${u86}

      int b = index / ${c103};
      index -= b * ${c103};

      int r = 2 * (index / ${o80});
      int c = imod(index, ${o80}) * 2;

      return ivec${e36.length}(${s84});
    }
  `;
}
function K15(e36, n67, r56) {
  if (r56) return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(outTexShape[0], outTexShape[1]));
      int index = resTexRC.x * outTexShape[1] + resTexRC.y;
      ${h54(["r", "c", "d", "d2"], e36)}
      return ivec4(r, c, d, d2);
    }
  `;
  let t67 = p62(["r", "c", "d", "d2"], e36);
  return `
    ivec4 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${n67[0]}, ${n67[1]}));
      int index = resTexRC.x * ${n67[1]} + resTexRC.y;
      ${t67}
      return ivec4(r, c, d, d2);
    }
  `;
}
function W11(e36, n67) {
  let r56 = p62(["r", "c", "d", "d2", "d3"], e36);
  return `
    ivec5 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${n67[0]},
                             ${n67[1]}));

      int index = resTexRC.x * ${n67[1]} + resTexRC.y;

      ${r56}

      ivec5 outShape = ivec5(r, c, d, d2, d3);
      return outShape;
    }
  `;
}
function Q8(e36, n67) {
  let r56 = p62(["r", "c", "d", "d2", "d3", "d4"], e36);
  return `
    ivec6 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
        vec2(${n67[0]}, ${n67[1]}));
      int index = resTexRC.x * ${n67[1]} + resTexRC.y;

      ${r56}

      ivec6 result = ivec6(r, c, d, d2, d3, d4);
      return result;
    }
  `;
}
function Y9(e36, n67, r56) {
  let t67 = [Math.ceil(n67[0] / 2), Math.ceil(n67[1] / 2)];
  if (util_exports.arraysEqual(e36, n67)) return r56 ? `
      ivec2 getOutputCoords() {
        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));
      }
    ` : `
      ivec2 getOutputCoords() {
        return 2 * ivec2(resultUV.yx * vec2(${t67[0]}, ${t67[1]}));
      }
    `;
  let o80 = Math.ceil(e36[1] / 2);
  return r56 ? `
    ivec2 getOutputCoords() {
      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));
      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(packedTexShape[0], packedTexShape[1]));

      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;
      int r = 2 * (index / texelsInLogicalRow);
      int c = imod(index, texelsInLogicalRow) * 2;

      return ivec2(r, c);
    }
  ` : `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${t67[0]}, ${t67[1]}));

      int index = resTexRC.x * ${t67[1]} + resTexRC.y;
      int r = 2 * (index / ${o80});
      int c = imod(index, ${o80}) * 2;

      return ivec2(r, c);
    }
  `;
}
function Z11(e36, n67, r56) {
  return util_exports.arraysEqual(e36, n67) ? r56 ? `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));
      }
    ` : `
      ivec2 getOutputCoords() {
        return ivec2(resultUV.yx * vec2(${n67[0]}, ${n67[1]}));
      }
    ` : e36[1] === 1 ? r56 ? `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(outTexShape[0], outTexShape[1]));
        int index = resTexRC.x * outTexShape[1] + resTexRC.y;
        return ivec2(index, 0);
      }
    ` : `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${n67[0]}, ${n67[1]}));
        int index = resTexRC.x * ${n67[1]} + resTexRC.y;
        return ivec2(index, 0);
      }
    ` : e36[0] === 1 ? r56 ? `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(outTexShape[0], outTexShape[1]));
        int index = resTexRC.x * outTexShape[1] + resTexRC.y;
        return ivec2(0, index);
      }
    ` : `
      ivec2 getOutputCoords() {
        ivec2 resTexRC = ivec2(resultUV.yx *
                               vec2(${n67[0]}, ${n67[1]}));
        int index = resTexRC.x * ${n67[1]} + resTexRC.y;
        return ivec2(0, index);
      }
    ` : r56 ? `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(outTexShape[0], outTexShape[1]));
      int index = resTexRC.x * outTexShape[1] + resTexRC.y;
      int r = index / outShape[1];
      int c = index - r * outShape[1];
      return ivec2(r, c);
    }
  ` : `
    ivec2 getOutputCoords() {
      ivec2 resTexRC = ivec2(resultUV.yx *
                             vec2(${n67[0]}, ${n67[1]}));
      int index = resTexRC.x * ${n67[1]} + resTexRC.y;
      int r = index / ${e36[1]};
      int c = index - r * ${e36[1]};
      return ivec2(r, c);
    }
  `;
}
function T29(e36) {
  return `offset${e36}`;
}
function ee4(e36) {
  let n67 = e36.name, r56 = "get" + n67.charAt(0).toUpperCase() + n67.slice(1), t67 = c71();
  return `
    vec4 ${r56}() {
      return ${t67.texture2D}(${n67}, halfCR);
    }
  `;
}
function te4(e36, n67) {
  let r56 = e36.name, t67 = "get" + r56.charAt(0).toUpperCase() + r56.slice(1);
  if (e36.shapeInfo.isUniform) return `float ${t67}() {return ${r56};}`;
  let [o80, c103] = e36.shapeInfo.texShape;
  if (o80 === 1 && c103 === 1) return `
      float ${t67}() {
        return sampleTexture(${r56}, halfCR);
      }
    `;
  let i88 = T29(r56);
  if (n67) return `
    float ${t67}() {
      vec2 uv = uvFromFlat(${r56}TexShape[0], ${r56}TexShape[1], ${i88});
      return sampleTexture(${r56}, uv);
    }
  `;
  let [u86, s84] = e36.shapeInfo.texShape;
  return `
    float ${t67}() {
      vec2 uv = uvFromFlat(${u86}, ${s84}, ${i88});
      return sampleTexture(${r56}, uv);
    }
  `;
}
function ne4(e36, n67) {
  let r56 = e36.name, t67 = "get" + r56.charAt(0).toUpperCase() + r56.slice(1), o80 = e36.shapeInfo.texShape, c103 = c71();
  if (n67) return `
    vec4 ${t67}(int index) {
      ivec2 packedTexShape = ivec2(ceil(float(${r56}TexShape[0]) / 2.0), ceil(float(${r56}TexShape[1]) / 2.0));
      vec2 uv = packedUVfrom1D(
        packedTexShape[0], packedTexShape[1], index);
      return ${c103.texture2D}(${r56}, uv);
    }
  `;
  let i88 = [Math.ceil(o80[0] / 2), Math.ceil(o80[1] / 2)];
  return `
    vec4 ${t67}(int index) {
      vec2 uv = packedUVfrom1D(
        ${i88[0]}, ${i88[1]}, index);
      return ${c103.texture2D}(${r56}, uv);
    }
  `;
}
function re4(e36, n67) {
  let r56 = e36.name, t67 = "get" + r56.charAt(0).toUpperCase() + r56.slice(1);
  if (e36.shapeInfo.isUniform) return `
      float ${t67}(int index) {
        ${y29(e36)}
      }
    `;
  let o80 = e36.shapeInfo.texShape, c103 = o80[0], i88 = o80[1];
  if (i88 === 1 && c103 === 1) return `
      float ${t67}(int index) {
        return sampleTexture(${r56}, halfCR);
      }
    `;
  let u86 = T29(r56);
  return i88 === 1 ? n67 ? `
      float ${t67}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${u86}) + 0.5) / float(${r56}TexShape[0]));
        return sampleTexture(${r56}, uv);
      }
    ` : `
      float ${t67}(int index) {
        vec2 uv = vec2(0.5, (float(index + ${u86}) + 0.5) / ${c103}.0);
        return sampleTexture(${r56}, uv);
      }
    ` : c103 === 1 ? n67 ? `
      float ${t67}(int index) {
        vec2 uv = vec2((float(index + ${u86}) + 0.5) / float(${r56}TexShape[1]), 0.5);
        return sampleTexture(${r56}, uv);
      }
    ` : `
      float ${t67}(int index) {
        vec2 uv = vec2((float(index + ${u86}) + 0.5) / ${i88}.0, 0.5);
        return sampleTexture(${r56}, uv);
      }
    ` : n67 ? `
    float ${t67}(int index) {
      vec2 uv = uvFromFlat(${r56}TexShape[0], ${r56}TexShape[1], index + ${u86});
      return sampleTexture(${r56}, uv);
    }
  ` : `
    float ${t67}(int index) {
      vec2 uv = uvFromFlat(${c103}, ${i88}, index + ${u86});
      return sampleTexture(${r56}, uv);
    }
  `;
}
function oe4(e36, n67) {
  let r56 = e36.shapeInfo.logicalShape, t67 = e36.name, o80 = "get" + t67.charAt(0).toUpperCase() + t67.slice(1), c103 = e36.shapeInfo.texShape, i88 = c103[0], u86 = c103[1], s84 = c71();
  if (c103 != null && util_exports.arraysEqual(r56, c103)) return n67 ? `
      vec4 ${o80}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${t67}TexShape[1], ${t67}TexShape[0]);

        return ${s84.texture2D}(${t67}, uv);
      }
    ` : `
      vec4 ${o80}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${u86}.0, ${i88}.0);

        return ${s84.texture2D}(${t67}, uv);
      }
    `;
  if (n67) return `
    vec4 ${o80}(int row, int col) {
      ivec2 packedTexShape = ivec2(ceil(float(${t67}TexShape[0]) / 2.0), ceil(float(${t67}TexShape[1]) / 2.0));
      int valuesPerRow = int(ceil(float(${t67}Shape[1]) / 2.0));
      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);
      return ${s84.texture2D}(${t67}, uv);
    }
  `;
  let l80 = [Math.ceil(c103[0] / 2), Math.ceil(c103[1] / 2)], x76 = Math.ceil(r56[1] / 2);
  return `
    vec4 ${o80}(int row, int col) {
      vec2 uv = packedUVfrom2D(${x76}, ${l80[0]}, ${l80[1]}, row, col);
      return ${s84.texture2D}(${t67}, uv);
    }
  `;
}
function ce3(e36, n67) {
  let r56 = e36.shapeInfo.logicalShape, t67 = e36.name, o80 = "get" + t67.charAt(0).toUpperCase() + t67.slice(1), c103 = e36.shapeInfo.texShape;
  if (c103 != null && util_exports.arraysEqual(r56, c103)) {
    if (n67) return `
      float ${o80}(int row, int col) {
        vec2 uv = (vec2(col, row) + halfCR) / vec2(${t67}TexShape[1], ${t67}TexShape[0]);
        return sampleTexture(${t67}, uv);
      }
    `;
    let p103 = c103[0], a71 = c103[1];
    return `
    float ${o80}(int row, int col) {
      vec2 uv = (vec2(col, row) + halfCR) / vec2(${a71}.0, ${p103}.0);
      return sampleTexture(${t67}, uv);
    }
  `;
  }
  let { newShape: i88, keptDims: u86 } = util_exports.squeezeShape(r56), s84 = i88;
  if (s84.length < r56.length) {
    let p103 = k32(e36, s84), a71 = ["row", "col"];
    return `
      ${w28(p103, n67)}
      float ${o80}(int row, int col) {
        return ${o80}(${N37(a71, u86)});
      }
    `;
  }
  if (e36.shapeInfo.isUniform) return `
      float ${o80}(int row, int col) {
        int index = round(dot(vec2(row, col), vec2(${r56[1]}, 1)));
        ${y29(e36)}
      }
    `;
  let l80 = c103[0], x76 = c103[1], d55 = T29(t67);
  return x76 === 1 ? n67 ? `
      float ${o80}(int row, int col) {
        float index = dot(vec3(row, col, ${d55}), vec3(${t67}Shape[1], 1, 1));
        vec2 uv = vec2(0.5, (index + 0.5) / float(${t67}TexShape[0]));
        return sampleTexture(${t67}, uv);
      }
    ` : `
    float ${o80}(int row, int col) {
      float index = dot(vec3(row, col, ${d55}), vec3(${r56[1]}, 1, 1));
      vec2 uv = vec2(0.5, (index + 0.5) / ${l80}.0);
      return sampleTexture(${t67}, uv);
    }
  ` : l80 === 1 ? n67 ? `
      float ${o80}(int row, int col) {
        float index = dot(vec3(row, col, ${d55}), vec3(${t67}Shape[1], 1, 1));
        vec2 uv = vec2((index + 0.5) / float(${t67}TexShape[1]), 0.5);
        return sampleTexture(${t67}, uv);
      }
    ` : `
    float ${o80}(int row, int col) {
      float index = dot(vec3(row, col, ${d55}), vec3(${r56[1]}, 1, 1));
      vec2 uv = vec2((index + 0.5) / ${x76}.0, 0.5);
      return sampleTexture(${t67}, uv);
    }
  ` : n67 ? `
      float ${o80}(int row, int col) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${t67}Shape[1] + col + ${d55};
        vec2 uv = uvFromFlat(${t67}TexShape[0], ${t67}TexShape[1], index);
        return sampleTexture(${t67}, uv);
      }
    ` : `
  float ${o80}(int row, int col) {
    // Explicitly use integer operations as dot() only works on floats.
    int index = row * ${r56[1]} + col + ${d55};
    vec2 uv = uvFromFlat(${l80}, ${x76}, index);
    return sampleTexture(${t67}, uv);
  }
`;
}
function ie5(e36, n67) {
  let r56 = e36.shapeInfo.logicalShape, t67 = e36.name, o80 = "get" + t67.charAt(0).toUpperCase() + t67.slice(1), c103 = e36.shapeInfo.texShape, i88 = [Math.ceil(c103[0] / 2), Math.ceil(c103[1] / 2)];
  if (r56[0] === 1) {
    let p103 = r56.slice(1), a71 = [1, 2], h74 = k32(e36, p103), v42 = ["b", "row", "col"];
    return `
        ${D19(h74, n67)}
        vec4 ${o80}(int b, int row, int col) {
          return ${o80}(${N37(v42, a71)});
        }
      `;
  }
  let u86 = c71();
  if (n67) return `
    vec4 ${o80}(int b, int row, int col) {
      ivec2 packedTexShape = ivec2(ceil(float(${t67}TexShape[0]) / 2.0), ceil(float(${t67}TexShape[1]) / 2.0));
      int valuesPerRow = int(ceil(float(${t67}Shape[2]) / 2.0));
      int texelsInBatch = valuesPerRow * int(ceil(float(${t67}Shape[1]) / 2.0));
      vec2 uv = packedUVfrom3D(
        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);
      return ${u86.texture2D}(${t67}, uv);
    }
  `;
  let s84 = i88[0], l80 = i88[1], x76 = Math.ceil(r56[2] / 2), d55 = x76 * Math.ceil(r56[1] / 2);
  return `
    vec4 ${o80}(int b, int row, int col) {
      vec2 uv = packedUVfrom3D(
        ${s84}, ${l80}, ${d55}, ${x76}, b, row, col);
      return ${u86.texture2D}(${t67}, uv);
    }
  `;
}
function ae3(e36, n67) {
  let r56 = e36.shapeInfo.logicalShape, t67 = e36.name, o80 = "get" + t67.charAt(0).toUpperCase() + t67.slice(1), c103 = r56[1] * r56[2], i88 = r56[2], { newShape: u86, keptDims: s84 } = util_exports.squeezeShape(r56), l80 = u86;
  if (l80.length < r56.length) {
    let v42 = k32(e36, l80), f85 = ["row", "col", "depth"];
    return `
        ${w28(v42, n67)}
        float ${o80}(int row, int col, int depth) {
          return ${o80}(${N37(f85, s84)});
        }
      `;
  }
  if (e36.shapeInfo.isUniform) return `
      float ${o80}(int row, int col, int depth) {
        int index = round(dot(vec3(row, col, depth),
                          vec3(${c103}, ${i88}, 1)));
        ${y29(e36)}
      }
    `;
  let x76 = e36.shapeInfo.texShape, d55 = x76[0], p103 = x76[1], a71 = e36.shapeInfo.flatOffset;
  if (p103 === c103 && a71 == null) return n67 ? `
      float ${o80}(int row, int col, int depth) {
        int stride1 = ${t67}Shape[2];
        float texR = float(row);
        float texC = dot(vec2(col, depth), vec2(stride1, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${t67}TexShape[1], ${t67}TexShape[0]);
        return sampleTexture(${t67}, uv);
      }
    ` : `
        float ${o80}(int row, int col, int depth) {
          float texR = float(row);
          float texC = dot(vec2(col, depth), vec2(${i88}, 1));
          vec2 uv = (vec2(texC, texR) + halfCR) /
                     vec2(${p103}.0, ${d55}.0);
          return sampleTexture(${t67}, uv);
        }
      `;
  if (p103 === i88 && a71 == null) return n67 ? `
      float ${o80}(int row, int col, int depth) {
        float texR = dot(vec2(row, col), vec2(${t67}Shape[1], 1));
        float texC = float(depth);
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${t67}TexShape[1], ${t67}TexShape[0]);
        return sampleTexture(${t67}, uv);
      }
    ` : `
    float ${o80}(int row, int col, int depth) {
      float texR = dot(vec2(row, col), vec2(${r56[1]}, 1));
      float texC = float(depth);
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${p103}.0, ${d55}.0);
      return sampleTexture(${t67}, uv);
    }
  `;
  let h74 = T29(t67);
  return n67 ? `
    float ${o80}(int row, int col, int depth) {
      // Explicitly use integer operations as dot() only works on floats.
      int stride0 = ${t67}Shape[1] * ${t67}Shape[2];
      int stride1 = ${t67}Shape[2];
      int index = row * stride0 + col * stride1 + depth + ${h74};
      vec2 uv = uvFromFlat(${t67}TexShape[0], ${t67}TexShape[1], index);
      return sampleTexture(${t67}, uv);
    }
    ` : `
      float ${o80}(int row, int col, int depth) {
        // Explicitly use integer operations as dot() only works on floats.
        int index = row * ${c103} + col * ${i88} + depth + ${h74};
        vec2 uv = uvFromFlat(${d55}, ${p103}, index);
        return sampleTexture(${t67}, uv);
      }
  `;
}
function ue3(e36, n67) {
  let r56 = e36.name, t67 = "get" + r56.charAt(0).toUpperCase() + r56.slice(1), o80 = c71();
  if (n67) return `
    vec4 ${t67}(int b2, int b, int row, int col) {
      int valuesPerRow = int(ceil(float(${r56}Shape[3]) / 2.0));
      int texelsInBatch = valuesPerRow * int(ceil(float(${r56}Shape[2]) / 2.0));
      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);
      texelsInBatch *= ${r56}Shape[1];
      index = b2 * texelsInBatch + index;
      ivec2 packedTexShape = ivec2(ceil(float(${r56}TexShape[0]) / 2.0), ceil(float(${r56}TexShape[1]) / 2.0));
      int texR = index / packedTexShape[1];
      int texC = index - texR * packedTexShape[1];
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ${o80.texture2D}(${r56}, uv);
    }
  `;
  let c103 = e36.shapeInfo.logicalShape, i88 = c103.length, u86 = e36.shapeInfo.texShape, s84 = [Math.ceil(u86[0] / 2), Math.ceil(u86[1] / 2)], l80 = s84[0], x76 = s84[1], d55 = Math.ceil(c103[i88 - 1] / 2), p103 = d55 * Math.ceil(c103[i88 - 2] / 2), a71 = "int b, int row, int col", h74 = `b * ${p103} + (row / 2) * ${d55} + (col / 2)`;
  for (let v42 = 2; v42 < i88 - 1; v42++) a71 = `int b${v42}, ` + a71, p103 *= c103[i88 - v42 - 1], h74 = `b${v42} * ${p103} + ` + h74;
  return `
    vec4 ${t67}(${a71}) {
      int index = ${h74};
      int texR = index / ${x76};
      int texC = index - texR * ${x76};
      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${x76}, ${l80});
      return ${o80.texture2D}(${r56}, uv);
    }
  `;
}
function se3(e36, n67) {
  let r56 = e36.shapeInfo.logicalShape, t67 = e36.name, o80 = "get" + t67.charAt(0).toUpperCase() + t67.slice(1), c103 = r56[3], i88 = r56[2] * c103, u86 = r56[1] * i88, { newShape: s84, keptDims: l80 } = util_exports.squeezeShape(r56);
  if (s84.length < r56.length) {
    let S45 = k32(e36, s84), g72 = ["row", "col", "depth", "depth2"];
    return `
      ${w28(S45, n67)}
      float ${o80}(int row, int col, int depth, int depth2) {
        return ${o80}(${N37(g72, l80)});
      }
    `;
  }
  if (e36.shapeInfo.isUniform) return `
      float ${o80}(int row, int col, int depth, int depth2) {
        int index = round(dot(vec4(row, col, depth, depth2),
                          vec4(${u86}, ${i88}, ${c103}, 1)));
        ${y29(e36)}
      }
    `;
  let x76 = e36.shapeInfo.flatOffset, d55 = e36.shapeInfo.texShape, p103 = d55[0], a71 = d55[1], h74 = `int stride2 = ${t67}Shape[3];`, v42 = `int stride1 = ${t67}Shape[2] * stride2;`, f85 = `int stride0 = ${t67}Shape[1] * stride1;`;
  if (a71 === u86 && x76 == null) return n67 ? `
      float ${o80}(int row, int col, int depth, int depth2) {
        ${h74}
        ${v42}
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(stride1, stride2, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${t67}TexShape[1], ${t67}TexShape[0]);
        return sampleTexture(${t67}, uv);
      }
    ` : `
      float ${o80}(int row, int col, int depth, int depth2) {
        float texR = float(row);
        float texC =
            dot(vec3(col, depth, depth2),
                vec3(${i88}, ${c103}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${a71}.0, ${p103}.0);
        return sampleTexture(${t67}, uv);
      }
    `;
  if (a71 === c103 && x76 == null) return n67 ? `
      float ${o80}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${t67}Shape[1] * ${t67}Shape[2], ${t67}Shape[2], 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${t67}TexShape[1], ${t67}TexShape[0]);
        return sampleTexture(${t67}, uv);
      }
    ` : `
      float ${o80}(int row, int col, int depth, int depth2) {
        float texR = dot(vec3(row, col, depth),
                         vec3(${r56[1] * r56[2]}, ${r56[2]}, 1));
        float texC = float(depth2);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${a71}.0, ${p103}.0);
        return sampleTexture(${t67}, uv);
      }
    `;
  let C28 = T29(t67);
  return n67 ? `
    float ${o80}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      ${h74}
      ${v42}
      ${f85}
      int index = row * stride0 + col * stride1 +
          depth * stride2 + depth2;
      vec2 uv = uvFromFlat(${t67}TexShape[0], ${t67}TexShape[1], index + ${C28});
      return sampleTexture(${t67}, uv);
    }
  ` : `
    float ${o80}(int row, int col, int depth, int depth2) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${u86} + col * ${i88} +
          depth * ${c103} + depth2;
      vec2 uv = uvFromFlat(${p103}, ${a71}, index + ${C28});
      return sampleTexture(${t67}, uv);
    }
  `;
}
function le2(e36) {
  let n67 = e36.shapeInfo.logicalShape, r56 = e36.name, t67 = "get" + r56.charAt(0).toUpperCase() + r56.slice(1), o80 = n67[4], c103 = n67[3] * o80, i88 = n67[2] * c103, u86 = n67[1] * i88, { newShape: s84, keptDims: l80 } = util_exports.squeezeShape(n67);
  if (s84.length < n67.length) {
    let v42 = k32(e36, s84), f85 = ["row", "col", "depth", "depth2", "depth3"];
    return `
      ${w28(v42)}
      float ${t67}(int row, int col, int depth, int depth2, int depth3) {
        return ${t67}(${N37(f85, l80)});
      }
    `;
  }
  if (e36.shapeInfo.isUniform) return `
      float ${t67}(int row, int col, int depth, int depth2, int depth3) {
        float index = dot(
          vec4(row, col, depth, depth2),
          vec4(${u86}, ${i88}, ${c103}, ${o80})) +
          depth3;
        ${y29(e36)}
      }
    `;
  let x76 = e36.shapeInfo.flatOffset, d55 = e36.shapeInfo.texShape, p103 = d55[0], a71 = d55[1];
  if (a71 === u86 && x76 == null) return `
      float ${t67}(int row, int col, int depth, int depth2, int depth3) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
                         vec4(${i88}, ${c103}, ${o80}, 1));
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${a71}.0, ${p103}.0);
        return sampleTexture(${r56}, uv);
      }
    `;
  if (a71 === o80 && x76 == null) return `
      float ${t67}(int row, int col, int depth, int depth2, int depth3) {
        float texR = dot(
          vec4(row, col, depth, depth2),
          vec4(${n67[1] * n67[2] * n67[3]},
               ${n67[2] * n67[3]}, ${n67[3]}, 1));
        int texC = depth3;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${a71}.0, ${p103}.0);
        return sampleTexture(${r56}, uv);
      }
    `;
  let h74 = T29(r56);
  return `
    float ${t67}(int row, int col, int depth, int depth2, int depth3) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${u86} + col * ${i88} + depth * ${c103} +
          depth2 * ${o80} + depth3 + ${h74};
      vec2 uv = uvFromFlat(${p103}, ${a71}, index);
      return sampleTexture(${r56}, uv);
    }
  `;
}
function xe3(e36) {
  let n67 = e36.shapeInfo.logicalShape, r56 = e36.name, t67 = "get" + r56.charAt(0).toUpperCase() + r56.slice(1), { newShape: o80, keptDims: c103 } = util_exports.squeezeShape(n67);
  if (o80.length < n67.length) {
    let f85 = k32(e36, o80), C28 = ["row", "col", "depth", "depth2", "depth3", "depth4"];
    return `
      ${w28(f85)}
      float ${t67}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        return ${t67}(${N37(C28, c103)});
      }
    `;
  }
  let i88 = n67[5], u86 = n67[4] * i88, s84 = n67[3] * u86, l80 = n67[2] * s84, x76 = n67[1] * l80;
  if (e36.shapeInfo.isUniform) return `
      float ${t67}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
        int index = round(dot(
          vec4(row, col, depth, depth2),
          vec4(${x76}, ${l80}, ${s84}, ${u86})) +
          dot(
            vec2(depth3, depth4),
            vec2(${i88}, 1)));
        ${y29(e36)}
      }
    `;
  let d55 = e36.shapeInfo.flatOffset, p103 = e36.shapeInfo.texShape, a71 = p103[0], h74 = p103[1];
  if (h74 === x76 && d55 == null) return `
      float ${t67}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        int texR = row;
        float texC = dot(vec4(col, depth, depth2, depth3),
          vec4(${l80}, ${s84}, ${u86}, ${i88})) +
               float(depth4);
        vec2 uv = (vec2(texC, texR) + halfCR) /
                   vec2(${h74}.0, ${a71}.0);
        return sampleTexture(${r56}, uv);
      }
    `;
  if (h74 === i88 && d55 == null) return `
      float ${t67}(int row, int col, int depth,
                    int depth2, int depth3, int depth4) {
        float texR = dot(vec4(row, col, depth, depth2),
          vec4(${n67[1] * n67[2] * n67[3] * n67[4]},
               ${n67[2] * n67[3] * n67[4]},
               ${n67[3] * n67[4]},
               ${n67[4]})) + float(depth3);
        int texC = depth4;
        vec2 uv = (vec2(texC, texR) + halfCR) /
                  vec2(${h74}.0, ${a71}.0);
        return sampleTexture(${r56}, uv);
      }
    `;
  let v42 = T29(r56);
  return `
    float ${t67}(int row, int col, int depth,
                  int depth2, int depth3, int depth4) {
      // Explicitly use integer operations as dot() only works on floats.
      int index = row * ${x76} + col * ${l80} + depth * ${s84} +
          depth2 * ${u86} + depth3 * ${i88} + depth4 + ${v42};
      vec2 uv = uvFromFlat(${a71}, ${h74}, index);
      return sampleTexture(${r56}, uv);
    }
  `;
}
function y29(e36) {
  let n67 = e36.name, r56 = util_exports.sizeFromShape(e36.shapeInfo.logicalShape);
  return r56 < 2 ? `return ${n67};` : `
    for (int i = 0; i < ${r56}; i++) {
      if (i == index) {
        return ${n67}[i];
      }
    }
  `;
}
function pe2(e36, n67) {
  let r56 = e36.name, t67 = r56.charAt(0).toUpperCase() + r56.slice(1), o80 = "get" + t67 + "AtOutCoords", c103 = e36.shapeInfo.logicalShape.length, i88 = n67.logicalShape.length, u86 = O16(e36.shapeInfo.logicalShape, n67.logicalShape), s84 = F22(i88), l80 = i88 - c103, x76, d55 = ["x", "y", "z", "w", "u", "v"];
  c103 === 0 ? x76 = "" : i88 < 2 && u86.length >= 1 ? x76 = "coords = 0;" : x76 = u86.map((S45) => `coords.${d55[S45 + l80]} = 0;`).join(`
`);
  let p103 = "";
  i88 < 2 && c103 > 0 ? p103 = "coords" : p103 = e36.shapeInfo.logicalShape.map((S45, g72) => `coords.${d55[g72 + l80]}`).join(", ");
  let a71 = "return outputValue;", v42 = util_exports.sizeFromShape(e36.shapeInfo.logicalShape) === 1, C28 = util_exports.sizeFromShape(n67.logicalShape) === 1;
  if (c103 === 1 && !v42 && !C28) a71 = `
      return vec4(outputValue.xy, outputValue.xy);
    `;
  else if (v42 && !C28) i88 === 1 ? a71 = `
        return vec4(outputValue.x, outputValue.x, 0., 0.);
      ` : a71 = `
        return vec4(outputValue.x);
      `;
  else if (u86.length) {
    let S45 = c103 - 2, g72 = c103 - 1;
    u86.indexOf(S45) > -1 && u86.indexOf(g72) > -1 ? a71 = "return vec4(outputValue.x);" : u86.indexOf(S45) > -1 ? a71 = "return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);" : u86.indexOf(g72) > -1 && (a71 = "return vec4(outputValue.xx, outputValue.zz);");
  }
  return `
    vec4 ${o80}() {
      ${s84} coords = getOutputCoords();
      ${x76}
      vec4 outputValue = get${t67}(${p103});
      ${a71}
    }
  `;
}
function de2(e36, n67) {
  let r56 = e36.name, t67 = r56.charAt(0).toUpperCase() + r56.slice(1), o80 = "get" + t67 + "AtOutCoords", c103 = n67.texShape, i88 = e36.shapeInfo.texShape, u86 = e36.shapeInfo.logicalShape.length, s84 = n67.logicalShape.length;
  if (!e36.shapeInfo.isUniform && u86 === s84 && e36.shapeInfo.flatOffset == null && util_exports.arraysEqual(i88, c103)) return `
      float ${o80}() {
        return sampleTexture(${r56}, resultUV);
      }
    `;
  let l80 = F22(s84), x76 = O16(e36.shapeInfo.logicalShape, n67.logicalShape), d55 = s84 - u86, p103, a71 = ["x", "y", "z", "w", "u", "v"];
  u86 === 0 ? p103 = "" : s84 < 2 && x76.length >= 1 ? p103 = "coords = 0;" : p103 = x76.map((v42) => `coords.${a71[v42 + d55]} = 0;`).join(`
`);
  let h74 = "";
  return s84 < 2 && u86 > 0 ? h74 = "coords" : h74 = e36.shapeInfo.logicalShape.map((v42, f85) => `coords.${a71[f85 + d55]}`).join(", "), `
    float ${o80}() {
      ${l80} coords = getOutputCoords();
      ${p103}
      return get${t67}(${h74});
    }
  `;
}
function F22(e36) {
  if (e36 <= 1) return "int";
  if (e36 === 2) return "ivec2";
  if (e36 === 3) return "ivec3";
  if (e36 === 4) return "ivec4";
  if (e36 === 5) return "ivec5";
  if (e36 === 6) return "ivec6";
  throw Error(`GPU for rank ${e36} is not yet supported`);
}
function he(e36, n67, r56) {
  let { newShape: t67, keptDims: o80 } = util_exports.squeezeShape(n67), c103 = n67.length, i88 = e36 && c103 === 3 && n67[0] === 1, u86 = i88 ? n67.slice(1) : t67, s84 = !e36 && c103 > 1 && !util_exports.arraysEqual(n67, r56) && t67.length < c103 || i88;
  return { useSqueezeShape: s84, uniformShape: s84 ? u86 : n67, keptDims: o80 };
}
function k32(e36, n67) {
  let r56 = JSON.parse(JSON.stringify(e36));
  return r56.shapeInfo.logicalShape = n67, r56;
}
function N37(e36, n67) {
  return n67.map((r56) => e36[r56]).join(", ");
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/gpgpu_math.mjs
function N38(e36, a71, r56, s84) {
  let m96 = r56.map((t67, f85) => {
    let h74 = { logicalShape: t67.shape, texShape: t67.isUniform ? null : t67.texData.texShape, isUniform: t67.isUniform, isPacked: t67.isUniform ? false : t67.texData.isPacked, flatOffset: null };
    return t67.texData != null && t67.texData.slice != null && t67.texData.slice.flatOffset > 0 && (h74.flatOffset = t67.texData.slice.flatOffset), { name: a71.variableNames[f85], shapeInfo: h74 };
  }), l80 = m96.map((t67) => t67.shapeInfo), i88 = { logicalShape: s84.shape, texShape: s84.texData.texShape, isUniform: false, isPacked: s84.texData.isPacked, flatOffset: null }, c103 = fe2(m96, i88, a71), n67 = V13(e36.gl, c103), o80 = e36.createProgram(n67);
  return l().get("ENGINE_COMPILE_ONLY") ? { program: a71, fragmentShader: n67, source: c103, webGLProgram: o80, inShapeInfos: l80, outShapeInfo: i88, variablesLocations: null, customUniformLocations: null, infLoc: null, nanLoc: null, outShapeLocation: null, outShapeStridesLocation: null, outTexShapeLocation: null } : (e36.buildVao(o80), Object.assign({ program: a71, fragmentShader: n67, source: c103, webGLProgram: o80, inShapeInfos: l80, outShapeInfo: i88 }, O17(e36, a71, o80)));
}
function O17(e36, a71, r56) {
  let s84 = [], m96 = [], l80, i88, c103, n67 = null, o80 = null;
  o80 = e36.getUniformLocation(r56, "NAN", false), l().getNumber("WEBGL_VERSION") === 1 && (n67 = e36.getUniformLocation(r56, "INFINITY", false));
  let t67 = false;
  for (let f85 of a71.variableNames) {
    let h74 = { name: f85, uniform: e36.getUniformLocation(r56, f85, t67), offset: e36.getUniformLocation(r56, `offset${f85}`, t67) };
    a71.enableShapeUniforms && (h74.shape = e36.getUniformLocation(r56, `${f85}Shape`, t67), h74.texShape = e36.getUniformLocation(r56, `${f85}TexShape`, t67)), s84.push(h74);
  }
  if (a71.enableShapeUniforms && (l80 = e36.getUniformLocation(r56, "outShape", t67), c103 = e36.getUniformLocation(r56, "outShapeStrides", t67), i88 = e36.getUniformLocation(r56, "outTexShape", t67)), a71.customUniforms) for (let f85 of a71.customUniforms) m96.push(e36.getUniformLocation(r56, f85.name, t67));
  return { variablesLocations: s84, customUniformLocations: m96, infLoc: n67, nanLoc: o80, outShapeLocation: l80, outShapeStridesLocation: c103, outTexShapeLocation: i88 };
}
function U13(e36, a71) {
  if (e36.length !== a71.length) throw Error(`Binary was compiled with ${e36.length} inputs, but was executed with ${a71.length} inputs`);
  e36.forEach((r56, s84) => {
    let m96 = r56.logicalShape, l80 = a71[s84], i88 = l80.shape;
    if (!util_exports.arraysEqual(m96, i88)) throw Error(`Binary was compiled with different shapes than the current args. Shapes ${m96} and ${i88} must match`);
    if (r56.isUniform && l80.isUniform) return;
    let c103 = r56.texShape, n67 = l80.isUniform ? null : l80.texData.texShape;
    if (!util_exports.arraysEqual(c103, n67)) throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${c103} and ${n67} must match`);
  });
}
function y30(e36, a71, r56, s84, m96) {
  a71.program.enableShapeUniforms || (U13(a71.inShapeInfos, r56), U13([a71.outShapeInfo], [s84]));
  let l80 = s84.texData.texture, i88 = s84.texData.texShape;
  s84.texData.isPacked ? e36.setOutputPackedMatrixTexture(l80.texture, i88[0], i88[1]) : e36.setOutputMatrixTexture(l80.texture, i88[0], i88[1]), e36.setProgram(a71.webGLProgram), e36.bindVertexArray(a71.webGLProgram.vao), l().getNumber("WEBGL_VERSION") === 1 && a71.infLoc !== null && e36.gl.uniform1f(a71.infLoc, 1 / 0), a71.nanLoc !== null && e36.gl.uniform1f(a71.nanLoc, NaN);
  for (let n67 = 0; n67 < r56.length; ++n67) {
    let o80 = r56[n67], { uniform: t67, offset: f85, shape: h74, texShape: d55 } = a71.variablesLocations[n67];
    if (h74) {
      let { uniformShape: S45 } = he(a71.program.packedInputs, o80.shape, o80.texData.texShape);
      switch (S45.length) {
        case 1:
          e36.gl.uniform1iv(h74, new Int32Array(S45));
          break;
        case 2:
          e36.gl.uniform2iv(h74, new Int32Array(S45));
          break;
        case 3:
          e36.gl.uniform3iv(h74, new Int32Array(S45));
          break;
        case 4:
          e36.gl.uniform4iv(h74, new Int32Array(S45));
          break;
        default:
          break;
      }
    }
    if (d55 && e36.gl.uniform2i(d55, o80.texData.texShape[0], o80.texData.texShape[1]), t67 != null) {
      if (o80.isUniform) {
        if (util_exports.sizeFromShape(o80.shape) < 2) e36.gl.uniform1f(t67, o80.uniformValues[0]);
        else {
          let S45 = o80.uniformValues;
          S45 instanceof Float32Array || (S45 = new Float32Array(S45)), e36.gl.uniform1fv(t67, S45);
        }
        continue;
      }
      o80.texData.slice != null && f85 != null && e36.gl.uniform1i(f85, o80.texData.slice.flatOffset), e36.setInputMatrixTexture(o80.texData.texture.texture, t67, n67);
    }
  }
  let c103 = a71.outShapeLocation;
  if (c103) switch (s84.shape.length) {
    case 1:
      e36.gl.uniform1iv(c103, new Int32Array(s84.shape));
      break;
    case 2:
      e36.gl.uniform2iv(c103, new Int32Array(s84.shape));
      break;
    case 3:
      e36.gl.uniform3iv(c103, new Int32Array(s84.shape));
      break;
    case 4:
      e36.gl.uniform4iv(c103, new Int32Array(s84.shape));
      break;
    default:
      break;
  }
  if (a71.outShapeStridesLocation) {
    let n67 = util_exports.computeStrides(s84.shape);
    switch (s84.shape.length) {
      case 2:
        e36.gl.uniform1iv(a71.outShapeStridesLocation, new Int32Array(n67));
        break;
      case 3:
        e36.gl.uniform2iv(a71.outShapeStridesLocation, new Int32Array(n67));
        break;
      case 4:
        e36.gl.uniform3iv(a71.outShapeStridesLocation, new Int32Array(n67));
        break;
      default:
        break;
    }
  }
  if (a71.outTexShapeLocation && e36.gl.uniform2i(a71.outTexShapeLocation, s84.texData.texShape[0], s84.texData.texShape[1]), a71.program.customUniforms && m96) for (let n67 = 0; n67 < a71.program.customUniforms.length; ++n67) {
    let o80 = a71.program.customUniforms[n67], t67 = a71.customUniformLocations[n67], f85 = m96[n67];
    if (o80.type === "float") e36.gl.uniform1fv(t67, f85);
    else if (o80.type === "vec2") e36.gl.uniform2fv(t67, f85);
    else if (o80.type === "vec3") e36.gl.uniform3fv(t67, f85);
    else if (o80.type === "vec4") e36.gl.uniform4fv(t67, f85);
    else if (o80.type === "int") e36.gl.uniform1iv(t67, f85);
    else if (o80.type === "ivec2") e36.gl.uniform2iv(t67, f85);
    else if (o80.type === "ivec3") e36.gl.uniform3iv(t67, f85);
    else if (o80.type === "ivec4") e36.gl.uniform4iv(t67, f85);
    else throw Error(`uniform type ${o80.type} is not supported yet.`);
  }
  e36.executeProgram();
}
function B19(e36, a71, r56) {
  let s84 = "";
  a71.concat(r56).forEach((i88) => {
    let c103 = i88.texData != null && i88.texData.slice != null && i88.texData.slice.flatOffset > 0;
    if (e36.enableShapeUniforms && !i88.isUniform) {
      let n67 = i88.texData.texShape, { useSqueezeShape: o80, uniformShape: t67, keptDims: f85 } = he(e36.packedInputs, i88.shape, n67), h74 = "", d55 = "", S45 = "";
      if (t67.length === 1 && e36.packedInputs) {
        let x76 = [Math.ceil(n67[0] / 2), Math.ceil(n67[1] / 2)];
        h74 = `${x76[0] > 1}_${x76[1] > 1}`;
      } else if (t67.length === 2 && !e36.packedInputs) d55 = `${t67[0] > 1}_${t67[1] > 1}`;
      else if (t67.length > 2 && !e36.packedInputs) {
        let x76 = util_exports.computeStrides(t67);
        S45 = `${x76[0] === n67[1]}_${x76[x76.length - 1] === n67[1]}`;
      }
      let k63 = i88.shape.length, I44 = t67.length === 2 && util_exports.arraysEqual(i88.shape, n67), $37 = util_exports.sizeFromShape(i88.shape) === 1, _24 = backend_util_exports.getBroadcastDims(i88.shape, r56.shape), D42 = !e36.packedInputs && k63 === r56.shape.length && util_exports.arraysEqual(n67, r56.texData.texShape), p103 = e36.packedInputs || t67.length > 2 ? "" : `${n67[0] > 1}_${n67[1] > 1}`;
      s84 += `${k63}_${D42}_${o80 ? f85 : ""}_${t67.length}_${$37}_${_24}_${I44}_${h74}_${d55}_${S45}_${p103}_${c103}`;
    } else {
      let n67 = i88.isUniform ? "uniform" : i88.texData.texShape;
      s84 += `${i88.shape}_${n67}_${c103}`;
    }
  });
  let m96 = e36.userCode, l80 = e36.constructor.name;
  return l80 += "_" + s84 + "_" + m96 + `${l().getNumber("WEBGL_VERSION")}`, l80;
}
function F23(e36) {
  return l().getBool("WEBGL_USE_SHAPES_UNIFORMS") && e36 <= 4;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/decode_matrix_gpu.mjs
var i46 = class {
  constructor(t67) {
    this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true, this.outPackingScheme = L13.DENSE, this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    let r56 = c71();
    this.outputShape = t67, this.enableShapeUniforms = F23(this.outputShape.length), this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${this.enableShapeUniforms ? h54(["r", "c", "d"], t67) : p62(["r", "c", "d"], t67)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));
        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getA(rc.x, rc.y, rc.z);
        }

        ${r56.output} = result;
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/decode_matrix_packed_gpu.mjs
var i47 = class {
  constructor(t67) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outPackingScheme = L13.DENSE, this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    let r56 = c71();
    this.outputShape = t67, this.enableShapeUniforms = F23(this.outputShape.length), this.userCode = `
      ivec3 outCoordsFromFlatIndex(int index) {
        ${this.enableShapeUniforms ? h54(["r", "c", "d"], t67) : p62(["r", "c", "d"], t67)}
        return ivec3(r, c, d);
      }

      void main() {
        ivec2 resTexRC = ivec2(resultUV.yx * vec2(texShape[0], texShape[1]));
        int index = 4 * (resTexRC.x * texShape[1] + resTexRC.y);

        vec4 result = vec4(0.);

        for (int i=0; i<4; i++) {
          int flatIndex = index + i;
          ivec3 rc = outCoordsFromFlatIndex(flatIndex);
          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));
        }

        ${r56.output} = result;
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/encode_float_gpu.mjs
var t27 = class {
  constructor(e36) {
    this.variableNames = ["A"], this.outTexUsage = R19.DOWNLOAD;
    let o80 = c71();
    this.outputShape = e36, this.userCode = `
      ${S29}

      void main() {
        float x = getAAtOutCoords();
        ${o80.output} = encode_float(x);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/encode_float_packed_gpu.mjs
var t28 = class {
  constructor(e36) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = false, this.outTexUsage = R19.DOWNLOAD;
    let o80 = c71();
    this.outputShape = e36, this.userCode = `
      ${S29}

      void main() {
        ivec3 coords = getOutputCoords();
        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));
        ${o80.output} = encode_float(x);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/encode_matrix_gpu.mjs
var p63 = { R: 0, G: 1, B: 2, A: 3 };
var r23 = class {
  constructor(l80, n67 = false, e36 = "RGBA") {
    this.variableNames = ["A"], this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    let s84 = c71();
    this.outputShape = l80, this.enableShapeUniforms = F23(this.outputShape.length);
    let a71 = "result";
    n67 && (a71 = "floor(result * 255. + 0.5)");
    let i88 = "";
    for (let t67 = 0; t67 < e36.length; t67++) {
      let f85 = e36[t67];
      i88 += `
          if(offset == ${t67}) {
            result = values[${p63[f85]}];
          }`;
    }
    this.userCode = `
      ${this.enableShapeUniforms ? v30() : d28(l80)}

      void main() {
        ivec3 coords = getOutputCoords();
        int flatIndex = getFlatIndex(coords);
        float result = 0.;
        int offset = imod(flatIndex, ${e36.length});

        flatIndex = idiv(flatIndex, ${e36.length}, 1.);

        int r = flatIndex / texShape[1];
        if (r < texShape[0]) {
          int c = imod(flatIndex, texShape[1]);
          vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);
          vec4 values = ${s84.texture2D}(A, uv);
          ${i88}
        }
        ${s84.output} = vec4(${a71}, 0., 0., 0.);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/encode_matrix_packed_gpu.mjs
var f63 = class {
  constructor(s84, u86 = false) {
    this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true, this.customUniforms = [{ name: "texShape", type: "ivec2" }];
    let a71 = c71();
    this.outputShape = s84, this.enableShapeUniforms = F23(this.outputShape.length);
    let r56 = "", i88 = "result";
    u86 && (i88 = "floor(result * 255. + 0.5)");
    for (let e36 = 0; e36 <= 1; e36++) for (let t67 = 0; t67 <= 1; t67++) {
      let o80 = e36 * 2 + t67;
      r56 += `
          localCoords = coords;
          if(localCoords[2] + ${t67} < ${this.enableShapeUniforms ? "outShape[2]" : `${s84[2]}`}) {
          localCoords[2] += ${t67};
          if (localCoords[1] + ${e36} < ${this.enableShapeUniforms ? "outShape[1]" : `${s84[1]}`}) {
            localCoords[1] += ${e36};

            flatIndex = getFlatIndex(localCoords);
            offset = imod(flatIndex, 4);

            flatIndex = idiv(flatIndex, 4, 1.);

            int r = flatIndex / texShape[1];
            int c = imod(flatIndex, texShape[1]);
            vec2 uv = (vec2(c, r) + halfCR) / vec2(texShape[1], texShape[0]);
            values = ${a71.texture2D}(A, uv);

            if (offset == 0) {
              result[${o80}] = values[0];
            } else if (offset == 1) {
              result[${o80}] = values[1];
            } else if (offset == 2) {
              result[${o80}] = values[2];
            } else {
              result[${o80}] = values[3];
            }
          }
        }
        `;
    }
    this.userCode = `
        ${this.enableShapeUniforms ? v30() : d28(s84)}

        void main() {
          ivec3 coords = getOutputCoords();

          vec4 result = vec4(0.);
          int flatIndex, r, c, offset;
          ivec3 localCoords;
          vec2 uv;
          vec4 values;

          ${r56}

          ${a71.output} = ${i88};
        }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/gpgpu_util.mjs
var gpgpu_util_exports = {};
__export(gpgpu_util_exports, {
  bindVertexProgramAttributeStreams: () => I28,
  createBufferFromOutputTexture: () => G20,
  createFloat16MatrixTexture: () => m71,
  createFloat16PackedMatrixTexture: () => k33,
  createFloat32MatrixTexture: () => U14,
  createIndexBuffer: () => w29,
  createPackedMatrixTexture: () => S30,
  createUnsignedBytesMatrixTexture: () => p64,
  createVertexBuffer: () => P20,
  createVertexShader: () => h55,
  downloadByteEncodedFloatMatrixFromOutputTexture: () => N39,
  downloadFloat32MatrixFromBuffer: () => M21,
  downloadMatrixFromPackedOutputTexture: () => y31,
  downloadPackedMatrixFromBuffer: () => X16,
  getInternalFormatForFloat16MatrixTexture: () => A26,
  getInternalFormatForFloat16PackedMatrixTexture: () => s45,
  getInternalFormatForFloat32MatrixTexture: () => E34,
  getInternalFormatForPackedMatrixTexture: () => b34,
  getInternalFormatForUnsignedBytesMatrixTexture: () => F24,
  uploadDenseMatrixToTexture: () => D20,
  uploadPixelDataToTexture: () => C15
});
function h55(e36) {
  let r56 = c71(), t67 = `${r56.version}
    precision highp float;
    ${r56.attribute} vec3 clipSpacePos;
    ${r56.attribute} vec2 uv;
    ${r56.varyingVs} vec2 resultUV;

    void main() {
      gl_Position = vec4(clipSpacePos, 1);
      resultUV = uv;
    }`;
  return z23(e36, t67);
}
function P20(e36) {
  let r56 = new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]);
  return p61(e36, r56);
}
function w29(e36) {
  let r56 = new Uint16Array([0, 1, 2, 2, 1, 3]);
  return Y8(e36, r56);
}
function d29(e36, r56, t67, n67, u86, i88) {
  Q7(r56, t67);
  let c103 = Z10(e36), o80 = e36.TEXTURE_2D;
  return o41(e36, () => e36.bindTexture(o80, c103)), o41(e36, () => e36.texParameteri(o80, e36.TEXTURE_WRAP_S, e36.CLAMP_TO_EDGE)), o41(e36, () => e36.texParameteri(o80, e36.TEXTURE_WRAP_T, e36.CLAMP_TO_EDGE)), o41(e36, () => e36.texParameteri(o80, e36.TEXTURE_MIN_FILTER, e36.NEAREST)), o41(e36, () => e36.texParameteri(o80, e36.TEXTURE_MAG_FILTER, e36.NEAREST)), l().getNumber("WEBGL_VERSION") === 1 ? o41(e36, () => e36.texImage2D(o80, 0, n67, r56, t67, 0, u86, i88, null)) : o41(e36, () => e36.texStorage2D(o80, 1, n67, r56, t67)), o41(e36, () => e36.bindTexture(e36.TEXTURE_2D, null)), { texture: c103, texShape: [t67, r56] };
}
function E34(e36) {
  return e36.internalFormatFloat;
}
function U14(e36, r56, t67, n67) {
  let [u86, i88] = N35(r56, t67);
  return d29(e36, u86, i88, E34(n67), n67.textureFormatFloat, e36.FLOAT);
}
function A26(e36) {
  return e36.internalFormatHalfFloat;
}
function m71(e36, r56, t67, n67) {
  let [u86, i88] = N35(r56, t67);
  return d29(e36, u86, i88, A26(n67), n67.textureFormatFloat, n67.textureTypeHalfFloat);
}
function F24(e36) {
  return e36.downloadTextureFormat;
}
function p64(e36, r56, t67, n67) {
  let [u86, i88] = N35(r56, t67);
  return d29(e36, u86, i88, F24(n67), e36.RGBA, e36.UNSIGNED_BYTE);
}
function b34(e36) {
  return e36.internalFormatPackedFloat;
}
function S30(e36, r56, t67, n67) {
  let [u86, i88] = O14(r56, t67);
  return d29(e36, u86, i88, b34(n67), e36.RGBA, e36.FLOAT);
}
function s45(e36) {
  return e36.internalFormatPackedHalfFloat;
}
function k33(e36, r56, t67, n67) {
  let [u86, i88] = O14(r56, t67);
  return d29(e36, u86, i88, s45(n67), e36.RGBA, n67.textureTypeHalfFloat);
}
function I28(e36, r56, t67) {
  return o41(e36, () => e36.bindBuffer(e36.ARRAY_BUFFER, t67)), J9(e36, r56, "clipSpacePos", t67, 3, 20, 0) && J9(e36, r56, "uv", t67, 2, 20, 12);
}
function D20(e36, r56, t67, n67, u86, i88) {
  o41(e36, () => e36.bindTexture(e36.TEXTURE_2D, r56));
  let c103, o80, x76;
  u86 instanceof Uint8Array ? (c103 = new Uint8Array(t67 * n67 * 4), o80 = e36.UNSIGNED_BYTE, x76 = e36.RGBA) : (c103 = new Float32Array(t67 * n67 * 4), o80 = e36.FLOAT, x76 = i88.internalFormatPackedFloat), c103.set(u86), l().getNumber("WEBGL_VERSION") === 2 ? o41(e36, () => e36.texSubImage2D(e36.TEXTURE_2D, 0, 0, 0, t67, n67, e36.RGBA, o80, c103)) : o41(e36, () => e36.texImage2D(e36.TEXTURE_2D, 0, x76, t67, n67, 0, e36.RGBA, o80, c103)), o41(e36, () => e36.bindTexture(e36.TEXTURE_2D, null));
}
function C15(e36, r56, t67) {
  o41(e36, () => e36.bindTexture(e36.TEXTURE_2D, r56)), t67.data instanceof Uint8Array ? l().getNumber("WEBGL_VERSION") === 2 ? o41(e36, () => e36.texSubImage2D(e36.TEXTURE_2D, 0, 0, 0, t67.width, t67.height, e36.RGBA, e36.UNSIGNED_BYTE, t67.data)) : o41(e36, () => e36.texImage2D(e36.TEXTURE_2D, 0, e36.RGBA, t67.width, t67.height, 0, e36.RGBA, e36.UNSIGNED_BYTE, t67.data)) : l().getNumber("WEBGL_VERSION") === 2 ? o41(e36, () => e36.texSubImage2D(e36.TEXTURE_2D, 0, 0, 0, e36.RGBA, e36.UNSIGNED_BYTE, t67)) : o41(e36, () => e36.texImage2D(e36.TEXTURE_2D, 0, e36.RGBA, e36.RGBA, e36.UNSIGNED_BYTE, t67)), o41(e36, () => e36.bindTexture(e36.TEXTURE_2D, null));
}
function G20(e36, r56, t67, n67) {
  let u86 = e36.createBuffer();
  o41(e36, () => e36.bindBuffer(e36.PIXEL_PACK_BUFFER, u86));
  let o80 = 4 * 4 * r56 * t67;
  return o41(e36, () => e36.bufferData(e36.PIXEL_PACK_BUFFER, o80, e36.STREAM_READ)), o41(e36, () => e36.readPixels(0, 0, t67, r56, e36.RGBA, e36.FLOAT, 0)), o41(e36, () => e36.bindBuffer(e36.PIXEL_PACK_BUFFER, null)), u86;
}
function M21(e36, r56, t67) {
  let n67 = e36, u86 = new Float32Array(t67);
  return n67.bindBuffer(n67.PIXEL_PACK_BUFFER, r56), n67.getBufferSubData(n67.PIXEL_PACK_BUFFER, 0, u86), n67.bindBuffer(n67.PIXEL_PACK_BUFFER, null), u86;
}
function N39(e36, r56, t67, n67) {
  let [u86, i88] = N35(r56, t67), c103 = 4, o80 = new Uint8Array(m69(r56 * t67, c103));
  return o41(e36, () => e36.readPixels(0, 0, u86, i88, n67.downloadTextureFormat, e36.UNSIGNED_BYTE, o80)), new Float32Array(o80.buffer);
}
function X16(e36, r56, t67, n67, u86, i88, c103, o80) {
  let x76 = e36, T40 = new Float32Array(c70(i88, c103));
  return x76.bindBuffer(x76.PIXEL_PACK_BUFFER, r56), x76.getBufferSubData(x76.PIXEL_PACK_BUFFER, 0, T40), x76.bindBuffer(x76.PIXEL_PACK_BUFFER, null), T40;
}
function y31(e36, r56, t67) {
  let n67 = new Float32Array(r56 * t67 * 4);
  return o41(e36, () => e36.readPixels(0, 0, t67, r56, e36.RGBA, e36.FLOAT, n67)), n67;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/gpgpu_context.mjs
var f64 = class {
  constructor(e36) {
    this.outputTexture = null, this.program = null, this.disposed = false, this.itemsToPoll = [];
    let t67 = l().getNumber("WEBGL_VERSION");
    if (e36 != null ? (this.gl = e36, d27(t67, e36)) : this.gl = f62(t67), e36 = this.gl, l().getNumber("WEBGL_VERSION") === 2) {
      let o80 = e36;
      this.createVertexArray = () => o41(o80, () => o80.createVertexArray()), this.bindVertexArray = (n67) => o41(o80, () => o80.bindVertexArray(n67)), this.deleteVertexArray = (n67) => o41(o80, () => o80.deleteVertexArray(n67)), this.getVertexArray = () => o41(o80, () => o80.getParameter(o80.VERTEX_ARRAY_BINDING));
    } else if (e36 != null) {
      let o80 = e36.getExtension("OES_vertex_array_object");
      if (o80 == null) throw new Error("All WebGL1 implementations are expected to offer OES_vertex_array_object.");
      this.createVertexArray = () => o41(e36, () => o80.createVertexArrayOES()), this.bindVertexArray = (n67) => o41(e36, () => o80.bindVertexArrayOES(n67)), this.deleteVertexArray = (n67) => o41(e36, () => o80.deleteVertexArrayOES(n67)), this.getVertexArray = () => o41(e36, () => e36.getParameter(o80.VERTEX_ARRAY_BINDING_OES));
    }
    let r56 = "WEBGL_color_buffer_float", s84 = "EXT_color_buffer_half_float";
    if (this.parallelCompilationExtension = this.gl.getExtension("KHR_parallel_shader_compile"), l().getNumber("WEBGL_VERSION") === 1) {
      let o80 = "OES_texture_float", n67 = "OES_texture_half_float";
      if (this.textureFloatExtension = y28(this.gl, o80), F21(this.gl, n67)) this.textureHalfFloatExtension = y28(this.gl, n67);
      else if (l().get("WEBGL_FORCE_F16_TEXTURES")) throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
      if (this.colorBufferFloatExtension = this.gl.getExtension(r56), F21(this.gl, s84)) this.colorBufferHalfFloatExtension = y28(this.gl, s84);
      else if (l().get("WEBGL_FORCE_F16_TEXTURES")) throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
    } else if (r56 = "EXT_color_buffer_float", F21(this.gl, r56)) this.colorBufferFloatExtension = this.gl.getExtension(r56);
    else if (F21(this.gl, s84)) this.colorBufferHalfFloatExtension = this.gl.getExtension(s84);
    else throw new Error("GL context does not support color renderable floats");
    this.vertexBuffer = P20(this.gl), this.indexBuffer = w29(this.gl), this.framebuffer = K14(this.gl), this.textureConfig = G18(this.gl, this.textureHalfFloatExtension);
  }
  get debug() {
    return l().getBool("DEBUG");
  }
  dispose() {
    if (this.disposed) return;
    this.program != null && console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."), this.outputTexture != null && console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");
    let e36 = this.gl;
    o41(e36, () => e36.finish()), o41(e36, () => e36.bindFramebuffer(e36.FRAMEBUFFER, null)), o41(e36, () => e36.deleteFramebuffer(this.framebuffer)), o41(e36, () => e36.bindBuffer(e36.ARRAY_BUFFER, null)), o41(e36, () => e36.bindBuffer(e36.ELEMENT_ARRAY_BUFFER, null)), o41(e36, () => e36.deleteBuffer(this.indexBuffer)), this.disposed = true;
  }
  createFloat32MatrixTexture(e36, t67) {
    return this.throwIfDisposed(), U14(this.gl, e36, t67, this.textureConfig);
  }
  createFloat16MatrixTexture(e36, t67) {
    return this.throwIfDisposed(), m71(this.gl, e36, t67, this.textureConfig);
  }
  createUnsignedBytesMatrixTexture(e36, t67) {
    return this.throwIfDisposed(), p64(this.gl, e36, t67, this.textureConfig);
  }
  uploadPixelDataToTexture(e36, t67) {
    this.throwIfDisposed(), C15(this.gl, e36, t67);
  }
  uploadDenseMatrixToTexture(e36, t67, r56, s84) {
    this.throwIfDisposed(), D20(this.gl, e36, t67, r56, s84, this.textureConfig);
  }
  createFloat16PackedMatrixTexture(e36, t67) {
    return this.throwIfDisposed(), k33(this.gl, e36, t67, this.textureConfig);
  }
  createPackedMatrixTexture(e36, t67) {
    return this.throwIfDisposed(), S30(this.gl, e36, t67, this.textureConfig);
  }
  deleteMatrixTexture(e36) {
    this.throwIfDisposed(), this.outputTexture === e36 && (ue2(this.gl, this.framebuffer), this.outputTexture = null), o41(this.gl, () => this.gl.deleteTexture(e36));
  }
  downloadByteEncodedFloatMatrixFromOutputTexture(e36, t67, r56) {
    return this.downloadMatrixDriver(e36, () => N39(this.gl, t67, r56, this.textureConfig));
  }
  downloadPackedMatrixFromBuffer(e36, t67, r56, s84, o80, n67) {
    return X16(this.gl, e36, t67, r56, s84, o80, n67, this.textureConfig);
  }
  downloadFloat32MatrixFromBuffer(e36, t67) {
    return M21(this.gl, e36, t67);
  }
  createBufferFromTexture(e36, t67, r56) {
    this.bindTextureToFrameBuffer(e36);
    let s84 = G20(this.gl, t67, r56, this.textureConfig);
    return this.unbindTextureToFrameBuffer(), s84;
  }
  createAndWaitForFence() {
    let e36 = this.createFence(this.gl);
    return this.pollFence(e36);
  }
  createFence(e36) {
    let t67, r56;
    if (l().getBool("WEBGL_FENCE_API_ENABLED")) {
      let s84 = e36, o80 = s84.fenceSync(s84.SYNC_GPU_COMMANDS_COMPLETE, 0);
      e36.flush(), r56 = () => {
        let n67 = s84.clientWaitSync(o80, 0, 0);
        return n67 === s84.ALREADY_SIGNALED || n67 === s84.CONDITION_SATISFIED;
      }, t67 = o80;
    } else l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 ? (t67 = this.beginQuery(), this.endQuery(), r56 = () => this.isQueryAvailable(t67, l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))) : r56 = () => true;
    return { query: t67, isFencePassed: r56 };
  }
  downloadMatrixFromPackedTexture(e36, t67, r56) {
    return this.downloadMatrixDriver(e36, () => y31(this.gl, t67, r56));
  }
  createProgram(e36) {
    this.throwIfDisposed();
    let t67 = this.gl;
    this.vertexShader == null && (this.vertexShader = h55(t67));
    let r56 = q15(t67);
    o41(t67, () => t67.attachShader(r56, this.vertexShader)), o41(t67, () => t67.attachShader(r56, e36)), $31(t67, r56);
    let s84 = Object.assign(r56, { vao: this.createVertexArray() });
    return this.debug && k31(t67, s84), s84;
  }
  buildVao(e36) {
    this.setProgram(e36), this.bindVertexArray(e36.vao);
    let t67 = this.gl;
    o41(t67, () => t67.bindBuffer(t67.ELEMENT_ARRAY_BUFFER, this.indexBuffer)), I28(t67, e36, this.vertexBuffer);
  }
  deleteProgram(e36) {
    this.throwIfDisposed(), e36 === this.program && (this.program = null), e36 != null && (o41(this.gl, () => this.gl.deleteProgram(e36)), this.deleteVertexArray(e36.vao));
  }
  setProgram(e36) {
    this.throwIfDisposed(), this.program = e36, this.program != null && this.debug && k31(this.gl, this.program), o41(this.gl, () => this.gl.useProgram(e36));
  }
  getUniformLocation(e36, t67, r56 = true) {
    return this.throwIfDisposed(), r56 ? ee3(this.gl, e36, t67) : re3(this.gl, e36, t67);
  }
  getAttributeLocation(e36, t67) {
    return this.throwIfDisposed(), o41(this.gl, () => this.gl.getAttribLocation(e36, t67));
  }
  getUniformLocationNoThrow(e36, t67) {
    return this.throwIfDisposed(), this.gl.getUniformLocation(e36, t67);
  }
  setInputMatrixTexture(e36, t67, r56) {
    this.throwIfDisposed(), this.throwIfNoProgram(), te3(this.gl, e36, t67, r56);
  }
  setOutputMatrixTexture(e36, t67, r56) {
    this.setOutputMatrixTextureDriver(e36, r56, t67);
  }
  setOutputPackedMatrixTexture(e36, t67, r56) {
    this.throwIfDisposed();
    let [s84, o80] = O14(t67, r56);
    this.setOutputMatrixTextureDriver(e36, s84, o80);
  }
  setOutputMatrixWriteRegion(e36, t67, r56, s84) {
    this.setOutputMatrixWriteRegionDriver(r56, e36, s84, t67);
  }
  setOutputPackedMatrixWriteRegion(e36, t67, r56, s84) {
    throw new Error("setOutputPackedMatrixWriteRegion not implemented.");
  }
  debugValidate() {
    this.program != null && k31(this.gl, this.program), ie4(this.gl);
  }
  executeProgram() {
    this.throwIfDisposed(), this.throwIfNoProgram();
    let e36 = this.gl;
    if (this.debug) {
      let t67 = this.getVertexArray();
      console.assert(t67 === this.program.vao, "VAO changed between setProgram and executeProgram!"), this.debugValidate();
    }
    o41(e36, () => e36.drawElements(e36.TRIANGLES, 6, e36.UNSIGNED_SHORT, 0));
  }
  blockUntilAllProgramsCompleted() {
    this.throwIfDisposed(), o41(this.gl, () => this.gl.finish());
  }
  getQueryTimerExtension() {
    return this.disjointQueryTimerExtension == null && (this.disjointQueryTimerExtension = y28(this.gl, l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2 ? "EXT_disjoint_timer_query_webgl2" : "EXT_disjoint_timer_query")), this.disjointQueryTimerExtension;
  }
  getQueryTimerExtensionWebGL2() {
    return this.getQueryTimerExtension();
  }
  getQueryTimerExtensionWebGL1() {
    return this.getQueryTimerExtension();
  }
  beginQuery() {
    if (l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
      let r56 = this.gl, s84 = this.getQueryTimerExtensionWebGL2(), o80 = r56.createQuery();
      return r56.beginQuery(s84.TIME_ELAPSED_EXT, o80), o80;
    }
    let e36 = this.getQueryTimerExtensionWebGL1(), t67 = e36.createQueryEXT();
    return e36.beginQueryEXT(e36.TIME_ELAPSED_EXT, t67), t67;
  }
  endQuery() {
    if (l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") === 2) {
      let t67 = this.gl, r56 = this.getQueryTimerExtensionWebGL2();
      t67.endQuery(r56.TIME_ELAPSED_EXT);
      return;
    }
    let e36 = this.getQueryTimerExtensionWebGL1();
    e36.endQueryEXT(e36.TIME_ELAPSED_EXT);
  }
  async waitForQueryAndGetTime(e36) {
    return await util_exports.repeatedTry(() => this.disposed || this.isQueryAvailable(e36, l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))), this.getQueryTime(e36, l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
  }
  getQueryTime(e36, t67) {
    if (t67 === 0) return null;
    if (t67 === 2) {
      let r56 = this.gl;
      return r56.getQueryParameter(e36, r56.QUERY_RESULT) / 1e6;
    } else {
      let r56 = this.getQueryTimerExtensionWebGL1();
      return r56.getQueryObjectEXT(e36, r56.QUERY_RESULT_EXT) / 1e6;
    }
  }
  isQueryAvailable(e36, t67) {
    if (t67 === 0) return true;
    if (t67 === 2) {
      let r56 = this.gl, s84 = this.getQueryTimerExtensionWebGL2(), o80 = r56.getQueryParameter(e36, r56.QUERY_RESULT_AVAILABLE);
      return this.disjoint == null && (this.disjoint = this.gl.getParameter(s84.GPU_DISJOINT_EXT)), o80 && !this.disjoint;
    } else {
      let r56 = this.getQueryTimerExtensionWebGL1(), s84 = r56.getQueryObjectEXT(e36, r56.QUERY_RESULT_AVAILABLE_EXT);
      return this.disjoint == null && (this.disjoint = this.gl.getParameter(r56.GPU_DISJOINT_EXT)), s84 && !this.disjoint;
    }
  }
  pollFence(e36) {
    return new Promise((t67) => {
      this.addItemToPoll(() => e36.isFencePassed(), () => t67());
    });
  }
  pollItems() {
    let e36 = _19(this.itemsToPoll.map((t67) => t67.isDoneFn));
    for (let t67 = 0; t67 <= e36; ++t67) {
      let { resolveFn: r56 } = this.itemsToPoll[t67];
      r56();
    }
    this.itemsToPoll = this.itemsToPoll.slice(e36 + 1);
  }
  addItemToPoll(e36, t67) {
    if (this.itemsToPoll.push({ isDoneFn: e36, resolveFn: t67 }), this.itemsToPoll.length > 1) return;
    let r56;
    "setTimeoutCustom" in l().platform && (r56 = l().platform.setTimeoutCustom.bind(l().platform)), util_exports.repeatedTry(() => (this.pollItems(), this.itemsToPoll.length === 0), () => 0, null, r56);
  }
  bindTextureToFrameBuffer(e36) {
    this.throwIfDisposed(), oe3(this.gl, e36, this.framebuffer), this.debug && ie4(this.gl);
  }
  unbindTextureToFrameBuffer() {
    this.outputTexture != null ? (oe3(this.gl, this.outputTexture, this.framebuffer), this.debug && ie4(this.gl)) : ue2(this.gl, this.framebuffer);
  }
  downloadMatrixDriver(e36, t67) {
    this.bindTextureToFrameBuffer(e36);
    let r56 = t67();
    return this.unbindTextureToFrameBuffer(), r56;
  }
  setOutputMatrixTextureDriver(e36, t67, r56) {
    this.throwIfDisposed();
    let s84 = this.gl;
    oe3(s84, e36, this.framebuffer), this.debug && ie4(s84), this.outputTexture = e36, o41(s84, () => s84.viewport(0, 0, t67, r56)), o41(s84, () => s84.scissor(0, 0, t67, r56));
  }
  setOutputMatrixWriteRegionDriver(e36, t67, r56, s84) {
    this.throwIfDisposed(), o41(this.gl, () => this.gl.scissor(e36, t67, r56, s84));
  }
  throwIfDisposed() {
    if (this.disposed) throw new Error("Attempted to use disposed GPGPUContext.");
  }
  throwIfNoProgram() {
    if (this.program == null) throw new Error("No GPU program is currently set.");
  }
};
function _19(h74) {
  let e36 = 0;
  for (; e36 < h74.length && h74[e36](); ++e36) ;
  return e36 - 1;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernel_utils/shared.mjs
var { addImpl: p65, bincountImpl: m72, bincountReduceImpl: I29, bitwiseAndImpl: e20, castImpl: s46, ceilImpl: t29, concatImpl: a45, equalImpl: r24, expImpl: i48, expm1Impl: C16, floorImpl: P21, gatherNdImpl: U15, gatherV2Impl: n34, greaterImpl: g51, greaterEqualImpl: o42, lessImpl: c72, lessEqualImpl: u61, linSpaceImpl: d30, logImpl: q17, maxImpl: R20, maximumImpl: h56, minimumImpl: x54, multiplyImpl: b35, negImpl: E35, notEqualImpl: S31, prodImpl: T30, raggedGatherImpl: w30, raggedRangeImpl: y32, raggedTensorToTensorImpl: A27, rangeImpl: F25, rsqrtImpl: G21, scatterImpl: N40, sigmoidImpl: f65, simpleAbsImpl: k34, sliceImpl: B20, sparseFillEmptyRowsImpl: H11, sparseReshapeImpl: K16, sparseSegmentReductionImpl: V14, sqrtImpl: j17, staticRegexReplaceImpl: v31, stridedSliceImpl: z25, stringNGramsImpl: D21, stringSplitImpl: J11, stringToHashBucketFastImpl: L16, subImpl: M22, tileImpl: O18, topKImpl: Q9, transposeImpl: W12, uniqueImpl: X17 } = shared_exports;

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/packing_util.mjs
function n35(e36, t67) {
  return ["x", "y", "z", "w", "u", "v"].slice(0, t67).map((r56) => `${e36}.${r56}`);
}
function u62(e36, t67) {
  return t67 === 1 ? [e36] : n35(e36, t67);
}
function c73(e36, t67) {
  if (e36 === 1) return "rc";
  let r56 = "";
  for (let o80 = 0; o80 < e36; o80++) r56 += t67[o80], o80 < e36 - 1 && (r56 += ",");
  return r56;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/pack_gpu.mjs
var i49 = class {
  constructor(o80) {
    if (this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true, this.outputShape = o80, this.rank = o80.length, this.enableShapeUniforms = F23(this.outputShape.length), this.rank === 0) this.userCode = `
        void main() {
          setOutput(vec4(getA(), 0., 0., 0.));
        }
      `;
    else {
      let t67 = u62("rc", this.rank), e36 = F22(this.rank), s84 = this.getOutOfBoundsCondition(t67), r56 = this.getSetup(t67), n67 = this.getOutput(t67);
      this.userCode = `
        void main() {
          ${e36} rc = getOutputCoords();

          if(${s84}) {
            setOutput(vec4(0));
          } else {
            ${r56}

            setOutput(vec4(${n67}));
          }
        }
      `;
    }
  }
  getSourceCoordsArr(o80) {
    let t67 = [];
    for (let e36 = 0; e36 <= 1; e36++) for (let s84 = 0; s84 <= 1; s84++) {
      let r56 = `${e36 === 0 ? "r" : "rp1"}, ${s84 === 0 ? "c" : "cp1"}`;
      for (let n67 = 2; n67 < this.rank; n67++) r56 = `${o80[o80.length - 1 - n67]},` + r56;
      t67.push(r56);
    }
    return t67;
  }
  getOutOfBoundsCondition(o80) {
    if (this.rank === 1) return `rc > ${this.enableShapeUniforms ? "outShape" : this.outputShape[0]}`;
    let t67 = "";
    for (let e36 = this.rank - 2; e36 < this.rank; e36++) t67 += `${o80[e36]} >= ${this.enableShapeUniforms ? `outShape[${e36}]` : this.outputShape[e36]}`, e36 < this.rank - 1 && (t67 += "||");
    return t67;
  }
  getSetup(o80) {
    if (this.rank === 1) return "";
    let t67 = o80.slice(-2), e36 = this.enableShapeUniforms ? `outShape[${this.rank} - 1]` : this.outputShape[this.rank - 1], s84 = this.enableShapeUniforms ? `outShape[${this.rank} - 2]` : this.outputShape[this.rank - 2];
    return `
      int r = ${t67[0]};
      int c = ${t67[1]};
      int rp1 = r + 1;
      int cp1 = c + 1;

      bool cEdge = cp1 >= ${e36};
      bool rEdge = rp1 >= ${s84};
    `;
  }
  getOutput(o80) {
    let t67 = this.getSourceCoordsArr(o80);
    return this.rank === 1 ? `getA(rc), (rc + 1 >= ${this.enableShapeUniforms ? "outShape" : this.outputShape[0]} ? 0. : getA(rc + 1)), 0, 0` : `getA(${t67[0]}),
            cEdge ? 0. : getA(${t67[1]}),
            rEdge ? 0. : getA(${t67[2]}),
            rEdge || cEdge ? 0. : getA(${t67[3]})`;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/reshape_packed_gpu.mjs
var a46 = class {
  constructor(i88, o80) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "inputShape", type: "ivec3" }], this.outputShape = i88, this.enableShapeUniforms = F23(this.outputShape.length);
    let r56 = "";
    for (let e36 = 0; e36 < 4; e36++) {
      let s84 = "thisRC = rc;";
      e36 % 2 === 1 && (s84 += "thisRC.z += 1;"), e36 > 1 && (s84 += "thisRC.y += 1;"), r56 += `
        ${s84}
        ${e36 > 0 ? "if(thisRC.y < rows && thisRC.z < cols){" : ""}
          int flatIndex = getFlatIndex(thisRC);

          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);
          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));

          result[${e36}] =
            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);
        ${e36 > 0 ? "}" : ""}
      `;
    }
    this.userCode = `
      ${p66(o80, this.enableShapeUniforms)}
      ${this.enableShapeUniforms ? v30() : d28(i88)}

      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0.);

        ivec3 thisRC;
        int rows = ${this.enableShapeUniforms ? "outShape[1]" : i88[1]};
        int cols = ${this.enableShapeUniforms ? "outShape[2]" : i88[2]};

        ${r56}

        setOutput(result);
      }
    `;
  }
};
function p66(n67, i88) {
  return `
    ivec3 inputCoordsFromReshapedOutCoords(int index) {
      ${i88 ? g50(["r", "c", "d"], "inputShape") : p62(["r", "c", "d"], n67)}
      return ivec3(r, c, d);
    }
  `;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/texture_manager.mjs
var c74 = class {
  constructor(e36) {
    this.gpgpu = e36, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0, this.freeTextures = {}, this.usedTextures = {}, this.logEnabled = false;
  }
  acquireTexture(e36, r56, l80) {
    let u86 = f66(r56, l80), n67 = d31(e36, u86, l80);
    n67 in this.freeTextures || (this.freeTextures[n67] = []), n67 in this.usedTextures || (this.usedTextures[n67] = []);
    let o80 = g52(e36, u86, this.gpgpu.gl, this.gpgpu.textureConfig, l80);
    if (this.freeTextures[n67].length > 0) {
      this.numFreeTextures--, this.numUsedTextures++, this._numBytesFree -= o80, this.log();
      let x76 = this.freeTextures[n67].pop();
      return this.usedTextures[n67].push(x76), x76;
    }
    let i88;
    return u86 === S27.PACKED_2X2_FLOAT32 ? i88 = this.gpgpu.createPackedMatrixTexture(e36[0], e36[1]) : u86 === S27.PACKED_2X2_FLOAT16 ? i88 = this.gpgpu.createFloat16PackedMatrixTexture(e36[0], e36[1]) : u86 === S27.UNPACKED_FLOAT32 ? i88 = this.gpgpu.createFloat32MatrixTexture(e36[0], e36[1]) : u86 === S27.UNPACKED_FLOAT16 ? i88 = this.gpgpu.createFloat16MatrixTexture(e36[0], e36[1]) : u86 === S27.PACKED_4X1_UNSIGNED_BYTE && (i88 = this.gpgpu.createUnsignedBytesMatrixTexture(e36[0], e36[1])), this.usedTextures[n67].push(i88), this.numUsedTextures++, this._numBytesAllocated += o80, this.log(), i88;
  }
  releaseTexture(e36, r56, l80, u86) {
    if (this.freeTextures == null) return;
    let n67 = f66(l80, u86), o80 = d31(r56, n67, u86);
    o80 in this.freeTextures || (this.freeTextures[o80] = []);
    let i88 = g52(r56, n67, this.gpgpu.gl, this.gpgpu.textureConfig, u86), x76 = l().getNumber("WEBGL_DELETE_TEXTURE_THRESHOLD");
    x76 !== -1 && this._numBytesAllocated > x76 ? (this.gpgpu.deleteMatrixTexture(e36.texture), this._numBytesAllocated -= i88) : (this.freeTextures[o80].push(e36), this.numFreeTextures++, this._numBytesFree += i88), this.numUsedTextures--;
    let h74 = this.usedTextures[o80], a71 = h74 && h74.indexOf(e36);
    if (a71 == null || a71 < 0) throw new Error("Cannot release a texture that was never provided by this texture manager");
    h74[a71] = h74[h74.length - 1], h74.pop(), this.log();
  }
  log() {
    if (!this.logEnabled) return;
    let e36 = this.numFreeTextures + this.numUsedTextures;
    console.log("Free/Used", `${this.numFreeTextures} / ${this.numUsedTextures}`, `(${e36})`);
    let r56 = this._numBytesFree / this._numBytesAllocated;
    console.log(`Bytes allocated: ${this._numBytesAllocated}`), console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100 * r56)}%)`);
  }
  get numBytesAllocated() {
    return this._numBytesAllocated;
  }
  get numBytesFree() {
    return this._numBytesFree;
  }
  getNumUsedTextures() {
    return this.numUsedTextures;
  }
  getNumFreeTextures() {
    return this.numFreeTextures;
  }
  dispose() {
    if (this.freeTextures != null) {
      for (let e36 in this.freeTextures) this.freeTextures[e36].forEach((r56) => {
        this.gpgpu.deleteMatrixTexture(r56.texture);
      });
      for (let e36 in this.usedTextures) this.usedTextures[e36].forEach((r56) => {
        this.gpgpu.deleteMatrixTexture(r56.texture);
      });
      this.freeTextures = null, this.usedTextures = null, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0;
    }
  }
};
function U16(t67, e36) {
  let r56 = t67;
  if (e36 === r56.R32F) return 4;
  if (e36 === r56.R16F) return 2;
  if (e36 === r56.RGBA32F) return 16;
  if (e36 === t67.RGBA) return 16;
  if (e36 === r56.RGBA16F) return 8;
  if (e36 === r56.RGBA8) return 4;
  throw new Error(`Unknown internal format ${e36}`);
}
function g52(t67, e36, r56, l80, u86) {
  let n67 = D22(e36, l80), o80;
  if (u86) {
    let [x76, h74] = O14(t67[0], t67[1]);
    o80 = x76 * h74;
  } else {
    let [x76, h74] = N35(t67[0], t67[1]);
    o80 = x76 * h74;
  }
  let i88 = U16(r56, n67);
  return o80 * i88;
}
function D22(t67, e36) {
  switch (t67) {
    case S27.PACKED_2X2_FLOAT32:
      return b34(e36);
    case S27.PACKED_2X2_FLOAT16:
      return s45(e36);
    case S27.UNPACKED_FLOAT32:
      return E34(e36);
    case S27.UNPACKED_FLOAT16:
      return A26(e36);
    case S27.PACKED_4X1_UNSIGNED_BYTE:
      return F24(e36);
    default:
      throw new Error(`Unknown physical texture type ${t67}`);
  }
}
function L17(t67) {
  return l().getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? t67 ? S27.PACKED_2X2_FLOAT32 : S27.UNPACKED_FLOAT32 : t67 ? S27.PACKED_2X2_FLOAT16 : S27.UNPACKED_FLOAT16;
}
function f66(t67, e36) {
  if (t67 === R19.UPLOAD) return S27.PACKED_2X2_FLOAT32;
  if (t67 === R19.RENDER || t67 == null) return L17(e36);
  if (t67 === R19.DOWNLOAD || t67 === R19.PIXELS) return S27.PACKED_4X1_UNSIGNED_BYTE;
  throw new Error(`Unknown logical texture type ${t67}`);
}
function d31(t67, e36, r56) {
  return `${t67[0]}_${t67[1]}_${e36}_${r56}`;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/unaryop_gpu.mjs
var e21 = class {
  constructor(o80, n67) {
    this.variableNames = ["A"], this.outputShape = o80, this.enableShapeUniforms = F23(this.outputShape.length), this.userCode = `
      float unaryOperation(float x) {
        ${n67}
      }

      void main() {
        float x = getAAtOutCoords();
        float y = unaryOperation(x);

        setOutput(y);
      }
    `;
  }
};
var t30 = "if (isnan(x)) return x;";
var u63 = "return x;";
var p67 = "return abs(x);";
var i50 = "return (x >= 0.0) ? x : (exp(x) - 1.0);";
var c75 = t30 + `
  return (x < 0.0) ? 0.0 : x;
`;
var f67 = t30 + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
var h57 = "return x;";
var l52 = "return 1.0 / (1.0 + exp(-1.0 * x));";

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/unaryop_packed_gpu.mjs
var x55 = "return x;";
var l53 = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
var i51 = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var n36 = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var o43 = "return 1.0 / (1.0 + exp(-1.0 * x));";
var e22 = class {
  constructor(t67, r56) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outputShape = t67, this.enableShapeUniforms = F23(this.outputShape.length), this.userCode = `
      vec4 unaryOperation(vec4 x) {
        ${r56}
      }

      void main() {
        vec4 x = getAAtOutCoords();
        vec4 y = unaryOperation(x);

        setOutput(y);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/unpack_gpu.mjs
var o44 = class {
  constructor(e36) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = false, this.outputShape = e36, this.enableShapeUniforms = F23(this.outputShape.length);
    let t67 = e36.length, s84 = u62("rc", t67), n67 = F22(t67), r56 = c73(t67, s84), c103 = s84.slice(-2), i88 = t67 <= 1 ? "rc" : `vec2(${c103.join(",")})`;
    this.userCode = `
      void main() {
        ${n67} rc = getOutputCoords();
        vec4 packedInput = getA(${r56});

        setOutput(getChannel(packedInput, ${i88}));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/backend_webgl.mjs
var ae4 = kernel_impls_exports.whereImpl;
var re5 = 1e-7;
var ne5 = 1e-4;
var C17 = {};
function oe5(P36) {
  return P36 in C17 || (C17[P36] = {}), C17[P36];
}
var ie6 = l().getNumber("CPU_HANDOFF_SIZE_THRESHOLD");
var le3 = 600;
function ue4() {
  return l().global.screen == null ? 1024 : l().global.screen.height * l().global.screen.width * globalThis.devicePixelRatio * le3 / 1024 / 1024;
}
var N41 = class P22 extends o {
  nextDataId() {
    return P22.nextDataId++;
  }
  constructor(e36) {
    if (super(), this.pendingRead = /* @__PURE__ */ new WeakMap(), this.pendingDisposal = /* @__PURE__ */ new WeakSet(), this.dataRefCount = /* @__PURE__ */ new WeakMap(), this.numBytesInGPU = 0, this.uploadWaitMs = 0, this.downloadWaitMs = 0, this.lastGlFlushTime = 0, this.warnedAboutMemory = false, this.pendingDeletes = 0, this.disposed = false, !l().getBool("HAS_WEBGL")) throw new Error("WebGL is not supported on this device");
    let t67;
    if (e36 != null) {
      if (e36 instanceof f64) t67 = e36;
      else {
        let s84 = f62(l().getNumber("WEBGL_VERSION"), e36);
        t67 = new f64(s84);
      }
      this.binaryCache = {}, this.gpgpuCreatedLocally = false;
    } else {
      let s84 = f62(l().getNumber("WEBGL_VERSION"));
      t67 = new f64(s84), this.binaryCache = oe5(l().getNumber("WEBGL_VERSION")), this.gpgpuCreatedLocally = true;
    }
    this.gpgpu = t67, this.canvas = this.gpgpu.gl.canvas, this.textureManager = new c74(this.gpgpu), this.numMBBeforeWarning = ue4(), this.texData = new n(this, k7());
  }
  numDataIds() {
    return this.texData.numDataIds() - this.pendingDeletes;
  }
  writeTexture(e36, t67, s84, a71, o80, l80) {
    let n67 = this.makeTensorInfo(t67, s84), r56 = this.texData.get(n67.dataId);
    r56.isPacked = false, r56.texture = { texture: e36, texShape: [a71, o80] }, r56.texShape = [a71, o80];
    let i88 = fe(t67), h74 = new r23(i88, false, l80), g72 = this.runWebGLProgram(h74, [n67], s84, [[a71, o80]]);
    return g72.shape = t67, r56.texture = null, this.disposeIntermediateTensorInfo(n67), g72.dataId;
  }
  write(e36, t67, s84) {
    if ((l().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS") || l().getBool("DEBUG")) && this.checkNumericalProblems(e36), s84 === "complex64" && e36 != null) throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
    let a71 = { id: this.nextDataId() };
    return this.texData.set(a71, { shape: t67, dtype: s84, values: e36, usage: R19.UPLOAD, refCount: 1 }), a71;
  }
  refCount(e36) {
    return this.texData.has(e36) ? this.texData.get(e36).refCount : 0;
  }
  incRef(e36) {
    let t67 = this.texData.get(e36);
    t67.refCount++;
  }
  decRef(e36) {
    if (this.texData.has(e36)) {
      let t67 = this.texData.get(e36);
      t67.refCount--;
    }
  }
  move(e36, t67, s84, a71, o80) {
    if (l().getBool("DEBUG") && this.checkNumericalProblems(t67), a71 === "complex64") throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
    this.texData.set(e36, { shape: s84, dtype: a71, values: t67, usage: R19.UPLOAD, refCount: o80 });
  }
  disposeIntermediateTensorInfo(e36) {
    this.disposeData(e36.dataId);
  }
  readSync(e36) {
    let t67 = this.texData.get(e36), { values: s84, dtype: a71, complexTensorInfos: o80, slice: l80, shape: n67, isPacked: r56 } = t67;
    if (l80 != null) {
      let m96;
      r56 ? m96 = new e22(n67, h57) : m96 = new e21(n67, h57);
      let x76 = this.runWebGLProgram(m96, [{ dataId: e36, shape: n67, dtype: a71 }], a71), c103 = this.readSync(x76.dataId);
      return this.disposeIntermediateTensorInfo(x76), c103;
    }
    if (s84 != null) return this.convertAndCacheOnCPU(e36);
    if (a71 === "string") return s84;
    let i88 = this.activeTimers != null, h74;
    i88 && (h74 = util_exports.now());
    let g72;
    if (a71 === "complex64") {
      let m96 = this.readSync(o80.real.dataId), x76 = this.readSync(o80.imag.dataId);
      g72 = backend_util_exports.mergeRealAndImagArrays(m96, x76);
    } else g72 = this.getValuesFromTexture(e36);
    return i88 && (this.downloadWaitMs += util_exports.now() - h74), this.convertAndCacheOnCPU(e36, g72);
  }
  async read(e36) {
    if (this.pendingRead.has(e36)) {
      let c103 = this.pendingRead.get(e36);
      return new Promise((D42) => c103.push(D42));
    }
    let t67 = this.texData.get(e36), { values: s84, shape: a71, slice: o80, dtype: l80, complexTensorInfos: n67, isPacked: r56 } = t67;
    if (o80 != null) {
      let c103;
      r56 ? c103 = new e22(a71, h57) : c103 = new e21(a71, h57);
      let D42 = this.runWebGLProgram(c103, [{ dataId: e36, shape: a71, dtype: l80 }], l80), E44 = this.read(D42.dataId);
      return this.disposeIntermediateTensorInfo(D42), E44;
    }
    if (s84 != null) return this.convertAndCacheOnCPU(e36);
    if (l().getBool("DEBUG") && !l().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED") && l().getNumber("WEBGL_VERSION") === 2) throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");
    let i88 = null, h74;
    if (l80 !== "complex64" && l().get("WEBGL_BUFFER_SUPPORTED")) {
      h74 = this.decode(e36);
      let c103 = this.texData.get(h74.dataId);
      i88 = this.gpgpu.createBufferFromTexture(c103.texture.texture, ...C13(a71));
    }
    this.pendingRead.set(e36, []), l80 !== "complex64" && await this.gpgpu.createAndWaitForFence();
    let g72;
    if (l80 === "complex64") {
      let c103 = await Promise.all([this.read(n67.real.dataId), this.read(n67.imag.dataId)]), D42 = c103[0], E44 = c103[1];
      g72 = backend_util_exports.mergeRealAndImagArrays(D42, E44);
    } else if (i88 == null) g72 = this.getValuesFromTexture(e36);
    else {
      let c103 = util_exports.sizeFromShape(a71);
      g72 = this.gpgpu.downloadFloat32MatrixFromBuffer(i88, c103);
    }
    if (h74 != null && this.disposeIntermediateTensorInfo(h74), i88 != null) {
      let c103 = this.gpgpu.gl;
      o41(c103, () => c103.deleteBuffer(i88));
    }
    let m96 = this.convertAndCacheOnCPU(e36, g72), x76 = this.pendingRead.get(e36);
    return this.pendingRead.delete(e36), x76.forEach((c103) => c103(m96)), this.pendingDisposal.has(e36) && (this.pendingDisposal.delete(e36), this.disposeData(e36) && k7().removeDataId(e36, this), this.pendingDeletes--), m96;
  }
  readToGPU(e36, t67 = {}) {
    let s84 = this.texData.get(e36), { values: a71, shape: o80, slice: l80, dtype: n67, isPacked: r56, texture: i88 } = s84;
    if (n67 === "complex64") throw new Error("Does not support reading texture for complex64 dtype.");
    if (l80 != null) {
      let x76;
      r56 ? x76 = new e22(o80, h57) : x76 = new e21(o80, h57);
      let c103 = this.runWebGLProgram(x76, [{ dataId: e36, shape: o80, dtype: n67 }], n67), D42 = this.readToGPU(c103, t67);
      return this.disposeIntermediateTensorInfo(c103), D42;
    }
    if (i88 == null) throw a71 != null ? new Error("Data is not on GPU but on CPU.") : new Error("There is no data on GPU or CPU.");
    let h74 = this.decode(e36, t67.customTexShape), g72 = k7().makeTensorFromTensorInfo(h74), m96 = this.texData.get(h74.dataId);
    return Object.assign({ tensorRef: g72 }, m96.texture);
  }
  bufferSync(e36) {
    let t67 = this.readSync(e36.dataId);
    if (e36.dtype === "string") try {
      let s84 = t67.map((a71) => util_exports.decodeString(a71));
      return i7(e36.shape, e36.dtype, s84);
    } catch {
      throw new Error("Failed to decode encoded string bytes into utf-8");
    }
    return i7(e36.shape, e36.dtype, t67);
  }
  checkNumericalProblems(e36) {
    if (e36 != null) for (let t67 = 0; t67 < e36.length; t67++) {
      let s84 = e36[t67];
      if (!H9(s84)) throw l().getBool("WEBGL_RENDER_FLOAT32_CAPABLE") ? Error(`The value ${s84} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`) : Error(`The value ${s84} cannot be represented on this device.`);
    }
  }
  getValuesFromTexture(e36) {
    let { shape: t67, dtype: s84, isPacked: a71 } = this.texData.get(e36), o80 = util_exports.sizeFromShape(t67);
    if (l().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")) {
      let m96 = this.decode(e36), x76 = this.texData.get(m96.dataId), c103 = this.gpgpu.downloadMatrixFromPackedTexture(x76.texture.texture, ...C13(t67)).subarray(0, o80);
      return this.disposeIntermediateTensorInfo(m96), c103;
    }
    let l80 = l().getBool("WEBGL_PACK") && a71 === true, n67 = l80 ? fe(t67) : t67, r56 = l80 ? new t28(n67) : new t27(n67), i88 = this.runWebGLProgram(r56, [{ shape: n67, dtype: s84, dataId: e36 }], "float32"), h74 = this.texData.get(i88.dataId), g72 = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(h74.texture.texture, h74.texShape[0], h74.texShape[1]).subarray(0, o80);
    return this.disposeIntermediateTensorInfo(i88), g72;
  }
  timerAvailable() {
    return l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0;
  }
  time(e36) {
    let t67 = this.activeTimers, s84 = [], a71 = false;
    this.programTimersStack == null ? (this.programTimersStack = s84, a71 = true) : this.activeTimers.push(s84), this.activeTimers = s84, e36();
    let o80 = util_exports.flatten(this.activeTimers.map((r56) => r56.query)).filter((r56) => r56 != null), l80 = util_exports.flatten(this.activeTimers.map((r56) => r56.name)).filter((r56) => r56 != null);
    this.activeTimers = t67, a71 && (this.programTimersStack = null);
    let n67 = { uploadWaitMs: this.uploadWaitMs, downloadWaitMs: this.downloadWaitMs, kernelMs: null, wallMs: null };
    return (async () => {
      if (l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
        let r56 = await Promise.all(o80);
        n67.kernelMs = util_exports.sum(r56), n67.getExtraProfileInfo = () => r56.map((i88, h74) => ({ name: l80[h74], ms: i88 })).map((i88) => `${i88.name}: ${i88.ms}`).join(", ");
      } else n67.kernelMs = { error: "WebGL query timers are not supported in this environment." };
      return this.uploadWaitMs = 0, this.downloadWaitMs = 0, n67;
    })();
  }
  memory() {
    return { unreliable: false, numBytesInGPU: this.numBytesInGPU, numBytesInGPUAllocated: this.textureManager.numBytesAllocated, numBytesInGPUFree: this.textureManager.numBytesFree };
  }
  startTimer() {
    return l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? this.gpgpu.beginQuery() : { startMs: util_exports.now(), endMs: null };
  }
  endTimer(e36) {
    return l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? (this.gpgpu.endQuery(), e36) : (e36.endMs = util_exports.now(), e36);
  }
  async getQueryTime(e36) {
    if (l().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) return this.gpgpu.waitForQueryAndGetTime(e36);
    let t67 = e36;
    return t67.endMs - t67.startMs;
  }
  disposeData(e36, t67 = false) {
    if (this.pendingDisposal.has(e36)) return false;
    if (!this.texData.has(e36)) return true;
    if (t67 ? this.texData.get(e36).refCount = 0 : this.texData.get(e36).refCount--, !t67 && this.texData.get(e36).refCount > 0) return false;
    if (this.pendingRead.has(e36)) return this.pendingDisposal.add(e36), this.pendingDeletes++, false;
    this.releaseGPUData(e36);
    let { complexTensorInfos: s84 } = this.texData.get(e36);
    return s84 != null && (this.disposeData(s84.real.dataId, t67), this.disposeData(s84.imag.dataId, t67)), this.texData.delete(e36), true;
  }
  releaseGPUData(e36) {
    let { texture: t67, dtype: s84, texShape: a71, usage: o80, isPacked: l80, slice: n67 } = this.texData.get(e36), r56 = n67 && n67.origDataId || e36, i88 = this.dataRefCount.get(r56);
    i88 > 1 ? this.dataRefCount.set(r56, i88 - 1) : (this.dataRefCount.delete(r56), t67 != null && (this.numBytesInGPU -= this.computeBytes(a71, s84), this.textureManager.releaseTexture(t67, a71, o80, l80)));
    let h74 = this.texData.get(e36);
    h74.texture = null, h74.texShape = null, h74.isPacked = false, h74.slice = null;
  }
  getTexture(e36) {
    return this.uploadToGPU(e36), this.texData.get(e36).texture.texture;
  }
  getDataInfo(e36) {
    return this.texData.get(e36);
  }
  shouldExecuteOnCPU(e36, t67 = ie6) {
    return l().getBool("WEBGL_CPU_FORWARD") && e36.every((s84) => this.texData.get(s84.dataId).texture == null && util_exports.sizeFromShape(s84.shape) < t67);
  }
  getGPGPUContext() {
    return this.gpgpu;
  }
  where(e36) {
    backend_util_exports.warn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");
    let t67 = e36.dataSync();
    return ae4(e36.shape, t67);
  }
  packedUnaryOp(e36, t67, s84) {
    let a71 = new e22(e36.shape, t67), o80 = this.compileAndRun(a71, [e36], s84);
    return k7().makeTensorFromTensorInfo(o80);
  }
  abs(e36) {
    if (this.shouldExecuteOnCPU([e36]) && e36.dtype !== "complex64") {
      let a71 = k34(this.texData.get(e36.dataId).values);
      return this.makeOutput(e36.shape, e36.dtype, a71);
    }
    if (l().getBool("WEBGL_PACK_UNARY_OPERATIONS")) return this.packedUnaryOp(e36, p67, e36.dtype);
    let t67 = new e21(e36.shape, p67), s84 = this.compileAndRun(t67, [e36]);
    return k7().makeTensorFromTensorInfo(s84);
  }
  makeTensorInfo(e36, t67, s84) {
    let a71;
    if (t67 === "string" && s84 != null && s84.length > 0 && util_exports.isString(s84[0])) {
      let o80 = s84.map((l80) => util_exports.encodeString(l80));
      a71 = this.write(o80, e36, t67);
    } else a71 = this.write(s84, e36, t67);
    return this.texData.get(a71).usage = null, { dataId: a71, shape: e36, dtype: t67 };
  }
  makeOutput(e36, t67, s84) {
    return k7().makeTensorFromTensorInfo(this.makeTensorInfo(e36, t67, s84), this);
  }
  unpackTensor(e36) {
    let t67 = new o44(e36.shape);
    return this.runWebGLProgram(t67, [e36], e36.dtype);
  }
  packTensor(e36) {
    let t67 = new i49(e36.shape);
    return this.runWebGLProgram(t67, [e36], e36.dtype, null, true);
  }
  packedReshape(e36, t67) {
    let s84 = [N36(e36.shape), ...O15(e36.shape)], a71 = { dtype: e36.dtype, shape: s84, dataId: e36.dataId }, o80 = [N36(t67), ...O15(t67)], l80 = new a46(o80, s84), n67 = true, r56 = [s84], i88 = this.runWebGLProgram(l80, [a71], e36.dtype, r56, n67);
    return { dataId: i88.dataId, shape: t67, dtype: i88.dtype };
  }
  decode(e36, t67) {
    let s84 = this.texData.get(e36), { isPacked: a71, shape: o80, dtype: l80 } = s84;
    if (t67 != null) {
      let m96 = util_exports.sizeFromShape(o80), x76 = t67[0] * t67[1] * 4;
      util_exports.assert(m96 <= x76, () => "customTexShape is too small. Row * Column * 4 should be equal or larger than the size of the tensor data.");
    }
    let n67 = fe(o80), r56;
    a71 ? r56 = new i47(n67) : r56 = new i46(n67);
    let i88 = true, h74 = [t67 ?? C13(n67)], g72 = this.runWebGLProgram(r56, [{ shape: n67, dtype: l80, dataId: e36 }], l80, h74, i88, t67);
    return { dtype: l80, shape: o80, dataId: g72.dataId };
  }
  runWebGLProgram(e36, t67, s84, a71, o80 = false, l80) {
    let n67 = this.makeTensorInfo(e36.outputShape, s84), r56 = this.texData.get(n67.dataId);
    if (e36.packedOutput && (r56.isPacked = true), e36.outPackingScheme === L13.DENSE) {
      let p103 = l80 ?? C13(e36.outputShape);
      r56.texShape = p103.map((T40) => T40 * 2);
    }
    if (e36.outTexUsage != null && (r56.usage = e36.outTexUsage), util_exports.sizeFromShape(n67.shape) === 0) return r56.values = util_exports.getTypedArrayFromDType(n67.dtype, 0), n67;
    let i88 = [], h74 = t67.map((p103) => {
      if (p103.dtype === "complex64") throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");
      let T40 = this.texData.get(p103.dataId);
      if (T40.texture == null) {
        if (!e36.packedInputs && util_exports.sizeFromShape(p103.shape) <= l().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM")) return { shape: p103.shape, texData: null, isUniform: true, uniformValues: T40.values };
        e36.packedInputs && (T40.isPacked = true, T40.shape = p103.shape);
      }
      if (this.uploadToGPU(p103.dataId), !!T40.isPacked != !!e36.packedInputs) p103 = T40.isPacked ? this.unpackTensor(p103) : this.packTensor(p103), i88.push(p103), T40 = this.texData.get(p103.dataId);
      else if (T40.isPacked && !ae2(T40.shape, p103.shape)) {
        let L22 = p103, S45 = p103.shape;
        p103.shape = T40.shape, p103 = this.packedReshape(p103, S45), i88.push(p103), T40 = this.texData.get(p103.dataId), L22.shape = S45;
      }
      return { shape: p103.shape, texData: T40, isUniform: false };
    });
    this.uploadToGPU(n67.dataId);
    let g72 = { shape: n67.shape, texData: r56, isUniform: false }, m96 = B19(e36, h74, g72), x76 = this.getAndSaveBinary(m96, () => N38(this.gpgpu, e36, h74, g72)), c103 = this.activeTimers != null, D42;
    c103 && (D42 = this.startTimer()), l().get("ENGINE_COMPILE_ONLY") || y30(this.gpgpu, x76, h74, g72, a71), i88.forEach((p103) => this.disposeIntermediateTensorInfo(p103)), c103 && (D42 = this.endTimer(D42), this.activeTimers.push({ name: e36.constructor.name, query: this.getQueryTime(D42) }));
    let E44 = l().getNumber("WEBGL_FLUSH_THRESHOLD");
    if (E44 > 0) {
      let p103 = util_exports.now();
      p103 - this.lastGlFlushTime > E44 && (this.gpgpu.gl.flush(), this.lastGlFlushTime = p103);
    }
    if (!l().getBool("WEBGL_LAZILY_UNPACK") && r56.isPacked && o80 === false) {
      let p103 = this.unpackTensor(n67);
      return this.disposeIntermediateTensorInfo(n67), p103;
    }
    return n67;
  }
  compileAndRun(e36, t67, s84, a71, o80 = false) {
    return s84 = s84 || t67[0].dtype, this.runWebGLProgram(e36, t67, s84, a71, o80);
  }
  getAndSaveBinary(e36, t67) {
    return e36 in this.binaryCache || (this.binaryCache[e36] = t67()), this.binaryCache[e36];
  }
  getTextureManager() {
    return this.textureManager;
  }
  dispose() {
    this.disposed || (l().getBool("IS_TEST") || Object.keys(this.binaryCache).forEach((t67) => {
      this.gpgpu.deleteProgram(this.binaryCache[t67].webGLProgram), delete this.binaryCache[t67];
    }), this.textureManager.dispose(), this.canvas != null && typeof HTMLCanvasElement < "u" && this.canvas instanceof HTMLCanvasElement ? this.canvas.remove() : this.canvas = null, this.gpgpuCreatedLocally && (this.gpgpu.program = null, this.gpgpu.dispose()), this.disposed = true);
  }
  floatPrecision() {
    return this.floatPrecisionValue == null && (this.floatPrecisionValue = g4(() => {
      if (!l().get("WEBGL_RENDER_FLOAT32_ENABLED")) {
        let e36 = l().getBool("DEBUG");
        l().set("DEBUG", false);
        let t67 = this.abs(m21(1e-8)).dataSync()[0];
        if (l().set("DEBUG", e36), t67 > 0) return 32;
      }
      return 16;
    })), this.floatPrecisionValue;
  }
  epsilon() {
    return this.floatPrecision() === 32 ? re5 : ne5;
  }
  uploadToGPU(e36) {
    let t67 = this.texData.get(e36), { shape: s84, dtype: a71, values: o80, texture: l80, usage: n67, isPacked: r56 } = t67;
    if (l80 != null) return;
    let i88 = this.activeTimers != null, h74;
    i88 && (h74 = util_exports.now());
    let g72 = t67.texShape;
    if (g72 == null && (g72 = Ee(s84, r56), t67.texShape = g72), o80 != null) {
      let m96 = fe(s84), x76, c103 = g72[1], D42 = g72[0], E44 = o80 instanceof Uint8Array || o80 instanceof Uint8ClampedArray;
      (r56 || !E44) && ([c103, D42] = O14(g72[0], g72[1])), r56 ? x76 = new f63(m96, E44) : x76 = new r23(m96, E44);
      let p103 = E44 ? [D42, c103] : g72, T40 = this.makeTensorInfo(p103, a71), L22 = this.texData.get(T40.dataId);
      E44 ? L22.usage = R19.PIXELS : L22.usage = R19.UPLOAD, L22.texShape = p103, this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(T40.dataId), c103, D42, o80);
      let S45 = [[D42, c103]], U24 = this.runWebGLProgram(x76, [T40], a71, S45, true), b58 = this.texData.get(U24.dataId);
      t67.texShape = b58.texShape, t67.isPacked = b58.isPacked, t67.usage = b58.usage, l().get("ENGINE_COMPILE_ONLY") ? this.disposeData(U24.dataId) : (t67.texture = b58.texture, t67.values = null, this.texData.delete(U24.dataId)), this.disposeIntermediateTensorInfo(T40), i88 && (this.uploadWaitMs += util_exports.now() - h74);
    } else {
      let m96 = this.acquireTexture(g72, n67, a71, r56);
      t67.texture = m96;
    }
  }
  convertAndCacheOnCPU(e36, t67) {
    let s84 = this.texData.get(e36), { dtype: a71 } = s84;
    return t67 != null && (s84.values = he2(t67, a71)), s84.values;
  }
  acquireTexture(e36, t67, s84, a71) {
    if (this.numBytesInGPU += this.computeBytes(e36, s84), !this.warnedAboutMemory && this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {
      let o80 = (this.numBytesInGPU / 1024 / 1024).toFixed(2);
      this.warnedAboutMemory = true, console.warn(`High memory usage in GPU: ${o80} MB, most likely due to a memory leak`);
    }
    return this.textureManager.acquireTexture(e36, t67, a71);
  }
  computeBytes(e36, t67) {
    return e36[0] * e36[1] * util_exports.bytesPerElement(t67);
  }
  checkCompileCompletion() {
    for (let [, e36] of Object.entries(this.binaryCache)) this.checkCompletion_(e36);
  }
  async checkCompileCompletionAsync() {
    let e36 = [];
    if (this.gpgpu.parallelCompilationExtension) {
      for (let [, t67] of Object.entries(this.binaryCache)) e36.push(this.checkCompletionAsync_(t67));
      return Promise.all(e36);
    } else {
      for (let [, t67] of Object.entries(this.binaryCache)) {
        let s84 = new Promise((a71) => {
          try {
            this.checkCompletion_(t67), a71(true);
          } catch (o80) {
            throw o80;
          }
        });
        e36.push(s84);
      }
      return Promise.all(e36);
    }
  }
  async checkCompletionAsync_(e36) {
    return this.gpgpu.gl.getProgramParameter(e36.webGLProgram, this.gpgpu.parallelCompilationExtension.COMPLETION_STATUS_KHR) ? this.checkCompletion_(e36) : (await n18(), this.checkCompletionAsync_(e36));
  }
  checkCompletion_(e36) {
    if (this.gpgpu.gl.getProgramParameter(e36.webGLProgram, this.gpgpu.gl.LINK_STATUS) === false) throw console.log(this.gpgpu.gl.getProgramInfoLog(e36.webGLProgram)), this.gpgpu.gl.getShaderParameter(e36.fragmentShader, this.gpgpu.gl.COMPILE_STATUS) === false ? (X14(e36.source, this.gpgpu.gl.getShaderInfoLog(e36.fragmentShader)), new Error("Failed to compile fragment shader.")) : new Error("Failed to link vertex and fragment shaders.");
    return true;
  }
  getUniformLocations() {
    for (let e36 of Object.values(this.binaryCache)) {
      this.gpgpu.buildVao(e36.webGLProgram);
      let { variablesLocations: t67, customUniformLocations: s84, infLoc: a71, nanLoc: o80, outShapeLocation: l80, outShapeStridesLocation: n67, outTexShapeLocation: r56 } = O17(this.gpgpu, e36.program, e36.webGLProgram);
      e36.variablesLocations = t67, e36.customUniformLocations = s84, e36.infLoc = a71, e36.nanLoc = o80, e36.outShapeLocation = l80, e36.outShapeStridesLocation = n67, e36.outTexShapeLocation = r56;
    }
  }
  createTensorFromGPUData(e36, t67, s84) {
    e36.channels = e36.channels || "RGBA";
    let { texture: a71, height: o80, width: l80, channels: n67 } = e36, r56 = k7().backend;
    if (!r56.gpgpu.gl.isTexture(a71)) throw new Error("The texture is invalid. Also, please make sure the texture and the TFJS WebGL backend are using the same canvas. If you want to use your own custom canvas, you have to create and use the custom TFJS WebGL backend created from the canvas through 'new tf.MathBackendWebGL(customCanvas)'.");
    let i88 = r56.writeTexture(a71, t67, s84, o80, l80, n67);
    return k7().makeTensorFromDataId(i88, t67, s84, r56);
  }
};
N41.nextDataId = 0;
function he2(P36, e36) {
  if (e36 === "float32" || e36 === "complex64") return P36;
  if (e36 === "int32" || e36 === "bool") {
    let t67 = e36 === "int32" ? new Int32Array(P36.length) : new Uint8Array(P36.length);
    for (let s84 = 0; s84 < t67.length; ++s84) t67[s84] = Math.round(P36[s84]);
    return t67;
  } else throw new Error(`Unknown dtype ${e36}`);
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/version.mjs
var o45 = "4.22.0";

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/webgl.mjs
function p68() {
  l().set("WEBGL_FORCE_F16_TEXTURES", true);
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/base.mjs
device_util_exports.isBrowser() && R3("webgl", () => new N41(), 2);
var s47 = { forceHalfFloat: p68 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/binaryop_gpu.mjs
var p69 = `
  if (isnan(a)) return a;
  if (isnan(b)) return b;
`;
var t31 = class {
  constructor(a71, o80, e36) {
    this.variableNames = ["A", "B"], this.outputShape = backend_util_exports.assertAndGetBroadcastShape(o80, e36), this.enableShapeUniforms = F23(this.outputShape.length), this.userCode = `
      float binaryOperation(float a, float b) {
        ${a71}
      }

      void main() {
        float a = getAAtOutCoords();
        float b = getBAtOutCoords();
        setOutput(binaryOperation(a, b));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/binaryop_packed_gpu.mjs
var x56 = `
  result.r = isNaN.r ? NAN : result.r;
  result.g = isNaN.g ? NAN : result.g;
  result.b = isNaN.b ? NAN : result.b;
  result.a = isNaN.a ? NAN : result.a;
`;
var u64 = class {
  constructor(o80, r56, l80, n67 = false) {
    this.variableNames = ["A", "B"], this.supportsBroadcasting = true, this.packedInputs = true, this.packedOutput = true, this.outputShape = backend_util_exports.assertAndGetBroadcastShape(r56, l80);
    let t67 = this.outputShape.length;
    this.enableShapeUniforms = F23(t67);
    let e36 = "";
    if (n67) if (t67 === 0 || util_exports.sizeFromShape(this.outputShape) === 1) e36 = `
          result.y = 0.;
          result.z = 0.;
          result.w = 0.;
        `;
    else if (e36 = `
          ${F22(t67)} coords = getOutputCoords();
        `, t67 === 1) this.enableShapeUniforms ? e36 += `
            result.y = (coords + 1) >= outShape ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          ` : e36 += `
            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;
            result.z = 0.;
            result.w = 0.;
          `;
    else {
      let s84 = u62("coords", t67);
      this.enableShapeUniforms ? e36 += `
            bool nextRowOutOfBounds =
              (${s84[t67 - 2]} + 1) >= outShape[${t67} - 2];
            bool nextColOutOfBounds =
              (${s84[t67 - 1]} + 1) >= outShape[${t67} - 1];
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          ` : e36 += `
            bool nextRowOutOfBounds =
              (${s84[t67 - 2]} + 1) >= ${this.outputShape[t67 - 2]};
            bool nextColOutOfBounds =
              (${s84[t67 - 1]} + 1) >= ${this.outputShape[t67 - 1]};
            result.y = nextColOutOfBounds ? 0. : result.y;
            result.z = nextRowOutOfBounds ? 0. : result.z;
            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;
          `;
    }
    this.userCode = `
      vec4 binaryOperation(vec4 a, vec4 b) {
        ${o80}
      }

      void main() {
        vec4 a = getAAtOutCoords();
        vec4 b = getBAtOutCoords();

        vec4 result = binaryOperation(a, b);
        ${e36}

        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Identity.mjs
function i52(t67) {
  let { inputs: n67, backend: d55 } = t67, { x: e36 } = n67;
  return d55.incRef(e36.dataId), { dataId: e36.dataId, shape: e36.shape, dtype: e36.dtype };
}
var c76 = { kernelName: mo, backendName: "webgl", kernelFunc: i52 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Complex.mjs
function i53(c103) {
  let { inputs: m96, backend: e36 } = c103, { real: o80, imag: r56 } = m96, n67 = e36.makeTensorInfo(o80.shape, "complex64"), a71 = e36.texData.get(n67.dataId), s84 = i52({ inputs: { x: o80 }, backend: e36 }), p103 = i52({ inputs: { x: r56 }, backend: e36 });
  return a71.complexTensorInfos = { real: s84, imag: p103 }, n67;
}
var g53 = { kernelName: P2, backendName: "webgl", kernelFunc: i53 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/LeakyRelu.mjs
var h58 = "return (a < 0.) ? b * a : a;";
var L18 = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
function k35(o80) {
  let { inputs: n67, backend: a71, attrs: t67 } = o80, { x: r56 } = n67, { alpha: s84 } = t67, e36 = a71.makeTensorInfo([], "float32", util_exports.createScalarValue(s84, "float32")), c103 = l().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new u64(L18, r56.shape, e36.shape) : new t31(h58, r56.shape, e36.shape), l80 = a71.runWebGLProgram(c103, [r56, e36], "float32");
  return a71.disposeIntermediateTensorInfo(e36), l80;
}
var R21 = { kernelName: No, backendName: "webgl", kernelFunc: k35 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Prelu.mjs
var l54 = "return (a < 0.) ? b * a : a;";
var u65 = `
  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));
  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);
`;
function P23(a71) {
  let { inputs: n67, backend: o80 } = a71, { x: e36, alpha: r56 } = n67, t67 = l().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new u64(u65, e36.shape, r56.shape) : new t31(l54, e36.shape, r56.shape);
  return o80.runWebGLProgram(t67, [e36, r56], "float32");
}
var L19 = { kernelName: xt, backendName: "webgl", kernelFunc: P23 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernel_utils/kernel_funcs_utils.mjs
var q18 = "if (isnan(x)) return x;";
function v32({ opSnippet: t67, packedOpSnippet: a71, cpuKernelImpl: c103, dtype: I44 }) {
  return ({ inputs: y43, backend: P36 }) => {
    let { x: u86 } = y43, p103 = P36, e36 = I44 || u86.dtype;
    if (p103.shouldExecuteOnCPU([u86]) && c103 != null) {
      let l80 = p103.texData.get(u86.dataId), E44 = c103(l80.values, e36);
      return p103.makeTensorInfo(u86.shape, e36, E44);
    }
    let n67 = l().getBool("WEBGL_PACK_UNARY_OPERATIONS") && a71 != null, r56;
    return n67 ? r56 = new e22(u86.shape, a71) : r56 = new e21(u86.shape, t67), p103.runWebGLProgram(r56, [u86], e36);
  };
}
function z26({ opSnippet: t67, packedOpSnippet: a71, checkOutOfBounds: c103 = false, supportsComplex: I44 = false, cpuKernelImpl: y43, dtype: P36 }) {
  return ({ inputs: u86, backend: p103 }) => {
    let { a: e36, b: n67 } = u86, r56 = p103;
    if (I44 && e36.dtype === "complex64") {
      let m96 = r56.texData.get(e36.dataId), f85 = r56.texData.get(n67.dataId), [g72, _24] = [[m96.complexTensorInfos.real, f85.complexTensorInfos.real], [m96.complexTensorInfos.imag, f85.complexTensorInfos.imag]].map((L22) => {
        let [d55, i88] = L22, T40 = { dataId: d55.dataId, dtype: d55.dtype, shape: e36.shape }, D42 = { dataId: i88.dataId, dtype: i88.dtype, shape: n67.shape }, O21 = new t31(t67, e36.shape, n67.shape);
        return r56.runWebGLProgram(O21, [T40, D42], c5(d55.dtype, i88.dtype));
      }), x76 = i53({ inputs: { real: g72, imag: _24 }, backend: r56 });
      return r56.disposeIntermediateTensorInfo(g72), r56.disposeIntermediateTensorInfo(_24), x76;
    }
    let l80 = P36 || c5(e36.dtype, n67.dtype);
    if ((e36.dtype === "string" || n67.dtype === "string" || r56.shouldExecuteOnCPU([e36, n67])) && y43 != null) {
      let m96 = r56.texData.get(e36.dataId).values, f85 = r56.texData.get(n67.dataId).values, g72 = e36.dtype === "string" ? backend_util_exports.fromUint8ToStringArray(m96) : m96, _24 = e36.dtype === "string" ? backend_util_exports.fromUint8ToStringArray(f85) : f85, [x76, L22] = y43(e36.shape, n67.shape, g72, _24, l80), d55 = r56.makeTensorInfo(L22, l80), i88 = r56.texData.get(d55.dataId);
      return i88.values = x76, d55;
    }
    let E44 = l().getBool("WEBGL_PACK_BINARY_OPERATIONS") && a71 != null, h74;
    return E44 ? h74 = new u64(a71, e36.shape, n67.shape, c103) : h74 = new t31(t67, e36.shape, n67.shape), r56.runWebGLProgram(h74, [e36, n67], l80);
  };
}
function J12(t67, a71 = false) {
  if (t67 === "linear") return a71 ? x55 : u63;
  if (t67 === "relu") return a71 ? i51 : c75;
  if (t67 === "elu") return a71 ? l53 : i50;
  if (t67 === "relu6") return a71 ? n36 : f67;
  if (t67 === "prelu") return a71 ? u65 : l54;
  if (t67 === "leakyrelu") return a71 ? L18 : h58;
  if (t67 === "sigmoid") return a71 ? o43 : l52;
  throw new Error(`Activation ${t67} has not been implemented for the WebGL backend.`);
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/mulmat_packed_gpu.mjs
var d32 = class {
  constructor(e36, s84, b58, c103 = false, r56 = false, a71 = false, t67 = null, o80 = false, l80 = false) {
    this.variableNames = ["matrixA", "matrixB"], this.packedInputs = true, this.packedOutput = true, this.outputShape = b58, this.enableShapeUniforms = F23(this.outputShape.length);
    let m96 = c103 ? e36[1] : e36[2], u86 = Math.ceil(m96 / 2), x76 = c103 ? "i * 2, rc.y" : "rc.y, i * 2", $37 = r56 ? "rc.z, i * 2" : "i * 2, rc.z", n67 = c103 ? ["a.xxyy", "a.zzww"] : ["a.xxzz", "a.yyww"], p103 = r56 ? ["b.xzxz", "b.ywyw"] : ["b.xyxy", "b.zwzw"], i88 = "", h74 = "";
    t67 && (o80 ? i88 = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${t67}
        }` : l80 ? i88 = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${t67}
        }` : i88 = `vec4 activation(vec4 x) {
          ${t67}
        }`, h74 = "result = activation(result);");
    let z32 = a71 ? "result += getBiasAtOutCoords();" : "";
    a71 && this.variableNames.push("bias"), o80 && this.variableNames.push("preluActivationWeights"), l80 && this.variableNames.push("leakyreluAlpha");
    let f85 = "rc.x", v42 = "rc.x";
    e36[0] < s84[0] ? f85 = `imod(rc.x, ${e36[0]})` : s84[0] < e36[0] && (v42 = `imod(rc.x, ${s84[0]})`), this.userCode = `
      ${i88}
      // Don't use uniform for sharedDimensionPacked for performance.
      const float sharedDimension = ${u86}.0;

      vec4 dot2x2ARowBCol(ivec3 rc) {
        vec4 result = vec4(0);
        int batchA = ${f85};
        int batchB = ${v42};
        for (int i = 0; i < ${u86}; i++) {
          vec4 a = getMatrixA(batchA, ${x76});
          vec4 b = getMatrixB(batchB, ${$37});

          // These swizzled products need to be separately added.
          // See: https://github.com/tensorflow/tfjs/issues/1735
          result += (${n67[0]} * ${p103[0]});
          result += (${n67[1]} * ${p103[1]});
        }
        return result;
      }

      void main() {
        ivec3 rc = getOutputCoords();
        vec4 result = dot2x2ARowBCol(rc);

        ${z32}

        ${h74}

        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/binaryop_complex_gpu.mjs
var m73 = { REAL: "return areal * breal - aimag * bimag;", IMAG: "return areal * bimag + aimag * breal;" };
var a47 = class {
  constructor(t67, e36, o80) {
    this.variableNames = ["AReal", "AImag", "BReal", "BImag"], this.outputShape = backend_util_exports.assertAndGetBroadcastShape(e36, o80), this.userCode = `
      float binaryOpComplex(
          float areal, float aimag, float breal, float bimag) {
        ${t67}
      }

      void main() {
        float areal = getARealAtOutCoords();
        float aimag = getAImagAtOutCoords();
        float breal = getBRealAtOutCoords();
        float bimag = getBImagAtOutCoords();
        setOutput(binaryOpComplex(areal, aimag, breal, bimag));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Multiply.mjs
var I30 = "return a * b;";
function D23(g72) {
  let { inputs: f85, backend: e36 } = g72, { a: a71, b: t67 } = f85, s84 = backend_util_exports.upcastType(a71.dtype, t67.dtype);
  if (a71.dtype === "complex64") {
    let o80 = e36.texData.get(a71.dataId), p103 = e36.texData.get(t67.dataId), d55 = new a47(m73.REAL, a71.shape, t67.shape), l80 = new a47(m73.IMAG, a71.shape, t67.shape), r56 = [{ dataId: o80.complexTensorInfos.real.dataId, dtype: o80.complexTensorInfos.real.dtype, shape: a71.shape }, { dataId: o80.complexTensorInfos.imag.dataId, dtype: o80.complexTensorInfos.imag.dtype, shape: a71.shape }, { dataId: p103.complexTensorInfos.real.dataId, dtype: p103.complexTensorInfos.real.dtype, shape: t67.shape }, { dataId: p103.complexTensorInfos.imag.dataId, dtype: p103.complexTensorInfos.imag.dtype, shape: t67.shape }], n67 = e36.runWebGLProgram(d55, r56, "float32"), i88 = e36.runWebGLProgram(l80, r56, "float32"), y43 = i53({ inputs: { real: n67, imag: i88 }, backend: e36 });
    return e36.disposeIntermediateTensorInfo(n67), e36.disposeIntermediateTensorInfo(i88), y43;
  }
  if (e36.shouldExecuteOnCPU([a71, t67])) {
    let o80 = e36.texData.get(a71.dataId), p103 = e36.texData.get(t67.dataId), [d55, l80] = b35(a71.shape, t67.shape, o80.values, p103.values, s84), r56 = e36.makeTensorInfo(l80, s84), n67 = e36.texData.get(r56.dataId);
    return n67.values = d55, r56;
  }
  let m96;
  return l().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? m96 = new u64(I30, a71.shape, t67.shape) : m96 = new t31(I30, a71.shape, t67.shape), e36.runWebGLProgram(m96, [a71, t67], s84);
}
var w31 = { kernelName: Qo, backendName: "webgl", kernelFunc: D23 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernel_utils/reshape.mjs
function D24(t67, e36, r56) {
  let a71 = [N36(t67.shape), ...O15(t67.shape)], d55 = { dtype: t67.dtype, shape: a71, dataId: t67.dataId }, c103 = [N36(e36), ...O15(e36)], n67 = new a46(c103, a71), m96 = true, u86 = [a71], o80 = r56.runWebGLProgram(n67, [d55], t67.dtype, u86, m96);
  return { dataId: o80.dataId, shape: e36, dtype: o80.dtype };
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Reshape.mjs
function f68(r56) {
  let { inputs: d55, backend: c103, attrs: i88 } = r56, { x: e36 } = d55, { shape: m96 } = i88, s84 = c103, n67 = util_exports.sizeFromShape(e36.shape), a71 = util_exports.inferFromImplicitShape(m96, n67), h74 = util_exports.sizeFromShape(a71);
  util_exports.assert(n67 === h74, () => `The new shape (${a71}) has ${h74} elements and the old shape (${e36.shape}) has ${n67} elements. The new shape and old shape must have the same number of elements.`);
  let p103 = s84.texData.get(e36.dataId);
  return p103.isPacked && !ae2(e36.shape, a71) && !(p103.texture !== null && ae2(p103.shape, a71)) ? D24(e36, a71, s84) : (s84.incRef(e36.dataId), { dataId: e36.dataId, shape: a71, dtype: e36.dtype });
}
var b36 = { kernelName: Rt, backendName: "webgl", kernelFunc: f68 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/mean_gpu.mjs
var s48 = class {
  constructor(l80, a71) {
    this.variableNames = ["x"];
    let { windowSize: t67, batchSize: d55, inSize: u86, outSize: h74 } = l80;
    this.outputShape = [d55, h74];
    let c103 = Math.floor(t67 / 4) * 4, i88 = t67 % 4, e36 = "sumValue += dot(values, ones);";
    if (a71 != null) {
      let n67 = 1 / a71;
      e36 = `sumValue += dot(values * ${util_exports.isInt(n67) ? n67.toPrecision(2) : n67}, ones);`;
    }
    let o80 = "";
    u86 % t67 > 0 && (o80 = `
        if (inIdx < 0 || inIdx >= ${u86}) {
          return 0.0;
        }
      `), this.userCode = `
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${o80}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${t67};

        float sumValue = 0.0;

        for (int i = 0; i < ${c103}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${e36}
        }

        int inIdx = inOffset + ${c103};
        if (${i88 === 1}) {
          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);

          ${e36}
        } else if (${i88 === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1), 0.0, 0.0);

          ${e36}
        } else if (${i88 === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2), 0.0);

          ${e36}
        }
        setOutput(sumValue);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/reduce_gpu.mjs
var d33 = class {
  constructor(c103, a71) {
    this.variableNames = ["x"];
    let { windowSize: n67, batchSize: x76, inSize: s84, outSize: $37 } = c103;
    this.outputShape = [x76, $37];
    let i88 = "0.0", u86 = "";
    a71 === "prod" ? i88 = "1.0" : a71 === "min" ? (i88 = "1.0 / 1e-20", u86 = "min") : a71 === "max" && (i88 = "-1.0 / 1e-20", u86 = "max");
    let t67 = `${a71}(${a71}(${a71}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    a71 === "sum" ? t67 = "sumValue" : a71 === "prod" ? t67 = "prodValue" : a71 === "all" ? t67 = "allValue" : a71 === "any" && (t67 = "anyValue");
    let V24 = Math.floor(n67 / 4) * 4, o80 = n67 % 4, e36 = `
      if (${a71 === "sum"}) {
        sumValue += dot(values, ones);
      } else if (${a71 === "prod"}) {
        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);
        prodValue *= tmp[0] * tmp[1];
      } else {
        minMaxValue = ${u86}(values, minMaxValue);
        if (${a71 === "min"} || ${a71 === "max"}) {
          minMaxValue = ${u86}(values, minMaxValue);
          bvec4 isNaN = isnan(values);
          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {
            minMaxValue = vec4(NAN);
          }
        }
      }
    `, l80 = "vec4";
    a71 === "all" ? (i88 = "1.0", e36 = `
        bool reducedAllValue = all(values);
        float floatedReducedAllValue = float(reducedAllValue);
        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);
      `, l80 = "bvec4") : a71 === "any" && (i88 = "0.0", e36 = `
        bool reducedAnyValue = any(values);
        float floatedReducedAnyValue = float(reducedAnyValue);
        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);
      `, l80 = "bvec4");
    let f85 = "";
    s84 % n67 > 0 && (f85 = `
        if (inIdx < 0 || inIdx >= ${s84}) {
          return initializationValue;
        }
      `), this.userCode = `
      const float initializationValue = ${i88};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float getValue(int batch, int inIdx) {
        ${f85}
        return getX(batch, inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${n67};

        vec4 minMaxValue = vec4(${i88});
        float prodValue = 1.0;
        float sumValue = 0.0;
        float allValue = 1.0;
        float anyValue = 0.0;

        for (int i = 0; i < ${V24}; i += 4) {
          int inIdx = inOffset + i;
          ${l80} values = ${l80}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          ${e36}
        }

        int inIdx = inOffset + ${V24};
        if (${o80 === 1}) {
          ${l80} values = ${l80}(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          ${e36}
        } else if (${o80 === 2}) {
          ${l80} values = ${l80}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          ${e36}
        } else if (${o80 === 3}) {
          ${l80} values = ${l80}(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          ${e36}
        }
        setOutput(${t67});
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernel_utils/reduce.mjs
function p70(t67) {
  let e36 = [];
  for (; e36.length === 0 || e36[e36.length - 1].outSize !== 1; ) {
    let i88 = e36.length ? e36[e36.length - 1].outSize : t67[1], o80 = backend_util_exports.computeOptimalWindowSize(i88);
    e36.push({ inSize: i88, windowSize: o80, outSize: Math.ceil(i88 / o80) });
  }
  return e36;
}
function w32(t67, e36, i88, o80) {
  let h74 = p70(t67.shape), n67 = t67;
  for (let r56 = 0; r56 < h74.length; r56++) {
    let { inSize: a71, windowSize: s84, outSize: u86 } = h74[r56], l80, c103;
    i88 === "mean" ? l80 = r56 === 0 ? new s48({ windowSize: s84, inSize: a71, batchSize: t67.shape[0], outSize: u86 }, a71) : new s48({ windowSize: s84, inSize: a71, batchSize: t67.shape[0], outSize: u86 }) : l80 = new d33({ windowSize: s84, inSize: a71, batchSize: t67.shape[0], outSize: u86 }, i88), c103 = n67, n67 = o80.runWebGLProgram(l80, [n67], e36), c103.dataId !== t67.dataId && o80.disposeIntermediateTensorInfo(c103);
  }
  return n67;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/transpose_gpu.mjs
var i54 = class {
  constructor(r56, s84) {
    this.variableNames = ["A"];
    let t67 = new Array(r56.length);
    for (let n67 = 0; n67 < t67.length; n67++) t67[n67] = r56[s84[n67]];
    this.outputShape = t67, this.rank = t67.length;
    let e36 = F22(this.rank), h74 = a48(s84);
    this.userCode = `
    void main() {
      ${e36} resRC = getOutputCoords();
      setOutput(getA(${h74}));
    }
    `;
  }
};
function a48(o80) {
  let r56 = o80.length;
  if (r56 > 6) throw Error(`Transpose for rank ${r56} is not yet supported`);
  let s84 = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u", "resRC.v"], t67 = new Array(r56);
  for (let e36 = 0; e36 < o80.length; e36++) t67[o80[e36]] = s84[e36];
  return t67.join();
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/transpose_packed_gpu.mjs
var u66 = class {
  constructor(o80, n67) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true;
    let r56 = new Array(o80.length);
    for (let t67 = 0; t67 < r56.length; t67++) r56[t67] = o80[n67[t67]];
    if (this.outputShape = r56, this.rank = r56.length, this.rank > 6) throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);
    let a71 = F22(this.rank), e36 = n35("rc", this.rank), i88 = new Array(this.rank);
    for (let t67 = 0; t67 < n67.length; t67++) i88[n67[t67]] = e36[t67];
    let c103 = `vec2(${i88.slice(-2).join()})`, h74 = `++${e36[this.rank - 1]} < ${r56[this.rank - 1]}`, s84 = `getChannel(getA(${i88.join()}), ${c103})`;
    this.userCode = `
    void main() {
      ${a71} rc = getOutputCoords();
      vec4 result = vec4(0.);
      result[0] = ${s84};
      if(${h74}) {
        result[1] = ${s84};
      }
      --${e36[this.rank - 1]};
      if(++${e36[this.rank - 2]} < ${r56[this.rank - 2]}) {
        result[2] = ${s84};
        if(${h74}) {
          result[3] = ${s84};
        }
      }
      setOutput(result);
    }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Transpose_impl.mjs
function i55(r56, o80, e36) {
  let p103 = l().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new u66(r56.shape, o80) : new i54(r56.shape, o80);
  return e36.runWebGLProgram(p103, [r56], r56.dtype);
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Sum_impl.mjs
function _20(s84, l80, S45, e36) {
  let x76 = l80, p103 = s84.shape.length, i88 = util_exports.parseAxisParam(x76, s84.shape), t67 = i88, u86 = backend_util_exports.getAxesPermutation(t67, p103), m96 = u86 != null, n67 = s84;
  m96 && (n67 = i55(s84, u86, e36), t67 = backend_util_exports.getInnerMostAxes(t67.length, p103)), backend_util_exports.assertAxesAreInnerMostDims("sum", t67, p103);
  let [a71, A35] = backend_util_exports.computeOutAndReduceShapes(n67.shape, t67), h74 = a71;
  S45 && (h74 = backend_util_exports.expandShapeToKeepDim(a71, i88));
  let c103 = util_exports.sizeFromShape(A35), T40 = util_exports.sizeFromShape(s84.shape) / c103, I44 = f68({ inputs: { x: n67 }, attrs: { shape: [T40, c103] }, backend: e36 }), z32 = l6(s84.dtype), d55 = w32(I44, z32, "sum", e36), g72 = f68({ inputs: { x: d55 }, attrs: { shape: h74 }, backend: e36 });
  return e36.disposeIntermediateTensorInfo(I44), e36.disposeIntermediateTensorInfo(d55), m96 && e36.disposeIntermediateTensorInfo(n67), g72;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Sum.mjs
function i56(e36) {
  let { inputs: n67, backend: t67, attrs: m96 } = e36, { x: o80 } = n67, { axis: r56, keepDims: s84 } = m96;
  return _20(o80, r56, s84, t67);
}
var k36 = { kernelName: bt, backendName: "webgl", kernelFunc: i56 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Transpose.mjs
function h59(r56) {
  let { inputs: p103, backend: c103, attrs: l80 } = r56, { x: e36 } = p103, { perm: o80 } = l80, t67 = c103, u86 = e36.shape.length, n67 = new Array(u86);
  for (let a71 = 0; a71 < n67.length; a71++) n67[a71] = e36.shape[o80[a71]];
  let s84;
  if (t67.shouldExecuteOnCPU([e36])) {
    let m96 = t67.texData.get(e36.dataId).values, x76 = W12(m96, e36.shape, e36.dtype, o80, n67);
    s84 = t67.makeTensorInfo(n67, e36.dtype);
    let d55 = t67.texData.get(s84.dataId);
    d55.values = x76;
  } else s84 = i55(e36, o80, t67);
  return s84;
}
var T31 = { kernelName: ce, backendName: "webgl", kernelFunc: h59 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/BatchMatMul_impl.mjs
var Z12 = 1e3;
function hs({ a: t67, b: e36, transposeA: h74, transposeB: n67, backend: s84, bias: A35 = null, preluActivationWeights: _24 = null, leakyreluAlpha: G30 = 0, activation: R26 = null }) {
  let m96 = t67.shape.length, f85 = e36.shape.length, d55 = h74 ? t67.shape[m96 - 2] : t67.shape[m96 - 1], S45 = n67 ? e36.shape[f85 - 1] : e36.shape[f85 - 2], l80 = h74 ? t67.shape[m96 - 1] : t67.shape[m96 - 2], o80 = n67 ? e36.shape[f85 - 2] : e36.shape[f85 - 1], U24 = t67.shape.slice(0, -2), W15 = e36.shape.slice(0, -2), T40 = util_exports.sizeFromShape(U24), $37 = util_exports.sizeFromShape(W15), j22 = broadcast_util_exports.assertAndGetBroadcastShape(t67.shape.slice(0, -2), e36.shape.slice(0, -2)).concat([l80, o80]);
  util_exports.assert(d55 === S45, () => `Error in matMul: inner shapes (${d55}) and (${S45}) of Tensors with shapes ${t67.shape} and ${e36.shape} and transposeA=${h74} and transposeB=${n67} must match.`);
  let B30 = h74 ? [T40, d55, l80] : [T40, l80, d55], E44 = n67 ? [$37, o80, S45] : [$37, S45, o80], r56 = f68({ inputs: { x: t67 }, backend: s84, attrs: { shape: B30 } }), x76 = f68({ inputs: { x: e36 }, backend: s84, attrs: { shape: E44 } }), p103 = [r56, x76], g72 = Math.max(T40, $37), I44 = h74 ? r56.shape[1] : r56.shape[2], F32 = A35 != null, P36 = _24 != null, V24 = R26 === "leakyrelu", H18 = R26 != null ? J12(R26, true) : null, q25 = F32 || P36 || V24 || H18 != null, D42;
  if ((l80 === 1 || o80 === 1) && I44 > Z12 && q25 === false) {
    let a71 = r56, u86 = x76;
    h74 && (a71 = h59({ inputs: { x: r56 }, backend: s84, attrs: { perm: [0, 2, 1] } }), p103.push(a71)), n67 && (u86 = h59({ inputs: { x: x76 }, backend: s84, attrs: { perm: [0, 2, 1] } }), p103.push(u86));
    let i88 = o80 !== 1, M30 = o80 === 1, L22 = a71;
    i88 && (L22 = f68({ inputs: { x: a71 }, backend: s84, attrs: { shape: [g72, I44, 1] } }), p103.push(L22));
    let C28 = o80 === 1 ? 2 : 1, O21 = u86;
    M30 && (O21 = f68({ inputs: { x: u86 }, backend: s84, attrs: { shape: [g72, 1, I44] } }), p103.push(O21));
    let w45 = D23({ inputs: { a: L22, b: O21 }, backend: s84 });
    D42 = i56({ inputs: { x: w45 }, backend: s84, attrs: { axis: C28, keepDims: true } }), p103.push(w45);
  } else {
    let a71 = c5(t67.dtype, e36.dtype), u86 = new d32(B30, E44, [g72, l80, o80], h74, n67, F32, H18, P36, V24), i88 = [r56, x76];
    if (A35 != null && i88.push(A35), P36 && i88.push(_24), V24) {
      let M30 = s84.makeTensorInfo([], "float32", util_exports.createScalarValue(G30, "float32"));
      i88.push(M30), p103.push(M30);
    }
    D42 = s84.runWebGLProgram(u86, i88, a71);
  }
  let v42 = f68({ inputs: { x: D42 }, backend: s84, attrs: { shape: j22 } });
  p103.push(D42);
  for (let a71 of p103) s84.disposeIntermediateTensorInfo(a71);
  return v42;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/_FusedMatMul.mjs
function b37(t67) {
  let { inputs: e36, backend: a71, attrs: n67 } = t67, { a: o80, b: r56, bias: s84, preluActivationWeights: u86 } = e36, { transposeA: l80, transposeB: c103, activation: i88, leakyreluAlpha: p103 } = n67;
  return hs({ a: o80, b: r56, transposeA: l80, transposeB: c103, backend: a71, bias: s84, preluActivationWeights: u86, leakyreluAlpha: p103, activation: i88 });
}
var k37 = { kernelName: De, backendName: "webgl", kernelFunc: b37 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Abs.mjs
var t32 = "return abs(x);";
function b38(n67) {
  let { inputs: a71, backend: r56 } = n67, { x: e36 } = a71;
  if (r56.shouldExecuteOnCPU([e36]) && e36.dtype !== "complex64") {
    let s84 = r56.texData.get(e36.dataId), p103 = k34(s84.values);
    return r56.makeTensorInfo(e36.shape, e36.dtype, p103);
  }
  let o80;
  return l().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? o80 = new e22(e36.shape, t32) : o80 = new e21(e36.shape, t32), r56.runWebGLProgram(o80, [e36], e36.dtype);
}
var P24 = { kernelName: o3, backendName: "webgl", kernelFunc: b38 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Acos.mjs
var n37 = t30 + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return acos(x);
`;
var t33 = v32({ opSnippet: n37 });
var p71 = { kernelName: t, backendName: "webgl", kernelFunc: t33 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Acosh.mjs
var n38 = t30 + `
  if (x < 1.0) return NAN;
return log(x + sqrt(x * x - 1.0));`;
var t34 = v32({ opSnippet: n38 });
var s49 = { kernelName: e2, backendName: "webgl", kernelFunc: t34 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Add.mjs
var e23 = "return a + b;";
var o46 = z26({ opSnippet: e23, packedOpSnippet: e23, supportsComplex: true, cpuKernelImpl: p65 });
var a49 = { kernelName: r, backendName: "webgl", kernelFunc: o46 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/addn_gpu.mjs
var e24 = class {
  constructor(o80, a71) {
    this.outputShape = [], this.outputShape = o80, this.variableNames = a71.map((t67, u86) => `T${u86}`);
    let s84 = [];
    this.variableNames.forEach((t67) => {
      s84.push(`float v${t67} = get${t67}AtOutCoords();`);
    });
    let i88 = this.variableNames.map((t67) => `v${t67}`).join(" + ");
    this.userCode = `
      void main() {
        ${s84.join(`
        `)}

        float result = ${i88};
        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/addn_packed_gpu.mjs
var e25 = class {
  constructor(u86, i88) {
    this.outputShape = [], this.packedInputs = true, this.packedOutput = true, this.outputShape = u86, this.variableNames = i88.map((t67, a71) => `T${a71}`);
    let s84 = [];
    this.variableNames.forEach((t67) => {
      s84.push(`vec4 v${t67} = get${t67}AtOutCoords();`);
    });
    let p103 = this.variableNames.map((t67) => `v${t67}`).join(" + ");
    this.userCode = `
      void main() {
        ${s84.join(`
        `)}

        vec4 result = ${p103};
        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/AddN.mjs
function r25(d55) {
  let { inputs: a71, backend: n67 } = d55, e36 = a71;
  if (e36.length === 1) return i52({ inputs: { x: e36[0] }, backend: n67 });
  if (e36.length > l().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")) {
    let t67 = Math.floor(e36.length / 2), o80 = r25({ inputs: e36.slice(0, t67), backend: n67 }), m96 = r25({ inputs: e36.slice(t67), backend: n67 });
    return r25({ inputs: [o80, m96], backend: n67 });
  }
  let c103 = e36.map((t67) => t67.dtype).reduce((t67, o80) => c5(t67, o80)), s84 = e36.map((t67) => t67.shape), i88 = l().getBool("WEBGL_PACK") ? new e25(e36[0].shape, s84) : new e24(e36[0].shape, s84);
  return n67.runWebGLProgram(i88, e36, c103);
}
var E36 = { kernelName: n4, backendName: "webgl", kernelFunc: r25 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/All.mjs
function w33(x76) {
  let { inputs: h74, backend: e36, attrs: f85 } = x76, { x: n67 } = h74, { axis: A35, keepDims: I44 } = f85, o80 = n67.shape.length, c103 = util_exports.parseAxisParam(A35, n67.shape), t67 = c103, a71 = backend_util_exports.getAxesPermutation(t67, o80), r56 = n67;
  a71 != null && (r56 = h59({ inputs: { x: n67 }, backend: e36, attrs: { perm: a71 } }), t67 = backend_util_exports.getInnerMostAxes(t67.length, o80)), backend_util_exports.assertAxesAreInnerMostDims("all", t67, o80);
  let [u86, g72] = backend_util_exports.computeOutAndReduceShapes(r56.shape, t67), k63 = util_exports.sizeFromShape(g72), p103 = f68({ inputs: { x: r56 }, backend: e36, attrs: { shape: [-1, k63] } }), i88 = w32(p103, p103.dtype, "all", e36), l80;
  if (I44) {
    let S45 = backend_util_exports.expandShapeToKeepDim(u86, c103);
    l80 = f68({ inputs: { x: i88 }, backend: e36, attrs: { shape: S45 } });
  } else l80 = f68({ inputs: { x: i88 }, backend: e36, attrs: { shape: u86 } });
  return e36.disposeIntermediateTensorInfo(p103), e36.disposeIntermediateTensorInfo(i88), a71 != null && e36.disposeIntermediateTensorInfo(r56), l80;
}
var P25 = { kernelName: s3, backendName: "webgl", kernelFunc: w33 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Any.mjs
function T32(h74) {
  let { inputs: l80, backend: e36, attrs: f85 } = h74, { x: n67 } = l80, { axis: A35, keepDims: I44 } = f85, o80 = n67.shape.length, u86 = util_exports.parseAxisParam(A35, n67.shape), t67 = u86, a71 = backend_util_exports.getAxesPermutation(t67, o80), r56 = n67;
  a71 != null && (r56 = h59({ inputs: { x: n67 }, backend: e36, attrs: { perm: a71 } }), t67 = backend_util_exports.getInnerMostAxes(t67.length, o80)), backend_util_exports.assertAxesAreInnerMostDims("any", t67, o80);
  let [d55, g72] = backend_util_exports.computeOutAndReduceShapes(r56.shape, t67), k63 = util_exports.sizeFromShape(g72), p103 = f68({ inputs: { x: r56 }, backend: e36, attrs: { shape: [-1, k63] } }), i88 = w32(p103, p103.dtype, "any", e36), m96;
  if (I44) {
    let S45 = backend_util_exports.expandShapeToKeepDim(d55, u86);
    m96 = f68({ inputs: { x: i88 }, backend: e36, attrs: { shape: S45 } });
  } else m96 = f68({ inputs: { x: i88 }, backend: e36, attrs: { shape: d55 } });
  return e36.disposeIntermediateTensorInfo(p103), e36.disposeIntermediateTensorInfo(i88), a71 != null && e36.disposeIntermediateTensorInfo(r56), m96;
}
var N42 = { kernelName: p2, backendName: "webgl", kernelFunc: T32 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/argminmax_gpu.mjs
var i57 = class {
  constructor(s84, n67, t67) {
    this.variableNames = ["A"];
    let { windowSize: e36, batchSize: d55, outSize: o80 } = s84;
    t67 || this.variableNames.push("bestIndicesA"), this.outputShape = [d55, o80];
    let a71 = n67 === "max" ? ">" : "<", c103 = t67 ? "inOffset + i;" : "round(getBestIndicesA(batch, inOffset + i));";
    this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = outIdx * ${e36};

        int bestIndex = inOffset;
        float bestValue = getA(batch, bestIndex);

        for (int i = 0; i < ${e36}; i++) {
          int inIdx = ${c103};
          float candidate = getA(batch, inIdx);
          if (candidate ${a71} bestValue) {
            bestValue = candidate;
            bestIndex = inIdx;
          }
        }
        setOutput(float(bestIndex));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/argminmax_packed_gpu.mjs
var j18 = class {
  constructor(i88, d55, l80, u86) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, util_exports.assert(i88.length > 2, () => `Packed arg${l80.charAt(0).toUpperCase() + l80.slice(1)} supports only inputs with rank above 2.`);
    let L22 = i88[i88.length - 1], $37 = Math.ceil(L22 / d55);
    this.outputShape = i88.slice(0, -1), $37 > 1 && this.outputShape.push($37), u86 || this.variableNames.push("bestIndicesA");
    let h74 = this.outputShape, e36 = h74.length, s84 = F22(e36), c103 = u62("coords", e36), p103, t67;
    if ($37 === 1) {
      t67 = e36 + 1;
      let o80 = F22(t67);
      p103 = `
        ${o80} sourceLocR = ${o80}(${c103.join()}, 0);
        ++${c103[e36 - 1]};
        ${o80} sourceLocG = ${o80}(${c103.join()}, 0);
        ++${c103[e36 - 2]};
        ${o80} sourceLocA = ${o80}(${c103.join()}, 0);
        --${c103[e36 - 1]};
        ${o80} sourceLocB = ${o80}(${c103.join()}, 0);
        --${c103[e36 - 2]};`;
    } else t67 = e36, p103 = `
        ${s84} sourceLocR = coords;
        ++${c103[e36 - 1]};
        ${s84} sourceLocG = coords;
        ++${c103[e36 - 2]};
        ${s84} sourceLocA = coords;
        --${c103[e36 - 1]};
        ${s84} sourceLocB = coords;
        --${c103[e36 - 2]};`;
    let n67 = ["x", "y", "z", "w", "u", "v"].slice(0, t67), r56 = "." + n67[t67 - 1], x76 = n67.map((o80) => "int " + o80), C28 = u62("sourceLocR", t67 - 1).concat("inIdx.r"), I44 = u62("sourceLocG", t67 - 1).concat("inIdx.g"), v42 = u62("sourceLocB", t67 - 1).concat("inIdx.b"), g72 = u62("sourceLocA", t67 - 1).concat("inIdx.a"), m96 = l80 === "max" ? "greaterThan" : "lessThan", B30 = u86 ? "" : `
          inIdx = round(vec4(getBestIndicesAChannel(${C28.join()}),
                             getBestIndicesAChannel(${I44.join()}),
                             getBestIndicesAChannel(${v42.join()}),
                             getBestIndicesAChannel(${g72.join()})));`, b58 = `vec4(
            getAChannel(${C28.join()}),
            hasNextCol ? getAChannel(${I44.join()}) : 0.,
            hasNextRow ? getAChannel(${v42.join()}) : 0.,
            hasNextRow && hasNextCol ? getAChannel(${g72.join()}) : 0.)`, f85 = u86 ? "" : `
      float getBestIndicesAChannel(${x76.join()}) {
        return getChannel(getBestIndicesA(${n67.join()}),
                                          vec2(${n67.slice(-2).join()}));
      }`;
    this.userCode = `
      float getAChannel(${x76.join()}) {
        return getChannel(getA(${n67.join()}),
                               vec2(${n67.slice(-2).join()}));
      }
      ${f85}
      void main() {
        ${s84} coords = getOutputCoords();
        bool hasNextCol = ${c103[e36 - 1]} < ${h74[e36 - 1] - 1};
        bool hasNextRow = ${c103[e36 - 2]} < ${h74[e36 - 2] - 1};
        ${p103}
        ivec4 srcIdx = ivec4(sourceLocR${r56}, sourceLocG${r56},
          sourceLocB${r56}, sourceLocA${r56}) * ${d55};
        ivec4 inIdx = srcIdx;
        vec4 bestIndex = vec4(inIdx);
        vec4 bestValue = ${b58};

        for (int i = 0; i < ${d55}; i++) {
          inIdx = srcIdx;
          ${B30}
          vec4 candidate = ${b58};
          bvec4 nan = isnan(candidate);
          bvec4 replace = bvec4(
            vec4(${m96}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));

          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,
                           replace.y  ? candidate.y : bestValue.y,
                           replace.z  ? candidate.z : bestValue.z,
                           replace.w  ? candidate.w : bestValue.w);
          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));
          srcIdx++;
        }
        setOutput(bestIndex);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernel_utils/arg_min_max.mjs
function S32(o80, t67, u86, n67 = null) {
  let r56 = t67.shape[0], e36 = t67.shape[1];
  n67 != null && (r56 = n67.shape[0], e36 = n67.shape[1]);
  let p103 = backend_util_exports.computeOptimalWindowSize(e36), l80 = { windowSize: p103, inSize: e36, batchSize: r56, outSize: Math.ceil(e36 / p103) }, a71 = new i57(l80, u86, n67 == null), s84 = [t67];
  n67 != null && s84.push(n67);
  let i88 = o80.runWebGLProgram(a71, s84, "int32");
  if (i88.shape[1] === 1) return i88;
  let m96 = S32(o80, t67, u86, i88);
  return o80.disposeIntermediateTensorInfo(i88), m96;
}
function z27(o80, t67, u86, n67 = null) {
  let r56 = n67 != null ? n67.shape : t67.shape, e36 = r56[r56.length - 1], p103 = backend_util_exports.computeOptimalWindowSize(e36), l80 = new j18(r56, p103, u86, n67 == null), a71 = n67 == null ? [t67] : [t67, n67], s84 = o80.runWebGLProgram(l80, a71, "int32");
  if (s84.shape.length === t67.shape.length) {
    let i88 = z27(o80, t67, u86, s84);
    return o80.disposeIntermediateTensorInfo(s84), i88;
  }
  return s84;
}
function L20(o80, t67, u86, n67) {
  let r56 = [u86];
  if (backend_util_exports.assertAxesAreInnerMostDims("arg" + n67.charAt(0).toUpperCase() + n67.slice(1), r56, t67.shape.length), !l().getBool("WEBGL_PACK_REDUCE") || t67.shape.length <= 2) {
    let e36 = [], p103 = o80.texData.get(t67.dataId), l80 = p103 !== null && p103.isPacked, a71 = t67;
    l80 && (a71 = o80.unpackTensor(t67), e36.push(a71));
    let [s84, i88] = backend_util_exports.computeOutAndReduceShapes(a71.shape, r56), m96 = util_exports.sizeFromShape(i88), c103 = f68({ inputs: { x: a71 }, backend: o80, attrs: { shape: [-1, m96] } });
    e36.push(c103);
    let f85 = S32(o80, c103, n67);
    e36.push(f85);
    let P36 = f68({ inputs: { x: f85 }, backend: o80, attrs: { shape: s84 } });
    return e36.forEach((w45) => o80.disposeIntermediateTensorInfo(w45)), P36;
  }
  return z27(o80, t67, n67);
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ArgMax.mjs
function d34(i88) {
  let { inputs: p103, backend: s84, attrs: x76 } = i88, { x: n67 } = p103, { axis: m96 } = x76, e36 = util_exports.parseAxisParam(m96, n67.shape), a71 = backend_util_exports.getAxesPermutation(e36, n67.shape.length), t67 = n67, o80 = [];
  a71 != null && (t67 = h59({ inputs: { x: n67 }, backend: s84, attrs: { perm: a71 } }), o80.push(t67), e36 = backend_util_exports.getInnerMostAxes(e36.length, t67.shape.length)), backend_util_exports.assertAxesAreInnerMostDims("argMax", [e36[0]], t67.shape.length);
  let c103 = L20(s84, t67, e36[0], "max");
  return o80.forEach((g72) => s84.disposeIntermediateTensorInfo(g72)), c103;
}
var I31 = { kernelName: c3, backendName: "webgl", kernelFunc: d34 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ArgMin.mjs
function d35(i88) {
  let { inputs: p103, backend: s84, attrs: m96 } = i88, { x: t67 } = p103, { axis: c103 } = m96, e36 = util_exports.parseAxisParam(c103, t67.shape), o80 = backend_util_exports.getAxesPermutation(e36, t67.shape.length), n67 = t67, a71 = [];
  o80 != null && (n67 = h59({ inputs: { x: t67 }, backend: s84, attrs: { perm: o80 } }), a71.push(n67), e36 = backend_util_exports.getInnerMostAxes(e36.length, n67.shape.length)), backend_util_exports.assertAxesAreInnerMostDims("argMin", [e36[0]], n67.shape.length);
  let g72 = L20(s84, n67, e36[0], "min");
  return a71.forEach((l80) => s84.disposeIntermediateTensorInfo(l80)), g72;
}
var I32 = { kernelName: a4, backendName: "webgl", kernelFunc: d35 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Asin.mjs
var o47 = t30 + `
  if (abs(x) > 1.) {
    return NAN;
  }
  return asin(x);
`;
var t35 = v32({ opSnippet: o47 });
var p72 = { kernelName: x2, backendName: "webgl", kernelFunc: t35 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Asinh.mjs
var o48 = t30 + "return log(x + sqrt(x * x + 1.0));";
var t36 = v32({ opSnippet: o48 });
var s50 = { kernelName: i, backendName: "webgl", kernelFunc: t36 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Atan.mjs
var t37 = t30 + `
  return atan(x);
`;
var o49 = v32({ opSnippet: t37 });
var c77 = { kernelName: l2, backendName: "webgl", kernelFunc: o49 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Atan2.mjs
var i58 = p69 + `
  return atan(a, b);
`;
var t38 = `
  vec4 result = atan(a, b);
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + x56 + `
  return result;
`;
var r26 = z26({ opSnippet: i58, packedOpSnippet: t38 });
var p73 = { kernelName: u, backendName: "webgl", kernelFunc: r26 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Atanh.mjs
var o50 = t30 + `
  if ((x < -1.0) || (x > 1.0)) return NAN;
return (log(1.0 + x) - log(1.0 - x)) / 2.0;`;
var t39 = v32({ opSnippet: o50 });
var N43 = { kernelName: d2, backendName: "webgl", kernelFunc: t39 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/pool_gpu.mjs
var M23 = class {
  constructor(t67, e36, u86, p103 = false, D42 = false) {
    if (this.variableNames = ["x"], e36 === "avg" && u86) throw new Error("Cannot compute positions for average pool.");
    let c103 = t67.filterWidth, d55 = t67.strideHeight, h74 = t67.strideWidth, C28 = t67.dilationHeight, i88 = t67.dilationWidth, $37 = t67.effectiveFilterHeight, a71 = t67.effectiveFilterWidth, V24 = t67.padInfo.top, r56 = t67.padInfo.left;
    this.outputShape = t67.outShape;
    let x76 = e36 === "avg", g72 = `((batch  * ${t67.inHeight} + xR) * ${t67.inWidth} + xC) * ${t67.inChannels} + d`, f85 = `(xR * ${t67.inWidth} + xC) * ${t67.inChannels} + d`, l80 = "0.0";
    if (x76 || (l80 = "-1.0 / 1e-20"), u86) {
      let R26 = ">=";
      this.userCode = `
        const ivec2 strides = ivec2(${d55}, ${h74});
        const ivec2 pads = ivec2(${V24}, ${r56});

        void main() {
          ivec4 coords = getOutputCoords();
          int batch = coords[0];
          int d = coords[3];

          ivec2 xRCCorner = coords.yz * strides - pads;
          int xRCorner = xRCCorner.x;
          int xCCorner = xRCCorner.y;

          // max/min x(?, ?, d) to get y(yR, yC, d).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;
          float avgValue = 0.0;

          for (int wR = 0; wR < ${$37};
              wR += ${C28}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${t67.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${a71};
                wC += ${i88}) {
              int xC = xCCorner + wC;

              if (xC < 0 || xC >= ${t67.inWidth}) {
                continue;
              }

              float value = getX(batch, xR, xC, d);

              // If a min / max value has already been found, use it. If not,
              // use the current value.
              float currMinMaxValue = mix(
                  value, minMaxValue, minMaxValueFound);
              if (value ${R26} currMinMaxValue) {
                minMaxValue = value;
                minMaxValueFound = 1.0;
                minMaxPosition = ${p103 ? D42 ? g72 : f85 : `wR * ${a71} + wC`};
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
      return;
    }
    let m96 = "max", o80 = `${e36}(${e36}(${e36}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    e36 === "avg" && (o80 = "avgValue / max(count, 1.0)");
    let v42 = Math.floor(c103 / 4) * 4, s84 = c103 % 4, n67 = `
      if (${x76}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${m96}(values, minMaxValue);
      }
    `;
    this.userCode = `
      const ivec2 strides = ivec2(${d55}, ${h74});
      const ivec2 pads = ivec2(${V24}, ${r56});
      const float initializationValue = ${l80};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xR, int xC, int d) {
        if (xC < 0 || xC >= ${t67.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xR, xC, d);
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d = coords[3];

        ivec2 xRCCorner = coords.yz * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // max/min x(?, ?, d) to get y(yR, yC, d).
        // ? = to be determined
        vec4 minMaxValue = vec4(${l80});
        float avgValue = 0.0;
        count = 0.0;

        for (int wR = 0; wR < ${$37};
            wR += ${C28}) {
          int xR = xRCorner + wR;

          if (xR < 0 || xR >= ${t67.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${v42}; wC += 4) {
            int xC = xCCorner + wC * ${i88};

            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${i88}, d),
              getValue(batch, xR, xC + 2 * ${i88}, d),
              getValue(batch, xR, xC + 3 * ${i88}, d)
            );

            ${n67}
          }

          int xC = xCCorner + ${v42};
          if (${s84 === 1}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              initializationValue,
              initializationValue,
              initializationValue
            );

            ${n67}
          } else if (${s84 === 2}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${i88}, d),
              initializationValue,
              initializationValue
            );

            ${n67}
          } else if (${s84 === 3}) {
            vec4 values = vec4(
              getValue(batch, xR, xC, d),
              getValue(batch, xR, xC + ${i88}, d),
              getValue(batch, xR, xC + 2 * ${i88}, d),
              initializationValue
            );

            ${n67}
          }
        }
        setOutput(${o80});
      }
    `;
  }
};
var b39 = class {
  constructor(t67, e36, u86, p103 = false, D42 = false) {
    if (this.variableNames = ["x"], e36 === "avg" && u86) throw new Error("Cannot compute positions for average pool.");
    let c103 = t67.filterWidth, d55 = t67.strideDepth, h74 = t67.strideHeight, C28 = t67.strideWidth, i88 = t67.dilationDepth, $37 = t67.dilationHeight, a71 = t67.dilationWidth, V24 = t67.effectiveFilterDepth, r56 = t67.effectiveFilterHeight, x76 = t67.effectiveFilterWidth, g72 = t67.padInfo.front, f85 = t67.padInfo.top, l80 = t67.padInfo.left;
    this.outputShape = t67.outShape;
    let m96 = e36 === "avg", o80 = "0.0";
    if (m96 || (o80 = "-1.0 / 1e-20"), u86) {
      let z32 = ">=";
      this.userCode = `
        const ivec3 strides =
            ivec3(${d55}, ${h74}, ${C28});
        const ivec3 pads = ivec3(${g72}, ${f85}, ${l80});

        void main() {
          ivec5 coords = getOutputCoords();
          int batch = coords.x;
          int ch = coords.u;

          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
          int xDCorner = xCorner.x;
          int xRCorner = xCorner.y;
          int xCCorner = xCorner.z;

          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).
          // ? = to be determined
          float minMaxValue = 0.0;
          float minMaxValueFound = 0.0;
          int minMaxPosition = 0;

          for (int wD = 0; wD < ${V24};
              wD += ${i88}) {
            int xD = xDCorner + wD;

            if (xD < 0 || xD >= ${t67.inDepth}) {
              continue;
            }

            for (int wR = 0; wR < ${r56};
                wR += ${$37}) {
              int xR = xRCorner + wR;

              if (xR < 0 || xR >= ${t67.inHeight}) {
                continue;
              }

              for (int wC = 0; wC < ${x76};
                  wC += ${a71}) {
                int xC = xCCorner + wC;

                if (xC < 0 || xC >= ${t67.inWidth}) {
                  continue;
                }

                float value = getX(batch, xD, xR, xC, ch);

                // If a min / max value has already been found, use it. If not,
                // use the current value.
                float currMinMaxValue = mix(
                    value, minMaxValue, minMaxValueFound);
                if (value ${z32} currMinMaxValue) {
                  minMaxValue = value;
                  minMaxValueFound = 1.0;
                  minMaxPosition = ${p103 ? D42 ? `(((batch * ${t67.inDepth} + xD) * ${t67.inHeight} + xR) * ${t67.inWidth} + xC) * ${t67.inChannels} + ch` : `((xD * ${t67.inHeight} + xR) * ${t67.inWidth} + xC) * ${t67.inChannels} + ch` : `wD * ${r56} * ${x76} +
                      wR * ${x76} + wC`};
                }
              }
            }
          }
          setOutput(float(minMaxPosition));
        }
      `;
      return;
    }
    let v42 = "max", s84 = `${e36}(${e36}(${e36}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;
    e36 === "avg" && (s84 = "avgValue / max(count, 1.0)");
    let n67 = Math.floor(c103 / 4) * 4, R26 = c103 % 4, w45 = `
      if (${m96}) {
        avgValue += dot(values, ones);
      } else {
        minMaxValue = ${v42}(values, minMaxValue);
      }
    `;
    this.userCode = `
      const ivec3 strides =
        ivec3(${d55}, ${h74}, ${C28});
      const ivec3 pads = ivec3(${g72}, ${f85}, ${l80});
      const float initializationValue = ${o80};
      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);

      float count = 0.0;

      float getValue(int batch, int xD, int xR, int xC, int ch) {
        if (xC < 0 || xC >= ${t67.inWidth}) {
          return initializationValue;
        }
        count += 1.0;
        return getX(batch, xD, xR, xC, ch);
      }

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xDCorner = xCorner.x;
        int xRCorner = xCorner.y;
        int xCCorner = xCorner.z;

        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).
        // ? = to be determined
        vec4 minMaxValue = vec4(${o80});
        float avgValue = 0.0;
        count = 0.0;

        for (int wD = 0; wD < ${V24};
            wD += ${i88}) {
          int xD = xDCorner + wD;

          if (xD < 0 || xD >= ${t67.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${r56};
            wR += ${$37}) {
            int xR = xRCorner + wR;

            if (xR < 0 || xR >= ${t67.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${n67}; wC += 4) {
              int xC = xCCorner + wC * ${a71};

              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${a71}, ch),
                getValue(batch, xD, xR, xC + 2 * ${a71}, ch),
                getValue(batch, xD, xR, xC + 3 * ${a71}, ch)
              );

              ${w45}
            }

            int xC = xCCorner + ${n67};
            if (${R26 === 1}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                initializationValue,
                initializationValue,
                initializationValue
              );

              ${w45}
            } else if (${R26 === 2}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${a71}, ch),
                initializationValue,
                initializationValue
              );

              ${w45}
            } else if (${R26 === 3}) {
              vec4 values = vec4(
                getValue(batch, xD, xR, xC, ch),
                getValue(batch, xD, xR, xC + ${a71}, ch),
                getValue(batch, xD, xR, xC + 2 * ${a71}, ch),
                initializationValue
              );

              ${w45}
            }
          }
        }
        setOutput(${s84});
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/AvgPool.mjs
function h60(s84) {
  let { inputs: l80, backend: i88, attrs: d55 } = s84, { x: t67 } = l80;
  be(t67, "avgPool");
  let { filterSize: m96, strides: r56, pad: c103, dimRoundingMode: f85 } = d55, e36 = 1;
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(r56, e36), () => `Error in avgPool: Either strides or dilations must be 1. Got strides ${r56} and dilations '${e36}'`);
  let o80 = backend_util_exports.computePool2DInfo(t67.shape, m96, r56, e36, c103, f85);
  if (o80.filterWidth === 1 && o80.filterHeight === 1 && util_exports.arraysEqual(o80.inShape, o80.outShape)) return i52({ inputs: { x: t67 }, backend: i88 });
  let g72 = new M23(o80, "avg", false);
  return i88.runWebGLProgram(g72, [t67], "float32");
}
var D25 = { kernelName: S2, backendName: "webgl", kernelFunc: h60 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/AvgPool3D.mjs
function u67(n67) {
  let { inputs: t67, backend: e36, attrs: a71 } = n67, { x: o80 } = t67, { filterSize: r56, strides: c103, pad: l80, dimRoundingMode: s84, dataFormat: i88 } = a71, m96 = [1, 1, 1], g72 = backend_util_exports.computePool3DInfo(o80.shape, r56, c103, m96, l80, s84, i88), d55 = new b39(g72, "avg", false);
  return e36.runWebGLProgram(d55, [o80], "float32");
}
var k38 = { kernelName: D2, backendName: "webgl", kernelFunc: u67 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/avg_pool_backprop_gpu.mjs
var n39 = class {
  constructor(t67) {
    this.variableNames = ["dy"], this.outputShape = t67.inShape;
    let o80 = t67.filterHeight, s84 = t67.filterWidth, a71 = t67.strideHeight, l80 = t67.strideWidth, y43 = t67.dilationHeight, h74 = t67.dilationWidth, i88 = t67.effectiveFilterHeight, e36 = t67.effectiveFilterWidth, C28 = i88 - 1 - t67.padInfo.top, d55 = e36 - 1 - t67.padInfo.left, r56 = 1 / (o80 * s84);
    this.userCode = `
      const ivec2 pads = ivec2(${C28}, ${d55});
      const float avgMultiplier = float(${r56});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${i88};
            wR += ${y43}) {
          float dyR = float(dyRCorner + wR) / ${a71}.0;

          if (dyR < 0.0 || dyR >= ${t67.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${e36};
            wC+= ${h74}) {
            float dyC = float(dyCCorner + wC) / ${l80}.0;

            if (dyC < 0.0 || dyC >= ${t67.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);

            dotProd += dyValue * avgMultiplier;
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var f69 = class {
  constructor(t67) {
    this.variableNames = ["dy"], this.outputShape = t67.inShape;
    let o80 = t67.filterDepth, s84 = t67.filterHeight, a71 = t67.filterWidth, l80 = t67.strideDepth, y43 = t67.strideHeight, h74 = t67.strideWidth, i88 = t67.dilationDepth, e36 = t67.dilationHeight, C28 = t67.dilationWidth, d55 = t67.effectiveFilterDepth, r56 = t67.effectiveFilterHeight, c103 = t67.effectiveFilterWidth, u86 = d55 - 1 - t67.padInfo.front, R26 = r56 - 1 - t67.padInfo.top, $37 = c103 - 1 - t67.padInfo.left, g72 = 1 / (o80 * s84 * a71);
    this.userCode = `
      const ivec3 pads = ivec3(${u86}, ${R26}, ${$37});
      const float avgMultiplier = float(${g72});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${d55};
            wD += ${i88}) {
          float dyD = float(dyDCorner + wD) / ${l80}.0;

          if (dyD < 0.0 || dyD >= ${t67.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${r56};
              wR += ${e36}) {
            float dyR = float(dyRCorner + wR) / ${y43}.0;

            if (dyR < 0.0 || dyR >= ${t67.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${c103};
                wC += ${C28}) {
              float dyC = float(dyCCorner + wC) / ${h74}.0;

              if (dyC < 0.0 || dyC >= ${t67.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);

              dotProd += dyValue * avgMultiplier;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/AvgPool3DGrad.mjs
function k39(n67) {
  let { inputs: r56, backend: t67, attrs: e36 } = n67, { dy: a71, input: c103 } = r56, o80 = c103, { filterSize: d55, strides: i88, pad: p103, dimRoundingMode: s84 } = e36, l80 = [1, 1, 1], g72 = backend_util_exports.computePool3DInfo(o80.shape, d55, i88, l80, p103, s84), m96 = new f69(g72);
  return t67.runWebGLProgram(m96, [a71], o80.dtype);
}
var D26 = { kernelName: m, backendName: "webgl", kernelFunc: k39 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/AvgPoolGrad.mjs
function u68(n67) {
  let { inputs: e36, backend: a71, attrs: c103 } = n67, { dy: o80, input: r56 } = e36, t67 = r56;
  be([o80, r56], "avgPoolGrad");
  let { filterSize: p103, strides: s84, pad: l80 } = c103, m96 = backend_util_exports.computePool2DInfo(t67.shape, p103, s84, 1, l80), d55 = new n39(m96);
  return a71.runWebGLProgram(d55, [o80], t67.dtype);
}
var G22 = { kernelName: g2, backendName: "webgl", kernelFunc: u68 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/BatchMatMul.mjs
function u69(t67) {
  let { inputs: a71, backend: n67, attrs: e36 } = t67, { a: o80, b: r56 } = a71, { transposeA: c103, transposeB: s84 } = e36;
  return hs({ a: o80, b: r56, transposeA: c103, transposeB: s84, backend: n67 });
}
var m74 = { kernelName: R2, backendName: "webgl", kernelFunc: u69 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/batchnorm_gpu.mjs
var r27 = class {
  constructor(t67, n67, l80, a71, s84, f85) {
    this.outputShape = [], this.variableNames = ["x", "mean", "variance"], backend_util_exports.assertAndGetBroadcastShape(t67, n67), backend_util_exports.assertAndGetBroadcastShape(t67, l80);
    let o80 = "0.0";
    a71 != null && (backend_util_exports.assertAndGetBroadcastShape(t67, a71), this.variableNames.push("offset"), o80 = "getOffsetAtOutCoords()");
    let i88 = "1.0";
    s84 != null && (backend_util_exports.assertAndGetBroadcastShape(t67, s84), this.variableNames.push("scale"), i88 = "getScaleAtOutCoords()"), this.outputShape = t67, this.userCode = `
      void main() {
        float x = getXAtOutCoords();
        float mean = getMeanAtOutCoords();
        float variance = getVarianceAtOutCoords();
        float offset = ${o80};
        float scale = ${i88};
        float inv = scale * inversesqrt(variance + float(${f85}));
        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/batchnorm_packed_gpu.mjs
var i59 = class {
  constructor(e36, n67, o80, s84, a71, u86) {
    this.packedInputs = true, this.packedOutput = true, this.variableNames = ["x", "mean", "variance"], backend_util_exports.assertAndGetBroadcastShape(e36, n67), backend_util_exports.assertAndGetBroadcastShape(e36, o80);
    let r56 = "vec4(0.0)";
    s84 != null && (backend_util_exports.assertAndGetBroadcastShape(e36, s84), this.variableNames.push("offset"), r56 = "getOffsetAtOutCoords()");
    let c103 = "vec4(1.0)";
    a71 != null && (backend_util_exports.assertAndGetBroadcastShape(e36, a71), this.variableNames.push("scale"), c103 = "getScaleAtOutCoords()"), this.outputShape = e36, this.userCode = `
      void main() {
        vec4 offset = ${r56};
        vec4 scale = ${c103};

        vec4 x = getXAtOutCoords();
        vec4 mean = getMeanAtOutCoords();
        vec4 variance = getVarianceAtOutCoords();

        vec4 inv = scale * inversesqrt(variance + vec4(${u86}));

        setOutput((x - mean) * inv + offset);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/BatchNorm.mjs
var B21 = ({ inputs: i88, backend: u86, attrs: m96 }) => {
  let { x: o80, mean: e36, variance: t67, offset: a71, scale: n67 } = i88;
  util_exports.assert(e36.shape.length === t67.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks."), util_exports.assert(a71 == null || e36.shape.length === a71.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks."), util_exports.assert(n67 == null || e36.shape.length === n67.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  let { varianceEpsilon: r56 } = m96;
  r56 == null && (r56 = 1e-3);
  let s84 = [o80, e36, t67], l80 = null;
  a71 != null && (l80 = a71.shape, s84.push(a71));
  let h74 = null;
  n67 != null && (h74 = n67.shape, s84.push(n67));
  let c103 = l().getBool("WEBGL_PACK_NORMALIZATION") ? new i59(o80.shape, e36.shape, t67.shape, l80, h74, r56) : new r27(o80.shape, e36.shape, t67.shape, l80, h74, r56);
  return u86.runWebGLProgram(c103, s84, s84[0].dtype);
};
var P26 = { kernelName: lo, backendName: "webgl", kernelFunc: B21 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/slice_gpu.mjs
var n40 = class {
  constructor(t67) {
    this.variableNames = ["source"], this.outputShape = t67, this.rank = t67.length;
    let e36 = F22(this.rank);
    this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
    let u86 = p74(this.rank), c103, i88 = t67.map((d55, r56) => `sourceLoc.${s51[r56]} = start[${r56}] + coords.${s51[r56]};`);
    c103 = `
        ${e36} sourceLoc;
        ${e36} coords = getOutputCoords();
        ${i88.join(`
`)}
      `, this.userCode = `
      void main() {
        ${c103}
        setOutput(getSource(${u86}));
      }
    `;
  }
};
var s51 = ["x", "y", "z", "w", "u", "v"];
function p74(o80) {
  if (o80 === 1) return "sourceLoc";
  if (o80 <= 6) return s51.slice(0, o80).map((t67) => "sourceLoc." + t67).join(",");
  throw Error(`Slicing for rank ${o80} is not yet supported`);
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/slice_packed_gpu.mjs
var e26 = class {
  constructor(t67) {
    this.variableNames = ["source"], this.packedInputs = true, this.packedOutput = true, this.outputShape = t67, this.rank = t67.length, this.customUniforms = [{ name: "start", arrayIndex: this.rank, type: "int" }];
    let a71 = F22(this.rank), r56 = u62("coords", this.rank), s84 = u62("sourceLoc", this.rank), i88 = this.rank === 1 ? "sourceLoc" : `vec2(${s84.slice(-2).join()})`, n67 = `getChannel(getSource(${s84.join()}), ${i88})`, h74 = `
      result.x = ${n67};
      if (++${r56[this.rank - 1]} < ${t67[this.rank - 1]}) {
        ++${s84[this.rank - 1]};
        result.y = ${n67};
        --${s84[this.rank - 1]};
      }
    `, u86 = this.rank === 1 ? "" : `
      --${r56[this.rank - 1]};
      if (++${r56[this.rank - 2]} < ${t67[this.rank - 2]}) {
        ++${s84[this.rank - 2]};
        result.z = ${n67};
        if (++${r56[this.rank - 1]} < ${t67[this.rank - 1]}) {
          ++${s84[this.rank - 1]};
          result.w = ${n67};
        }
      }
    `, $37 = this.rank <= 4 ? `sourceLoc = coords +
            ${a71}(${t67.map((k63, o80) => `start[${o80}]`).join()});` : t67.map((k63, o80) => `${s84[o80]} = ${r56[o80]} + start[${o80}];`).join(`
`);
    this.userCode = `
      void main() {
        ${a71} coords = getOutputCoords();
        ${a71} sourceLoc;
        ${$37}
        vec4 result = vec4(0.);
        ${h74}
        ${u86}
        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Slice.mjs
function x57(n67, l80, e36, i88) {
  let t67 = i88.texData.get(n67.dataId), r56 = i88.makeTensorInfo(e36, n67.dtype), o80 = i88.texData.get(r56.dataId);
  Object.assign(o80, t67), o80.refCount = 1, o80.shape = e36, o80.dtype = n67.dtype;
  let s84 = slice_util_exports.computeFlatOffset(l80, util_exports.computeStrides(n67.shape));
  t67.slice && (s84 += t67.slice.flatOffset), o80.slice = { flatOffset: s84, origDataId: t67.slice && t67.slice.origDataId || n67.dataId };
  let a71 = i88.dataRefCount.get(o80.slice.origDataId) || 1;
  return i88.dataRefCount.set(o80.slice.origDataId, a71 + 1), r56;
}
function S33(n67) {
  let { inputs: l80, backend: e36, attrs: i88 } = n67, { x: t67 } = l80, { begin: r56, size: o80 } = i88, [s84, a71] = slice_util_exports.parseSliceParams(t67, r56, o80);
  if (slice_util_exports.assertParamsValid(t67, s84, a71), util_exports.sizeFromShape(a71) === 0) return e36.makeTensorInfo(a71, t67.dtype, []);
  if (e36.shouldExecuteOnCPU([t67]) || t67.dtype === "string") {
    let d55 = e36.texData.get(t67.dataId), u86 = B20(d55.values, s84, a71, t67.shape, t67.dtype);
    return e36.makeTensorInfo(a71, t67.dtype, u86);
  }
  let { isPacked: p103 } = e36.texData.get(t67.dataId), m96 = slice_util_exports.isSliceContinous(t67.shape, s84, a71);
  if (p103 || !m96) {
    let d55 = l().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new e26(a71) : new n40(a71), u86 = [s84];
    return e36.runWebGLProgram(d55, [t67], t67.dtype, u86);
  }
  return e36.uploadToGPU(t67.dataId), x57(t67, s84, a71, e36);
}
var k40 = { kernelName: Et, backendName: "webgl", kernelFunc: S33 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/BatchToSpaceND.mjs
var B22 = (u86) => {
  let { inputs: g72, backend: t67, attrs: b58 } = u86, { x: n67 } = g72, { blockShape: e36, crops: a71 } = b58;
  util_exports.assert(n67.shape.length <= 4, () => "batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");
  let p103 = e36.reduce((r56, N58) => r56 * N58), c103 = backend_util_exports.getReshaped(n67.shape, e36, p103), S45 = backend_util_exports.getPermuted(c103.length, e36.length), i88 = backend_util_exports.getReshapedPermuted(n67.shape, e36, p103), f85 = backend_util_exports.getSliceBeginCoords(a71, e36.length), k63 = backend_util_exports.getSliceSize(i88, a71, e36.length), o80 = [], h74 = f68({ inputs: { x: n67 }, backend: t67, attrs: { shape: c103 } }), d55 = h59({ inputs: { x: h74 }, backend: t67, attrs: { perm: S45 } }), m96 = f68({ inputs: { x: d55 }, backend: t67, attrs: { shape: i88 } }), x76 = S33({ inputs: { x: m96 }, backend: t67, attrs: { begin: f85, size: k63 } });
  return o80.push(h74), o80.push(d55), o80.push(m96), o80.forEach((r56) => t67.disposeIntermediateTensorInfo(r56)), x76;
};
var y33 = { kernelName: h3, backendName: "webgl", kernelFunc: B22 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Bincount.mjs
function m75(o80) {
  let { inputs: c103, backend: t67, attrs: s84 } = o80, { x: a71, weights: n67 } = c103, { size: e36 } = s84, r56 = t67.readSync(a71.dataId), i88 = t67.readSync(n67.dataId), d55 = m72(r56, i88, n67.dtype, n67.shape, e36);
  return t67.makeTensorInfo([e36], n67.dtype, d55);
}
var f70 = { kernelName: M2, backendName: "webgl", kernelFunc: m75 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/BitwiseAnd.mjs
var P27 = `
  int r = int(a.r) & int(b.r);
  int g = int(a.g) & int(b.g);
  int rb = int(a.b) & int(b.b);
  int ra = int(a.a) & int(b.a);
  return vec4(r, g, rb, ra);
`;
var B23 = `
  return float(int(a.r) & int(b.r));
`;
function N44(s84) {
  let { inputs: i88, backend: e36 } = s84, { a: t67, b: a71 } = i88, p103 = l().getBool("WEBGL_PACK_BINARY_OPERATIONS"), u86 = l().getNumber("WEBGL_VERSION");
  if (e36.shouldExecuteOnCPU([t67, a71]) || u86 === 1) {
    let c103 = e36.texData.get(t67.dataId).values, b58 = e36.texData.get(a71.dataId).values, [d55, m96] = e20(t67.shape, a71.shape, c103, b58, t67.dtype), r56 = e36.makeTensorInfo(m96, t67.dtype), l80 = e36.texData.get(r56.dataId);
    return l80.values = d55, r56;
  }
  let n67;
  return p103 ? n67 = new u64(P27, t67.shape, a71.shape, false) : n67 = new t31(B23, t67.shape, a71.shape), e36.runWebGLProgram(n67, [t67, a71], t67.dtype);
}
var k41 = { kernelName: A2, backendName: "webgl", kernelFunc: N44 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/BroadcastArgs.mjs
function b40(n67) {
  let { inputs: t67, backend: a71 } = n67, { s0: s84, s1: e36 } = t67, o80 = a71.readSync(s84.dataId), c103 = a71.readSync(e36.dataId), r56 = backend_util_exports.assertAndGetBroadcastShape(Array.from(o80), Array.from(c103));
  return a71.makeTensorInfo([r56.length], "int32", Int32Array.from(r56));
}
var l55 = { kernelName: N2, backendName: "webgl", kernelFunc: b40 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/NotEqual.mjs
var t40 = "return float(a != b);";
var r28 = z26({ opSnippet: t40, cpuKernelImpl: S31, dtype: "bool" });
var m76 = { kernelName: $o, backendName: "webgl", kernelFunc: r28 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Real.mjs
function c78(t67) {
  let { inputs: n67, backend: e36 } = t67, { input: o80 } = n67, a71 = e36.texData.get(o80.dataId);
  return i52({ inputs: { x: a71.complexTensorInfos.real }, backend: e36 });
}
var s52 = { kernelName: gt, backendName: "webgl", kernelFunc: c78 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernel_utils/int.mjs
var e27 = "return float(int(x));";
function d36(r56, a71) {
  let n67 = new e21(r56.shape, e27), t67 = a71.runWebGLProgram(n67, [r56], "int32");
  return { dataId: t67.dataId, shape: t67.shape, dtype: t67.dtype };
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Cast.mjs
function a50(m96) {
  let { inputs: c103, backend: t67, attrs: l80 } = m96, { x: e36 } = c103, { dtype: r56 } = l80;
  if (r56 === "complex64") {
    if (e36.dtype === "complex64") return i52({ inputs: { x: e36 }, backend: t67 });
    let o80 = e13(e36.shape), s84 = a50({ inputs: { x: e36 }, backend: t67, attrs: { dtype: "float32" } }), n67 = i53({ inputs: { real: s84, imag: o80 }, backend: t67 });
    return o80.dispose(), t67.disposeIntermediateTensorInfo(s84), n67;
  }
  if (e36.dtype === "complex64") {
    let o80 = c78({ inputs: { input: e36 }, backend: t67 }), s84 = a50({ inputs: { x: o80 }, backend: t67, attrs: { dtype: r56 } });
    return t67.disposeIntermediateTensorInfo(o80), s84;
  }
  if (!util_exports.hasEncodingLoss(e36.dtype, r56)) {
    let o80 = i52({ inputs: { x: e36 }, backend: t67 });
    return { dataId: o80.dataId, shape: o80.shape, dtype: r56 };
  }
  if (t67.shouldExecuteOnCPU([e36])) {
    let o80 = t67.texData.get(e36.dataId).values, [s84, n67, f85] = s46(o80, e36.shape, e36.dtype, r56);
    return t67.makeTensorInfo(s84, n67, f85);
  }
  if (r56 === "int32") return d36(e36, t67);
  if (r56 === "bool") {
    let o80 = t67.makeTensorInfo([], "bool", util_exports.getTypedArrayFromDType("bool", 1)), n67 = r28({ inputs: { a: e36, b: o80 }, backend: t67 });
    return t67.disposeIntermediateTensorInfo(o80), n67;
  }
  throw new Error(`Error in Cast: failed to cast ${e36.dtype} to ${r56}`);
}
var D27 = { kernelName: C2, backendName: "webgl", kernelFunc: a50 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Ceil.mjs
var e28 = "return ceil(x);";
var o51 = v32({ opSnippet: e28, packedOpSnippet: e28, cpuKernelImpl: t29 });
var t41 = { kernelName: v2, backendName: "webgl", kernelFunc: o51 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/clip_gpu.mjs
var t42 = class {
  constructor(a71) {
    this.variableNames = ["A"], this.customUniforms = [{ name: "minVal", type: "float" }, { name: "maxVal", type: "float" }], this.outputShape = a71, this.userCode = `

      void main() {
        float value = getAAtOutCoords();
        if (isnan(value)) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, minVal, maxVal));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/clip_packed_gpu.mjs
var t43 = class {
  constructor(e36) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "minVal", type: "float" }, { name: "maxVal", type: "float" }], this.outputShape = e36, this.userCode = `
      void main() {
        vec4 value = getAAtOutCoords();

        if (any(isnan(value))) {
          setOutput(value);
          return;
        }

        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ClipByValue.mjs
function g54(r56) {
  let { inputs: n67, backend: a71, attrs: l80 } = r56, { x: e36 } = n67, { clipValueMin: t67, clipValueMax: p103 } = l80, o80;
  l().getBool("WEBGL_PACK_CLIP") ? o80 = new t43(e36.shape) : o80 = new t42(e36.shape);
  let c103 = [[t67], [p103]];
  return a71.runWebGLProgram(o80, [e36], e36.dtype, c103);
}
var V15 = { kernelName: F2, backendName: "webgl", kernelFunc: g54 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/complex_abs_gpu.mjs
var t44 = class {
  constructor(e36) {
    this.variableNames = ["real", "imag"], this.outputShape = e36, this.userCode = `
      void main() {
        float re = abs(getRealAtOutCoords());
        float im = abs(getImagAtOutCoords());
        float mx = max(re, im);

        // sadly the length function in glsl is not underflow-safe
        // (at least not on Intel GPUs). So the safe solution is
        // to ensure underflow-safety in all cases.
        setOutput(
          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))
        );
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ComplexAbs.mjs
function p75(n67, e36) {
  return { dataId: e36.dataId, dtype: e36.dtype, shape: n67.shape };
}
function d37(n67) {
  let { inputs: e36, backend: t67 } = n67, { x: o80 } = e36, r56 = t67.texData.get(o80.dataId), s84 = new t44(o80.shape), a71 = [p75(o80, r56.complexTensorInfos.real), p75(o80, r56.complexTensorInfos.imag)];
  return t67.runWebGLProgram(s84, a71, a71[0].dtype);
}
var b41 = { kernelName: T2, backendName: "webgl", kernelFunc: d37 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/concat_gpu.mjs
var n41 = class {
  constructor(o80) {
    this.outputShape = [], this.outputShape = backend_util_exports.computeOutShape(o80, 1), this.variableNames = o80.map((t67, i88) => `T${i88}`);
    let e36 = new Array(o80.length - 1);
    e36[0] = o80[0][1];
    for (let t67 = 1; t67 < e36.length; t67++) e36[t67] = e36[t67 - 1] + o80[t67][1];
    let s84 = [`if (yC < ${e36[0]}) setOutput(getT0(yR, yC));`];
    for (let t67 = 1; t67 < e36.length; t67++) {
      let i88 = e36[t67 - 1];
      s84.push(`else if (yC < ${e36[t67]}) setOutput(getT${t67}(yR, yC-${i88}));`);
    }
    let u86 = e36.length, l80 = e36[e36.length - 1];
    s84.push(`else setOutput(getT${u86}(yR, yC-${l80}));`), this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int yR = coords.x;
        int yC = coords.y;

        ${s84.join(`
        `)}
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/concat_packed_gpu.mjs
var d38 = class {
  constructor(s84, u86) {
    this.packedInputs = true, this.packedOutput = true, this.outputShape = [], this.outputShape = backend_util_exports.computeOutShape(s84, u86);
    let l80 = this.outputShape, t67 = l80.length, c103 = F22(t67), e36 = u62("coords", t67), $37 = ["x", "y", "z", "w", "u", "v"].slice(0, t67);
    this.variableNames = s84.map((n67, i88) => `T${i88}`);
    let o80 = new Array(s84.length - 1);
    o80[0] = s84[0][u86];
    for (let n67 = 1; n67 < o80.length; n67++) o80[n67] = o80[n67 - 1] + s84[n67][u86];
    let r56 = $37[u86], p103 = $37.slice(-2), m96 = $37.join(), g72 = `if (${r56} < ${o80[0]}) {
        return getChannel(
            getT0(${m96}), vec2(${p103.join()}));
        }`;
    for (let n67 = 1; n67 < o80.length; n67++) {
      let i88 = o80[n67 - 1];
      g72 += `
        if (${r56} < ${o80[n67]}  && ${r56} >= ${o80[n67 - 1]}) {
          return getChannel(
            getT${n67}(${a51($37, r56, i88)}),
            vec2(${a51(p103, r56, i88)}));
        }`;
    }
    let C28 = o80.length, f85 = o80[o80.length - 1];
    g72 += `
        return getChannel(
          getT${C28}(${a51($37, r56, f85)}),
          vec2(${a51(p103, r56, f85)}));`, this.userCode = `
      float getValue(${$37.map((n67) => "int " + n67)}) {
        ${g72}
      }

      void main() {
        ${c103} coords = getOutputCoords();
        vec4 result = vec4(getValue(${e36}), 0., 0., 0.);

        ${e36[t67 - 1]} = ${e36[t67 - 1]} + 1;
        if (${e36[t67 - 1]} < ${l80[t67 - 1]}) {
          result.g = getValue(${e36});
        }

        ${e36[t67 - 2]} = ${e36[t67 - 2]} + 1;
        if (${e36[t67 - 2]} < ${l80[t67 - 2]}) {
          result.a = getValue(${e36});
        }

        ${e36[t67 - 1]} = ${e36[t67 - 1]} - 1;
        if (${e36[t67 - 2]} < ${l80[t67 - 2]} &&
            ${e36[t67 - 1]} < ${l80[t67 - 1]}) {
          result.b = getValue(${e36});
        }
        setOutput(result);
      }
    `;
  }
};
function a51(h74, s84, u86) {
  let l80 = h74.indexOf(s84);
  return h74.map((c103, e36) => e36 === l80 ? `${c103} - ${u86}` : c103).join();
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Imag.mjs
function r29(n67) {
  let { inputs: e36, backend: t67 } = n67, { input: o80 } = e36, a71 = t67.texData.get(o80.dataId);
  return i52({ inputs: { x: a71.complexTensorInfos.imag }, backend: t67 });
}
var s53 = { kernelName: ho, backendName: "webgl", kernelFunc: r29 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Concat_impl.mjs
function h61(r56, s84, o80) {
  let m96 = r56[0].dtype;
  if (m96 === "complex64") {
    let e36 = r56.map((a71) => c78({ inputs: { input: a71 }, backend: o80 })), i88 = r56.map((a71) => r29({ inputs: { input: a71 }, backend: o80 })), n67 = h61(e36, s84, o80), u86 = h61(i88, s84, o80), I44 = i53({ inputs: { real: n67, imag: u86 }, backend: o80 });
    return e36.forEach((a71) => o80.disposeIntermediateTensorInfo(a71)), i88.forEach((a71) => o80.disposeIntermediateTensorInfo(a71)), o80.disposeIntermediateTensorInfo(n67), o80.disposeIntermediateTensorInfo(u86), I44;
  }
  let c103 = o80.shouldExecuteOnCPU(r56);
  if (m96 === "string" && (c103 = true), c103) {
    let e36 = r56.map((p103) => {
      let D42 = [-1, util_exports.sizeFromShape(p103.shape.slice(s84))];
      return f68({ inputs: { x: p103 }, backend: o80, attrs: { shape: D42 } });
    }), i88 = e36.map((p103) => ({ vals: o80.readSync(p103.dataId), shape: p103.shape })), n67 = backend_util_exports.computeOutShape(e36.map((p103) => p103.shape), 1), u86 = e36[0].shape[0] === 1, I44 = a45(i88, n67, m96, u86), a71 = backend_util_exports.computeOutShape(r56.map((p103) => p103.shape), s84), A35 = o80.makeTensorInfo(a71, m96, I44);
    return e36.forEach((p103) => o80.disposeIntermediateTensorInfo(p103)), A35;
  }
  let t67 = r56.filter((e36) => util_exports.sizeFromShape(e36.shape) > 0), T40 = l().getBool("WEBGL_PACK_ARRAY_OPERATIONS") && t67[0].shape.length > 1;
  if (t67.length === 1) {
    let e36 = T40 ? new e21(r56[0].shape, h57) : new e22(r56[0].shape, h57);
    return o80.runWebGLProgram(e36, r56, m96);
  }
  let f85 = l().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER");
  if (t67.length > f85) {
    let e36 = [];
    for (let n67 = 0; n67 < t67.length; n67 += f85) {
      let u86 = t67.slice(n67, n67 + f85);
      e36.push(h61(u86, s84, o80));
    }
    let i88 = h61(e36, s84, o80);
    for (let n67 of e36) o80.disposeIntermediateTensorInfo(n67);
    return i88;
  }
  if (T40) {
    let e36 = new d38(t67.map((i88) => i88.shape), s84);
    return o80.runWebGLProgram(e36, t67, m96);
  }
  let { tensors2D: l80, outShape: d55 } = B24(t67, s84, o80), _24 = new n41(l80.map((e36) => e36.shape)), E44 = o80.runWebGLProgram(_24, l80, m96);
  l80.forEach((e36) => o80.disposeIntermediateTensorInfo(e36));
  let y43 = f68({ inputs: { x: E44 }, attrs: { shape: d55 }, backend: o80 });
  return o80.disposeIntermediateTensorInfo(E44), y43;
}
function B24(r56, s84, o80) {
  let m96 = backend_util_exports.computeOutShape(r56.map((t67) => t67.shape), s84);
  return { tensors2D: r56.map((t67) => f68({ inputs: { x: t67 }, attrs: { shape: [-1, util_exports.sizeFromShape(t67.shape.slice(s84))] }, backend: o80 })), outShape: m96 };
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Concat.mjs
function k42(i88) {
  let { inputs: t67, backend: n67, attrs: c103 } = i88, { axis: m96 } = c103, a71 = util_exports.parseAxisParam(m96, t67[0].shape)[0], u86 = t67.map((e36) => e36.shape);
  backend_util_exports.assertParamsConsistent(u86, a71);
  let r56 = backend_util_exports.computeOutShape(t67.map((e36) => e36.shape), a71);
  if (util_exports.sizeFromShape(r56) === 0) return n67.makeTensorInfo(r56, t67[0].dtype, []);
  let s84 = t67.filter((e36) => util_exports.sizeFromShape(e36.shape) > 0);
  return s84.length === 1 ? i52({ inputs: { x: s84[0] }, backend: n67 }) : h61(s84, a71, n67);
}
var S34 = { kernelName: L2, backendName: "webgl", kernelFunc: k42 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/conv_gpu.mjs
var g55 = class {
  constructor(e36, a71 = false, s84 = null, o80 = false, x76 = false) {
    this.variableNames = ["x", "W"], this.outputShape = e36.outShape;
    let l80 = e36.padInfo.top, c103 = e36.padInfo.left, C28 = e36.strideHeight, h74 = e36.strideWidth, w45 = e36.dilationHeight, n67 = e36.dilationWidth, R26 = e36.filterHeight, u86 = e36.filterWidth, t67 = Math.floor(e36.inChannels / 4) * 4, i88 = e36.inChannels % 4, d55 = e36.dataFormat === "channelsLast", W15 = d55 ? 1 : 2, V24 = d55 ? 2 : 3, F32 = d55 ? 3 : 1, r56 = "", $37 = "";
    s84 && (o80 ? r56 = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${s84}
        }` : x76 ? r56 = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${s84}
        }` : r56 = `
          float activation(float x) {
            ${s84}
          }
        `, $37 = "result = activation(result);");
    let f85 = a71 ? "result += getBiasAtOutCoords();" : "";
    a71 && this.variableNames.push("bias"), o80 && this.variableNames.push("preluActivationWeights"), x76 && this.variableNames.push("leakyreluAlpha"), this.userCode = `
      ${r56}

      const ivec2 strides = ivec2(${C28}, ${h74});
      const ivec2 pads = ivec2(${l80}, ${c103});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d2 = coords[${F32}];

        ivec2 xRCCorner =
            ivec2(coords[${W15}], coords[${V24}]) * strides - pads;
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${R26}; wR++) {
          int xR = xRCorner + wR * ${w45};

          if (xR < 0 || xR >= ${e36.inHeight}) {
            continue;
          }

          for (int wC = 0; wC < ${u86}; wC++) {
            int xC = xCCorner + wC * ${n67};

            if (xC < 0 || xC >= ${e36.inWidth}) {
              continue;
            }

            for (int d1 = 0; d1 < ${t67}; d1 += 4) {
              vec4 wValues = vec4(
                getW(wR, wC, d1, d2),
                getW(wR, wC, d1 + 1, d2),
                getW(wR, wC, d1 + 2, d2),
                getW(wR, wC, d1 + 3, d2)
              );

              if (${d55}) {
                vec4 xValues = vec4(
                  getX(batch, xR, xC, d1),
                  getX(batch, xR, xC, d1 + 1),
                  getX(batch, xR, xC, d1 + 2),
                  getX(batch, xR, xC, d1 + 3)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec4 xValues = vec4(
                  getX(batch, d1, xR, xC),
                  getX(batch, d1 + 1, xR, xC),
                  getX(batch, d1 + 2, xR, xC),
                  getX(batch, d1 + 3, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }
            }

            if (${i88 === 1}) {

              if (${d55}) {
                dotProd +=
                    getX(batch, xR, xC, ${t67}) *
                    getW(wR, wC, ${t67}, d2);
              } else {
                dotProd +=
                    getX(batch, ${t67}, xR, xC) *
                    getW(wR, wC, ${t67}, d2);
              }

            } else if (${i88 === 2}) {
              vec2 wValues = vec2(
                getW(wR, wC, ${t67}, d2),
                getW(wR, wC, ${t67} + 1, d2)
              );

              if (${d55}) {
                vec2 xValues = vec2(
                  getX(batch, xR, xC, ${t67}),
                  getX(batch, xR, xC, ${t67} + 1)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec2 xValues = vec2(
                  getX(batch, ${t67}, xR, xC),
                  getX(batch, ${t67} + 1, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            } else if (${i88 === 3}) {
              vec3 wValues = vec3(
                getW(wR, wC, ${t67}, d2),
                getW(wR, wC, ${t67} + 1, d2),
                getW(wR, wC, ${t67} + 2, d2)
              );

              if (${d55}) {
                vec3 xValues = vec3(
                  getX(batch, xR, xC, ${t67}),
                  getX(batch, xR, xC, ${t67} + 1),
                  getX(batch, xR, xC, ${t67} + 2)
                );
                dotProd += dot(xValues, wValues);
              } else {
                vec3 xValues = vec3(
                  getX(batch, ${t67}, xR, xC),
                  getX(batch, ${t67} + 1, xR, xC),
                  getX(batch, ${t67} + 2, xR, xC)
                );
                dotProd += dot(xValues, wValues);
              }

            }
          }
        }

        float result = dotProd;
        ${f85}
        ${$37}
        setOutput(result);
      }
    `;
  }
};
var p76 = class {
  constructor(e36) {
    this.variableNames = ["x", "W"], this.outputShape = e36.outShape;
    let a71 = e36.padInfo.front, s84 = e36.padInfo.top, o80 = e36.padInfo.left, x76 = e36.strideDepth, l80 = e36.strideHeight, c103 = e36.strideWidth, C28 = e36.dilationDepth, h74 = e36.dilationHeight, w45 = e36.dilationWidth, n67 = e36.filterDepth, R26 = e36.filterHeight, u86 = e36.filterWidth, t67 = Math.floor(e36.inChannels / 4) * 4, i88 = e36.inChannels % 4;
    this.userCode = `
      const ivec3 strides = ivec3(${x76}, ${l80}, ${c103});
      const ivec3 pads = ivec3(${a71}, ${s84}, ${o80});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d2 = coords.u;

        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;
        int xFCorner = xFRCCorner.x;
        int xRCorner = xFRCCorner.y;
        int xCCorner = xFRCCorner.z;

        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get
        // y(yF, yR, yC, d2). ? = to be determined. : = across all
        // values in that axis.
        float dotProd = 0.0;
        for (int wF = 0; wF < ${n67}; wF++) {
          int xF = xFCorner + wF * ${C28};

          if (xF < 0 || xF >= ${e36.inDepth}) {
            continue;
          }

          for (int wR = 0; wR < ${R26}; wR++) {
            int xR = xRCorner + wR * ${h74};

            if (xR < 0 || xR >= ${e36.inHeight}) {
              continue;
            }

            for (int wC = 0; wC < ${u86}; wC++) {
              int xC = xCCorner + wC * ${w45};

              if (xC < 0 || xC >= ${e36.inWidth}) {
                continue;
              }

              for (int d1 = 0; d1 < ${t67}; d1 += 4) {
                vec4 xValues = vec4(
                  getX(batch, xF, xR, xC, d1),
                  getX(batch, xF, xR, xC, d1 + 1),
                  getX(batch, xF, xR, xC, d1 + 2),
                  getX(batch, xF, xR, xC, d1 + 3)
                );
                vec4 wValues = vec4(
                  getW(wF, wR, wC, d1, d2),
                  getW(wF, wR, wC, d1 + 1, d2),
                  getW(wF, wR, wC, d1 + 2, d2),
                  getW(wF, wR, wC, d1 + 3, d2)
                );

                dotProd += dot(xValues, wValues);
              }

              if (${i88 === 1}) {
                dotProd +=
                  getX(batch, xF, xR, xC, ${t67}) *
                  getW(wF, wR, wC, ${t67}, d2);
              } else if (${i88 === 2}) {
                vec2 xValues = vec2(
                  getX(batch, xF, xR, xC, ${t67}),
                  getX(batch, xF, xR, xC, ${t67} + 1)
                );
                vec2 wValues = vec2(
                  getW(wF, wR, wC, ${t67}, d2),
                  getW(wF, wR, wC, ${t67} + 1, d2)
                );
                dotProd += dot(xValues, wValues);
              } else if (${i88 === 3}) {
                vec3 xValues = vec3(
                  getX(batch, xF, xR, xC, ${t67}),
                  getX(batch, xF, xR, xC, ${t67} + 1),
                  getX(batch, xF, xR, xC, ${t67} + 2)
                );
                vec3 wValues = vec3(
                  getW(wF, wR, wC, ${t67}, d2),
                  getW(wF, wR, wC, ${t67} + 1, d2),
                  getW(wF, wR, wC, ${t67} + 2, d2)
                );
                dotProd += dot(xValues, wValues);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/conv_packed_gpu.mjs
var o52 = class {
  constructor(s84, d55 = false, f85 = null, c103 = false, n67 = false) {
    this.variableNames = ["x", "W"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "pads", type: "ivec2" }, { name: "strides", type: "ivec2" }, { name: "dilations", type: "ivec2" }, { name: "inDims", type: "ivec2" }], this.outputShape = s84.outShape, this.enableShapeUniforms = F23(this.outputShape.length);
    let C28 = s84.padInfo.left, T40 = s84.strideWidth, l80 = s84.dilationWidth, u86 = s84.filterHeight, i88 = s84.filterWidth, v42 = i88, x76 = `
       int xR; int xC; int xCOffset;
       vec4 wTexel; vec4 previous; vec4 final;`;
    for (let t67 = 0; t67 < i88; t67++) x76 += `
           vec4 xTexelC${t67 * 2};
           int xTexelC${t67 * 2}Ready;
           vec4 xTexelC${t67 * 2 + 1};
           int xTexelC${t67 * 2 + 1}Ready;
           vec4 xC${t67};`;
    x76 += `
     for (int r = 0; r < ${u86}; r++) {
      for (int d1 = 0; d1 < ${s84.inChannels}; d1 += 2) {
       `;
    for (let t67 = 0; t67 < i88; t67++) x76 += `
           xTexelC${t67 * 2} = vec4(0.0);
           xTexelC${t67 * 2}Ready = 0;
           xTexelC${t67 * 2 + 1} = vec4(0.0);
           xTexelC${t67 * 2 + 1}Ready = 0;
           xC${t67} = vec4(0.0);`;
    x76 += `
         xR = xRCorner + r * dilations[0];
         if (xR >=0 && xR < inDims[0]) {
       `;
    for (let t67 = 0; t67 < (v42 + 1) / 2; t67++) {
      let e36 = t67 * 2;
      if (x76 += `
           xC = xCCorner + ${e36 * l80};
           `, T40 === 1) {
        if (e36 < i88 && (C28 % 2 === 1 ? (x76 += `
                 xCOffset = xC + 1;
                 if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${e36}Ready == 0) {
                   xTexelC${e36} = getX(batch, xR, xCOffset, d1);

                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${e36}.zw = vec2(0.0);
                   }
                   xTexelC${e36}Ready = 1;
                 }
               `, l80 === 1 && e36 > 0 ? x76 += `
                 xC${e36} = vec4(xTexelC${e36 - 2}.zw, xTexelC${e36}.xy);
                 ` : x76 += `
                   xCOffset = xC + 1 - 2;

                   if (xCOffset >= 0 && xCOffset < inDims[1]) {
                     previous = getX(batch, xR, xCOffset, d1);

                     // Need to manually clear unused channels in case
                     // we're reading from recycled texture.
                     if (xCOffset + 1 >= inDims[1]) {
                       previous.zw = vec2(0.0);
                     }

                     xC${e36} = vec4(previous.zw, xTexelC${e36}.xy);
                   } else {
                     xC${e36} = vec4(0.0, 0.0, xTexelC${e36}.xy);
                   }
                   `) : x76 += `
                 if (xC >= 0 && xC < inDims[1] && xTexelC${e36}Ready == 0) {
                   xTexelC${e36} = getX(batch, xR, xC, d1);
                   if (xC + 1 >= inDims[1]) {
                     xTexelC${e36}.zw = vec2(0.0);
                   }
                   xTexelC${e36}Ready = 1;
                 }

                 xC${e36} = xTexelC${e36};
                 `, e36 + 1 < i88)) {
          let r56 = C28 % 2 === 0 ? util_exports.nearestLargerEven(l80) : l80;
          l80 % 2 === 0 && C28 % 2 === 1 || l80 % 2 !== 0 && C28 % 2 !== 1 ? (x76 += `
                   xCOffset = xC + imod(pads[1], 2) + ${r56};

                   if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${e36 + 1}Ready == 0) {
                     xTexelC${e36 + 1} = getX(batch, xR, xCOffset, d1);

                     // Need to manually clear unused channels in case
                     // we're reading from recycled texture.
                     if (xCOffset + 1 >= inDims[1]) {
                       xTexelC${e36 + 1}.zw = vec2(0.0);
                     }
                     xTexelC${e36 + 1}Ready = 1;
                   }
                   `, l80 > 1 ? x76 += `
                     xCOffset -= 2;
                     if (xCOffset >= 0 && xCOffset < inDims[1]) {
                      previous = getX(batch, xR, xCOffset, d1);
                      xC${e36 + 1} = vec4(previous.zw, xTexelC${e36 + 1}.xy);
                     } else {
                      xC${e36 + 1} = vec4(0.0, 0.0, xTexelC${e36 + 1}.xy);
                     }
                     ` : x76 += `
                     xC${e36 + 1} = vec4(xTexelC${e36}.zw, xTexelC${e36 + 1}.xy);
                     `) : r56 === 1 ? x76 += `
                     xC${e36 + 1} = xTexelC${e36};
                     ` : x76 += `
                     xCOffset = xC + ${r56};

                     if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${e36 + 1}Ready == 0) {
                       xTexelC${e36 + 1} = getX(batch, xR, xCOffset, d1);
                       if (xCOffset + 1 >= inDims[1]) {
                         xTexelC${e36 + 1}.zw = vec2(0.0);
                       }
                       xTexelC${e36 + 1}Ready = 1;
                     }

                     xC${e36 + 1} = xTexelC${e36 + 1};
                     `;
        }
      } else e36 < i88 && (C28 % 2 === 1 ? (x76 += `
                 xCOffset = xC + 1 - strides[1];
                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${e36}Ready == 0) {
                   xTexelC${e36} = getX(batch, xR, xCOffset, d1);
                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${e36}.zw = vec2(0.0);
                   }
                   xTexelC${e36}Ready = 1;
                 }

                 if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${e36 + 1}Ready == 0) {
                   xTexelC${e36 + 1} = getX(batch, xR, xC + 1, d1);
                   // Need to manually clear unused channels in case
                   // we're reading from recycled texture.
                   if (xC + 2 >= inDims[1]) {
                     xTexelC${e36 + 1}.zw = vec2(0.0);
                   }
                   xTexelC${e36 + 1}Ready = 1;
                 }

                 xC${e36} = vec4(xTexelC${e36}.zw, xTexelC${e36 + 1}.zw);
               `, e36 + 1 < i88 && (x76 += `
                   final = vec4(0.0);
                   xCOffset = xC + 1 + strides[1];
                   if(xCOffset >= 0 && xCOffset < inDims[1]) {
                     final = getX(batch, xR, xCOffset, d1);
                   }
                   xC${e36 + 1} = vec4(xTexelC${e36 + 1}.xy, final.xy);
                 `)) : (x76 += `
                 if(xC >= 0 && xC < inDims[1] && xTexelC${e36}Ready == 0) {
                   xTexelC${e36} = getX(batch, xR, xC, d1);
                   if (xC + 1 >= inDims[1]) {
                     xTexelC${e36}.zw = vec2(0.0);
                   }
                   xTexelC${e36}Ready = 1;
                 }

                 xCOffset = xC + strides[1];
                 if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${e36 + 1}Ready == 0) {
                   xTexelC${e36 + 1} = getX(batch, xR, xCOffset, d1);
                   if (xCOffset + 1 >= inDims[1]) {
                     xTexelC${e36 + 1}.zw = vec2(0.);
                   }
                   xTexelC${e36 + 1}Ready = 1;
                 }

                 xC${e36} = vec4(
                   xTexelC${e36}.xy, xTexelC${e36 + 1}.xy);
               `, e36 + 1 < i88 && (x76 += `
                   xC${e36 + 1} = vec4(xTexelC${e36}.zw, xTexelC${e36 + 1}.zw);
                 `)));
      e36 < i88 && (x76 += `
             wTexel = getW(r, ${e36}, d1, d2);
             dotProd += xC${e36}.xxzz * vec4(wTexel.xy, wTexel.xy);
             if(d1 + 1 < ${s84.inChannels}) {
               dotProd += xC${e36}.yyww * vec4(wTexel.zw, wTexel.zw);
             }
           `, e36 + 1 < i88 && (x76 += `
               wTexel = getW(r, ${e36 + 1}, d1, d2);
               dotProd += xC${e36 + 1}.xxzz * vec4(wTexel.xy, wTexel.xy);
               if(d1 + 1 < ${s84.inChannels}) {
                 dotProd += xC${e36 + 1}.yyww * vec4(wTexel.zw, wTexel.zw);
               }
             `));
    }
    x76 += `
     }
   `, x76 += `
     }
   `, x76 += `
     }
   `;
    let a71 = "", $37 = "";
    f85 && (c103 ? a71 = `vec4 activation(vec4 a) {
           vec4 b = getPreluActivationWeightsAtOutCoords();
           ${f85}
         }` : n67 ? a71 = `vec4 activation(vec4 a) {
           vec4 b = getLeakyreluAlphaAtOutCoords();
           ${f85}
         }` : a71 = `vec4 activation(vec4 x) {
           ${f85}
         }`, $37 = "result = activation(result);");
    let y43 = d55 ? "result += getBiasAtOutCoords();" : "";
    d55 && this.variableNames.push("bias"), c103 && this.variableNames.push("preluActivationWeights"), n67 && this.variableNames.push("leakyreluAlpha"), this.userCode = `
       ${a71}

       void main() {
         ivec4 coords = getOutputCoords();
         int batch = coords.x;
         ivec2 xRCCorner = coords.yz * strides - pads;
         int d2 = coords.w;
         int xRCorner = xRCCorner.x;
         int xCCorner = xRCCorner.y;

         //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.
         vec4 dotProd = vec4(0.000000000000001);

         ${x76}

         vec4 result = dotProd - vec4(0.000000000000001);
         ${y43}
         ${$37}
         setOutput(result);
       }
     `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/im2col_packed_gpu.mjs
var o53 = class {
  constructor(n67, c103) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "inputShape", type: "ivec4" }, { name: "pad", type: "ivec2" }, { name: "stride", type: "ivec2" }, { name: "dilation", type: "ivec2" }, { name: "inChannels", type: "int" }, { name: "itemsPerBlockRow", type: "int" }, { name: "outWidth", type: "int" }], this.outputShape = n67, this.enableShapeUniforms = F23(this.outputShape.length);
    let { dataFormat: r56 } = c103, d55 = c71(), i88 = r56 === "channelsLast", a71 = i88 ? 1 : 2, l80 = i88 ? 2 : 3, p103 = this.enableShapeUniforms ? "if(blockIndex < outShape[2] && pos < outShape[1]) {" : `if(blockIndex < ${n67[2]} && pos < ${n67[1]}) {`, s84 = "";
    for (let e36 = 0; e36 <= 1; e36++) for (let t67 = 0; t67 <= 1; t67++) s84 += `
          blockIndex = rc.z + ${t67};
          pos = rc.y + ${e36};

          ${p103}
            offsetY = int(blockIndex / outWidth) * stride[0] - pad[0];
            d0 = offsetY + dilation[0] * (pos / itemsPerBlockRow);

            if(d0 < inputShape[${a71}] && d0 >= 0) {
              // Use custom imod instead mod. On Intel GPU, mod may generate
              // unexpected value.
              // https://github.com/tensorflow/tfjs/issues/5447
              offsetX = imod(blockIndex, outWidth) * stride[1] - pad[1];
              d1 = offsetX + dilation[1] * (imod(pos, itemsPerBlockRow) /
                  inChannels);

              if(d1 < inputShape[${l80}] && d1 >= 0) {

                ch = imod(pos, inChannels);

                if (${i88}) {
                  innerDims = vec2(d1, ch);
                  result[${e36 * 2 + t67}] = getChannel(
                    getA(rc.x, d0, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                } else {
                  innerDims = vec2(d0, d1);
                  result[${e36 * 2 + t67}] = getChannel(
                    getA(rc.x, ch, int(innerDims.x),
                    int(innerDims.y)), innerDims);
                }
              }
            }
          }
        `;
    this.userCode = `
      void main() {
        ivec3 rc = getOutputCoords();

        vec4 result = vec4(0);

        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;
        vec2 innerDims;

        ${s84}

        ${d55.output} = result;
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Conv2D_impl.mjs
function T33(a71, d55) {
  let t67 = a71.length;
  return t67 >= 3 ? d55 ? [...a71.slice(0, -3), a71[t67 - 3] * a71[t67 - 2], a71[t67 - 1]] : [...a71.slice(0, -3), a71[t67 - 3], a71[t67 - 2] * a71[t67 - 1]] : !d55 && t67 === 1 && a71[0] > 1 ? [a71[0], 1] : null;
}
function I33({ x: a71, filter: d55, convInfo: t67, backend: s84, bias: l80 = null, preluActivationWeights: h74 = null, leakyreluAlpha: R26 = 0, activation: g72 = null }) {
  let i88 = a71.shape, p103 = s84.texData.get(a71.dataId), z32 = t67.inChannels, H18 = i88[0] * i88[1] * i88[2], L22 = t67.outChannels, m96 = t67.dataFormat === "channelsLast", S45 = false, f85 = false, C28, u86 = [];
  if (h74 != null) {
    let e36 = T33(h74.shape, m96);
    e36 != null && (h74 = f68({ inputs: { x: h74 }, backend: s84, attrs: { shape: e36 } }), u86.push(h74));
  }
  if (l80 != null) {
    let e36 = T33(l80.shape, m96);
    e36 != null && (l80 = f68({ inputs: { x: l80 }, backend: s84, attrs: { shape: e36 } }), u86.push(l80));
  }
  if (!((H18 === 1 || L22 === 1) && z32 > Z12) && p103.isPacked && m96 && p103.texture != null && i88[2] % 2 !== 0 && util_exports.arraysEqual(p103.shape.slice(-3), i88.slice(-3))) {
    let e36 = i88[0] * i88[1] * (i88[2] + 1), r56 = { dataId: a71.dataId, shape: [1, e36, t67.inChannels], dtype: a71.dtype }, x76 = p103.shape;
    p103.shape = p103.shape.slice(), p103.shape[p103.shape.length - 2]++, util_exports.assert(ae2(p103.shape, r56.shape), () => `packed reshape ${p103.shape} to ${r56.shape} isn't free`);
    let M30 = f68({ inputs: { x: d55 }, backend: s84, attrs: { shape: [1, t67.inChannels, t67.outChannels] } });
    u86.push(M30);
    let P36 = hs({ a: r56, b: M30, backend: s84, transposeA: S45, transposeB: f85, bias: l80, activation: g72, preluActivationWeights: h74, leakyreluAlpha: R26 }), c103 = s84.texData.get(P36.dataId);
    util_exports.assert(c103.isPacked, () => "batchMatMul result is expected to be packed"), p103.shape = x76, c103.shape = t67.outShape, C28 = i52({ inputs: { x: P36 }, backend: s84 }), C28.shape = t67.outShape, u86.push(P36);
  } else {
    let e36 = t67.outHeight * t67.outWidth, r56 = f68({ inputs: { x: a71 }, backend: s84, attrs: { shape: m96 ? [t67.batchSize, e36, t67.inChannels] : [t67.batchSize, t67.inChannels, e36] } }), x76 = f68({ inputs: { x: d55 }, backend: s84, attrs: { shape: [1, t67.inChannels, t67.outChannels] } }), M30 = hs({ a: m96 ? r56 : x76, b: m96 ? x76 : r56, transposeA: !m96, transposeB: f85, backend: s84, bias: l80, activation: g72, preluActivationWeights: h74, leakyreluAlpha: R26 });
    C28 = f68({ inputs: { x: M30 }, backend: s84, attrs: { shape: t67.outShape } }), u86.push(r56), u86.push(x76), u86.push(M30);
  }
  for (let e36 of u86) s84.disposeIntermediateTensorInfo(e36);
  return C28;
}
function v33({ x: a71, filter: d55, convInfo: t67, backend: s84, bias: l80 = null, preluActivationWeights: h74 = null, leakyreluAlpha: R26 = 0, activation: g72 = null }) {
  let { filterWidth: i88, filterHeight: p103, inChannels: z32, outWidth: H18, outHeight: L22, dataFormat: m96 } = t67, S45 = m96 === "channelsLast", f85 = i88 * p103 * z32, C28 = L22 * H18, u86 = [t67.batchSize, f85, C28], y43 = true, B30 = false, e36 = [];
  if (h74 != null) {
    let o80 = T33(h74.shape, S45);
    o80 != null && (h74 = f68({ inputs: { x: h74 }, backend: s84, attrs: { shape: o80 } }), e36.push(h74));
  }
  if (l80 != null) {
    let o80 = T33(l80.shape, S45);
    o80 != null && (l80 = f68({ inputs: { x: l80 }, backend: s84, attrs: { shape: o80 } }), e36.push(l80));
  }
  let r56 = f68({ inputs: { x: d55 }, backend: s84, attrs: { shape: [1, f85, util_exports.sizeFromShape(d55.shape) / f85] } });
  e36.push(r56);
  let x76 = new o53(u86, t67), M30 = [a71.shape, [t67.padInfo.top, t67.padInfo.left], [t67.strideHeight, t67.strideWidth], [t67.dilationHeight, t67.dilationWidth], [t67.inChannels], [t67.filterWidth * t67.inChannels], [t67.outWidth]], P36 = s84.runWebGLProgram(x76, [a71], "float32", M30), c103 = f68({ inputs: { x: P36 }, backend: s84, attrs: { shape: u86 } });
  e36.push(P36), e36.push(c103);
  let $37 = l80 != null, F32 = h74 != null, _24 = g72 === "leakyrelu", G30 = g72 ? J12(g72, true) : null, V24 = new d32(S45 ? c103.shape : r56.shape, S45 ? r56.shape : c103.shape, S45 ? [t67.batchSize, C28, t67.outChannels] : [t67.batchSize, t67.outChannels, C28], y43, B30, $37, G30, F32, _24), w45 = S45 ? [c103, r56] : [r56, c103];
  if (l80 && w45.push(l80), F32 && w45.push(h74), _24) {
    let o80 = s84.makeTensorInfo([], "float32", util_exports.createScalarValue(R26, "float32"));
    w45.push(o80), e36.push(o80);
  }
  let E44 = s84.runWebGLProgram(V24, w45, "float32"), X20 = f68({ inputs: { x: E44 }, backend: s84, attrs: { shape: t67.outShape } });
  e36.push(E44);
  for (let o80 of e36) s84.disposeIntermediateTensorInfo(o80);
  return X20;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Conv2D.mjs
function H12(p103) {
  let { inputs: m96, backend: o80, attrs: c103 } = p103, { x: n67, filter: i88 } = m96, { strides: l80, pad: f85, dataFormat: h74, dilations: g72, dimRoundingMode: u86 } = c103, a71 = backend_util_exports.convertConv2DDataFormat(h74), t67 = backend_util_exports.computeConv2DInfo(n67.shape, i88.shape, l80, g72, f85, u86, false, a71), e36;
  if (t67.filterHeight === 1 && t67.filterWidth === 1 && t67.dilationHeight === 1 && t67.dilationWidth === 1 && t67.strideHeight === 1 && t67.strideWidth === 1 && (t67.padInfo.type === "SAME" || t67.padInfo.type === "VALID")) e36 = I33({ x: n67, filter: i88, convInfo: t67, backend: o80 });
  else if (t67.strideWidth <= 2 && a71 === "channelsLast" && l().getBool("WEBGL_EXP_CONV")) {
    let r56 = new o52(t67), W15 = [[t67.padInfo.top, t67.padInfo.left], [t67.strideHeight, t67.strideWidth], [t67.dilationHeight, t67.dilationWidth], [t67.inHeight, t67.inWidth]];
    e36 = o80.runWebGLProgram(r56, [n67, i88], "float32", W15);
  } else if (l().getBool("WEBGL_CONV_IM2COL")) e36 = v33({ x: n67, filter: i88, convInfo: t67, backend: o80 });
  else {
    let r56 = new g55(t67);
    e36 = o80.runWebGLProgram(r56, [n67, i88], "float32");
  }
  let v42 = f68({ inputs: { x: e36 }, backend: o80, attrs: { shape: t67.outShape } });
  return o80.disposeIntermediateTensorInfo(e36), v42;
}
var x58 = { kernelName: k2, backendName: "webgl", kernelFunc: H12 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/conv_backprop_gpu.mjs
var h62 = class {
  constructor(t67) {
    this.variableNames = ["x", "dy"], this.outputShape = t67.filterShape;
    let d55 = t67.strideHeight, e36 = t67.strideWidth, r56 = t67.padInfo.top, o80 = t67.padInfo.left, i88 = t67.dataFormat === "channelsLast";
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int d2 = coords.w;

        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int b = 0; b < ${t67.batchSize}; b++) {
          for (int yR = 0; yR < ${t67.outHeight}; yR++) {
            int xR = wR + yR * ${d55} - ${r56};

            if (xR < 0 || xR >= ${t67.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${t67.outWidth}; yC++) {
              int xC = wC + yC * ${e36} - ${o80};

              if (xC < 0 || xC >= ${t67.inWidth}) {
                continue;
              }

              ${i88 ? `float dyValue = getDy(b, yR, yC, d2);
              float xValue = getX(b, xR, xC, d1);
              dotProd += (xValue * dyValue);` : `float dyValue = getDy(b, d2, yR, yC);
              float xValue = getX(b, d1, xR, xC);
              dotProd += (xValue * dyValue);`}
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var u70 = class {
  constructor(t67) {
    this.variableNames = ["dy", "W"], this.outputShape = t67.inShape;
    let d55 = t67.filterHeight, e36 = t67.filterWidth, r56 = t67.strideHeight, o80 = t67.strideWidth, i88 = t67.dataFormat === "channelsLast", s84 = d55 - 1 - t67.padInfo.top, y43 = e36 - 1 - t67.padInfo.left, l80 = i88 ? 1 : 2, C28 = i88 ? 2 : 3, w45 = i88 ? 3 : 1;
    this.userCode = `
      const ivec2 pads = ivec2(${s84}, ${y43});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[${w45}];

        ivec2 dyCorner = ivec2(coords[${l80}], coords[${C28}]) - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${d55}; wR++) {
          float dyR = float(dyRCorner + wR) / ${r56}.0;

          if (dyR < 0.0 || dyR >= ${t67.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${d55} - 1 - wR;

          for (int wC = 0; wC < ${e36}; wC++) {
            float dyC = float(dyCCorner + wC) / ${o80}.0;

            if (dyC < 0.0 || dyC >= ${t67.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${e36} - 1 - wC;

            for (int d2 = 0; d2 < ${t67.outChannels}; d2++) {

              if (${i88}) {
                float xValue = getDy(batch, idyR, idyC, d2);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              } else {
                float xValue = getDy(batch, d2, idyR, idyC);
                float wValue = getW(wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }

            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var n42 = class {
  constructor(t67) {
    this.variableNames = ["x", "dy"], this.outputShape = t67.filterShape;
    let d55 = t67.strideDepth, e36 = t67.strideHeight, r56 = t67.strideWidth, o80 = t67.padInfo.front, i88 = t67.padInfo.top, s84 = t67.padInfo.left;
    this.userCode = `
      void main() {
        ivec5 coords = getOutputCoords();
        int wF = coords.x;
        int wR = coords.y;
        int wC = coords.z;
        int d1 = coords.w;
        int d2 = coords.u;

        float dotProd = 0.0;

        for (int b = 0; b < ${t67.batchSize}; b++) {
          for (int yF = 0; yF < ${t67.outDepth}; yF++) {
            int xF = wF + yF * ${d55} - ${o80};

            if (xF < 0 || xF >= ${t67.inDepth}) {
              continue;
            }

            for (int yR = 0; yR < ${t67.outHeight}; yR++) {
              int xR = wR + yR * ${e36} - ${i88};

              if (xR < 0 || xR >= ${t67.inHeight}) {
                continue;
              }

              for (int yC = 0; yC < ${t67.outWidth}; yC++) {
                int xC = wC + yC * ${r56} - ${s84};

                if (xC < 0 || xC >= ${t67.inWidth}) {
                  continue;
                }

                float dyValue = getDy(b, yF, yR, yC, d2);
                float xValue = getX(b, xF, xR, xC, d1);
                dotProd += (xValue * dyValue);
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var p77 = class {
  constructor(t67) {
    this.variableNames = ["dy", "W"], this.outputShape = t67.inShape;
    let d55 = t67.filterDepth, e36 = t67.filterHeight, r56 = t67.filterWidth, o80 = t67.strideDepth, i88 = t67.strideHeight, s84 = t67.strideWidth, y43 = d55 - 1 - t67.padInfo.front, l80 = e36 - 1 - t67.padInfo.top, C28 = r56 - 1 - t67.padInfo.left;
    this.userCode = `
      const ivec3 pads = ivec3(${y43}, ${l80}, ${C28});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.u;


        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyFCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        float dotProd = 0.0;
        for (int wF = 0; wF < ${d55}; wF++) {
          float dyF = float(dyFCorner + wF) / ${o80}.0;

          if (dyF < 0.0 || dyF >= ${t67.outDepth}.0 || fract(dyF) > 0.0) {
            continue;
          }
          int idyF = int(dyF);

          int wFPerm = ${d55} - 1 - wF;

          for (int wR = 0; wR < ${e36}; wR++) {
            float dyR = float(dyRCorner + wR) / ${i88}.0;

            if (dyR < 0.0 || dyR >= ${t67.outHeight}.0 ||
              fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            int wRPerm = ${e36} - 1 - wR;

            for (int wC = 0; wC < ${r56}; wC++) {
              float dyC = float(dyCCorner + wC) / ${s84}.0;

              if (dyC < 0.0 || dyC >= ${t67.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              int wCPerm = ${r56} - 1 - wC;

              for (int d2 = 0; d2 < ${t67.outChannels}; d2++) {
                float xValue = getDy(batch, idyF, idyR, idyC, d2);
                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);
                dotProd += xValue * wValue;
              }
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Conv2DBackpropFilter.mjs
function D28(r56) {
  let { inputs: t67, backend: e36, attrs: a71 } = r56, { x: o80, dy: c103 } = t67, { strides: p103, pad: i88, dataFormat: m96, dimRoundingMode: s84, filterShape: d55 } = a71, l80 = backend_util_exports.convertConv2DDataFormat(m96), f85 = backend_util_exports.computeConv2DInfo(o80.shape, d55, p103, 1, i88, s84, false, l80), k63 = new h62(f85);
  return e36.runWebGLProgram(k63, [o80, c103], "float32");
}
var b42 = { kernelName: G2, backendName: "webgl", kernelFunc: D28 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/conv_backprop_packed_gpu.mjs
var y34 = class {
  constructor(e36) {
    this.variableNames = ["dy", "W"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "strides", type: "vec2" }], this.outputShape = e36.inShape, this.enableShapeUniforms = F23(this.outputShape.length);
    let d55 = e36.filterHeight, t67 = e36.filterWidth, a71 = d55 - 1 - e36.padInfo.top, i88 = t67 - 1 - e36.padInfo.left;
    this.userCode = `
      const ivec2 pads = ivec2(${a71}, ${i88});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[3];

        ivec2 dyCorner = ivec2(coords[1], coords[2]) - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        vec4 result = vec4(0.);
        for (int wR = 0; wR < ${d55}; wR++) {
          float dyR = float(dyRCorner + wR) / strides[0];
          if (dyR < 0.0 || dyR >= ${e36.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);
          int wRPerm = ${d55} - 1 - wR;

          for (int wC = 0; wC < ${t67}; wC++) {
            int wCPerm = ${t67} - 1 - wC;

            float dyC = float(dyCCorner + wC) / strides[1];
            bool idyCVal = (dyC >= 0.0) && (dyC < ${e36.outWidth}.0)
              && (fract(dyC) == 0.0);
            int idyC = int(dyC);

            float dyC2 = float(dyCCorner + wC + 1) / strides[1];
            bool idyCVal2 = (dyC2 >= 0.0) && (dyC2 < ${e36.outWidth}.0)
              && (fract(dyC2) == 0.0);
            int idyC2 = int(dyC2);

            if (idyCVal && idyCVal2) {
              for (int d2 = 0; d2 < ${e36.outChannels}; d2 += 2) {
                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);
                vec4 dySample = getDy(batch, idyR, idyC, d2);
                vec4 dySample2 = (idyC / 2 == idyC2 / 2) ?
                  dySample : getDy(batch, idyR, idyC2, d2);

                vec2 dyValue = mod(float(idyC), 2.) == 0. ?
                  dySample.xy : dySample.zw;
                result.xy += vec2(dot(dyValue, wValue.xy),
                  dot(dyValue, wValue.zw));

                dyValue = mod(float(idyC2), 2.) == 0. ?
                  dySample2.xy : dySample2.zw;
                result.zw += vec2(dot(dyValue, wValue.xy),
                  dot(dyValue, wValue.zw));
              }
            } else if (idyCVal) {
              for (int d2 = 0; d2 < ${e36.outChannels}; d2 += 2) {
                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);
                vec4 dySample = getDy(batch, idyR, idyC, d2);
                vec2 dyValue = mod(float(idyC), 2.) == 0. ?
                  dySample.xy : dySample.zw;
                result.xy += vec2(dot(dyValue, wValue.xy),
                  dot(dyValue, wValue.zw));
              }
            } else if (idyCVal2) {
              for (int d2 = 0; d2 < ${e36.outChannels}; d2 += 2) {
                vec4 wValue = getW(wRPerm, wCPerm, d1, d2);
                vec4 dySample = getDy(batch, idyR, idyC2, d2);
                vec2 dyValue = mod(float(idyC2), 2.) == 0. ?
                  dySample.xy : dySample.zw;
                result.zw += vec2(dot(dyValue, wValue.xy),
                  dot(dyValue, wValue.zw));
              }
            }
          }
        }
        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Conv2DBackpropInput.mjs
function I34(p103) {
  let { inputs: s84, backend: r56, attrs: m96 } = p103, { dy: e36, filter: n67 } = s84, { inputShape: u86, strides: i88, pad: d55, dataFormat: f85, dimRoundingMode: l80 } = m96, a71 = backend_util_exports.convertConv2DDataFormat(f85), o80 = backend_util_exports.computeConv2DInfo(u86, n67.shape, i88, 1, d55, l80, false, a71);
  if (l().getBool("WEBGL_PACK_CONV2DTRANSPOSE") && a71 === "channelsLast") {
    let t67 = [[o80.strideHeight, o80.strideWidth]], g72 = new y34(o80);
    return r56.runWebGLProgram(g72, [e36, n67], "float32", t67);
  } else {
    let t67 = new u70(o80);
    return r56.runWebGLProgram(t67, [e36, n67], "float32");
  }
}
var B25 = { kernelName: E2, backendName: "webgl", kernelFunc: I34 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Conv3D.mjs
function d39(t67) {
  let { inputs: e36, backend: r56, attrs: c103 } = t67, { x: n67, filter: o80 } = e36, { strides: a71, pad: s84, dilations: i88 } = c103, m96 = backend_util_exports.computeConv3DInfo(n67.shape, o80.shape, a71, i88, s84), p103 = new p76(m96);
  return r56.runWebGLProgram(p103, [n67, o80], "float32");
}
var g56 = { kernelName: f3, backendName: "webgl", kernelFunc: d39 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Conv3DBackpropFilterV2.mjs
function u71(r56) {
  let { inputs: n67, backend: e36, attrs: t67 } = r56, { x: o80, dy: c103 } = n67, { strides: a71, pad: p103, filterShape: i88 } = t67, s84 = backend_util_exports.computeConv3DInfo(o80.shape, i88, a71, 1, p103), l80 = new n42(s84);
  return e36.runWebGLProgram(l80, [o80, c103], "float32");
}
var D29 = { kernelName: I2, backendName: "webgl", kernelFunc: u71 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Conv3DBackpropInputV2.mjs
function d40(o80) {
  let { inputs: t67, backend: r56, attrs: e36 } = o80, { dy: p103, filter: n67 } = t67, { pad: c103, strides: a71, inputShape: u86 } = e36, s84 = backend_util_exports.computeConv3DInfo(u86, n67.shape, a71, 1, c103), m96 = new p77(s84);
  return r56.runWebGLProgram(m96, [p103, n67], "float32");
}
var D30 = { kernelName: q2, backendName: "webgl", kernelFunc: d40 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Cos.mjs
var t45 = q18 + `
  return cos(x);
`;
var c79 = `
  vec4 result = cos(x);
  bvec4 isNaN = isnan(x);
  ${x56}
  return result;
`;
var s54 = v32({ opSnippet: t45, packedOpSnippet: c79 });
var i60 = { kernelName: w2, backendName: "webgl", kernelFunc: s54 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Cosh.mjs
var n43 = `
  float e2x = exp(-x);
  return (e2x + 1.0 / e2x) / 2.0;
`;
var r30 = v32({ opSnippet: n43 });
var p78 = { kernelName: V2, backendName: "webgl", kernelFunc: r30 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/crop_and_resize_gpu.mjs
var s55 = class {
  constructor(n67, l80, u86, f85, a71) {
    this.variableNames = ["Image", "Boxes", "BoxInd"], this.outputShape = [];
    let [h74, c103, r56, d55] = n67, [g72] = l80, [t67, o80] = u86;
    this.outputShape = [g72, t67, o80, d55];
    let x76 = f85 === "bilinear" ? 1 : 0, [e36, i88] = [`${c103 - 1}.0`, `${r56 - 1}.0`], [C28, R26, b58] = t67 > 1 ? [`${(c103 - 1) / (t67 - 1)}`, "(y2-y1) * height_ratio", `y1*${e36} + float(y)*(height_scale)`] : ["0.0", "0.0", `0.5 * (y1+y2) * ${e36}`], [p103, m96, $37] = o80 > 1 ? [`${(r56 - 1) / (o80 - 1)}`, "(x2-x1) * width_ratio", `x1*${i88} + float(x)*(width_scale)`] : ["0.0", "0.0", `0.5 * (x1+x2) * ${i88}`];
    this.userCode = `
      const float height_ratio = float(${C28});
      const float width_ratio = float(${p103});
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int y = coords[1];
        int x = coords[2];
        int d = coords[3];

        // get box vals
        float y1 = getBoxes(b,0);
        float x1 = getBoxes(b,1);
        float y2 = getBoxes(b,2);
        float x2 = getBoxes(b,3);

        // get image in batch index
        int bInd = round(getBoxInd(b));
        if(bInd < 0 || bInd >= ${h74}) {
          return;
        }

        float height_scale = ${R26};
        float width_scale = ${m96};

        float in_y = ${b58};
        if( in_y < 0.0 || in_y > ${e36} ) {
          setOutput(float(${a71}));
          return;
        }
        float in_x = ${$37};
        if( in_x < 0.0 || in_x > ${i88} ) {
          setOutput(float(${a71}));
          return;
        }

        vec2 sourceFracIndexCR = vec2(in_x,in_y);
        if(${x76} == 1) {
          // Compute the four integer indices.
          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);
          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));

          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);
          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);
          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);
          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);

          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);

          float top = topLeft + (topRight - topLeft) * fracCR.x;
          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;
          float newValue = top + (bottom - top) * fracCR.y;
          setOutput(newValue);
        } else {
          // Compute the coordinators of nearest neighbor point.
          ivec2 sourceNearestCR = ivec2(floor(
            sourceFracIndexCR + vec2(0.5,0.5)));
          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);
          setOutput(newValue);
        }
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/CropAndResize.mjs
var g57 = (r56) => {
  let { inputs: n67, backend: t67, attrs: a71 } = r56, { image: e36, boxes: o80, boxInd: s84 } = n67, { cropSize: p103, method: c103, extrapolationValue: i88 } = a71, m96 = new s55(e36.shape, o80.shape, p103, c103, i88);
  return t67.runWebGLProgram(m96, [e36, o80, s84], "float32");
};
var x59 = { kernelName: z2, backendName: "webgl", kernelFunc: g57 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/cum_gpu.mjs
var p79;
(function(o80) {
  o80.Prod = "*", o80.Sum = "+";
})(p79 || (p79 = {}));
var $32 = class {
  constructor(t67, i88, u86, s84) {
    this.op = t67, this.outputShape = i88, this.variableNames = ["x"], this.customUniforms = [{ name: "index", type: "float" }];
    let e36 = this.outputShape.length, f85 = this.op === p79.Prod ? "1.0" : "0.0", c103 = u86 ? f85 : `getX(${l56(e36, "coords", this.op)})`, d55 = this.outputShape[this.outputShape.length - 1], r56 = "", n67 = "";
    u86 ? (r56 = s84 ? `end != ${d55 - 1}` : "end != 0", n67 = s84 ? "end + 1" : "end - 1") : (r56 = s84 ? `end + pow2 < ${d55}` : "end >= pow2", n67 = s84 ? "end + pow2" : "end - pow2"), this.userCode = `
      void main() {
        ${F22(e36)} coords = getOutputCoords();
        int end = ${h63(e36, "coords", this.op)};
        float val = ${c103};
        int pow2 = int(pow(2.0, index));
        if (${r56}) {
          int idx = ${n67};
          ${h63(e36, "coords", this.op)} = idx;
          val ${this.op}= getX(${l56(e36, "coords", this.op)});
        }
        setOutput(val);
      }
    `;
  }
};
function l56(o80, t67, i88) {
  if (o80 === 1) return `${t67}`;
  if (o80 === 2) return `${t67}.x, ${t67}.y`;
  if (o80 === 3) return `${t67}.x, ${t67}.y, ${t67}.z`;
  if (o80 === 4) return `${t67}.x, ${t67}.y, ${t67}.z, ${t67}.w`;
  throw new Error(`Cumulative ${i88} for rank ${o80} is not yet supported`);
}
function h63(o80, t67, i88) {
  if (o80 === 1) return `${t67}`;
  if (o80 === 2) return `${t67}.y`;
  if (o80 === 3) return `${t67}.z`;
  if (o80 === 4) return `${t67}.w`;
  throw new Error(`Cumulative ${i88} for rank ${o80} is not yet supported`);
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Cum_impl.mjs
function y35(u86, n67, e36, a71, l80, f85) {
  let p103 = n67.shape.length, i88 = backend_util_exports.getAxesPermutation([a71], p103), s84 = n67;
  i88 != null && (s84 = h59({ inputs: { x: n67 }, backend: e36, attrs: { perm: i88 } }));
  let g72 = backend_util_exports.getInnerMostAxes(1, p103)[0];
  if (g72 !== p103 - 1) throw new Error(`WebGL cumprod shader expects an inner-most axis=${n67.shape.length - 1} but got axis=${a71}`);
  let I44 = s84.shape[g72], t67 = i52({ inputs: { x: s84 }, backend: e36 });
  for (let r56 = 0; r56 <= Math.ceil(Math.log2(I44)) - 1; r56++) {
    let o80 = new $32(u86, s84.shape, false, f85), c103 = [[r56]], x76 = t67;
    t67 = e36.runWebGLProgram(o80, [t67], t67.dtype, c103), e36.disposeIntermediateTensorInfo(x76);
  }
  if (l80) {
    let r56 = new $32(u86, s84.shape, l80, f85), o80 = t67;
    t67 = e36.runWebGLProgram(r56, [t67], t67.dtype), e36.disposeIntermediateTensorInfo(o80);
  }
  if (i88 != null) {
    let r56 = backend_util_exports.getUndoAxesPermutation(i88), o80 = h59({ inputs: { x: t67 }, backend: e36, attrs: { perm: r56 } });
    return e36.disposeIntermediateTensorInfo(t67), e36.disposeIntermediateTensorInfo(s84), o80;
  }
  return t67;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Cumprod.mjs
function a52(r56) {
  let { inputs: e36, backend: o80, attrs: m96 } = r56, { x: n67 } = e36, { axis: t67, exclusive: c103, reverse: p103 } = m96;
  return y35(p79.Prod, n67, o80, t67, c103, p103);
}
var x60 = { kernelName: y3, backendName: "webgl", kernelFunc: a52 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Cumsum.mjs
function a53(e36) {
  let { inputs: m96, backend: r56, attrs: n67 } = e36, { x: o80 } = m96, { axis: t67, exclusive: u86, reverse: c103 } = n67;
  return y35(p79.Sum, o80, r56, t67, u86, c103);
}
var k43 = { kernelName: b2, backendName: "webgl", kernelFunc: a53 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/DenseBincount.mjs
function h64(c103) {
  let { inputs: u86, backend: n67, attrs: i88 } = c103, { x: t67, weights: e36 } = u86, { size: s84, binaryOutput: p103 } = i88;
  if (t67.shape.length === 1) {
    let r56 = n67.readSync(t67.dataId), a71 = n67.readSync(e36.dataId), o80 = m72(r56, a71, e36.dtype, e36.shape, s84);
    return n67.makeTensorInfo([s84], e36.dtype, o80);
  } else if (t67.shape.length === 2) {
    let r56 = n67.bufferSync(t67), a71 = n67.bufferSync(e36), o80 = I29(r56, a71, s84, p103);
    return n67.makeTensorInfo(o80.shape, e36.dtype, o80.values);
  }
  throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${t67.shape.length}.`);
}
var g58 = { kernelName: U2, backendName: "webgl", kernelFunc: h64 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/depth_to_space_gpu.mjs
var i61 = class {
  constructor(e36, t67, r56) {
    this.variableNames = ["x"], this.outputShape = [], this.outputShape = e36, this.blockSize = t67, this.dataFormat = r56, this.userCode = `
    void main() {
      ivec4 coords = getOutputCoords();
      int b = coords[0];
      int h = ${this.getHeightCoordString()};
      int w = ${this.getWidthCoordString()};
      int d = ${this.getDepthCoordString()};

      int in_h = h / ${t67};
      int offset_h = imod(h, ${t67});
      int in_w = w / ${t67};
      int offset_w = imod(w, ${t67});
      int offset_d = (offset_h * ${t67} + offset_w) *
        ${this.getOutputDepthSize()};
      int in_d = d + offset_d;

      float result = ${this.getInputSamplingString()};
      setOutput(result);
    }
  `;
  }
  getHeightCoordString() {
    return this.dataFormat === "NHWC" ? "coords[1]" : "coords[2]";
  }
  getWidthCoordString() {
    return this.dataFormat === "NHWC" ? "coords[2]" : "coords[3]";
  }
  getDepthCoordString() {
    return this.dataFormat === "NHWC" ? "coords[3]" : "coords[1]";
  }
  getOutputDepthSize() {
    return this.dataFormat === "NHWC" ? this.outputShape[3] : this.outputShape[1];
  }
  getInputSamplingString() {
    return this.dataFormat === "NHWC" ? "getX(b, in_h, in_w, in_d)" : "getX(b, in_d, in_h, in_w)";
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/DepthToSpace.mjs
function H13(s84) {
  let { inputs: h74, backend: r56, attrs: u86 } = s84, { x: t67 } = h74, { blockSize: e36, dataFormat: o80 } = u86, p103 = t67.shape[0], i88 = o80 === "NHWC" ? t67.shape[1] : t67.shape[2], m96 = o80 === "NHWC" ? t67.shape[2] : t67.shape[3], d55 = o80 === "NHWC" ? t67.shape[3] : t67.shape[1], n67 = i88 * e36, a71 = m96 * e36, c103 = d55 / (e36 * e36), g72 = o80 === "NHWC" ? [p103, n67, a71, c103] : [p103, c103, n67, a71], S45 = new i61(g72, e36, o80);
  return r56.runWebGLProgram(S45, [t67], t67.dtype);
}
var C18 = { kernelName: O2, backendName: "webgl", kernelFunc: H13 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/conv_gpu_depthwise.mjs
var n44 = class {
  constructor(t67, o80 = false, e36 = null, a71 = false, s84 = false) {
    this.variableNames = ["x", "W"], this.customUniforms = [{ name: "pads", type: "ivec2" }, { name: "strides", type: "ivec2" }, { name: "dilations", type: "ivec2" }, { name: "inDims", type: "ivec2" }], this.outputShape = t67.outShape, this.enableShapeUniforms = F23(this.outputShape.length);
    let d55 = t67.filterHeight, u86 = t67.filterWidth, l80 = t67.outChannels / t67.inChannels, i88 = "", r56 = "";
    e36 && (a71 ? i88 = `float activation(float a) {
          float b = getPreluActivationWeightsAtOutCoords();
          ${e36}
        }` : s84 ? i88 = `float activation(float a) {
          float b = getLeakyreluAlphaAtOutCoords();
          ${e36}
        }` : i88 = `
          float activation(float x) {
            ${e36}
          }
        `, r56 = "result = activation(result);");
    let h74 = o80 ? "result += getBiasAtOutCoords();" : "";
    o80 && this.variableNames.push("bias"), a71 && this.variableNames.push("preluActivationWeights"), s84 && this.variableNames.push("leakyreluAlpha"), this.userCode = `
      ${i88}

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${l80};
        int q = d2 - d1 * ${l80};

        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.
        for (int wR = 0; wR < ${d55}; wR++) {
          int xR = xRCorner + wR * dilations[0];

          if (xR < 0 || xR >= inDims[0]) {
            continue;
          }

          for (int wC = 0; wC < ${u86}; wC++) {
            int xC = xCCorner + wC * dilations[1];

            if (xC < 0 || xC >= inDims[1]) {
              continue;
            }

            float xVal = getX(batch, xR, xC, d1);
            float wVal = getW(wR, wC, d1, q);
            dotProd += xVal * wVal;
          }
        }

        float result = dotProd;
        ${h74}
        ${r56}
        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/conv_packed_gpu_depthwise.mjs
var T34 = class {
  constructor(s84, c103 = false, f85 = null, n67 = false, d55 = false) {
    this.variableNames = ["x", "W"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "pads", type: "ivec2" }, { name: "strides", type: "ivec2" }, { name: "dilations", type: "ivec2" }, { name: "inDims", type: "ivec2" }], this.outputShape = s84.outShape, this.enableShapeUniforms = F23(this.outputShape.length);
    let $37 = s84.outChannels / s84.inChannels, C28 = s84.padInfo.left, u86 = s84.strideWidth, l80 = s84.dilationWidth, v42 = s84.filterHeight, i88 = s84.filterWidth, m96 = i88, x76 = `
      int xR; int xC; int xCOffset;
      vec4 wTexel; vec4 previous; vec4 final;`;
    for (let t67 = 0; t67 < i88; t67++) x76 += `
          vec4 xTexelC${t67 * 2};
          int xTexelC${t67 * 2}Ready;
          vec4 xTexelC${t67 * 2 + 1};
          int xTexelC${t67 * 2 + 1}Ready;
          vec4 xC${t67};`;
    x76 += `
    for (int r = 0; r < ${v42}; r++) {
      `;
    for (let t67 = 0; t67 < i88; t67++) x76 += `
          xTexelC${t67 * 2} = vec4(0.0);
          xTexelC${t67 * 2}Ready = 0;
          xTexelC${t67 * 2 + 1} = vec4(0.0);
          xTexelC${t67 * 2 + 1}Ready = 0;
          xC${t67} = vec4(0.0);`;
    x76 += `
        xR = xRCorner + r * dilations[0];
        if (xR >=0 && xR < inDims[0]) {
      `;
    for (let t67 = 0; t67 < (m96 + 1) / 2; t67++) {
      let e36 = t67 * 2;
      if (x76 += `
          xC = xCCorner + ${e36 * l80};
          `, u86 === 1) {
        if (e36 < i88 && (C28 % 2 === 1 ? (x76 += `
                xCOffset = xC + 1;
                if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${e36}Ready == 0) {
                  xTexelC${e36} = getX(batch, xR, xCOffset, d1);

                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${e36}.zw = vec2(0.0);
                  }
                  xTexelC${e36}Ready = 1;
                }
              `, l80 === 1 && e36 > 0 ? x76 += `
                xC${e36} = vec4(xTexelC${e36 - 2}.zw, xTexelC${e36}.xy);
                ` : x76 += `
                  xCOffset = xC + 1 - 2;

                  if (xCOffset >= 0 && xCOffset < inDims[1]) {
                    previous = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= inDims[1]) {
                      previous.zw = vec2(0.0);
                    }

                    xC${e36} = vec4(previous.zw, xTexelC${e36}.xy);
                  } else {
                    xC${e36} = vec4(0.0, 0.0, xTexelC${e36}.xy);
                  }
                  `) : x76 += `
                if (xC >= 0 && xC < inDims[1] && xTexelC${e36}Ready == 0) {
                  xTexelC${e36} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= inDims[1]) {
                    xTexelC${e36}.zw = vec2(0.0);
                  }
                  xTexelC${e36}Ready = 1;
                }

                xC${e36} = xTexelC${e36};
                `, e36 + 1 < i88)) {
          let r56 = C28 % 2 === 0 ? util_exports.nearestLargerEven(l80) : l80;
          l80 % 2 === 0 && C28 % 2 === 1 || l80 % 2 !== 0 && C28 % 2 !== 1 ? (x76 += `
                  xCOffset = xC + imod(pads[1], 2) + ${r56};

                  if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${e36 + 1}Ready == 0) {
                    xTexelC${e36 + 1} = getX(batch, xR, xCOffset, d1);

                    // Need to manually clear unused channels in case
                    // we're reading from recycled texture.
                    if (xCOffset + 1 >= inDims[1]) {
                      xTexelC${e36 + 1}.zw = vec2(0.0);
                    }
                    xTexelC${e36 + 1}Ready = 1;
                  }
                  `, l80 > 1 ? x76 += `
                    xCOffset -= 2;
                    if (xCOffset >= 0 && xCOffset < inDims[1]) {
                     previous = getX(batch, xR, xCOffset, d1);
                     xC${e36 + 1} = vec4(previous.zw, xTexelC${e36 + 1}.xy);
                    } else {
                     xC${e36 + 1} = vec4(0.0, 0.0, xTexelC${e36 + 1}.xy);
                    }
                    ` : x76 += `
                    xC${e36 + 1} = vec4(xTexelC${e36}.zw, xTexelC${e36 + 1}.xy);
                    `) : r56 === 1 ? x76 += `
                    xC${e36 + 1} = xTexelC${e36};
                    ` : x76 += `
                    xCOffset = xC + ${r56};

                    if (xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${e36 + 1}Ready == 0) {
                      xTexelC${e36 + 1} = getX(batch, xR, xCOffset, d1);
                      if (xCOffset + 1 >= inDims[1]) {
                        xTexelC${e36 + 1}.zw = vec2(0.0);
                      }
                      xTexelC${e36 + 1}Ready = 1;
                    }

                    xC${e36 + 1} = xTexelC${e36 + 1};
                    `;
        }
      } else e36 < i88 && (C28 % 2 === 1 ? (x76 += `
                xCOffset = xC + 1 - strides[1];
                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${e36}Ready == 0) {
                  xTexelC${e36} = getX(batch, xR, xCOffset, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${e36}.zw = vec2(0.0);
                  }
                  xTexelC${e36}Ready = 1;
                }

                if(xC + 1 >= 0 && xC + 1 < inDims[1] && xTexelC${e36 + 1}Ready == 0) {
                  xTexelC${e36 + 1} = getX(batch, xR, xC + 1, d1);
                  // Need to manually clear unused channels in case
                  // we're reading from recycled texture.
                  if (xC + 2 >= inDims[1]) {
                    xTexelC${e36 + 1}.zw = vec2(0.0);
                  }
                  xTexelC${e36 + 1}Ready = 1;
                }

                xC${e36} = vec4(xTexelC${e36}.zw, xTexelC${e36 + 1}.zw);
              `, e36 + 1 < i88 && (x76 += `
                  final = vec4(0.0);
                  xCOffset = xC + 1 + strides[1];
                  if(xCOffset >= 0 && xCOffset < inDims[1]) {
                    final = getX(batch, xR, xCOffset, d1);
                  }
                  xC${e36 + 1} = vec4(xTexelC${e36 + 1}.xy, final.xy);
                `)) : (x76 += `
                if(xC >= 0 && xC < inDims[1] && xTexelC${e36}Ready == 0) {
                  xTexelC${e36} = getX(batch, xR, xC, d1);
                  if (xC + 1 >= inDims[1]) {
                    xTexelC${e36}.zw = vec2(0.0);
                  }
                  xTexelC${e36}Ready = 1;
                }

                xCOffset = xC + strides[1];
                if(xCOffset >= 0 && xCOffset < inDims[1] && xTexelC${e36 + 1}Ready == 0) {
                  xTexelC${e36 + 1} = getX(batch, xR, xCOffset, d1);
                  if (xCOffset + 1 >= inDims[1]) {
                    xTexelC${e36 + 1}.zw = vec2(0.);
                  }
                  xTexelC${e36 + 1}Ready = 1;
                }

                xC${e36} = vec4(
                  xTexelC${e36}.xy, xTexelC${e36 + 1}.xy);
              `, e36 + 1 < i88 && (x76 += `
                  xC${e36 + 1} = vec4(xTexelC${e36}.zw, xTexelC${e36 + 1}.zw);
                `)));
      e36 < i88 && (x76 += `
            wTexel = getW(r, ${e36}, d1, q);
            dotProd += xC${e36} * vec4(wTexel.xz, wTexel.xz);
          `, e36 + 1 < i88 && (x76 += `
              wTexel = getW(r, ${e36 + 1}, d1, q);
              dotProd += xC${e36 + 1} * vec4(wTexel.xz, wTexel.xz);
            `));
    }
    x76 += `
    }
  `, x76 += `
      }
    `;
    let a71 = "", o80 = "";
    f85 && (n67 ? a71 = `vec4 activation(vec4 a) {
          vec4 b = getPreluActivationWeightsAtOutCoords();
          ${f85}
        }` : d55 ? a71 = `vec4 activation(vec4 a) {
          vec4 b = getLeakyreluAlphaAtOutCoords();
          ${f85}
        }` : a71 = `vec4 activation(vec4 x) {
          ${f85}
        }`, o80 = "result = activation(result);");
    let h74 = c103 ? "result += getBiasAtOutCoords();" : "";
    c103 && this.variableNames.push("bias"), n67 && this.variableNames.push("preluActivationWeights"), d55 && this.variableNames.push("leakyreluAlpha"), this.userCode = `
      ${a71}

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        ivec2 xRCCorner = coords.yz * strides - pads;
        int d2 = coords.w;
        int d1 = d2 / ${$37};
        int q = d2 - d1 * ${$37};
        int xRCorner = xRCCorner.x;
        int xCCorner = xRCCorner.y;

        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.
        vec4 dotProd = vec4(0.000000000000001);

        ${x76}

        vec4 result = dotProd - vec4(0.000000000000001);
        ${h74}
        ${o80}
        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/DepthwiseConv2dNative.mjs
function D31(d55) {
  let { inputs: a71, backend: l80, attrs: p103 } = d55, { x: o80, filter: r56 } = a71, { strides: i88, pad: h74, dilations: m96, dimRoundingMode: c103 } = p103, t67 = m96;
  t67 == null && (t67 = [1, 1]), util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(i88, t67), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${i88} and dilations '${t67}'`);
  let e36 = backend_util_exports.computeConv2DInfo(o80.shape, r56.shape, i88, t67, h74, c103, true), n67;
  l().getBool("WEBGL_PACK_DEPTHWISECONV") && e36.strideWidth <= 2 && e36.outChannels / e36.inChannels === 1 ? n67 = new T34(e36) : n67 = new n44(e36);
  let u86 = [[e36.padInfo.top, e36.padInfo.left], [e36.strideHeight, e36.strideWidth], [e36.dilationHeight, e36.dilationWidth], [e36.inHeight, e36.inWidth]];
  return l80.runWebGLProgram(n67, [o80, r56], "float32", u86);
}
var N45 = { kernelName: H2, backendName: "webgl", kernelFunc: D31 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/conv_backprop_gpu_depthwise.mjs
var a54 = class {
  constructor(t67) {
    this.variableNames = ["x", "dy"], this.outputShape = t67.filterShape;
    let d55 = t67.strideHeight, i88 = t67.strideWidth, e36 = t67.padInfo.top, r56 = t67.padInfo.left, o80 = t67.outChannels / t67.inChannels;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int wR = coords.x;
        int wC = coords.y;
        int d1 = coords.z;
        int dm = coords.w;
        int d2 = d1 * ${o80} + dm;

        float dotProd = 0.0;

        // TO DO: Vec4 over the batch size
        for (int b = 0; b < ${t67.batchSize}; b++) {
          for (int yR = 0; yR < ${t67.outHeight}; yR++) {
            int xR = wR + yR * ${d55} - ${e36};

            if (xR < 0 || xR >= ${t67.inHeight}) {
              continue;
            }

            for (int yC = 0; yC < ${t67.outWidth}; yC++) {
              int xC = wC + yC * ${i88} - ${r56};

              if (xC < 0 || xC >= ${t67.inWidth}) {
                continue;
              }

              float dyValue = getDy(b, yR, yC, d2);
              float xValue = getX(b, xR, xC, d1);
              dotProd += (xValue * dyValue);
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var y36 = class {
  constructor(t67) {
    this.variableNames = ["dy", "W"], this.outputShape = t67.inShape;
    let d55 = t67.filterHeight, i88 = t67.filterWidth, e36 = t67.strideHeight, r56 = t67.strideWidth, o80 = d55 - 1 - t67.padInfo.top, h74 = i88 - 1 - t67.padInfo.left, s84 = t67.outChannels / t67.inChannels;
    this.userCode = `
      const ivec2 pads = ivec2(${o80}, ${h74});

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords[0];
        int d1 = coords[3];
        ivec2 dyCorner = coords.yz - pads;
        int dyRCorner = dyCorner.x;
        int dyCCorner = dyCorner.y;

        float dotProd = 0.0;

        for (int wR = 0; wR < ${d55}; wR++) {
          float dyR = float(dyRCorner + wR) / ${e36}.0;

          if (dyR < 0.0 || dyR >= ${t67.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          int wRPerm = ${d55} - 1 - wR;

          for (int wC = 0; wC < ${i88}; wC++) {
            float dyC = float(dyCCorner + wC) / ${r56}.0;

            if (dyC < 0.0 || dyC >= ${t67.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            int wCPerm = ${i88} - 1 - wC;

            // TO DO: Vec4 over the channelMul
            for (int dm = 0; dm < ${s84}; dm++) {
              int d2 = d1 * ${s84} + dm;
              float xValue = getDy(batch, idyR, idyC, d2);
              float wValue = getW(wRPerm, wCPerm, d1, dm);
              dotProd += xValue * wValue;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/DepthwiseConv2dNativeBackpropFilter.mjs
function k44(o80) {
  let { inputs: t67, backend: n67, attrs: r56 } = o80, { x: e36, dy: i88 } = t67, { strides: a71, dilations: p103, pad: c103, dimRoundingMode: s84, filterShape: d55 } = r56, l80 = backend_util_exports.computeConv2DInfo(e36.shape, d55, a71, p103, c103, s84, true), m96 = new a54(l80);
  return n67.runWebGLProgram(m96, [e36, i88], "float32");
}
var w34 = { kernelName: W2, backendName: "webgl", kernelFunc: k44 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/DepthwiseConv2dNativeBackpropInput.mjs
function l57(e36) {
  let { inputs: t67, backend: o80, attrs: p103 } = e36, { dy: r56, filter: n67 } = t67, { strides: a71, dilations: i88, pad: c103, dimRoundingMode: s84, inputShape: d55 } = p103, u86 = backend_util_exports.computeConv2DInfo(d55, n67.shape, a71, i88, c103, s84, true), m96 = new y36(u86);
  return o80.runWebGLProgram(m96, [r56, n67], "float32");
}
var w35 = { kernelName: K2, backendName: "webgl", kernelFunc: l57 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/diag_gpu.mjs
var t46 = class {
  constructor(o80) {
    this.variableNames = ["X"], this.outputShape = [o80, o80], this.userCode = `
      void main() {
          ivec2 coords = getOutputCoords();
          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;
          setOutput(val);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Diag.mjs
function f71(a71) {
  let { inputs: p103, backend: e36 } = a71, { x: t67 } = p103, i88 = [...t67.shape, ...t67.shape], n67 = util_exports.sizeFromShape(t67.shape), o80 = f68({ inputs: { x: t67 }, backend: e36, attrs: { shape: [n67] } }), m96 = new t46(n67), r56 = e36.runWebGLProgram(m96, [o80], o80.dtype), c103 = f68({ inputs: { x: r56 }, backend: e36, attrs: { shape: i88 } });
  return e36.disposeIntermediateTensorInfo(o80), e36.disposeIntermediateTensorInfo(r56), c103;
}
var b43 = { kernelName: X2, backendName: "webgl", kernelFunc: f71 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/dilation_gpu.mjs
var i62 = class {
  constructor(t67) {
    this.variableNames = ["x", "W"], this.outputShape = t67.outShape;
    let { inHeight: e36, inWidth: o80, padInfo: n67, strideHeight: a71, strideWidth: s84, filterHeight: r56, filterWidth: h74, dilationHeight: d55, dilationWidth: l80 } = t67, { top: c103, left: f85 } = n67;
    this.userCode = `
      const ivec2 strides = ivec2(${a71}, ${s84});
      const ivec2 pads = ivec2(${c103}, ${f85});
      const float neg_infinity = -3.4e38;

      void main() {
        ivec4 coords = getOutputCoords();
        int batch = coords.x;
        int d1 = coords.w;
        ivec2 outTopLeftCorner =
            coords.yz * strides - pads;
        int hBeg = outTopLeftCorner.x;
        int wBeg = outTopLeftCorner.y;

        float curVal = neg_infinity;
        for (int h = 0; h < ${r56}; h++) {
          int hIn = hBeg + h * ${d55};

          if (hIn >= 0 && hIn < ${e36}) {
            for (int w = 0; w < ${h74}; w++) {
              int wIn = wBeg + w * ${l80};

              if (wIn >= 0 && wIn < ${o80}) {
                float xVal = getX(batch, hIn, wIn, d1);
                float wVal = getW(h, w, d1);

                float val = xVal + wVal;
                if (val > curVal) {
                  curVal = val;
                }
              }
            }
          }
        }

        float result = curVal;
        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Dilation2D.mjs
function b44(a71) {
  let { inputs: i88, backend: o80, attrs: s84 } = a71, { x: n67, filter: e36 } = i88, { strides: p103, pad: c103, dilations: l80 } = s84, r56 = backend_util_exports.computeDilation2DInfo(n67.shape, e36.shape, p103, c103, "NHWC", l80), t67, m96 = new i62(r56);
  t67 = o80.runWebGLProgram(m96, [n67, e36], "float32");
  let d55 = f68({ inputs: { x: t67 }, backend: o80, attrs: { shape: r56.outShape } });
  return o80.disposeIntermediateTensorInfo(t67), d55;
}
var I35 = { kernelName: Z2, backendName: "webgl", kernelFunc: b44 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Einsum.mjs
function N46(x76) {
  let { inputs: D42, backend: n67, attrs: E44 } = x76, { equation: b58 } = E44, m96 = D42, { allDims: r56, summedDims: I44, idDims: u86 } = backend_util_exports.decodeEinsumEquation(b58, m96.length);
  backend_util_exports.checkEinsumDimSizes(r56.length, u86, m96);
  let { path: f85, steps: h74 } = backend_util_exports.getEinsumComputePath(I44, u86), d55 = h74.length, t67 = null, p103 = r56.length, i88 = [];
  for (let s84 = 0; s84 < d55; ++s84) {
    for (let a71 of h74[s84]) {
      let { permutationIndices: g72, expandDims: k63 } = backend_util_exports.getEinsumPermutation(p103, u86[a71]), e36;
      backend_util_exports.isIdentityPermutation(g72) ? e36 = m96[a71] : (e36 = h59({ inputs: { x: m96[a71] }, backend: n67, attrs: { perm: g72 } }), i88.push(e36));
      let l80 = e36.shape.slice();
      for (let c103 = 0; c103 < k63.length; ++c103) l80.splice(k63[c103], 0, 1);
      util_exports.arraysEqual(e36.shape, l80) || (e36 = f68({ inputs: { x: e36 }, backend: n67, attrs: { shape: l80 } }), i88.push(e36)), t67 === null ? t67 = e36 : (t67 = D23({ inputs: { a: e36, b: t67 }, backend: n67 }), i88.push(t67));
    }
    s84 < d55 - 1 && (f85[s84] >= 0 && (t67 = i56({ inputs: { x: t67 }, backend: n67, attrs: { axis: f85[s84] - (r56.length - p103), keepDims: false } }), i88.push(t67)), p103--);
  }
  for (let s84 of i88) s84 !== t67 && n67.disposeIntermediateTensorInfo(s84);
  return t67;
}
var j19 = { kernelName: Y2, backendName: "webgl", kernelFunc: N46 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Elu.mjs
var x61 = "return (x >= 0.0) ? x : (exp(x) - 1.0);";
var t47 = `
  vec4 result;

  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);
  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);
  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);
  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);

  return result;
`;
var n45 = v32({ opSnippet: x61, packedOpSnippet: t47 });
var l58 = { kernelName: $2, backendName: "webgl", kernelFunc: n45 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/EluGrad.mjs
var E37 = "return (b >= 0.0) ? a : a * (b + 1.0);";
var b45 = `
  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));
  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));
`;
var u72 = (a71) => {
  let { inputs: o80, backend: n67 } = a71, { dy: e36, y: r56 } = o80, t67 = l().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new u64(b45, e36.shape, r56.shape) : new t31(E37, e36.shape, r56.shape);
  return n67.runWebGLProgram(t67, [e36, r56], e36.dtype);
};
var G23 = { kernelName: oo, backendName: "webgl", kernelFunc: u72 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Equal.mjs
var r31 = `
  return vec4(equal(a, b));
`;
var p80 = "return float(a == b);";
var t48 = z26({ opSnippet: p80, packedOpSnippet: r31, dtype: "bool", cpuKernelImpl: r24 });
var m77 = { kernelName: eo, backendName: "webgl", kernelFunc: t48 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Erf.mjs
var o54 = `
  // Error function is calculated approximately with elementary function.
  // See "Handbook of Mathematical Functions with Formulas,
  // Graphs, and Mathematical Tables", Abramowitz and Stegun.
  float p = ${backend_util_exports.ERF_P};
  float a1 = ${backend_util_exports.ERF_A1};
  float a2 = ${backend_util_exports.ERF_A2};
  float a3 = ${backend_util_exports.ERF_A3};
  float a4 = ${backend_util_exports.ERF_A4};
  float a5 = ${backend_util_exports.ERF_A5};

  float sign = sign(x);
  x = abs(x);
  float t = 1.0 / (1.0 + p * x);
  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));
`;
var n46 = v32({ opSnippet: o54 });
var i63 = { kernelName: to, backendName: "webgl", kernelFunc: n46 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Exp.mjs
var s56 = q18 + `
  return exp(x);
`;
var n47 = `
  vec4 result = exp(x);
  bvec4 isNaN = isnan(x);
  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var l59 = v32({ opSnippet: s56, packedOpSnippet: n47, cpuKernelImpl: i48, dtype: "float32" });
var x62 = { kernelName: ro, backendName: "webgl", kernelFunc: l59 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ExpandDims.mjs
function u73(a71) {
  let { inputs: p103, attrs: r56, backend: o80 } = a71, { dim: e36 } = r56, { input: t67 } = p103, n67 = t67.shape.length, s84 = t67.shape.slice(), i88 = e36;
  return e36 < 0 && (util_exports.assert(-(n67 + 1) <= e36, () => `Axis must be in the interval [${-(n67 + 1)}, ${n67}]`), i88 = n67 + e36 + 1), s84.splice(i88, 0, 1), f68({ inputs: { x: t67 }, backend: o80, attrs: { shape: s84 } });
}
var x63 = { kernelName: no, backendName: "webgl", kernelFunc: u73 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Expm1.mjs
var e29 = "return exp(x) - 1.0;";
var m78 = v32({ opSnippet: e29, packedOpSnippet: e29, cpuKernelImpl: C16 });
var x64 = { kernelName: so, backendName: "webgl", kernelFunc: m78 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/fft_gpu.mjs
var l60 = class {
  constructor(t67, i88, o80) {
    this.variableNames = ["real", "imag"];
    let e36 = i88[1];
    this.outputShape = i88;
    let r56 = o80 ? `2.0 * ${Math.PI}` : `-2.0 * ${Math.PI}`, n67 = o80 ? `${e36}.0` : "1.0", a71;
    if (t67 === "real") a71 = "return real * expR - imag * expI;";
    else if (t67 === "imag") a71 = "return real * expI + imag * expR;";
    else throw new Error(`FFT component must be either "real" or "imag", got ${t67}.`);
    this.userCode = `
      const float exponentMultiplier = ${r56};

      float unaryOpComplex(float real, float expR, float imag, float expI) {
        ${a71}
      }

      float mulMatDFT(int batch, int index) {
        float indexRatio = float(index) / float(${e36});
        float exponentMultiplierTimesIndexRatio =
            exponentMultiplier * indexRatio;

        float result = 0.0;

        for (int i = 0; i < ${e36}; i++) {
          // x = (-2|2 * PI / N) * index * i;
          float x = exponentMultiplierTimesIndexRatio * float(i);
          float expR = cos(x);
          float expI = sin(x);
          float real = getReal(batch, i);
          float imag = getImag(batch, i);

          result +=
              unaryOpComplex(real, expR, imag, expI) / ${n67};
        }

        return result;
      }

      void main() {
        ivec2 coords = getOutputCoords();
        setOutput(mulMatDFT(coords[0], coords[1]));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/FFT_impl.mjs
function z28(e36, r56, t67) {
  let o80 = t67.texData.get(e36.dataId), h74 = util_exports.sizeFromShape(e36.shape), a71 = e36.shape[e36.shape.length - 1], u86 = h74 / a71, p103 = f68({ inputs: { x: e36 }, backend: t67, attrs: { shape: [u86, a71] } }), s84 = p103.shape, d55 = new l60("real", s84, r56), c103 = new l60("imag", s84, r56), n67 = [{ dataId: o80.complexTensorInfos.real.dataId, dtype: o80.complexTensorInfos.real.dtype, shape: s84 }, { dataId: o80.complexTensorInfos.imag.dataId, dtype: o80.complexTensorInfos.imag.dtype, shape: s84 }], m96 = t67.runWebGLProgram(d55, n67, "float32"), i88 = t67.runWebGLProgram(c103, n67, "float32"), l80 = i53({ inputs: { real: m96, imag: i88 }, backend: t67 });
  t67.disposeIntermediateTensorInfo(m96), t67.disposeIntermediateTensorInfo(i88);
  let g72 = f68({ inputs: { x: l80 }, backend: t67, attrs: { shape: e36.shape } });
  return t67.disposeIntermediateTensorInfo(p103), t67.disposeIntermediateTensorInfo(l80), g72;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/FFT.mjs
function c80(n67) {
  let { inputs: t67, backend: e36 } = n67, { input: f85 } = t67;
  return z28(f85, false, e36);
}
var i64 = { kernelName: po, backendName: "webgl", kernelFunc: c80 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/fill_gpu.mjs
var t49 = class {
  constructor(e36, a71) {
    this.outputShape = [], this.customUniforms = [{ name: "value", type: "float" }], this.variableNames = ["x"], this.outputShape = e36, this.userCode = `
      void main() {
        // Input can be obtained from uniform value.
        setOutput(value);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Fill.mjs
function f72(s84) {
  let { backend: l80, attrs: a71 } = s84, { shape: o80, value: r56 } = a71, { dtype: e36 } = a71;
  if (e36 = e36 || util_exports.inferDtype(r56), e36 === "string") {
    let n67 = util_exports.getArrayFromDType(e36, util_exports.sizeFromShape(o80));
    return n67.fill(r56), l80.makeTensorInfo(o80, e36, n67);
  } else {
    let n67 = new t49(o80, r56), i88 = [[r56]];
    return l80.runWebGLProgram(n67, [], e36, i88);
  }
}
var g59 = { kernelName: co, backendName: "webgl", kernelFunc: f72 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/flip_left_right_gpu.mjs
var s57 = class {
  constructor(o80) {
    this.variableNames = ["Image"], this.outputShape = [];
    let t67 = o80[2];
    this.outputShape = o80, this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];

          int coordX = ${t67} - x - 1;
          float outputValue;
          if(coordX >= 0 && coordX < ${t67}) {
            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);
          } else {
            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);
          }
          setOutput(outputValue);
        }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/FlipLeftRight.mjs
var c81 = { kernelName: ao, backendName: "webgl", kernelFunc: ({ inputs: t67, backend: o80 }) => {
  let { image: e36 } = t67, r56 = o80, n67 = new s57(e36.shape);
  return r56.runWebGLProgram(n67, [e36], e36.dtype);
} };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Floor.mjs
var o55 = "return floor(x);";
var p81 = v32({ opSnippet: o55, packedOpSnippet: o55, cpuKernelImpl: P21 });
var c82 = { kernelName: xo, backendName: "webgl", kernelFunc: p81 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/FloorDiv.mjs
var e30 = `
  float s = sign(a) * sign(b);
  int ia = round(a);
  int ib = round(b);
  if (ib != 0) {
    // Windows (D3D) wants guaranteed non-zero int division at compile-time.
    return float(idiv(ia, ib, s));
  } else {
    return NAN;
  }
`;
var o56 = `
  ivec4 ia = round(a);
  ivec4 ib = round(b);
  bvec4 cond = notEqual(ib, ivec4(0));
  ivec4 result = ivec4(0);
  vec4 s = sign(a) * sign(b);

  // Windows (D3D) wants guaranteed non-zero int division at compile-time.
  if (cond[0]) {
    result[0] = idiv(ia[0], ib[0], s[0]);
  }
  if (cond[1]) {
    result[1] = idiv(ia[1], ib[1], s[1]);
  }
  if (cond[2]) {
    result[2] = idiv(ia[2], ib[2], s[2]);
  }
  if (cond[3]) {
    result[3] = idiv(ia[3], ib[3], s[3]);
  }
  return vec4(result);
`;
var t50 = z26({ opSnippet: e30, packedOpSnippet: o56, dtype: "int32" });
var a55 = { kernelName: io, backendName: "webgl", kernelFunc: t50 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/FromPixels_utils/from_pixels_gpu.mjs
var t51 = class {
  constructor(e36) {
    this.variableNames = ["A"];
    let s84 = c71(), [l80, o80] = e36;
    this.outputShape = e36, this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];
        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${o80}.0, ${l80}.0);

        vec4 values = ${s84.texture2D}(A, uv);
        float value;
        if (depth == 0) {
          value = values.r;
        } else if (depth == 1) {
          value = values.g;
        } else if (depth == 2) {
          value = values.b;
        } else if (depth == 3) {
          value = values.a;
        }

        setOutput(floor(value * 255.0 + 0.5));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/FromPixels_utils/from_pixels_packed_gpu.mjs
var o57 = class {
  constructor(e36) {
    this.variableNames = ["A"], this.packedInputs = false, this.packedOutput = true;
    let t67 = c71(), [s84, l80] = e36;
    this.outputShape = e36, this.userCode = `
      void main() {
        ivec3 coords = getOutputCoords();
        int texR = coords[0];
        int texC = coords[1];
        int depth = coords[2];

        vec4 result = vec4(0.);

        for(int row=0; row<=1; row++) {
          for(int col=0; col<=1; col++) {
            texC = coords[1] + row;
            depth = coords[2] + col;

            vec2 uv = (vec2(texC, texR) + halfCR) /
                       vec2(${l80}.0, ${s84}.0);
            vec4 values = ${t67.texture2D}(A, uv);
            float value;
            if (depth == 0) {
              value = values.r;
            } else if (depth == 1) {
              value = values.g;
            } else if (depth == 2) {
              value = values.b;
            } else if (depth == 3) {
              value = values.a;
            }

            result[row * 2 + col] = floor(value * 255.0 + 0.5);
          }
        }

        ${t67.output} = result;
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/FromPixels.mjs
var A28 = { kernelName: Se, backendName: "webgl", kernelFunc: _21 };
var o58;
var r32 = l().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
function _21(c103) {
  let { inputs: g72, backend: t67, attrs: f85 } = c103, { pixels: e36 } = g72, { numChannels: u86 } = f85, m96 = typeof HTMLVideoElement < "u" && e36 instanceof HTMLVideoElement, p103 = typeof HTMLImageElement < "u" && e36 instanceof HTMLImageElement, [n67, a71] = m96 ? [e36.videoWidth, e36.videoHeight] : [e36.width, e36.height], x76 = [a71, n67], l80 = [a71, n67, u86];
  if (p103 || m96) {
    let d55 = l().getBool("CANVAS2D_WILL_READ_FREQUENTLY_FOR_GPU");
    (o58 == null || d55 !== r32) && (r32 = d55, o58 = document.createElement("canvas").getContext("2d", { willReadFrequently: r32 })), o58.canvas.width = n67, o58.canvas.height = a71, o58.drawImage(e36, 0, 0, n67, a71), e36 = o58.canvas;
  }
  let i88 = t67.makeTensorInfo(x76, "int32");
  t67.texData.get(i88.dataId).usage = R19.PIXELS, t67.gpgpu.uploadPixelDataToTexture(t67.getTexture(i88.dataId), e36);
  let P36 = l().getBool("WEBGL_PACK") ? new o57(l80) : new t51(l80), h74 = t67.runWebGLProgram(P36, [i88], "int32");
  return t67.disposeData(i88.dataId), h74;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/FusedConv2D.mjs
function S35(P36) {
  let { inputs: b58, backend: n67, attrs: y43 } = P36, { x: r56, filter: l80, bias: p103, preluActivationWeights: d55 } = b58, { strides: H18, pad: B30, dataFormat: c103, dilations: F32, dimRoundingMode: x76, activation: a71, leakyreluAlpha: h74 } = y43, W15 = backend_util_exports.convertConv2DDataFormat(c103), t67 = backend_util_exports.computeConv2DInfo(r56.shape, l80.shape, H18, F32, B30, x76, false, W15), s84, u86 = [], f85 = p103 != null, m96 = d55 != null, g72 = a71 === "leakyrelu", I44 = () => {
    let o80 = [r56, l80], i88 = (e36, v42) => {
      if (v42 === "NCHW" && e36.shape.length === 1 && e36.shape[0] !== 1) {
        let C28 = f68({ inputs: { x: e36 }, backend: n67, attrs: { shape: [e36.shape[0], 1, 1] } });
        return u86.push(C28), C28;
      }
      return e36;
    };
    if (f85 && o80.push(i88(p103, c103)), m96 && o80.push(i88(d55, c103)), g72) {
      let e36 = n67.makeTensorInfo([], "float32", util_exports.createScalarValue(h74, "float32"));
      o80.push(e36), u86.push(e36);
    }
    return o80;
  };
  if (t67.filterHeight === 1 && t67.filterWidth === 1 && t67.dilationHeight === 1 && t67.dilationWidth === 1 && t67.strideHeight === 1 && t67.strideWidth === 1 && (t67.padInfo.type === "SAME" || t67.padInfo.type === "VALID")) s84 = I33({ x: r56, filter: l80, convInfo: t67, backend: n67, bias: p103, activation: a71, preluActivationWeights: d55, leakyreluAlpha: h74 });
  else if (t67.strideWidth <= 2 && W15 === "channelsLast" && l().getBool("WEBGL_EXP_CONV")) {
    let o80 = a71 ? J12(a71, true) : null, i88 = new o52(t67, f85, o80, m96, g72), e36 = [[t67.padInfo.top, t67.padInfo.left], [t67.strideHeight, t67.strideWidth], [t67.dilationHeight, t67.dilationWidth], [t67.inHeight, t67.inWidth]], v42 = I44();
    s84 = n67.runWebGLProgram(i88, v42, "float32", e36);
  } else if (l().getBool("WEBGL_CONV_IM2COL")) s84 = v33({ x: r56, filter: l80, convInfo: t67, backend: n67, bias: p103, activation: a71, preluActivationWeights: d55, leakyreluAlpha: h74 });
  else {
    let o80 = a71 ? J12(a71, false) : null, i88 = new g55(t67, f85, o80, m96, g72), e36 = I44();
    s84 = n67.runWebGLProgram(i88, e36, "float32");
  }
  let E44 = f68({ inputs: { x: s84 }, backend: n67, attrs: { shape: t67.outShape } });
  return u86.push(s84), u86.forEach((o80) => n67.disposeIntermediateTensorInfo(o80)), E44;
}
var q19 = { kernelName: me, backendName: "webgl", kernelFunc: S35 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/FusedDepthwiseConv2D.mjs
function B26(k63) {
  let { inputs: w45, backend: i88, attrs: A35 } = k63, { x: h74, filter: p103, bias: c103, preluActivationWeights: f85 } = w45, { strides: s84, pad: I44, dilations: P36, dimRoundingMode: W15, activation: a71, leakyreluAlpha: b58 } = A35, m96 = [], t67 = P36;
  t67 == null && (t67 = [1, 1]), util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(s84, t67), () => `Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${s84} and dilations '${t67}'`);
  let e36 = backend_util_exports.computeConv2DInfo(h74.shape, p103.shape, s84, t67, I44, W15, true), g72 = l().getBool("WEBGL_PACK_DEPTHWISECONV") && e36.strideWidth <= 2 && e36.outChannels / e36.inChannels === 1, v42 = a71 ? J12(a71, g72) : null, o80 = [h74, p103], r56 = c103 != null, l80 = f85 != null, d55 = a71 === "leakyrelu";
  if (r56 && o80.push(c103), l80 && o80.push(f85), d55) {
    let n67 = i88.makeTensorInfo([], "float32", util_exports.createScalarValue(b58, "float32"));
    o80.push(n67), m96.push(n67);
  }
  let u86;
  g72 ? u86 = new T34(e36, r56, v42, l80, d55) : u86 = new n44(e36, r56, v42, l80, d55);
  let E44 = [[e36.padInfo.top, e36.padInfo.left], [e36.strideHeight, e36.strideWidth], [e36.dilationHeight, e36.dilationWidth], [e36.inHeight, e36.inWidth]], y43 = i88.runWebGLProgram(u86, o80, "float32", E44);
  return m96.forEach((n67) => i88.disposeIntermediateTensorInfo(n67)), y43;
}
var V16 = { kernelName: Re, backendName: "webgl", kernelFunc: B26 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/gather_nd_gpu.mjs
var e31 = class {
  constructor(i88, d55, o80, n67) {
    this.sliceDim = i88, this.strides = d55, this.paramsShape = n67, this.variableNames = ["x", "indices"], this.outputShape = o80;
    let u86 = F22(o80.length), s84 = `
    int index;`;
    for (let t67 = 0; t67 < this.sliceDim; t67++) s84 += `
          index = round(getIndices(coords[0], ${t67}));
          out_of_bounds = out_of_bounds || index < 0;
          out_of_bounds = out_of_bounds || index >= ${this.paramsShape[t67]};
          flattenIndex += index * ${this.strides[t67]};`;
    this.userCode = `
         void main() {
          ${u86} coords = getOutputCoords();
          int flattenIndex = 0;
          bool out_of_bounds = false;

          ${s84}

          setOutput(out_of_bounds ? 0.0 : getX(flattenIndex, coords[1]));
        }
      `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/GatherNd.mjs
function T35(l80) {
  let { inputs: f85, backend: e36 } = l80, { params: t67, indices: s84 } = f85, i88 = s84.shape, a71 = i88[i88.length - 1], g72 = util_exports.sizeFromShape(t67.shape), [c103, r56, n67, d55] = backend_util_exports.prepareAndValidate(t67, s84), m96 = f68({ inputs: { x: s84 }, backend: e36, attrs: { shape: [r56, a71] } }), o80 = f68({ inputs: { x: t67 }, backend: e36, attrs: { shape: [util_exports.sizeFromShape(t67.shape) / n67, n67] } });
  if (e36.shouldExecuteOnCPU([t67, s84]) || t67.dtype === "string") {
    let k63 = e36.readSync(s84.dataId), N58 = e36.bufferSync(t67), b58 = U15(k63, N58, t67.dtype, r56, a71, n67, d55, t67.shape, g72);
    return e36.makeTensorInfo(c103, t67.dtype, b58.values);
  }
  let I44 = new e31(a71, d55, [r56, n67], t67.shape), h74 = e36.runWebGLProgram(I44, [o80, m96], o80.dtype), S45 = f68({ inputs: { x: h74 }, backend: e36, attrs: { shape: c103 } });
  return e36.disposeIntermediateTensorInfo(m96), e36.disposeIntermediateTensorInfo(o80), e36.disposeIntermediateTensorInfo(h74), S45;
}
var D32 = { kernelName: So, backendName: "webgl", kernelFunc: T35 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/gather_gpu.mjs
var r33 = class {
  constructor(o80, t67) {
    this.variableNames = ["A", "indices"], this.outputShape = t67, this.rank = t67.length;
    let e36 = F22(this.rank), s84 = d41(o80, 2);
    this.userCode = `
      void main() {
        ${e36} resRC = getOutputCoords();
        int index = int(getIndices(resRC.x, resRC.z));
        float inBounds = (index >= 0) && (index < ${o80[2]}) ? 1.0 : 0.0;
        setOutput(inBounds * getA(${s84}));
      }
    `;
  }
};
function d41(n67, o80) {
  let t67 = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"], e36 = [];
  for (let s84 = 0; s84 < n67.length; s84++) s84 === 2 ? e36.push("index") : e36.push(`${t67[s84]}`);
  return e36.join();
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/GatherV2.mjs
function E38(x76) {
  let { inputs: b58, backend: t67, attrs: g72 } = x76, { x: s84, indices: o80 } = b58, { axis: z32, batchDims: I44 } = g72, d55 = util_exports.parseAxisParam(z32, s84.shape)[0];
  if (l().get("DEBUG")) {
    let n67 = t67.readSync(o80.dataId), p103 = s84.shape[d55];
    for (let a71 = 0; a71 < n67.length; ++a71) {
      let c103 = n67[a71];
      util_exports.assert(c103 <= p103 - 1 && c103 >= 0, () => `GatherV2: the index value ${c103} is not in [0, ${p103 - 1}]`);
    }
  }
  let e36 = backend_util_exports.segment_util.collectGatherOpShapeInfo(s84, o80, d55, I44), m96 = util_exports.sizeFromShape(o80.shape), r56 = [], i88 = f68({ inputs: { x: s84 }, backend: t67, attrs: { shape: [e36.batchSize, e36.outerSize, e36.dimSize, e36.sliceSize] } }), h74 = f68({ inputs: { x: o80 }, backend: t67, attrs: { shape: [e36.batchSize, m96 / e36.batchSize] } });
  r56.push(i88), r56.push(h74);
  let l80 = [e36.batchSize, e36.outerSize, m96 / e36.batchSize, e36.sliceSize];
  if (t67.shouldExecuteOnCPU([s84, o80]) || s84.dtype === "string") {
    let n67 = t67.bufferSync(h74), p103 = t67.bufferSync(i88), a71 = n34(p103, n67, l80);
    return r56.forEach((c103) => t67.disposeIntermediateTensorInfo(c103)), t67.makeTensorInfo(e36.outputShape, a71.dtype, a71.values);
  }
  let k63 = new r33(i88.shape, l80), S45 = t67.runWebGLProgram(k63, [i88, h74], i88.dtype);
  r56.push(S45);
  let y43 = f68({ inputs: { x: S45 }, backend: t67, attrs: { shape: e36.outputShape } });
  return r56.forEach((n67) => t67.disposeIntermediateTensorInfo(n67)), y43;
}
var U17 = { kernelName: uo, backendName: "webgl", kernelFunc: E38 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Greater.mjs
var n48 = "return float(a > b);";
var o59 = `
  return vec4(greaterThan(a, b));
`;
var p82 = z26({ opSnippet: n48, packedOpSnippet: o59, cpuKernelImpl: g51, dtype: "bool" });
var l61 = { kernelName: go, backendName: "webgl", kernelFunc: p82 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/GreaterEqual.mjs
var a56 = "return float(a >= b);";
var n49 = `
  return vec4(greaterThanEqual(a, b));
`;
var o60 = z26({ opSnippet: a56, packedOpSnippet: n49, dtype: "bool", cpuKernelImpl: o42 });
var c83 = { kernelName: Do, backendName: "webgl", kernelFunc: o60 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/IFFT.mjs
function i65(t67) {
  let { inputs: n67, backend: e36 } = t67, { input: o80 } = n67;
  return z28(o80, true, e36);
}
var p83 = { kernelName: Ro, backendName: "webgl", kernelFunc: i65 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/IsFinite.mjs
var i66 = "return float(!isnan(x) && !isinf(x));";
var o61 = v32({ opSnippet: i66, dtype: "bool" });
var p84 = { kernelName: Mo, backendName: "webgl", kernelFunc: o61 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/IsInf.mjs
var o62 = "return float(isinf(x));";
var r34 = v32({ opSnippet: o62, dtype: "bool" });
var i67 = { kernelName: Ao, backendName: "webgl", kernelFunc: r34 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/IsNaN.mjs
var o63 = "return float(isnan(x));";
var r35 = v32({ opSnippet: o63, dtype: "bool" });
var N47 = { kernelName: Bo, backendName: "webgl", kernelFunc: r35 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Less.mjs
var r36 = "return float(a < b);";
var p85 = `
  return vec4(lessThan(a, b));
`;
var t52 = z26({ opSnippet: r36, packedOpSnippet: p85, cpuKernelImpl: c72, dtype: "bool" });
var m79 = { kernelName: Co, backendName: "webgl", kernelFunc: t52 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/LessEqual.mjs
var l62 = "return float(a <= b);";
var n50 = `
  return vec4(lessThanEqual(a, b));
`;
var p86 = z26({ opSnippet: l62, packedOpSnippet: n50, cpuKernelImpl: u61, dtype: "bool" });
var c84 = { kernelName: vo, backendName: "webgl", kernelFunc: p86 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/LinSpace.mjs
function m80(e36) {
  let { backend: t67, attrs: o80 } = e36, { start: a71, stop: r56, num: c103 } = o80, n67 = d30(a71, r56, c103);
  return t67.makeTensorInfo([n67.length], "float32", n67);
}
var f73 = { kernelName: Fo, backendName: "webgl", kernelFunc: m80 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Log.mjs
var o64 = q18 + `
  return x < 0.0 ? 0./0. : log(x);
`;
var s58 = `
  vec4 result = log(x);
  bvec4 isNaN = isnan(x);
  result.r = isNaN.r ? x.r : (x.r < 0.0 ? 0./0. : result.r);
  result.g = isNaN.g ? x.g : (x.g < 0.0 ? 0./0. : result.g);
  result.b = isNaN.b ? x.b : (x.b < 0.0 ? 0./0. : result.b);
  result.a = isNaN.a ? x.a : (x.a < 0.0 ? 0./0. : result.a);
  return result;
`;
var n51 = v32({ opSnippet: o64, packedOpSnippet: s58, cpuKernelImpl: q17 });
var p87 = { kernelName: Po, backendName: "webgl", kernelFunc: n51 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Log1p.mjs
var r37 = q18 + `
  return log(1.0 + x);
`;
var p88 = v32({ opSnippet: r37 });
var c85 = { kernelName: To, backendName: "webgl", kernelFunc: p88 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/LogicalAnd.mjs
var o65 = "return float(a >= 1.0 && b >= 1.0);";
var r38 = `
  return vec4(
    vec4(greaterThanEqual(a, vec4(1.0))) *
    vec4(greaterThanEqual(b, vec4(1.0))));
`;
var a57 = z26({ opSnippet: o65, packedOpSnippet: r38, dtype: "bool" });
var l63 = { kernelName: Lo, backendName: "webgl", kernelFunc: a57 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/LogicalNot.mjs
var n52 = "return float(!(x >= 1.0));";
var t53 = v32({ opSnippet: n52 });
var c86 = { kernelName: ko, backendName: "webgl", kernelFunc: t53 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/LogicalOr.mjs
var n53 = "return float(a >= 1.0 || b >= 1.0);";
var o66 = `
  return min(
    vec4(greaterThanEqual(a, vec4(1.0))) +
    vec4(greaterThanEqual(b, vec4(1.0))),
    vec4(1.0));
`;
var a58 = z26({ opSnippet: n53, packedOpSnippet: o66, dtype: "bool" });
var l64 = { kernelName: Go, backendName: "webgl", kernelFunc: a58 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/lrn_gpu.mjs
var r39 = class {
  constructor(i88, a71, d55, c103, o80) {
    this.variableNames = ["x"], this.outputShape = [];
    let e36 = a71, l80 = i88[3] - 1;
    this.outputShape = i88;
    let t67, s84 = `float(${d55}) + float(${c103}) * sum`;
    o80 === 0.5 ? t67 = `inversesqrt(${s84})` : o80 === 1 ? t67 = `1.0/(${s84})` : t67 = `exp(log(${s84}) * float(-${o80}));`, this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];
        int d = coords[3];
        float x = getX(b, r, c, d);
        float sum = 0.0;
        for (int j = -${e36}; j <= ${e36}; j++) {
          int idx = d + j;
          if (idx >= 0 && idx <=  ${l80}) {
            float z = getX(b, r, c, idx);
            sum += z * z;
          }
        }
        float val = x * ${t67};
        setOutput(val);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/lrn_packed_gpu.mjs
var r40 = class {
  constructor(a71, s84, c103, u86, t67) {
    this.variableNames = ["x"], this.outputShape = [], this.packedInputs = true, this.packedOutput = true;
    let o80 = s84, h74 = a71[3] - 1;
    this.outputShape = a71;
    let e36, n67 = `float(${c103}) + float(${u86}) * sum`;
    t67 === 0.5 ? e36 = `inversesqrt(${n67})` : t67 === 1 ? e36 = `1.0/(${n67})` : e36 = `exp(log(${n67}) * float(-${t67}));`, this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords.x;
        int r = coords.y;
        int c = coords.z;
        int d = coords.w;

        bool hasNextCol = d < ${this.outputShape[3]};
        bool hasNextRow = c < ${this.outputShape[2]};

        vec4 sum = vec4(0.);
        vec4 xFragAtOutputCoords = getX(b, r, c, d);

        vec4 xAtOutputCoords = vec4(
          getChannel(xFragAtOutputCoords, vec2(c, d)),
          hasNextCol ?
            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,
          hasNextRow ?
            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,
          (hasNextRow && hasNextCol) ?
            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0
        );

        int firstChannel = d - ${o80};
        vec2 cache = vec2(0.);
        if(firstChannel >= 0){
          vec4 firstChannelFrag = getX(b, r, c, firstChannel);
          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));
            if(hasNextRow){
              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));
            }
        }

        ivec2 depth = ivec2(d, d + 1);
        for (int j = - ${o80}; j <= ${o80}; j++) {
          ivec2 idx = depth + j;
          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));
          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${h74}));

          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;
          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;

          if(depthInRange || depthPlusOneInRange){
            vec4 z = vec4(0.);
            vec4 xFragAtCurrentDepth;
            z.xz = cache.xy;
            if(depthPlusOneInRange && hasNextCol){
              xFragAtCurrentDepth = idx.y != d ?
                getX(b, r, c, idx.y) : xFragAtOutputCoords;
              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));
              if(hasNextRow){
                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));
              }
            }
            cache.xy = z.yw;
            sum += z * z;
          }
        }
        vec4 result = xAtOutputCoords * ${e36};
        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/LRN.mjs
var b46 = (a71) => {
  let { inputs: m96, backend: p103, attrs: s84 } = a71, { x: e36 } = m96, { depthRadius: r56, bias: o80, alpha: n67, beta: t67 } = s84, c103 = l().getBool("WEBGL_PACK_NORMALIZATION") ? new r40(e36.shape, r56, o80, n67, t67) : new r39(e36.shape, r56, o80, n67, t67);
  return p103.runWebGLProgram(c103, [e36], e36.dtype);
};
var k45 = { kernelName: qo, backendName: "webgl", kernelFunc: b46 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/lrn_grad_gpu.mjs
var d42 = class {
  constructor(o80, t67, n67, e36, i88) {
    this.variableNames = ["inputImage", "outputImage", "dy"], this.outputShape = [], this.outputShape = o80, this.depth = o80[3], this.depthRadius = t67, this.bias = n67, this.alpha = e36, this.beta = i88, this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int r = coords[1];
        int c = coords[2];

        float result = 0.0;
        for (int d = 0; d < ${this.depth}; ++d) {
          int depthBegin = int(max(0.0, float(d - ${t67})));
          int depthEnd = int(min(float(${this.depth}),
              float(d + ${t67} + 1)));

          const int MIN_DEPTH_BEGIN = 0;
          const int MAX_DEPTH_END = ${this.depth};

          float norm = 0.0;
          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd) {
              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);
            }
            else {
              break;
            }
          }

          norm = float(${e36}) * norm + float(${n67});

          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){
            if (k < depthBegin){
              continue;
            }
            else if (k >= depthBegin && k < depthEnd){
              float dyi = -2.0 * float(${e36})
                * float(${i88})
                * getInputImage(b, r, c, k) * getOutputImage(b, r, c, d)
                / norm;
              if (k == d) {
                dyi += pow(norm, -1.0 * ${i88});
              }
              if (k == coords[3]) {
                dyi *= getDy(b, r, c, d);
                result += dyi;
              }
            }
            else {
              break;
            }
          }
      }
      setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/LRNGrad.mjs
var l65 = (a71) => {
  let { inputs: e36, backend: n67, attrs: t67 } = a71, { x: r56, y: o80, dy: s84 } = e36, { depthRadius: d55, bias: p103, alpha: c103, beta: m96 } = t67, b58 = new d42(r56.shape, d55, p103, c103, m96);
  return n67.runWebGLProgram(b58, [r56, o80, s84], r56.dtype);
};
var N48 = { kernelName: wo, backendName: "webgl", kernelFunc: l65 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Max_impl.mjs
function I36(t67, n67, m96, e36) {
  let s84 = util_exports.sizeFromShape(n67), a71 = util_exports.sizeFromShape(t67.shape) / s84, o80 = f68({ inputs: { x: t67 }, attrs: { shape: [a71, s84] }, backend: e36 }), r56 = w32(o80, t67.dtype, "max", e36), u86 = f68({ inputs: { x: r56 }, attrs: { shape: m96 }, backend: e36 });
  return e36.disposeIntermediateTensorInfo(o80), e36.disposeIntermediateTensorInfo(r56), u86;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Max.mjs
function w36(g72) {
  let { inputs: k63, backend: t67, attrs: A35 } = g72, { x: e36 } = k63, { reductionIndices: T40, keepDims: S45 } = A35, p103 = e36.shape.length, d55 = util_exports.parseAxisParam(T40, e36.shape), n67 = d55, r56 = backend_util_exports.getAxesPermutation(n67, p103), i88 = r56 != null, I44 = t67.shouldExecuteOnCPU([e36]), a71 = e36;
  if (i88) {
    if (I44) {
      let c103 = t67.texData.get(a71.dataId).values, s84 = new Array(p103);
      for (let u86 = 0; u86 < s84.length; u86++) s84[u86] = e36.shape[r56[u86]];
      let l80 = W12(c103, e36.shape, e36.dtype, r56, s84);
      a71 = t67.makeTensorInfo(s84, e36.dtype);
      let P36 = t67.texData.get(a71.dataId);
      P36.values = l80;
    } else a71 = i55(e36, r56, t67);
    n67 = backend_util_exports.getInnerMostAxes(n67.length, p103);
  }
  backend_util_exports.assertAxesAreInnerMostDims("max", n67, p103);
  let [h74, f85] = backend_util_exports.computeOutAndReduceShapes(a71.shape, n67), m96 = h74;
  S45 && (m96 = backend_util_exports.expandShapeToKeepDim(h74, d55));
  let x76;
  if (I44) {
    let c103 = t67.texData.get(a71.dataId).values, s84 = R20(c103, util_exports.sizeFromShape(f85), m96, e36.dtype);
    x76 = t67.makeTensorInfo(m96, e36.dtype);
    let l80 = t67.texData.get(x76.dataId);
    l80.values = s84;
  } else x76 = I36(a71, f85, m96, t67);
  return i88 && t67.disposeIntermediateTensorInfo(a71), x76;
}
var V17 = { kernelName: yo, backendName: "webgl", kernelFunc: w36 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Maximum.mjs
var r41 = p69 + `
  return max(a, b);
`;
var n54 = `
  vec4 result = vec4(max(a, b));
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + x56 + `
  return result;
`;
var s59 = z26({ opSnippet: r41, packedOpSnippet: n54, cpuKernelImpl: h56 });
var A29 = { kernelName: bo, backendName: "webgl", kernelFunc: s59 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/MaxPool.mjs
function h65(s84) {
  let { inputs: l80, backend: i88, attrs: m96 } = s84, { x: o80 } = l80;
  be(o80, "maxPool");
  let { filterSize: d55, strides: r56, pad: p103, dimRoundingMode: c103 } = m96, e36 = 1;
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(r56, e36), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${r56} and dilations '${e36}'`);
  let t67 = backend_util_exports.computePool2DInfo(o80.shape, d55, r56, e36, p103, c103);
  if (t67.filterWidth === 1 && t67.filterHeight === 1 && util_exports.arraysEqual(t67.inShape, t67.outShape)) return i52({ inputs: { x: o80 }, backend: i88 });
  let u86 = new M23(t67, "max", false);
  return i88.runWebGLProgram(u86, [o80], o80.dtype);
}
var D33 = { kernelName: zo, backendName: "webgl", kernelFunc: h65 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/MaxPool3D.mjs
function x65(n67) {
  let { inputs: t67, backend: e36, attrs: a71 } = n67, { x: o80 } = t67, { filterSize: r56, strides: m96, pad: c103, dataFormat: s84, dimRoundingMode: i88 } = a71, l80 = [1, 1, 1], d55 = backend_util_exports.computePool3DInfo(o80.shape, r56, m96, l80, c103, i88, s84), p103 = new b39(d55, "max", false);
  return e36.runWebGLProgram(p103, [o80], o80.dtype);
}
var k46 = { kernelName: Oo, backendName: "webgl", kernelFunc: x65 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/max_pool_backprop_gpu.mjs
var l66 = class {
  constructor(t67) {
    this.variableNames = ["dy", "maxPos"], this.outputShape = t67.inShape;
    let r56 = t67.strideHeight, s84 = t67.strideWidth, y43 = t67.dilationHeight, d55 = t67.effectiveFilterHeight, e36 = t67.effectiveFilterWidth, n67 = d55 - 1 - t67.padInfo.top, o80 = e36 - 1 - t67.padInfo.left, i88 = d55 * e36 - 1;
    this.userCode = `
      const ivec2 pads = ivec2(${n67}, ${o80});

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];

        ivec2 dyRCCorner = coords.yz - pads;
        int dyRCorner = dyRCCorner.x;
        int dyCCorner = dyRCCorner.y;

        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;
        for (int wR = 0; wR < ${d55};
          wR += ${y43}) {
          float dyR = float(dyRCorner + wR) / ${r56}.0;

          if (dyR < 0.0 || dyR >= ${t67.outHeight}.0 || fract(dyR) > 0.0) {
            continue;
          }
          int idyR = int(dyR);

          for (int wC = 0; wC < ${e36}; wC++) {
            float dyC = float(dyCCorner + wC) / ${s84}.0;

            if (dyC < 0.0 || dyC >= ${t67.outWidth}.0 ||
                fract(dyC) > 0.0) {
              continue;
            }
            int idyC = int(dyC);

            float dyValue = getDy(b, idyR, idyC, d);
            int maxPosValue = ${i88} - int(getMaxPos(b, idyR, idyC, d));

            // Get the current value, check it against the value from the
            // position matrix.
            int curPosValue = wR * ${e36} + wC;
            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

            dotProd += dyValue * mask;
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};
var h66 = class {
  constructor(t67) {
    this.variableNames = ["dy", "maxPos"], this.outputShape = t67.inShape;
    let r56 = t67.strideDepth, s84 = t67.strideHeight, y43 = t67.strideWidth, d55 = t67.dilationDepth, e36 = t67.dilationHeight, n67 = t67.dilationWidth, o80 = t67.effectiveFilterDepth, i88 = t67.effectiveFilterHeight, a71 = t67.effectiveFilterWidth, C28 = o80 - 1 - t67.padInfo.front, u86 = i88 - 1 - t67.padInfo.top, f85 = a71 - 1 - t67.padInfo.left, p103 = o80 * i88 * a71 - 1;
    this.userCode = `
      const ivec3 pads = ivec3(${C28}, ${u86}, ${f85});

      void main() {
        ivec5 coords = getOutputCoords();
        int batch = coords.x;
        int ch = coords.u;

        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;
        int dyDCorner = dyCorner.x;
        int dyRCorner = dyCorner.y;
        int dyCCorner = dyCorner.z;

        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get
        // dx(xD, xR, xC, ch).
        // ? = to be determined. : = across all values in that axis.
        float dotProd = 0.0;

        for (int wD = 0; wD < ${o80};
           wD += ${d55}) {
          float dyD = float(dyDCorner + wD) / ${r56}.0;

          if (dyD < 0.0 || dyD >= ${t67.outDepth}.0 || fract(dyD) > 0.0) {
            continue;
          }
          int idyD = int(dyD);

          for (int wR = 0; wR < ${i88};
              wR += ${e36}) {
            float dyR = float(dyRCorner + wR) / ${s84}.0;

            if (dyR < 0.0 || dyR >= ${t67.outHeight}.0 ||
                fract(dyR) > 0.0) {
              continue;
            }
            int idyR = int(dyR);

            for (int wC = 0; wC < ${a71};
                wC += ${n67}) {
              float dyC = float(dyCCorner + wC) / ${y43}.0;

              if (dyC < 0.0 || dyC >= ${t67.outWidth}.0 ||
                  fract(dyC) > 0.0) {
                continue;
              }
              int idyC = int(dyC);

              float dyValue = getDy(batch, idyD, idyR, idyC, ch);
              int maxPosValue = ${p103} -
                  int(getMaxPos(batch, idyD, idyR, idyC, ch));

              // Get the current value, check it against the value from the
              // position matrix.
              int curPosValue =
                  wD * ${i88} * ${a71} +
                  wR * ${a71} + wC;
              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);

              dotProd += dyValue * mask;
            }
          }
        }
        setOutput(dotProd);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/MaxPool3DGrad.mjs
function G24(e36) {
  let { inputs: a71, backend: n67, attrs: s84 } = e36, { dy: m96, input: i88 } = a71, o80 = i88, { filterSize: c103, strides: d55, pad: p103, dimRoundingMode: P36 } = s84, l80 = [1, 1, 1], r56 = backend_util_exports.computePool3DInfo(o80.shape, c103, d55, l80, p103, P36), u86 = new b39(r56, "max", true), t67 = n67.runWebGLProgram(u86, [o80], o80.dtype), x76 = new h66(r56), f85 = n67.runWebGLProgram(x76, [m96, t67], o80.dtype);
  return n67.disposeIntermediateTensorInfo(t67), f85;
}
var M24 = { kernelName: Ho, backendName: "webgl", kernelFunc: G24 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/MaxPoolGrad.mjs
function y37(a71) {
  let { inputs: s84, backend: r56, attrs: m96 } = a71, { dy: i88, input: t67, output: c103 } = s84, o80 = t67;
  be([t67, c103], "maxPoolGrad");
  let { filterSize: P36, strides: p103, pad: d55, dimRoundingMode: l80 } = m96, n67 = backend_util_exports.computePool2DInfo(o80.shape, P36, p103, 1, d55, l80), u86 = true, x76 = new M23(n67, "max", u86), e36 = r56.runWebGLProgram(x76, [o80], o80.dtype), f85 = new l66(n67), g72 = r56.runWebGLProgram(f85, [i88, e36], o80.dtype);
  return r56.disposeIntermediateTensorInfo(e36), g72;
}
var C19 = { kernelName: Uo, backendName: "webgl", kernelFunc: y37 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/MaxPoolWithArgmax_impl.mjs
function p89(o80, e36, t67, m96) {
  let r56 = new M23(t67, "max", false), u86 = m96.runWebGLProgram(r56, [o80], "float32");
  r56 = new M23(t67, "max", true, true, e36);
  let l80 = m96.runWebGLProgram(r56, [o80], "float32");
  return [u86, l80];
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/MaxPoolWithArgmax.mjs
var P28 = { kernelName: Wo, backendName: "webgl", kernelFunc: ({ inputs: i88, attrs: s84, backend: a71 }) => {
  let { x: t67 } = i88, { filterSize: l80, strides: o80, pad: m96, includeBatchInIndex: c103 } = s84, d55 = a71;
  util_exports.assert(t67.shape.length === 4, () => `Error in maxPool: input must be rank 4 but got rank ${t67.shape.length}.`);
  let e36 = [1, 1];
  util_exports.assert(backend_util_exports.eitherStridesOrDilationsAreOne(o80, e36), () => `Error in maxPool: Either strides or dilations must be 1. Got strides ${o80} and dilations '${e36}'`);
  let x76 = backend_util_exports.computePool2DInfo(t67.shape, l80, o80, e36, m96), [h74, p103] = p89(t67, c103, x76, d55);
  return [h74, p103];
} };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Mean_impl.mjs
function S36(t67, n67, m96, e36) {
  let s84 = util_exports.sizeFromShape(n67), a71 = util_exports.sizeFromShape(t67.shape) / s84, o80 = f68({ inputs: { x: t67 }, attrs: { shape: [a71, s84] }, backend: e36 }), r56 = w32(o80, "float32", "mean", e36), u86 = f68({ inputs: { x: r56 }, attrs: { shape: m96 }, backend: e36 });
  return e36.disposeIntermediateTensorInfo(o80), e36.disposeIntermediateTensorInfo(r56), u86;
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Mean.mjs
var N49 = { kernelName: Ko, backendName: "webgl", kernelFunc: ({ inputs: x76, attrs: h74, backend: I44 }) => {
  let { x: e36 } = x76, { keepDims: f85, axis: g72 } = h74, t67 = I44, o80 = e36.shape.length, u86 = util_exports.parseAxisParam(g72, e36.shape), s84 = u86, p103 = backend_util_exports.getAxesPermutation(s84, o80), A35 = p103 != null, k63 = t67.shouldExecuteOnCPU([e36]), c103 = [], n67 = e36;
  if (A35) {
    if (k63) {
      let T40 = t67.texData.get(n67.dataId).values, r56 = new Array(o80);
      for (let m96 = 0; m96 < r56.length; m96++) r56[m96] = e36.shape[p103[m96]];
      let P36 = W12(T40, e36.shape, e36.dtype, p103, r56);
      n67 = t67.makeTensorInfo(r56, e36.dtype);
      let b58 = t67.texData.get(n67.dataId);
      b58.values = P36;
    } else n67 = i55(e36, p103, t67);
    c103.push(n67), s84 = backend_util_exports.getInnerMostAxes(s84.length, o80);
  }
  backend_util_exports.assertAxesAreInnerMostDims("sum", s84, o80);
  let [l80, D42] = backend_util_exports.computeOutAndReduceShapes(n67.shape, s84), i88 = l80;
  f85 && (i88 = backend_util_exports.expandShapeToKeepDim(l80, u86));
  let S45 = S36(n67, D42, i88, t67);
  for (let d55 of c103) t67.disposeIntermediateTensorInfo(d55);
  return S45;
} };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Min.mjs
function M25(l80) {
  let { inputs: x76, backend: e36, attrs: f85 } = l80, { x: t67 } = x76, { axis: g72, keepDims: A35 } = f85, c103 = t67.shape.length, u86 = util_exports.parseAxisParam(g72, t67.shape), s84 = u86, o80 = backend_util_exports.getAxesPermutation(s84, c103), r56 = t67;
  o80 != null && (r56 = h59({ inputs: { x: t67 }, backend: e36, attrs: { perm: o80 } }), s84 = backend_util_exports.getInnerMostAxes(s84.length, t67.shape.length)), backend_util_exports.assertAxesAreInnerMostDims("min", s84, c103);
  let [d55, I44] = backend_util_exports.computeOutAndReduceShapes(r56.shape, s84), k63 = util_exports.sizeFromShape(I44), a71 = f68({ inputs: { x: r56 }, backend: e36, attrs: { shape: [-1, k63] } }), p103 = w32(a71, a71.dtype, "min", e36), i88;
  if (A35) {
    let S45 = backend_util_exports.expandShapeToKeepDim(d55, u86);
    i88 = f68({ inputs: { x: p103 }, backend: e36, attrs: { shape: S45 } });
  } else i88 = f68({ inputs: { x: p103 }, backend: e36, attrs: { shape: d55 } });
  return e36.disposeIntermediateTensorInfo(a71), e36.disposeIntermediateTensorInfo(p103), o80 != null && e36.disposeIntermediateTensorInfo(r56), i88;
}
var P29 = { kernelName: Xo, backendName: "webgl", kernelFunc: M25 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Minimum.mjs
var r42 = p69 + `
  return min(a, b);
`;
var a59 = `
  vec4 result = vec4(min(a, b));
  bvec4 isNaNA = isnan(a);
  bvec4 isNaNB = isnan(b);
  bvec4 isNaN = bvec4(isNaNA.x || isNaNB.x, isNaNA.y || isNaNB.y, isNaNA.z || isNaNB.z, isNaNA.w || isNaNB.w);
  ` + x56 + `
  return result;
`;
var s60 = z26({ opSnippet: r42, packedOpSnippet: a59, cpuKernelImpl: x54 });
var b47 = { kernelName: Zo, backendName: "webgl", kernelFunc: s60 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/mirror_pad_gpu.mjs
var a60 = class {
  constructor(i88, u86, c103) {
    this.variableNames = ["x"], this.outputShape = u86.map((o80, r56) => o80[0] + i88[r56] + o80[1]);
    let s84 = i88.length, t67 = F22(s84), n67 = u86.map((o80) => o80[0]).join(","), C28 = u86.map((o80, r56) => o80[0] + i88[r56]).join(","), d55 = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, s84), e36 = c103 === "reflect" ? 0 : 1;
    if (s84 === 1) {
      this.userCode = `
        int start = ${n67};
        int end = ${C28};

        void main() {
          int outC = getOutputCoords();
          if (outC < start) {
            outC = start * 2 - outC - ${e36};
          } else if(outC >= end) {
            outC = (end - 1) * 2 - outC + ${e36};
          }
          setOutput(getX(outC - start));
        }
      `;
      return;
    }
    this.userCode = `
      ${t67} start = ${t67}(${n67});
      ${t67} end = ${t67}(${C28});

      void main() {
        ${t67} outC = getOutputCoords();
        for (int i = 0; i < ${s84}; i++) {
          if (outC[i] < start[i]) {
            outC[i] = start[i] * 2 - outC[i] - ${e36};
          } else if(outC[i] >= end[i]) {
            outC[i] = (end[i] - 1) * 2 - outC[i] + ${e36};
          }
        }
        ${t67} coords = outC - start;
        setOutput(getX(${d55}));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/mirror_pad_packed_gpu.mjs
var g60 = class {
  constructor($37, n67, h74) {
    this.variableNames = ["x"], this.packedInputs = true, this.packedOutput = true, this.outputShape = n67.map((e36, l80) => e36[0] + $37[l80] + e36[1]);
    let s84 = $37.length, t67 = F22(s84), f85 = n67.map((e36) => e36[0]).join(","), m96 = n67.map((e36, l80) => e36[0] + $37[l80]).join(","), r56 = u62("rc", s84), o80 = u62("source", s84), i88 = `${r56[s84 - 1]} < ${this.outputShape[s84 - 1]}`, u86 = s84 === 1 ? "source" : `vec2(${o80.slice(-2).join()})`, c103 = h74 === "reflect" ? 0 : 1, a71 = "";
    if (s84 === 1) {
      let e36 = `
        ${t67} source = rc;
        if (source < start) {
          source = start * 2 - source - ${c103};
        } else if (source >= end) {
          source = (end - 1) * 2 - source + ${c103};
        }
        source -= start;
      `;
      a71 = `
        ${t67} rc = outputLoc;
        ${e36}
        result[0] = getChannel(getX(${o80.join()}), ${u86});
        ${r56[s84 - 1]} += 1;
        if(${i88}) {
          ${e36}
          result[1] = getChannel(getX(${o80.join()}), ${u86});
        }
      `;
    } else {
      let e36 = `
        ${t67} source = rc;
        ${t67} lt = ${t67}(lessThan(source, start));
        ${t67} gte = ${t67}(greaterThanEqual(source, end));
        ${t67} orig = 1 - (lt + gte);
        source = orig * source +
                lt * (start * 2 - source - ${c103}) +
                gte * ((end - 1) * 2 - source + ${c103});
        source -= start;
      `;
      a71 = `
        ${t67} rc = outputLoc;
        ${e36}
        result[0] = getChannel(getX(${o80.join()}), ${u86});
        ${r56[s84 - 1]} += 1;
        if(${i88}) {
          ${e36}
          result[1] = getChannel(getX(${o80.join()}), ${u86});
        }
        rc = outputLoc;
        ${r56[s84 - 2]} += 1;
        if(${r56[s84 - 2]} < ${this.outputShape[s84 - 2]}) {
          ${e36}
          result[2] = getChannel(getX(${o80.join()}), ${u86});
          ${r56[s84 - 1]} += 1;
          if(${i88}) {
            ${e36}
            result[3] = getChannel(getX(${o80.join()}), ${u86});
          }
        }
      `;
    }
    this.userCode = `
      const ${t67} start = ${t67}(${f85});
      const ${t67} end = ${t67}(${m96});

      void main() {
        ${t67} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${a71}
        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/MirrorPad.mjs
var i68 = ({ inputs: n67, backend: t67, attrs: a71 }) => {
  let { x: r56 } = n67, { paddings: o80, mode: e36 } = a71, m96 = l().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new g60(r56.shape, o80, e36) : new a60(r56.shape, o80, e36);
  return t67.runWebGLProgram(m96, [r56], r56.dtype);
};
var f74 = { kernelName: _o, backendName: "webgl", kernelFunc: i68 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Mod.mjs
var n55 = `if (b == 0.0) return NAN;
  return mod(a, b);`;
var t54 = `
  vec4 result = mod(a, b);
  bvec4 isNaN = equal(b, vec4(0.0));
  ` + x56 + `
  return result;
`;
var m81 = z26({ opSnippet: n55, packedOpSnippet: t54 });
var i69 = { kernelName: jo, backendName: "webgl", kernelFunc: m81 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/multinomial_gpu.mjs
var e32 = class {
  constructor(o80, t67, s84) {
    this.variableNames = ["probs"], this.customUniforms = [{ name: "seed", type: "float" }], this.outputShape = [o80, s84], this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];

        float r = random(seed);
        float cdf = 0.0;

        for (int i = 0; i < ${t67 - 1}; i++) {
          cdf += getProbs(batch, i);

          if (r < cdf) {
            setOutput(float(i));
            return;
          }
        }

        // If no other event happened, last event happened.
        setOutput(float(${t67 - 1}));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/RealDiv.mjs
var n56 = `
if (a == b) {
  return 1.0;
};
return a / b;`;
var t55 = `
  // vec4 one = vec4(equal(a, b));
  // return one + (vec4(1.0) - one) * a / b;
  vec4 result = a / b;
  if(a.x == b.x) {
    result.x = 1.;
  }
  if(a.y == b.y) {
    result.y = 1.;
  }
  if(a.z == b.z) {
    result.z = 1.;
  }
  if(a.w == b.w) {
    result.w = 1.;
  }

  return result;
`;
var a61 = z26({ opSnippet: n56, packedOpSnippet: t55, checkOutOfBounds: true });
var c87 = { kernelName: Q2, backendName: "webgl", kernelFunc: a61 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Sub.mjs
var e33 = "return a - b;";
var o67 = z26({ opSnippet: e33, packedOpSnippet: e33, supportsComplex: true, cpuKernelImpl: M22 });
var b48 = { kernelName: te, backendName: "webgl", kernelFunc: o67 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Softmax.mjs
function E39(x76) {
  let { inputs: c103, backend: e36, attrs: f85 } = x76, { logits: s84 } = c103, { dim: u86 } = f85, t67 = util_exports.parseAxisParam([u86], s84.shape), o80 = w36({ inputs: { x: s84 }, backend: e36, attrs: { reductionIndices: t67, keepDims: false } }), a71 = backend_util_exports.expandShapeToKeepDim(o80.shape, t67), i88 = f68({ inputs: { x: o80 }, backend: e36, attrs: { shape: a71 } }), r56 = o67({ inputs: { a: s84, b: i88 }, backend: e36 }), n67 = l59({ inputs: { x: r56 }, backend: e36 }), p103 = i56({ inputs: { x: n67 }, backend: e36, attrs: { axis: t67, keepDims: false } }), m96 = f68({ inputs: { x: p103 }, backend: e36, attrs: { shape: a71 } }), I44 = a61({ inputs: { a: n67, b: m96 }, backend: e36 });
  return e36.disposeIntermediateTensorInfo(o80), e36.disposeIntermediateTensorInfo(i88), e36.disposeIntermediateTensorInfo(r56), e36.disposeIntermediateTensorInfo(n67), e36.disposeIntermediateTensorInfo(p103), e36.disposeIntermediateTensorInfo(m96), I44;
}
var F26 = { kernelName: Ot, backendName: "webgl", kernelFunc: E39 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Multinomial.mjs
function h67(s84) {
  let { inputs: m96, backend: t67, attrs: r56 } = s84, { logits: n67 } = m96, { numSamples: i88, seed: a71, normalized: e36 } = r56, o80 = e36 ? n67 : E39({ inputs: { logits: n67 }, backend: t67, attrs: { dim: n67.shape.length - 1 } }), c103 = o80.shape[0], l80 = o80.shape[1], u86 = new e32(c103, l80, i88), p103 = [[a71]], f85 = t67.runWebGLProgram(u86, [o80], "int32", p103);
  return e36 || t67.disposeIntermediateTensorInfo(o80), f85;
}
var z29 = { kernelName: Jo, backendName: "webgl", kernelFunc: h67 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Neg.mjs
var i70 = t30 + `
  return -x;
`;
var x66 = `
  vec4 result = -x;
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
function P30(n67) {
  let { inputs: a71, backend: r56 } = n67, { x: e36 } = a71;
  if (r56.shouldExecuteOnCPU([e36])) {
    let s84 = r56.texData.get(e36.dataId), [o80, u86] = E35(s84.values, e36.shape, e36.dtype);
    return r56.makeTensorInfo(u86, e36.dtype, o80);
  }
  let t67;
  return l().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? t67 = new e22(e36.shape, x66) : t67 = new e21(e36.shape, i70), r56.runWebGLProgram(t67, [e36], e36.dtype);
}
var C20 = { kernelName: Yo, backendName: "webgl", kernelFunc: P30 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/NonMaxSuppressionV3.mjs
var m82 = kernel_impls_exports.nonMaxSuppressionV3Impl;
function k47(s84) {
  backend_util_exports.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  let { inputs: o80, backend: n67, attrs: t67 } = s84, { boxes: r56, scores: a71 } = o80, { maxOutputSize: c103, iouThreshold: p103, scoreThreshold: i88 } = t67, l80 = n67.readSync(r56.dataId), d55 = n67.readSync(a71.dataId), { selectedIndices: e36 } = m82(l80, d55, c103, p103, i88);
  return n67.makeTensorInfo([e36.length], "int32", new Int32Array(e36));
}
var b49 = { kernelName: ot, backendName: "webgl", kernelFunc: k47 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/NonMaxSuppressionV4.mjs
var k48 = kernel_impls_exports.nonMaxSuppressionV4Impl;
function M26(s84) {
  backend_util_exports.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  let { inputs: o80, backend: n67, attrs: t67 } = s84, { boxes: a71, scores: r56 } = o80, { maxOutputSize: p103, iouThreshold: c103, scoreThreshold: i88, padToMaxOutputSize: l80 } = t67, u86 = n67.readSync(a71.dataId), d55 = n67.readSync(r56.dataId), { selectedIndices: e36, validOutputs: x76 } = k48(u86, d55, p103, c103, i88, l80);
  return [n67.makeTensorInfo([e36.length], "int32", new Int32Array(e36)), n67.makeTensorInfo([], "int32", new Int32Array([x76]))];
}
var f75 = { kernelName: tt, backendName: "webgl", kernelFunc: M26 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/NonMaxSuppressionV5.mjs
var b50 = kernel_impls_exports.nonMaxSuppressionV5Impl;
function g61(o80) {
  backend_util_exports.warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  let { inputs: t67, backend: n67, attrs: a71 } = o80, { boxes: r56, scores: c103 } = t67, { maxOutputSize: l80, iouThreshold: i88, scoreThreshold: p103, softNmsSigma: d55 } = a71, u86 = n67.readSync(r56.dataId), m96 = n67.readSync(c103.dataId), S45 = l80, x76 = i88, h74 = p103, V24 = d55, { selectedIndices: e36, selectedScores: s84 } = b50(u86, m96, S45, x76, h74, V24);
  return [n67.makeTensorInfo([e36.length], "int32", new Int32Array(e36)), n67.makeTensorInfo([s84.length], "float32", new Float32Array(s84))];
}
var T36 = { kernelName: et, backendName: "webgl", kernelFunc: g61 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/onehot_gpu.mjs
var t56 = class {
  constructor(o80, s84, i88, e36) {
    this.variableNames = ["indices"], this.outputShape = [o80, s84], this.userCode = `
      void main() {
        ivec2 coords = getOutputCoords();
        int index = round(getIndices(coords.x));
        setOutput(mix(float(${e36}), float(${i88}),
                      float(index == coords.y)));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/OneHot.mjs
var x67 = (p103) => {
  let { inputs: i88, backend: e36, attrs: c103 } = p103, { indices: o80 } = i88, { dtype: m96, depth: t67, onValue: u86, offValue: d55 } = c103, n67 = util_exports.sizeFromShape(o80.shape), h74 = new t56(n67, t67, u86, d55), s84 = f68({ inputs: { x: o80 }, backend: e36, attrs: { shape: [n67] } }), r56 = e36.runWebGLProgram(h74, [s84], m96);
  e36.disposeIntermediateTensorInfo(s84);
  let f85 = [...o80.shape, t67], l80 = f68({ inputs: { x: r56 }, backend: e36, attrs: { shape: f85 } });
  return e36.disposeIntermediateTensorInfo(r56), l80;
};
var w37 = { kernelName: nt, backendName: "webgl", kernelFunc: x67 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ZerosLike.mjs
function n57(p103) {
  let { inputs: m96, backend: e36 } = p103, { x: t67 } = m96;
  if (t67.dtype === "complex64") {
    let o80 = c78({ inputs: { input: t67 }, backend: e36 }), r56 = n57({ inputs: { x: o80 }, backend: e36 }), s84 = r29({ inputs: { input: t67 }, backend: e36 }), i88 = n57({ inputs: { x: s84 }, backend: e36 }), a71 = i53({ inputs: { real: r56, imag: i88 }, backend: e36 });
    return e36.disposeIntermediateTensorInfo(o80), e36.disposeIntermediateTensorInfo(r56), e36.disposeIntermediateTensorInfo(s84), e36.disposeIntermediateTensorInfo(i88), a71;
  } else return f72({ attrs: { shape: t67.shape, dtype: t67.dtype, value: t67.dtype === "string" ? "" : 0 }, backend: e36 });
}
var T37 = { kernelName: de, backendName: "webgl", kernelFunc: n57 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/OnesLike.mjs
function i71(p103) {
  let { inputs: m96, backend: e36 } = p103, { x: t67 } = m96;
  if (t67.dtype === "string") throw new Error("onesLike is not supported under string dtype");
  if (t67.dtype === "complex64") {
    let n67 = c78({ inputs: { input: t67 }, backend: e36 }), o80 = i71({ inputs: { x: n67 }, backend: e36 }), r56 = r29({ inputs: { input: t67 }, backend: e36 }), s84 = n57({ inputs: { x: r56 }, backend: e36 }), a71 = i53({ inputs: { real: o80, imag: s84 }, backend: e36 });
    return e36.disposeIntermediateTensorInfo(n67), e36.disposeIntermediateTensorInfo(o80), e36.disposeIntermediateTensorInfo(r56), e36.disposeIntermediateTensorInfo(s84), a71;
  } else return f72({ attrs: { shape: t67.shape, dtype: t67.dtype, value: 1 }, backend: e36 });
}
var b51 = { kernelName: rt, backendName: "webgl", kernelFunc: i71 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Pack.mjs
function k49(c103) {
  let { inputs: t67, backend: e36, attrs: i88 } = c103, { axis: n67 } = i88;
  if (t67.length === 1) return u73({ inputs: { input: t67[0] }, backend: e36, attrs: { dim: n67 } });
  let d55 = t67[0].shape, m96 = t67[0].dtype;
  t67.forEach((s84) => {
    util_exports.assertShapesMatch(d55, s84.shape, "All tensors passed to stack must have matching shapes"), util_exports.assert(m96 === s84.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  let a71 = [], u86 = t67.map((s84) => {
    let o80 = u73({ inputs: { input: s84 }, backend: e36, attrs: { dim: n67 } });
    return a71.push(o80), o80;
  }), h74 = k42({ inputs: u86, backend: e36, attrs: { axis: n67 } });
  return a71.forEach((s84) => e36.disposeIntermediateTensorInfo(s84)), h74;
}
var T38 = { kernelName: st, backendName: "webgl", kernelFunc: k49 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/pad_gpu.mjs
var i72 = class {
  constructor(s84, e36, l80) {
    this.variableNames = ["x"], this.customUniforms = [{ name: "value", type: "float" }], this.outputShape = e36.map((o80, a71) => o80[0] + s84[a71] + o80[1]);
    let u86 = s84.length, t67 = F22(u86), n67 = e36.map((o80) => o80[0]).join(","), r56 = e36.map((o80, a71) => o80[0] + s84[a71]).join(","), c103 = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, u86);
    if (u86 === 1) {
      this.userCode = `
        int start = ${n67};
        int end = ${r56};

        void main() {
          int outC = getOutputCoords();
          if (outC < start || outC >= end) {
            setOutput(value);
          } else {
            setOutput(getX(outC - start));
          }
        }
      `;
      return;
    }
    this.userCode = `
      ${t67} start = ${t67}(${n67});
      ${t67} end = ${t67}(${r56});

      void main() {
        ${t67} outC = getOutputCoords();
        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {
          setOutput(value);
        } else {
          ${t67} coords = outC - start;
          setOutput(getX(${c103}));
        }
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/pad_packed_gpu.mjs
var p90 = class {
  constructor(c103, r56, j22) {
    this.variableNames = ["x"], this.packedInputs = true, this.packedOutput = true, this.customUniforms = [{ name: "value", type: "float" }], this.outputShape = r56.map((o80, n67) => o80[0] + c103[n67] + o80[1]);
    let t67 = c103.length, e36 = F22(t67), l80 = r56.map((o80) => o80[0]).join(","), m96 = r56.map((o80, n67) => o80[0] + c103[n67]).join(","), s84 = u62("rc", t67), a71 = u62("source", t67), i88 = `${s84[t67 - 1]} < ${this.outputShape[t67 - 1]}`, h74 = t67 === 1 ? "source" : `vec2(${a71.slice(-2).join()})`, f85 = [`${e36} rc = outputLoc;`, `${s84[t67 - 1]} += 1;
       if(${i88}) {
      `, t67 === 1 ? "" : `}
       rc = outputLoc;
       ${s84[t67 - 2]} += 1;
       if(${s84[t67 - 2]} < ${this.outputShape[t67 - 2]}) {`, t67 === 1 ? "" : `  ${s84[t67 - 1]} += 1;
         if(${i88}) {`], d55 = t67 === 1 ? "rc < start || rc >= end" : "any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))", u86 = "";
    for (let o80 = 0, n67 = t67 === 1 ? 2 : 4; o80 < n67; o80++) u86 += `
        ${f85[o80]}
        if (${d55}) {
          result[${o80}] = float(value);
        } else {
          ${e36} source = rc - start;
          result[${o80}] = getChannel(getX(${a71.join()}), ${h74});
        }
      `;
    u86 += t67 === 1 ? "} " : "}}", this.userCode = `
      const ${e36} start = ${e36}(${l80});
      const ${e36} end = ${e36}(${m96});

      void main() {
        ${e36} outputLoc = getOutputCoords();
        vec4 result = vec4(0.);
        ${u86}
        setOutput(result);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/PadV2.mjs
var k50 = (n67) => {
  let { inputs: p103, backend: o80, attrs: s84 } = n67, { x: e36 } = p103, { paddings: a71, constantValue: t67 } = s84;
  if (util_exports.sizeFromShape(e36.shape) === 0) {
    let d55 = a71.map((r56, u86) => r56[0] + e36.shape[u86] + r56[1]);
    return f72({ backend: o80, attrs: { shape: d55, value: t67, dtype: e36.dtype } });
  }
  let m96 = l().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new p90(e36.shape, a71, t67) : new i72(e36.shape, a71, t67), c103 = [[t67]];
  return o80.runWebGLProgram(m96, [e36], e36.dtype, c103);
};
var x68 = { kernelName: pt, backendName: "webgl", kernelFunc: k50 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Pow.mjs
var s61 = `
  if(a < 0.0 && floor(b) < b){
    return NAN;
  }
  if (b == 0.0) {
    return 1.0;
  }
  return (round(mod(b, 2.0)) != 1) ?
      pow(abs(a), b) : sign(a) * pow(abs(a), b);
`;
var i73 = `
  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.
  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));
  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);
  vec4 result = multiplier * pow(abs(a), b);

  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS
  bvec4 isExpZero = equal(b, vec4(0.0));
  result.r = isExpZero.r ? 1.0 : result.r;
  result.g = isExpZero.g ? 1.0 : result.g;
  result.b = isExpZero.b ? 1.0 : result.b;
  result.a = isExpZero.a ? 1.0 : result.a;

  bvec4 isNaN1 = lessThan(a, vec4(0.0));
  bvec4 isNaN2 = lessThan(floor(b), b);
  bvec4 isNaN = bvec4(isNaN1.x && isNaN2.x, isNaN1.y && isNaN2.y, isNaN1.z && isNaN2.z, isNaN1.w && isNaN2.w);
  ` + x56 + `
  return result;
`;
var a62 = z26({ opSnippet: s61, packedOpSnippet: i73 });
var N50 = { kernelName: at, backendName: "webgl", kernelFunc: a62 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Prod.mjs
function O19(g72) {
  let { inputs: k63, backend: e36, attrs: A35 } = g72, { x: n67 } = k63, { axis: D42, keepDims: S45 } = A35, i88 = n67.shape.length, r56 = [], h74 = util_exports.parseAxisParam(D42, n67.shape), p103 = h74, x76 = backend_util_exports.getAxesPermutation(p103, i88), t67 = n67;
  x76 != null && (t67 = h59({ inputs: { x: n67 }, backend: e36, attrs: { perm: x76 } }), p103 = backend_util_exports.getInnerMostAxes(p103.length, i88), r56.push(t67)), backend_util_exports.assertAxesAreInnerMostDims("prod", p103, i88);
  let s84;
  if (e36.shouldExecuteOnCPU([t67])) {
    let o80 = e36.texData.get(t67.dataId).values, { outVals: c103, outShape: m96, outDtype: u86 } = T30(t67.shape, t67.dtype, o80, p103);
    s84 = e36.makeTensorInfo(m96, u86, c103);
  } else {
    let [o80, c103] = backend_util_exports.computeOutAndReduceShapes(t67.shape, p103), m96 = util_exports.sizeFromShape(c103), u86 = f68({ inputs: { x: t67 }, backend: e36, attrs: { shape: [-1, m96] } }), I44 = l6(n67.dtype), l80 = w32(u86, I44, "prod", e36);
    s84 = f68({ inputs: { x: l80 }, backend: e36, attrs: { shape: o80 } }), r56.push(u86), r56.push(l80);
  }
  if (S45) {
    r56.push(s84);
    let o80 = backend_util_exports.expandShapeToKeepDim(s84.shape, h74);
    s84 = f68({ inputs: { x: s84 }, backend: e36, attrs: { shape: o80 } });
  }
  return r56.forEach((o80) => e36.disposeIntermediateTensorInfo(o80)), s84;
}
var N51 = { kernelName: it, backendName: "webgl", kernelFunc: O19 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/RaggedGather.mjs
function I37(o80) {
  let { inputs: p103, backend: t67, attrs: r56 } = o80, { paramsNestedSplits: s84, paramsDenseValues: a71, indices: n67 } = p103, { outputRaggedRank: d55 } = r56, c103 = s84.map((e36) => t67.readSync(e36.dataId)), u86 = s84.map((e36) => e36.shape), m96 = t67.readSync(a71.dataId), i88 = t67.readSync(n67.dataId), [l80, g72, h74] = w30(c103, u86, m96, a71.shape, a71.dtype, i88, n67.shape, d55), S45 = l80.map((e36) => t67.makeTensorInfo([e36.length], "int32", e36)), k63 = t67.makeTensorInfo(h74, a71.dtype, g72);
  return S45.concat([k63]);
}
var V18 = { kernelName: lt, backendName: "webgl", kernelFunc: I37 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/RaggedRange.mjs
function k51(d55) {
  let { inputs: o80, backend: e36 } = d55, { starts: t67, limits: a71, deltas: n67 } = o80, c103 = e36.readSync(t67.dataId), g72 = e36.readSync(a71.dataId), l80 = e36.readSync(n67.dataId), [s84, r56] = y32(c103, t67.shape, t67.dtype, g72, a71.shape, l80, n67.shape), p103 = e36.makeTensorInfo([s84.length], "int32", s84), i88 = e36.makeTensorInfo([r56.length], t67.dtype, r56);
  return [p103, i88];
}
var h68 = { kernelName: dt, backendName: "webgl", kernelFunc: k51 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/RaggedTensorToTensor.mjs
function I38(s84) {
  let { inputs: d55, backend: e36, attrs: p103 } = s84, { shape: n67, values: a71, defaultValue: t67, rowPartitionTensors: r56 } = d55, { rowPartitionTypes: c103 } = p103, u86 = e36.readSync(n67.dataId), T40 = e36.readSync(a71.dataId), i88 = e36.readSync(t67.dataId), l80 = r56.map((o80) => e36.readSync(o80.dataId)), g72 = r56.map((o80) => o80.shape), [m96, h74] = A27(u86, n67.shape, T40, a71.shape, a71.dtype, i88, t67.shape, l80, g72, c103);
  return e36.makeTensorInfo(m96, a71.dtype, h74);
}
var w38 = { kernelName: ut, backendName: "webgl", kernelFunc: I38 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Range.mjs
var g62 = (t67) => {
  let { backend: r56, attrs: o80 } = t67, { start: a71, stop: s84, step: c103, dtype: e36 } = o80, n67 = F25(a71, s84, c103, e36);
  return r56.makeTensorInfo([n67.length], e36, n67);
};
var f76 = { kernelName: St, backendName: "webgl", kernelFunc: g62 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Reciprocal.mjs
var o68 = "return 1.0 / x;";
var n58 = v32({ opSnippet: o68 });
var t57 = { kernelName: Dt, backendName: "webgl", kernelFunc: n58 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Relu.mjs
var s62 = t30 + `
  return (x < 0.0) ? 0.0 : x;
`;
var n59 = `
  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var u74 = v32({ opSnippet: s62, packedOpSnippet: n59 });
var o69 = { kernelName: mt, backendName: "webgl", kernelFunc: u74 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Relu6.mjs
var n60 = t30 + `
  return (x < 0.0) ? 0.0 : min(6.0, x);
`;
var s63 = `
  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var u75 = v32({ opSnippet: n60, packedOpSnippet: s63 });
var i74 = { kernelName: Nt, backendName: "webgl", kernelFunc: u75 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/resize_bilinear_gpu.mjs
var C21 = class {
  constructor(i88, t67, e36, o80, a71) {
    this.variableNames = ["A"], this.outputShape = [];
    let [f85, c103, u86, v42] = i88;
    this.outputShape = [f85, t67, e36, v42];
    let s84 = [o80 && t67 > 1 ? c103 - 1 : c103, o80 && e36 > 1 ? u86 - 1 : u86], R26 = [o80 && t67 > 1 ? t67 - 1 : t67, o80 && e36 > 1 ? e36 - 1 : e36], r56;
    a71 ? r56 = "(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)" : r56 = "vec2(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${s84[0] / R26[0]},
          ${s84[1] / R26[1]});
      const vec2 inputShapeRC = vec2(${c103}.0, ${u86}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${r56};

        // Compute the four integer indices.
        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));
        ivec2 sourceCeilRC = ivec2(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);
        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);
        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);
        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);

        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);

        float top = topLeft + (topRight - topLeft) * fracRC.y;
        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;
        float newValue = top + (bottom - top) * fracRC.x;

        setOutput(newValue);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/resize_bilinear_packed_gpu.mjs
var a63 = class {
  constructor(R26, o80, e36, t67, i88) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outputShape = [];
    let [x76, u86, c103, C28] = R26;
    this.outputShape = [x76, o80, e36, C28];
    let r56 = [t67 && o80 > 1 ? u86 - 1 : u86, t67 && e36 > 1 ? c103 - 1 : c103], l80 = [t67 && o80 > 1 ? o80 - 1 : o80, t67 && e36 > 1 ? e36 - 1 : e36], s84;
    i88 ? s84 = "(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)" : s84 = "vec3(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${r56[0] / l80[0]},
          ${r56[1] / l80[1]},
          ${r56[1] / l80[1]});
      const vec3 inputShapeRC = vec3(${u86}.0, ${c103}.0,
                                     ${c103}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${s84};

        // Compute the four integer indices.
        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));
        ivec3 sourceCeilRC = ivec3(
          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${C28 - 1};
        bool hasNextRow = coords.z < ${e36 - 1};

        // In parallel, construct four corners for all four components in
        // packed 2x2 cell.
        vec4 topLeft = vec4(
          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 bottomLeft = vec4(
          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);

        vec4 topRight = vec4(
          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec4 bottomRight = vec4(
          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),
          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);

        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);

        vec4 top = mix(topLeft, topRight, fracRC.yyzz);
        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);
        vec4 newValue = mix(top, bottom, fracRC.x);

        setOutput(newValue);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ResizeBilinear.mjs
function P31(a71) {
  let { inputs: t67, backend: s84, attrs: l80 } = a71, { images: e36 } = t67, { alignCorners: r56, halfPixelCenters: n67, size: m96 } = l80, [i88, o80] = m96, c103 = l().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new a63(e36.shape, i88, o80, r56, n67) : new C21(e36.shape, i88, o80, r56, n67);
  return s84.runWebGLProgram(c103, [e36], "float32");
}
var u76 = { kernelName: At, backendName: "webgl", kernelFunc: P31 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/resize_bilinear_backprop_gpu.mjs
var x69 = class {
  constructor(h74, n67, o80) {
    this.variableNames = ["dy"], this.outputShape = [], this.outputShape = n67;
    let [, i88, d55] = n67, [, t67, e36] = h74, f85 = [o80 && t67 > 1 ? i88 - 1 : i88, o80 && e36 > 1 ? d55 - 1 : d55], a71 = [o80 && t67 > 1 ? t67 - 1 : t67, o80 && e36 > 1 ? e36 - 1 : e36], c103 = f85[0] / a71[0], r56 = f85[1] / a71[1], l80 = 1 / c103, s84 = 1 / r56, y43 = Math.ceil(l80) * 2 + 2, R26 = Math.ceil(s84) * 2 + 2;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${c103});
        const float widthScale = float(${r56});

        const float invHeightScale = float(${l80});
        const float invWidthScale = float(${s84});

        const int winHeight = int(${y43});
        const int winWidth = int(${R26});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(startRLerp - float(winHeight / 2));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(startCLerp - float(winWidth / 2));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${t67}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${e36}) {
              continue;
            }

            float dxR = float(dyR) * heightScale;
            int topDxRIndex = int(floor(dxR));
            int bottomDxRIndex = int(min(ceil(dxR), ${i88 - 1}.0));
            float dxRLerp = dxR - float(topDxRIndex);
            float inverseDxRLerp = 1.0 - dxRLerp;

            float dxC = float(dyC) * widthScale;
            int leftDxCIndex = int(floor(dxC));
            int rightDxCIndex = int(min(ceil(dxC), ${d55 - 1}.0));
            float dxCLerp = dxC - float(leftDxCIndex);
            float inverseDxCLerp = 1.0 - dxCLerp;

            if (r == topDxRIndex && c == leftDxCIndex) {
              // topLeft
              accumulator +=
                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;
            }

            if (r == topDxRIndex && c == rightDxCIndex) {
              // topRight
              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;
            }

            if (r == bottomDxRIndex && c == leftDxCIndex) {
              // bottomLeft
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;
            }

            if (r == bottomDxRIndex && c == rightDxCIndex) {
              // bottomRight
              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ResizeBilinearGrad.mjs
function m83(r56) {
  let { inputs: n67, backend: a71, attrs: i88 } = r56, { images: o80, dy: e36 } = n67, { alignCorners: s84 } = i88, t67 = new x69(e36.shape, o80.shape, s84);
  return a71.runWebGLProgram(t67, [e36], e36.dtype);
}
var g63 = { kernelName: Bt, backendName: "webgl", kernelFunc: m83 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/resize_nearest_neighbor_gpu.mjs
var r43 = class {
  constructor(i88, e36, t67, c103, p103) {
    this.variableNames = ["A"], this.outputShape = [];
    let [R26, o80, u86, d55] = i88;
    this.outputShape = [R26, e36, t67, d55];
    let v42 = [c103 && e36 > 1 ? o80 - 1 : o80, c103 && t67 > 1 ? u86 - 1 : u86], a71 = [c103 && e36 > 1 ? e36 - 1 : e36, c103 && t67 > 1 ? t67 - 1 : t67], f85 = c103 ? "0.5" : "0.0", s84;
    p103 ? s84 = "max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))" : s84 = "vec2(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec2 effectiveInputOverOutputRatioRC = vec2(
          ${v42[0] / a71[0]},
          ${v42[1] / a71[1]});
      const vec2 inputShapeRC = vec2(${o80}.0, ${u86}.0);

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        ivec2 yRC = coords.yz;

        // Fractional source index.
        vec2 sourceFracIndexRC = ${s84};

        // Compute the coordinators of nearest neighbor point.
        ivec2 sourceNearestRC = ivec2(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${f85})));
        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);

        setOutput(newValue);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/resize_nearest_neighbor_packed_gpu.mjs
var i75 = class {
  constructor(n67, t67, e36, c103, v42) {
    this.variableNames = ["A"], this.packedInputs = true, this.packedOutput = true, this.outputShape = [];
    let [d55, u86, o80, l80] = n67;
    this.outputShape = [d55, t67, e36, l80];
    let s84 = [c103 && t67 > 1 ? u86 - 1 : u86, c103 && e36 > 1 ? o80 - 1 : o80], a71 = [c103 && t67 > 1 ? t67 - 1 : t67, c103 && e36 > 1 ? e36 - 1 : e36], R26 = c103 ? "0.5" : "0.0", r56;
    v42 ? r56 = "max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))" : r56 = "vec3(yRC) * effectiveInputOverOutputRatioRC", this.userCode = `
      const vec3 effectiveInputOverOutputRatioRC = vec3(
          ${s84[0] / a71[0]},
          ${s84[1] / a71[1]},
          ${s84[1] / a71[1]});
      const vec3 inputShapeRC = vec3(${u86}.0, ${o80}.0,
                                     ${o80}.0);

      float getAValue(int b, int r, int c, int d) {
        return getChannel(getA(b, r, c, d), vec2(c, d));
      }

      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        // Calculate values for next column in yRC.z.
        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);

        // Fractional source index.
        vec3 sourceFracIndexRC = ${r56};

        // Compute the coordinators of nearest neighbor point.
        ivec3 sourceNearestRC = ivec3(
          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${R26})));

        // Should we calculate next column and row elements in 2x2 packed cell.
        bool hasNextCol = d < ${l80 - 1};
        bool hasNextRow = coords.z < ${e36 - 1};

        vec4 newValue = vec4(
          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),
          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)
                     : 0.0,
          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)
                     : 0.0,
          (hasNextRow && hasNextCol) ?
            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);

        setOutput(newValue);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ResizeNearestNeighbor.mjs
function l67(s84) {
  let { inputs: i88, backend: a71, attrs: g72 } = s84, { images: e36 } = i88, { alignCorners: r56, halfPixelCenters: o80, size: m96 } = g72, [t67, n67] = m96, N58 = l().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new i75(e36.shape, t67, n67, r56, o80) : new r43(e36.shape, t67, n67, r56, o80);
  return a71.runWebGLProgram(N58, [e36], e36.dtype);
}
var d43 = { kernelName: ht, backendName: "webgl", kernelFunc: l67 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/resize_nearest_neighbor_backprop_gpu.mjs
var h69 = class {
  constructor(u86, n67, t67) {
    this.variableNames = ["dy"], this.outputShape = [], this.outputShape = n67;
    let [, c103, f85] = n67, [, o80, e36] = u86, i88 = [t67 && o80 > 1 ? c103 - 1 : c103, t67 && e36 > 1 ? f85 - 1 : f85], a71 = [t67 && o80 > 1 ? o80 - 1 : o80, t67 && e36 > 1 ? e36 - 1 : e36], s84 = i88[0] / a71[0], d55 = i88[1] / a71[1], l80 = 1 / s84, r56 = 1 / d55, y43 = Math.ceil(l80) * 2 + 2, w45 = Math.ceil(r56) * 2 + 2;
    this.userCode = `
      void main() {
        ivec4 coords = getOutputCoords();
        int b = coords[0];
        int d = coords[3];
        int r = coords[1];
        int c = coords[2];

        float accumulator = 0.0;

        const float heightScale = float(${s84});
        const float widthScale = float(${d55});

        const float invHeightScale = float(${l80});
        const float invWidthScale = float(${r56});

        const int winHeight = int(${y43});
        const int winWidth = int(${w45});

        // Compute bounds for where in dy we will look
        float startRLerp = floor(float(r) * invHeightScale);
        int startDyR = int(floor(startRLerp - float(winHeight / 2)));

        float startCLerp = floor(float(c) * invWidthScale);
        int startDyC = int(floor(startCLerp - float(winWidth / 2)));

        // Loop over dy
        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {
          int dyR = dyROffset + startDyR;

          // Guard against the window exceeding the bounds of dy
          if (dyR < 0 || dyR >= ${o80}) {
            continue;
          }

          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {
            int dyC = dyCOffset + startDyC;

            // Guard against the window exceeding the bounds of dy
            if (dyC < 0 || dyC >= ${e36}) {
              continue;
            }

            float sourceFracRow =
              float(${i88[0]}) *
                (float(dyR) / float(${a71[0]}));

            float sourceFracCol =
                float(${i88[1]}) *
                  (float(dyC) / float(${a71[1]}));

            int sourceNearestRow = int(min(
                float(int(${c103}) - 1),
                ${t67} ? float(round(sourceFracRow)) :
                                  float(floor(sourceFracRow))));

            int sourceNearestCol = int(min(
                float(int(${f85}) - 1),
                ${t67} ? float(round(sourceFracCol)) :
                                  float(floor(sourceFracCol))));

            if (r == sourceNearestRow && c == sourceNearestCol) {
              accumulator += getDy(b, dyR, dyC, d);
            }
          }
        }
        // End loop over dy

        setOutput(accumulator);
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ResizeNearestNeighborGrad.mjs
function c88(r56) {
  let { inputs: o80, backend: a71, attrs: n67 } = r56, { images: s84, dy: e36 } = o80, { alignCorners: t67 } = n67, i88 = new h69(e36.shape, s84.shape, t67);
  return a71.runWebGLProgram(i88, [e36], e36.dtype);
}
var b52 = { kernelName: Mt, backendName: "webgl", kernelFunc: c88 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/reverse_gpu.mjs
var s64 = class {
  constructor(t67, e36) {
    this.variableNames = ["x"];
    let r56 = t67.length;
    if (r56 > 4) throw new Error(`WebGL backend: Reverse of rank-${r56} tensor is not yet supported`);
    if (this.outputShape = t67, r56 === 1) {
      this.userCode = `
        void main() {
          int coord = getOutputCoords();
          setOutput(getX(${t67[0]} - coord - 1));
        }
      `;
      return;
    }
    let n67 = (o80) => e36.indexOf(o80) !== -1 && t67[o80] !== 1 ? `${t67[o80]} - coords[${o80}] - 1` : `coords[${o80}]`, d55 = t67.map((o80, i88) => n67(i88)).join(","), u86 = F22(r56);
    this.userCode = `
      void main() {
        ${u86} coords = getOutputCoords();
        setOutput(getX(${d55}));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/reverse_packed_gpu.mjs
var i76 = class {
  constructor(r56, c103) {
    this.variableNames = ["x"], this.packedInputs = true, this.packedOutput = true;
    let e36 = r56.length;
    if (e36 > 4) throw new Error(`WebGL backend: Reverse of rank-${e36} tensor is not yet supported`);
    this.outputShape = r56;
    let o80 = u62("rc", e36), s84 = `${o80[e36 - 1]} + 1 < ${this.outputShape[e36 - 1]}`, $37 = `${o80[e36 - 2]} + 1 < ${this.outputShape[e36 - 2]}`, g72 = F22(e36);
    e36 === 1 ? this.userCode = `
        void main(){
          int rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = getChannel(getX(${r56[0]} - rc - 1),
            ${r56[0]} - rc - 1);
          if(${s84}){
              result.g = getChannel(getX(${r56[0]} - (rc  + 1) - 1),
                ${r56[0]} - (rc  + 1) - 1);
          }
          setOutput(result);
        }
      ` : this.userCode = `
        void main() {
          ${g72} rc = getOutputCoords();
          vec4 result = vec4(0.);
          result.r = ${l80(o80.slice())};
          if(${s84}){
            result.g = ${f85(o80.slice())};
          }
          if(${$37}) {
            result.b = ${d55(o80.slice())};
            if(${s84}) {
              result.a = ${p103(o80.slice())};
            }
          }
          setOutput(result);
        }
    `;
    function l80(t67) {
      return n67(t67);
    }
    function f85(t67) {
      return t67[e36 - 1] = "(" + t67[e36 - 1] + " + 1)", n67(t67);
    }
    function d55(t67) {
      return t67[e36 - 2] = "(" + t67[e36 - 2] + " + 1)", n67(t67);
    }
    function p103(t67) {
      return t67[e36 - 1] = "(" + t67[e36 - 1] + " + 1)", t67[e36 - 2] = "(" + t67[e36 - 2] + " + 1)", n67(t67);
    }
    function n67(t67) {
      let u86 = r56.map((y43, a71) => C28(a71, t67)), m96 = u86.join(","), v42 = u86.slice(-2).join(",");
      return `getChannel(getX(${m96}), vec2(${v42}))`;
    }
    function C28(t67, u86) {
      return c103.indexOf(t67) !== -1 && r56[t67] !== 1 ? `${r56[t67]} - ${u86[t67]} - 1` : `${u86[t67]}`;
    }
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Reverse.mjs
function P32(t67) {
  let { inputs: o80, backend: r56, attrs: s84 } = t67, { x: e36 } = o80, { dims: a71 } = s84, m96 = e36.shape.length, n67 = util_exports.parseAxisParam(a71, e36.shape);
  if (m96 === 0) return i52({ inputs: { x: e36 }, backend: r56 });
  let i88 = l().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new i76(e36.shape, n67) : new s64(e36.shape, n67);
  return r56.runWebGLProgram(i88, [e36], e36.dtype);
}
var h70 = { kernelName: Ct, backendName: "webgl", kernelFunc: P32 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/rotate_gpu.mjs
var r44 = class {
  constructor(o80, t67) {
    this.variableNames = ["Image"], this.outputShape = [], this.customUniforms = [{ name: "params", type: "vec4" }];
    let s84 = o80[1], c103 = o80[2];
    this.outputShape = o80;
    let a71 = "";
    typeof t67 == "number" ? a71 = `float outputValue = ${t67.toFixed(2)};` : a71 = `
        vec3 fill = vec3(${t67.join(",")});
        float outputValue = fill[coords[3]];`, this.userCode = `
        void main() {
          ivec4 coords = getOutputCoords();
          int x = coords[2];
          int y = coords[1];
          float coordXFloat = (float(x) - params[0]) * params[3] -
            (float(y) - params[1]) * params[2];
          float coordYFloat = (float(x) - params[0]) * params[2] +
            (float(y) - params[1]) * params[3];
          int coordX = int(round(coordXFloat + params[0]));
          int coordY = int(round(coordYFloat + params[1]));
          ${a71}
          if(coordX >= 0 && coordX < ${c103} && coordY >= 0 && coordY < ${s84}) {
            outputValue = getImage(coords[0], coordY, coordX, coords[3]);
          }
          setOutput(outputValue);
        }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/RotateWithOffset.mjs
var w39 = { kernelName: ge, backendName: "webgl", kernelFunc: ({ inputs: o80, attrs: n67, backend: r56 }) => {
  let { image: e36 } = o80, { radians: t67, fillValue: a71, center: s84 } = n67, c103 = r56, m96 = new r44(e36.shape, a71), [i88, p103] = backend_util_exports.getImageCenter(s84, e36.shape[1], e36.shape[2]), u86 = [[i88, p103, Math.sin(t67), Math.cos(t67)]];
  return c103.runWebGLProgram(m96, [e36], e36.dtype, u86);
} };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Round.mjs
var o70 = `
  // OpenGL ES does not support round function.
  // The algorithm is based on banker's rounding.
  float base = floor(x);
  if ((x - base) < 0.5) {
    return floor(x);
  } else if ((x - base) > 0.5) {
    return ceil(x);
  } else {
    if (mod(base, 2.0) == 0.0) {
      return base;
    } else {
      return base + 1.0;
    }
  }
`;
var r45 = v32({ opSnippet: o70 });
var a64 = { kernelName: vt, backendName: "webgl", kernelFunc: r45 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Rsqrt.mjs
var t58 = "return inversesqrt(x);";
var o71 = v32({ opSnippet: t58, cpuKernelImpl: G21 });
var c89 = { kernelName: Ft, backendName: "webgl", kernelFunc: o71 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/scatter_gpu.mjs
var f77 = class {
  constructor(a71, i88, s84, o80, d55, n67, h74 = true, p103 = false) {
    this.variableNames = ["updates", "indices", "defaultValue"], this.outputShape = n67;
    let u86 = F22(d55.length), c103 = F22(n67.length), t67 = "";
    s84 === 1 ? t67 = "i" : s84 === 2 && (t67 = "i, j");
    let $37 = `getIndices(${t67})`, e36 = "";
    o80 === 1 ? e36 = "i" : o80 === 2 && (e36 = "i, coords[1]");
    let g72 = `getUpdates(${e36})`, l80 = "";
    p103 && (l80 = "coords[0], coords[1]");
    let m96 = `getDefaultValue(${l80})`, x76 = i88 > 1 ? "strides[j]" : "strides";
    this.userCode = `
        ${u86} strides = ${u86}(${d55});

        void main() {
          ${c103} coords = getOutputCoords();
          float sum = 0.0;
          bool found = false;
          for (int i = 0; i < ${a71}; i++) {
            int flattenedIndex = 0;
            for (int j = 0; j < ${i88}; j++) {
              int index = round(${$37});
              flattenedIndex += index * ${x76};
            }
            if (flattenedIndex == coords[0]) {
              sum += ${g72};
              found = true;
            }
          }
          setOutput(mix(${m96}, sum, float(found)));
        }
      `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/scatter_packed_gpu.mjs
var c90 = class {
  constructor(l80, e36, s84, n67, i88, o80, m96 = true, a71 = false) {
    this.variableNames = ["updates", "indices", "defaultValue"], this.packedInputs = true, this.packedOutput = true, this.outputShape = o80;
    let u86 = F22(i88.length), p103 = F22(o80.length), t67 = "";
    s84 === 1 ? t67 = "i" : s84 === 2 && (t67 = "i, j");
    let x76 = `getIndices(${t67})`, d55 = "";
    n67 === 1 ? d55 = "i" : n67 === 2 && (d55 = "i, coords[1]");
    let $37 = `getUpdates(${d55})`, f85 = "";
    a71 && (f85 = "coords[0], coords[1]");
    let v42 = `getDefaultValue(${f85})`, I44 = e36 > 1 ? "strides[j]" : "strides", g72 = e36 > 1 ? "strides[j + 1]" : "strides";
    this.userCode = `
        ${u86} strides = ${u86}(${i88});

        void main() {
          ${p103} coords = getOutputCoords();
          vec4 sum = vec4(0.);
          vec4 found = vec4(0.);
          for (int i = 0; i < ${l80}; i+=2) {
            ivec2 flattenedIndex = ivec2(0);
            for (int j = 0; j < ${e36}; j+=2) {
              ivec4 index = round(${x76});
              flattenedIndex += index.xz * ${I44};
              if (j + 1 < ${e36}) {
                flattenedIndex += index.yw * ${g72};
              }
            }
            if (flattenedIndex[0] == coords[0] || flattenedIndex[1] == coords[0] ||
                flattenedIndex[0] == coords[0] + 1 || flattenedIndex[1] == coords[0] + 1) {
              vec4 updVals = ${$37};
              if (flattenedIndex[0] == coords[0]) {
                sum.xy += updVals.xy;
                found.xy = vec2(1.);
              } else if (flattenedIndex[0] == coords[0] + 1) {
                sum.zw += updVals.xy;
                found.zw = vec2(1.);
              }
              if (flattenedIndex[1] == coords[0]) {
                sum.xy += updVals.zw;
                found.xy = vec2(1.);
              } else if (flattenedIndex[1] == coords[0] + 1) {
                sum.zw += updVals.zw;
                found.zw = vec2(1.);
              }
            }
          }
          setOutput(mix(${v42}, sum, found));
        }
      `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/ScatterNd.mjs
function w40(g72) {
  let { inputs: I44, backend: e36, attrs: k63 } = g72, { indices: r56, updates: d55 } = I44, { shape: a71 } = k63, { sliceRank: o80, numUpdates: n67, sliceSize: p103, strides: l80, outputSize: m96 } = backend_util_exports.calculateShapes(d55, r56, a71), f85 = [m96 / p103, p103];
  if (m96 === 0) return e36.makeTensorInfo(a71, r56.dtype);
  let s84 = f68({ inputs: { x: r56 }, backend: e36, attrs: { shape: [n67, o80] } }), t67 = f68({ inputs: { x: d55 }, backend: e36, attrs: { shape: [n67, p103] } }), u86 = e36.makeTensorInfo([], "float32", new Float32Array([0])), i88;
  l().getBool("WEBGL_PACK") ? i88 = new c90(n67, o80, s84.shape.length, t67.shape.length, l80, f85) : i88 = new f77(n67, o80, s84.shape.length, t67.shape.length, l80, f85);
  let h74 = e36.runWebGLProgram(i88, [t67, s84, u86], t67.dtype), S45 = f68({ inputs: { x: h74 }, backend: e36, attrs: { shape: a71 } });
  return e36.disposeIntermediateTensorInfo(s84), e36.disposeIntermediateTensorInfo(t67), e36.disposeIntermediateTensorInfo(h74), e36.disposeIntermediateTensorInfo(u86), S45;
}
var C22 = { kernelName: Pt, backendName: "webgl", kernelFunc: w40 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/search_sorted_gpu.mjs
var t59 = class {
  constructor(e36, i88, o80, n67) {
    this.variableNames = ["sortedSequence", "values"], this.customUniforms = [{ name: "numInputs", type: "int" }], this.outputShape = [e36, o80];
    let a71 = "while (left < right) {", u86 = `for (int i = 0; i < ${Math.ceil(Math.log2(i88 + 1))}; ++i) { if (left >= right) break;`, s84 = l().getNumber("WEBGL_VERSION") === 2 ? a71 : u86, l80 = n67 === "left" ? "<" : "<=";
    this.userCode = `
       int findBound(int batch, float value) {
         int left = 0;
         int right = numInputs;
         int mid;
         ${s84}
           mid = (left + right) / 2;
           if (getSortedSequence(batch, mid) ${l80} value) {
             left = mid + 1;
           } else {
             right = mid;
           }
         }
         return right;
       }

       void main() {
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int valueIndex = coords[1];

         float value = getValues(batch, valueIndex);

         setOutput(float(findBound(batch, value)));
       }
     `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/SearchSorted.mjs
function d44(o80) {
  let { inputs: t67, backend: n67, attrs: s84 } = o80, { sortedSequence: e36, values: r56 } = t67, { side: a71 } = s84, c103 = new t59(e36.shape[0], e36.shape[1], r56.shape[1], a71), m96 = [[e36.shape[1]]];
  return n67.runWebGLProgram(c103, [e36, r56], "int32", m96);
}
var S37 = { kernelName: Lt, backendName: "webgl", kernelFunc: d44 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/select_gpu.mjs
var a65 = class {
  constructor(c103, r56, o80) {
    this.variableNames = ["c", "a", "b"], this.outputShape = r56;
    let e36, s84;
    if (o80 > 4) throw Error(`Where for rank ${o80} is not yet supported`);
    if (o80 === 1) s84 = "resRC", e36 = "resRC";
    else {
      let C28 = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"], i88 = [], u86 = [];
      for (let t67 = 0; t67 < r56.length; t67++) u86.push(`${C28[t67]}`), t67 < c103 && i88.push(`${C28[t67]}`);
      e36 = i88.join(), s84 = u86.join();
    }
    let p103 = F22(o80);
    this.userCode = `
      void main() {
        ${p103} resRC = getOutputCoords();
        float cVal = getC(${e36});
        if (cVal >= 1.0) {
          setOutput(getA(${s84}));
        } else {
          setOutput(getB(${s84}));
        }
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Select.mjs
function m84(o80) {
  let { inputs: r56, backend: c103 } = o80, { condition: t67, t: e36, e: n67 } = r56, p103 = new a65(t67.shape.length, e36.shape, e36.shape.length);
  return c103.runWebGLProgram(p103, [t67, e36, n67], c5(e36.dtype, n67.dtype));
}
var u77 = { kernelName: kt, backendName: "webgl", kernelFunc: m84 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Selu.mjs
var l68 = `
  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.
  // see: https://arxiv.org/abs/1706.02515
  float scaleAlpha = ${backend_util_exports.SELU_SCALEALPHA};
  float scale = ${backend_util_exports.SELU_SCALE};
  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);
`;
var n61 = v32({ opSnippet: l68 });
var s65 = { kernelName: Gt, backendName: "webgl", kernelFunc: n61 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Sigmoid.mjs
var i77 = q18 + `
  return 1.0 / (1.0 + exp(-1.0 * x));
`;
var n62 = `
  vec4 result = 1.0 / (1.0 + exp(-1.0 * x));
  bvec4 isNaN = isnan(x);

  result.r = isNaN.r ? x.r : result.r;
  result.g = isNaN.g ? x.g : result.g;
  result.b = isNaN.b ? x.b : result.b;
  result.a = isNaN.a ? x.a : result.a;

  return result;
`;
var o72 = v32({ opSnippet: i77, packedOpSnippet: n62, cpuKernelImpl: f65 });
var N52 = { kernelName: wt, backendName: "webgl", kernelFunc: o72 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Sign.mjs
var r46 = `
  if (isnan(x)) { return 0.0; }
  return sign(x);
`;
var o73 = v32({ opSnippet: r46 });
var p91 = { kernelName: qt, backendName: "webgl", kernelFunc: o73 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Sin.mjs
var o74 = q18 + `
  return sin(x);
`;
var i78 = `
  vec4 result = sin(x);
  bvec4 isNaN = isnan(x);
  ${x56}
  return result;
`;
var N53 = v32({ opSnippet: o74, packedOpSnippet: i78 });
var m85 = { kernelName: ft, backendName: "webgl", kernelFunc: N53 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Sinh.mjs
var o75 = `
  float e2x = exp(x);
  return (e2x - 1.0 / e2x) / 2.0;
`;
var r47 = v32({ opSnippet: o75 });
var i79 = { kernelName: It, backendName: "webgl", kernelFunc: r47 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Softplus.mjs
var l69 = `
  float epsilon = 1.1920928955078125e-7;
  float threshold = log(epsilon) + 2.0;

  bool too_large = x > -threshold;
  bool too_small = x < threshold;

  float result;
  float exp_x = exp(x);

  if (too_large){
    result = x;
  }
  else if (too_small){
    result = exp_x;
  }
  else{
    result = log(exp_x + 1.0);
  }
  return result;
`;
var t60 = v32({ opSnippet: l69 });
var p92 = { kernelName: Vt, backendName: "webgl", kernelFunc: t60 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/SpaceToBatchND.mjs
var S38 = (l80) => {
  let { inputs: m96, backend: t67, attrs: f85 } = l80, { x: p103 } = m96, { blockShape: s84, paddings: g72 } = f85;
  util_exports.assert(p103.shape.length <= 4, () => "spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");
  let r56 = s84.reduce((e36, x76) => e36 * x76), o80 = [[0, 0]];
  o80.push(...g72);
  for (let e36 = 1 + s84.length; e36 < p103.shape.length; ++e36) o80.push([0, 0]);
  let a71 = [], n67 = k50({ inputs: { x: p103 }, backend: t67, attrs: { paddings: o80, constantValue: 0 } }), c103 = backend_util_exports.getReshaped(n67.shape, s84, r56, false), k63 = backend_util_exports.getPermuted(c103.length, s84.length, false), b58 = backend_util_exports.getReshapedPermuted(n67.shape, s84, r56, false), h74 = f68({ inputs: { x: n67 }, backend: t67, attrs: { shape: c103 } }), i88 = h59({ inputs: { x: h74 }, backend: t67, attrs: { perm: k63 } }), P36 = f68({ inputs: { x: i88 }, backend: t67, attrs: { shape: b58 } });
  return a71.push(n67), a71.push(h74), a71.push(i88), a71.forEach((e36) => t67.disposeIntermediateTensorInfo(e36)), P36;
};
var V19 = { kernelName: zt, backendName: "webgl", kernelFunc: S38 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/SparseFillEmptyRows.mjs
function b53(d55) {
  let { inputs: l80, backend: e36 } = d55, { indices: a71, values: t67, denseShape: s84, defaultValue: n67 } = l80;
  if (s84.shape.length !== 1) throw new Error(`Dense shape must be a vector, saw:
         ${s84.shape}`);
  if (a71.shape.length !== 2) throw new Error(`Indices must be a matrix, saw:
         ${a71.shape}`);
  if (t67.shape.length !== 1) throw new Error(`Values must be a vector, saw:
         ${t67.shape}`);
  if (n67.shape.length !== 0) throw new Error(`Default value must be a scalar, saw:
        ${n67.shape}`);
  let c103 = e36.readSync(a71.dataId), u86 = e36.readSync(t67.dataId), h74 = e36.readSync(s84.dataId), i88 = e36.readSync(n67.dataId)[0], [m96, r56, w45, o80, p103] = H11(c103, a71.shape, a71.dtype, u86, t67.dtype, h74, i88);
  return [e36.makeTensorInfo(r56, a71.dtype, m96), e36.makeTensorInfo([r56[0]], t67.dtype, w45), e36.makeTensorInfo([o80.length], "bool", new Uint8Array(o80.map((y43) => Number(y43)))), e36.makeTensorInfo([p103.length], a71.dtype, new Int32Array(p103))];
}
var E40 = { kernelName: Ht, backendName: "webgl", kernelFunc: b53 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/SparseReshape.mjs
function I39(p103) {
  let { inputs: s84, backend: a71 } = p103, { inputIndices: e36, inputShape: n67, newShape: r56 } = s84;
  if (e36.shape.length !== 2) throw new Error(`Input indices should be a matrix but received shape ${e36.shape}`);
  if (n67.shape.length !== 1) throw new Error(`Input shape should be a vector but received shape ${n67.shape}`);
  if (r56.shape.length !== 1) throw new Error(`Target shape should be a vector but received shape ${r56.shape}`);
  let o80 = Array.from(a71.readSync(n67.dataId)), h74 = a71.readSync(e36.dataId), d55 = Array.from(a71.readSync(r56.dataId)), [c103, i88, t67] = K16(h74, e36.shape, e36.dtype, o80, d55);
  return [a71.makeTensorInfo(i88, e36.dtype, c103), a71.makeTensorInfo([t67.length], r56.dtype, new Int32Array(t67))];
}
var w41 = { kernelName: Wt, backendName: "webgl", kernelFunc: I39 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/SparseSegmentMean.mjs
function u78(s84) {
  let { inputs: r56, backend: t67 } = s84, { data: e36, indices: a71, segmentIds: n67 } = r56;
  if (e36.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (a71.shape.length !== 1) throw new Error(`Indices should be a vector but received shape
              ${a71.shape}`);
  if (n67.shape.length !== 1) throw new Error(`Segment ids should be a vector but received shape
              ${n67.shape}`);
  let o80 = t67.readSync(e36.dataId), d55 = t67.readSync(a71.dataId), c103 = t67.readSync(n67.dataId), [p103, i88] = V14(o80, e36.shape, e36.dtype, d55, c103, true);
  return t67.makeTensorInfo(i88, e36.dtype, p103);
}
var S39 = { kernelName: Kt, backendName: "webgl", kernelFunc: u78 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/SparseSegmentSum.mjs
function u79(s84) {
  let { inputs: r56, backend: t67 } = s84, { data: e36, indices: a71, segmentIds: n67 } = r56;
  if (e36.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (a71.shape.length !== 1) throw new Error(`Indices should be a vector but received shape
             ${a71.shape}`);
  if (n67.shape.length !== 1) throw new Error(`Segment ids should be a vector but received shape
             ${n67.shape}`);
  let o80 = t67.readSync(e36.dataId), d55 = t67.readSync(a71.dataId), c103 = t67.readSync(n67.dataId), [p103, i88] = V14(o80, e36.shape, e36.dtype, d55, c103);
  return t67.makeTensorInfo(i88, e36.dtype, p103);
}
var g64 = { kernelName: Xt, backendName: "webgl", kernelFunc: u79 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/SparseToDense.mjs
function V20(f85) {
  let { inputs: l80, backend: e36, attrs: m96 } = f85, { sparseIndices: t67, sparseValues: s84, defaultValue: r56 } = l80, { outputShape: n67 } = m96, { sliceRank: a71, numUpdates: o80, sliceSize: S45, strides: c103, outputSize: p103 } = backend_util_exports.calculateShapes(s84, t67, n67), u86 = false;
  if (s84.dtype === "string") {
    let b58 = e36.bufferSync(t67), k63 = e36.bufferSync(s84), I44 = util_exports.decodeString(e36.readSync(r56.dataId)[0]), d55 = N40(b58, k63, n67, p103, S45, o80, a71, c103, I44, u86);
    return e36.makeTensorInfo(n67, d55.dtype, d55.values);
  }
  let g72 = new f77(o80, a71, t67.shape.length, s84.shape.length, c103, [p103, 1], u86), i88 = e36.runWebGLProgram(g72, [s84, t67, r56], s84.dtype), h74 = f68({ inputs: { x: i88 }, backend: e36, attrs: { shape: n67 } });
  return e36.disposeIntermediateTensorInfo(i88), h74;
}
var U18 = { kernelName: Zt, backendName: "webgl", kernelFunc: V20 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/SplitV.mjs
function g65(r56) {
  let { inputs: c103, backend: a71, attrs: o80 } = r56, { x: e36 } = c103, { numOrSizeSplits: p103, axis: l80 } = o80, t67 = util_exports.parseAxisParam(l80, e36.shape)[0], m96 = backend_util_exports.prepareSplitSize(e36, p103, t67), u86 = e36.shape.length, s84 = new Array(u86).fill(0), x76 = e36.shape.slice();
  return m96.map((i88) => {
    let n67 = [...x76];
    n67[t67] = i88;
    let S45 = S33({ inputs: { x: e36 }, backend: a71, attrs: { begin: s84, size: n67 } });
    return s84[t67] += i88, S45;
  });
}
var V21 = { kernelName: Ut, backendName: "webgl", kernelFunc: g65 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Sqrt.mjs
var r48 = "return sqrt(x);";
var p93 = v32({ opSnippet: r48, packedOpSnippet: r48, cpuKernelImpl: j17 });
var l70 = { kernelName: yt, backendName: "webgl", kernelFunc: p93 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Square.mjs
var n63 = "return x * x;";
var o76 = v32({ opSnippet: n63 });
var p94 = { kernelName: jt, backendName: "webgl", kernelFunc: o76 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/SquaredDifference.mjs
var e34 = "return (a - b) * (a - b);";
var o77 = z26({ opSnippet: e34, packedOpSnippet: e34 });
var c91 = { kernelName: _t, backendName: "webgl", kernelFunc: o77 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/StaticRegexReplace.mjs
function m86(n67) {
  let { inputs: r56, backend: e36, attrs: a71 } = n67, { x: t67 } = r56;
  if (t67.dtype !== "string") throw new Error("Input must be of datatype string");
  let o80 = e36.readSync(t67.dataId), c103 = backend_util_exports.fromUint8ToStringArray(o80), s84 = v31(c103, "string", a71);
  return e36.makeTensorInfo(t67.shape, "string", s84);
}
var d45 = { kernelName: Jt, backendName: "webgl", kernelFunc: m86 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Step.mjs
function s66({ inputs: r56, attrs: n67, backend: o80 }) {
  let { x: e36 } = r56, t67 = t30 + `
    return x > 0.0 ? 1.0 : float(${n67.alpha});
  `, p103 = new e21(e36.shape, t67);
  return o80.runWebGLProgram(p103, [e36], e36.dtype);
}
var i80 = { kernelName: ue, backendName: "webgl", kernelFunc: s66 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/strided_slice_gpu.mjs
var $33 = class {
  constructor(d55, p103, t67) {
    this.variableNames = ["x"], this.outputShape = t67;
    let u86 = t67.length, o80 = F22(t67.length), g72 = F22(t67.length), s84 = "";
    if (u86 === 1) s84 = "coords * strides + begin";
    else {
      let n67 = 0;
      s84 = t67.map((c103, e36) => (n67++, t67.length === 1 ? `coords * strides[${e36}] + begin[${e36}]` : `coords[${n67 - 1}] * strides[${e36}] + begin[${e36}]`)).join(",");
    }
    this.userCode = `
      ${o80} begin = ${o80}(${d55});
      ${o80} strides = ${o80}(${p103});

      void main() {
        ${g72} coords = getOutputCoords();
        setOutput(getX(${s84}));
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/StridedSlice.mjs
function z30(c103) {
  let { inputs: u86, backend: s84, attrs: m96 } = c103, { x: e36 } = u86, { begin: f85, end: h74, strides: S45, beginMask: g72, endMask: k63, ellipsisMask: x76, newAxisMask: b58, shrinkAxisMask: I44 } = m96, { finalShapeSparse: l80, finalShape: i88, isIdentity: P36, sliceDim0: y43, isSimpleSlice: C28, begin: r56, end: M30, strides: a71 } = slice_util_exports.sliceInfo(e36.shape, f85, h74, S45, g72, k63, x76, b58, I44), t67;
  if (P36) t67 = f68({ inputs: { x: e36 }, backend: s84, attrs: { shape: i88 } });
  else if (y43 || C28) {
    util_exports.assert(e36.shape.length >= 1, () => `Input must have rank at least 1, got: ${e36.shape.length}`);
    let p103 = slice_util_exports.computeOutShape(r56, M30, a71), n67 = S33({ inputs: { x: e36 }, backend: s84, attrs: { begin: r56, size: p103 } });
    t67 = f68({ inputs: { x: n67 }, backend: s84, attrs: { shape: i88 } }), s84.disposeIntermediateTensorInfo(n67);
  } else if (s84.shouldExecuteOnCPU([e36])) {
    let n67 = s84.readSync(e36.dataId), U24 = i7(e36.shape, e36.dtype, n67), $37 = z25(l80, U24, a71, r56);
    t67 = s84.makeTensorInfo(i88, e36.dtype, $37.values);
  } else {
    let n67 = new $33(r56, a71, l80);
    t67 = s84.runWebGLProgram(n67, [e36], e36.dtype);
  }
  let O21 = f68({ inputs: { x: t67 }, backend: s84, attrs: { shape: i88 } });
  return s84.disposeIntermediateTensorInfo(t67), O21;
}
var R22 = { kernelName: Qt, backendName: "webgl", kernelFunc: z30 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/StringNGrams.mjs
function k52(r56) {
  let { inputs: s84, backend: t67, attrs: e36 } = r56, { separator: o80, nGramWidths: d55, leftPad: i88, rightPad: m96, padWidth: c103, preserveShortSequences: p103 } = e36, { data: g72, dataSplits: a71 } = s84, l80 = t67.readSync(g72.dataId), S45 = t67.readSync(a71.dataId), [n67, f85] = D21(l80, S45, o80, d55, i88, m96, c103, p103);
  return [t67.makeTensorInfo([n67.length], "string", n67), t67.makeTensorInfo(a71.shape, "int32", f85)];
}
var I40 = { kernelName: Yt, backendName: "webgl", kernelFunc: k52 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/StringSplit.mjs
function h71(o80) {
  let { inputs: s84, backend: t67, attrs: a71 } = o80, { skipEmpty: p103 } = a71, { input: e36, delimiter: n67 } = s84;
  if (e36.dtype !== "string") throw new Error("Input must be of datatype string");
  if (e36.shape.length !== 1) throw new Error(`Input must be a vector, got shape: ${e36.shape}`);
  if (n67.shape.length !== 0) throw new Error(`Delimiter must be a scalar, got shape: ${n67.shape}`);
  let c103 = t67.readSync(e36.dataId), m96 = t67.readSync(n67.dataId)[0], [l80, r56, g72] = J11(c103, m96, p103), i88 = r56.length;
  return [t67.makeTensorInfo([i88, 2], "int32", l80), t67.makeTensorInfo([i88], "string", r56), t67.makeTensorInfo([2], "int32", new Int32Array(g72))];
}
var k53 = { kernelName: $t, backendName: "webgl", kernelFunc: h71 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/StringToHashBucketFast.mjs
function p95(r56) {
  let { inputs: s84, backend: n67, attrs: o80 } = r56, { numBuckets: e36 } = o80, { input: t67 } = s84;
  if (t67.dtype !== "string") throw new Error("Input must be of datatype string");
  if (e36 <= 0) throw new Error("Number of buckets must be at least 1");
  let a71 = n67.readSync(t67.dataId), u86 = L16(a71, e36);
  return n67.makeTensorInfo(t67.shape, "int32", u86);
}
var f78 = { kernelName: oe, backendName: "webgl", kernelFunc: p95 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Tan.mjs
var r49 = "return tan(x);";
var t61 = v32({ opSnippet: r49 });
var p96 = { kernelName: ee, backendName: "webgl", kernelFunc: t61 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Tanh.mjs
var o78 = `
  float e2x = exp(-2.0 * abs(x));
  return sign(x) * (1.0 - e2x) / (1.0 + e2x);
`;
var r50 = v32({ opSnippet: o78 });
var p97 = { kernelName: re, backendName: "webgl", kernelFunc: r50 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/TensorScatterUpdate.mjs
function U19(h74) {
  let { inputs: l80, backend: e36, attrs: I44 } = h74, { tensor: t67, indices: n67, updates: c103 } = l80, {} = I44, { sliceRank: d55, numUpdates: r56, sliceSize: a71, strides: S45, outputSize: m96 } = backend_util_exports.calculateShapes(c103, n67, t67.shape), u86 = [m96 / a71, a71];
  if (m96 === 0) return e36.makeTensorInfo(t67.shape, n67.dtype);
  let o80 = f68({ inputs: { x: n67 }, backend: e36, attrs: { shape: [r56, d55] } }), p103 = f68({ inputs: { x: c103 }, backend: e36, attrs: { shape: [r56, a71] } }), i88 = f68({ inputs: { x: t67 }, backend: e36, attrs: { shape: u86 } }), g72 = new f77(r56, d55, o80.shape.length, p103.shape.length, S45, u86, false, true), f85 = e36.runWebGLProgram(g72, [p103, o80, i88], i88.dtype), k63 = f68({ inputs: { x: f85 }, backend: e36, attrs: { shape: t67.shape } });
  return e36.disposeIntermediateTensorInfo(o80), e36.disposeIntermediateTensorInfo(p103), e36.disposeIntermediateTensorInfo(i88), e36.disposeIntermediateTensorInfo(f85), k63;
}
var N54 = { kernelName: Tt, backendName: "webgl", kernelFunc: U19 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/tile_gpu.mjs
var u80 = class {
  constructor(t67, n67) {
    this.variableNames = ["A"];
    let r56 = new Array(t67.length);
    for (let e36 = 0; e36 < r56.length; e36++) r56[e36] = t67[e36] * n67[e36];
    this.outputShape = r56, this.rank = r56.length;
    let o80 = F22(this.rank), i88 = C23(t67);
    this.userCode = `
      void main() {
        ${o80} resRC = getOutputCoords();
        setOutput(getA(${i88}));
      }
    `;
  }
};
function C23(s84) {
  let t67 = s84.length;
  if (t67 > 5) throw Error(`Tile for rank ${t67} is not yet supported`);
  if (t67 === 1) return `imod(resRC, ${s84[0]})`;
  let n67 = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u"], r56 = [];
  for (let o80 = 0; o80 < s84.length; o80++) r56.push(`imod(${n67[o80]}, ${s84[o80]})`);
  return r56.join();
}

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Tile.mjs
function y38(a71) {
  let { inputs: p103, backend: e36, attrs: s84 } = a71, { x: t67 } = p103, { reps: o80 } = s84;
  if (t67.dtype === "string" || t67.shape.length > 5) {
    let r56 = e36.readSync(t67.dataId), c103 = t67.dtype === "string" ? r56.map((m96) => util_exports.decodeString(m96)) : r56, i88 = i7(t67.shape, t67.dtype, c103), n67 = O18(i88, o80);
    return e36.makeTensorInfo(n67.shape, n67.dtype, n67.values);
  }
  let u86 = new u80(t67.shape, o80);
  return e36.runWebGLProgram(u86, [t67], t67.dtype);
}
var P33 = { kernelName: ne, backendName: "webgl", kernelFunc: y38 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/top_k_gpu.mjs
var i81 = class {
  constructor(e36) {
    this.variableNames = ["x", "indices"], this.customUniforms = [{ name: "n", type: "int" }, { name: "firstPass", type: "int" }, { name: "negativeInf", type: "float" }, { name: "dir", type: "int" }, { name: "inc", type: "int" }], this.outputShape = e36, this.userCode = `
       void main() {
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int elemIdx = coords[1];

         // We compare elements pair-wise within a group of size 2 * inc.
         // The comparing rule for each group alternates between ascending
         // and descending. Within each group, we compare each pair at
         // positions i and i+inc. To decide whether an element at position i
         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than
         // inc, it is in the first half of the group, we denote it as x0,
         // otherwise we denote it as x1.
         // For example, as shown in the Bitonic top K paper referenced above,
         // Figure5(a) shows that element[1] is in the
         // second half of the group when group size is 2, but it is in the
         // first half of the group when group size is 4.

         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;
         int i = isFirstInPair ? elemIdx : elemIdx - inc;

         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));
         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));
         float x0 = i0 < n ? getX(batch, i0) : negativeInf;
         float x1 = i1 < n ? getX(batch, i1) : negativeInf;

         // Denotes which direction indices are in (ascending or descending).
         bool reverse = imod(elemIdx, 2 * dir) >= dir;
         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);
         if (reverse == isGreater) { // Elements in opposite order of direction
           int iTemp = i0;
           i0 = i1;
           i1 = iTemp;
         }
         if (isFirstInPair) {
            setOutput(float(i0));
         } else {
            setOutput(float(i1));
         }
       }
     `;
  }
};
var t62 = class {
  constructor(e36) {
    this.variableNames = ["x", "indices"], this.customUniforms = [{ name: "n", type: "int" }, { name: "firstPass", type: "int" }, { name: "k", type: "int" }], this.outputShape = e36, this.userCode = `
    void main() {
         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...
         ivec2 coords = getOutputCoords();
         int batch = coords[0];
         int elemIdx = coords[1];

         // The output size is half of the previous size.
         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),
         // we only need to output the indices at positions |, the indices at
         // positions _ can be thrown away, see Figure5(b) After Phase 2
         // (Merge phase) in the Bitonic Top K paper referenced above.
         // For example, the paper shows we only need to output the orange bars.
         // The output sequence should look like this | | | | | | | |.
         // Because the sequence is halved, to map the output index back
         // to the previous sequence to find the corresponding value,
         // we need to double the index. When we double the index,
         // we basically interpolate a position, so 2i looks like
         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position
         // of each 2k positions by - elemIdx % k. E.g. for output at
         // index 4,5,6,7, we want to get the corresponding element at
         // original index 8,9,10,11, for output at index 8,9,10,11,
         // we want to get the corresponding element at original index
         // 16,17,18,19, so on and so forth.

         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));
         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));
         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));

         float x0 = getX(batch, i0);
         float x1 = i1 < n ? getX(batch, i1) : x0;

         setOutput(x0 >= x1 ? float(i0) : float(i1));
       }
     `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/TopK.mjs
function p98(u86, i88) {
  i88 !== null && u86.disposeIntermediateTensorInfo(i88);
}
function v34(u86) {
  let i88 = 1;
  for (; i88 < u86; ) i88 *= 2;
  return i88;
}
function Y10(u86) {
  let { inputs: i88, backend: t67, attrs: E44 } = u86, { x: r56 } = i88, { k: l80, sorted: L22 } = E44, U24 = l().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD"), A35 = l().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD"), o80 = r56.shape, c103 = o80[o80.length - 1];
  if (t67.shouldExecuteOnCPU([r56]) || c103 < U24 || l80 > A35) {
    let s84 = t67.readSync(r56.dataId), [a71, n67] = Q9(s84, o80, r56.dtype, l80, L22);
    return [t67.makeTensorInfo(a71.shape, a71.dtype, a71.values), t67.makeTensorInfo(n67.shape, n67.dtype, n67.values)];
  }
  if (l80 === 0) return o80[o80.length - 1] = 0, [t67.makeTensorInfo(o80, r56.dtype, []), t67.makeTensorInfo(o80, "int32", [])];
  if (c103 === 1) return [r56, f72({ attrs: { shape: o80, dtype: "int32", value: 0 }, backend: t67 })];
  let D42 = t67.texData.get(r56.dataId), k63 = D42 !== null && D42.isPacked, O21 = k63 ? t67.unpackTensor(r56) : r56, d55 = util_exports.sizeFromShape(o80) / c103, m96 = f68({ inputs: { x: O21 }, attrs: { shape: [d55, c103] }, backend: t67 });
  k63 && p98(t67, O21);
  let f85 = v34(l80), N58 = v34(c103), e36 = null, H18 = () => e36 === null ? [m96, m96] : [m96, e36], K21 = (s84, a71, n67) => {
    let b58 = H18(), h74 = new i81(n67), I44 = [[c103], [e36 === null ? 1 : 0], [Number.NEGATIVE_INFINITY], [s84], [a71]], x76 = e36;
    e36 = t67.runWebGLProgram(h74, b58, "int32", I44), p98(t67, x76);
  };
  for (let s84 = 1; s84 < f85; s84 *= 2) {
    let a71 = s84 * 2;
    for (let n67 = s84; n67 >= 1; n67 /= 2) K21(a71, n67, [d55, N58]);
  }
  for (let s84 = N58; s84 > f85; s84 /= 2) {
    let a71 = H18(), n67 = new t62([d55, s84 / 2]), h74 = [[c103], [e36 === null ? 1 : 0], [f85]], w45 = e36;
    e36 = t67.runWebGLProgram(n67, a71, "int32", h74), p98(t67, w45);
    let I44 = f85 / 2, x76 = I44 * 2;
    for (let g72 = I44; g72 >= 1; g72 /= 2) K21(x76, g72, e36.shape);
  }
  let T40 = e36;
  e36 = S33({ inputs: { x: e36 }, backend: t67, attrs: { begin: 0, size: [d55, l80] } }), p98(t67, T40);
  let P36 = E38({ inputs: { x: m96, indices: e36 }, backend: t67, attrs: { axis: 1, batchDims: 1 } });
  p98(t67, m96);
  let _24 = o80.slice(0, -1);
  _24.push(l80), T40 = e36, e36 = f68({ inputs: { x: e36 }, attrs: { shape: _24 }, backend: t67 }), p98(t67, T40);
  let C28 = P36;
  return P36 = f68({ inputs: { x: P36 }, attrs: { shape: _24 }, backend: t67 }), p98(t67, C28), [P36, e36];
}
var et3 = { kernelName: se, backendName: "webgl", kernelFunc: Y10 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/transform_gpu.mjs
var e35 = class {
  constructor(t67, l80, r56, n67, a71, i88) {
    this.variableNames = ["Image", "Transforms"], this.outputShape = i88;
    let f85 = r56 === "nearest" ? 1 : 2, o80;
    switch (n67) {
      case "constant":
        o80 = 1;
        break;
      case "reflect":
        o80 = 2;
        break;
      case "wrap":
        o80 = 3;
        break;
      case "nearest":
        o80 = 4;
        break;
      default:
        o80 = 1;
        break;
    }
    this.userCode = `
            float mapCoord(float outCoord, float len) {
              float inCoord = outCoord;
              if(${o80} == 2) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    if (inCoord < sz2) {
                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +
                      inCoord;
                    }
                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz2 = 2.0 * len;
                    inCoord -= sz2 * float(int(float(inCoord / sz2)));
                    if (inCoord >= len) {
                      inCoord = sz2 - inCoord - 1.0;
                    }
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${o80} == 3) {
                if (inCoord < 0.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);
                  }
                } else if (inCoord > len - 1.0) {
                  if (len <= 1.0) {
                    inCoord = 0.0;
                  } else {
                    float sz = len - 1.0;
                    inCoord -= len * float(int(float(inCoord / sz)));
                  }
                }
                return clamp(inCoord, 0.0, len - 1.0);
              } else if (${o80} == 4) {
                return clamp(outCoord, 0.0, len - 1.0);
              } else {
                return outCoord;
              }
            }

            float readWithFillValue(int batch, int coordY, int coordX,
              int channel) {
              float outputValue;
              if (0 <= coordY && coordY < ${t67} && 0 <= coordX && coordX < ${l80}) {
                  outputValue = getImage(batch, coordY, coordX, channel);
              } else {
                outputValue = float(${a71});
              }
              return outputValue;
            }

            void main() {
              ivec4 coords = getOutputCoords();
              float outputValue;
              int batch = coords[0];
              int x = coords[2];
              int y = coords[1];
              int channel = coords[3];
              float xf = float(x);
              float yf = float(y);
              float a1 = getTransforms(batch, 0);
              float a2 = getTransforms(batch, 1);
              float a3 = getTransforms(batch, 2);
              float b1 = getTransforms(batch, 3);
              float b2 = getTransforms(batch, 4);
              float b3 = getTransforms(batch, 5);
              float c1 = getTransforms(batch, 6);
              float c2 = getTransforms(batch, 7);
              float projection = c1 * xf + c2 * yf + 1.0;
              if (projection == 0.0) {
                outputValue = float(${a71});
              } else {
                float inX = (a1 * xf + a2 * yf + a3) / projection;
                float inY = (b1 * xf + b2 * yf + b3) / projection;
                float mapX = mapCoord(inX, float(${l80}));
                float mapY = mapCoord(inY, float(${t67}));

                if (${f85} == 1) {
                  int coordY = int(round(mapY));
                  int coordX = int(round(mapX));
                  outputValue = readWithFillValue(batch, coordY, coordX,
                    channel);
                } else {
                  float yFloor = floor(mapY);
                  float xFloor = floor(mapX);
                  float yCeil = yFloor + 1.0;
                  float xCeil = xFloor + 1.0;
                  float valueYFloor = (xCeil - mapX) *
                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);
                  float valueYCeil = (xCeil - mapX) *
                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +
                  (mapX - xFloor) *
                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);
                  outputValue = (yCeil - mapY) * valueYFloor +
                  (mapY - yFloor) * valueYCeil;
                }
              }
              setOutput(outputValue);
            }
        `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Transform.mjs
function w42(e36) {
  let { inputs: a71, backend: m96, attrs: s84 } = e36, { image: t67, transforms: i88 } = a71, { interpolation: c103, fillMode: l80, fillValue: u86, outputShape: o80 } = s84, [f85, n67, r56, p103] = t67.shape, [g72, h74] = o80 ?? [n67, r56], b58 = [f85, g72, h74, p103], d55 = new e35(n67, r56, c103, l80, u86, b58);
  return m96.runWebGLProgram(d55, [t67, i88], "float32");
}
var H14 = { kernelName: pe, backendName: "webgl", kernelFunc: w42 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Unique.mjs
function l71(t67) {
  let { inputs: a71, attrs: r56, backend: n67 } = t67, { axis: s84 } = r56, { x: e36 } = a71;
  be(e36, "unique"), console.warn("WARNING: ", "UI might be locked temporarily as data is being downloaded");
  let i88 = n67.readSync(e36.dataId), { outputValues: u86, outputShape: p103, indices: o80 } = X17(i88, s84, e36.shape, e36.dtype);
  return [n67.makeTensorInfo(p103, e36.dtype, u86), n67.makeTensorInfo([o80.length], "int32", o80)];
}
var b54 = { kernelName: ae, backendName: "webgl", kernelFunc: l71 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/Unpack.mjs
function y39(u86) {
  let { inputs: f85, backend: s84, attrs: m96 } = u86, { value: o80 } = f85, { axis: n67 } = m96;
  n67 < 0 && (n67 += o80.shape.length);
  let t67 = o80, r56 = t67.shape.length, k63 = o80.shape[n67], c103 = new Array(r56 - 1), d55 = 0;
  for (let e36 = 0; e36 < r56; e36++) e36 !== n67 && (c103[d55++] = t67.shape[e36]);
  let p103 = [], i88 = new Array(r56).fill(0), l80 = t67.shape.slice();
  l80[n67] = 1;
  let a71 = new Array(k63);
  for (let e36 = 0; e36 < a71.length; e36++) {
    i88[n67] = e36;
    let h74 = S33({ inputs: { x: t67 }, backend: s84, attrs: { begin: i88, size: l80 } }), x76 = f68({ inputs: { x: h74 }, backend: s84, attrs: { shape: c103 } });
    a71[e36] = x76, p103.push(h74);
  }
  return p103.forEach((e36) => s84.disposeIntermediateTensorInfo(e36)), a71;
}
var v35 = { kernelName: xe, backendName: "webgl", kernelFunc: y39 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/segment_gpu.mjs
var I41 = class {
  constructor(i88, S45) {
    this.variableNames = ["x", "segmentIds"];
    let e36 = i88.windowSize, g72 = i88.batchSize, t67 = i88.inSize, a71 = i88.numSegments, o80 = a71 * Math.ceil(t67 / e36);
    this.outputShape = [g72, o80];
    let r56 = "0.0", x76 = "sumValue", u86 = Math.floor(e36 / 4) * 4, d55 = e36 % 4, n67 = `
        sumValue += dot(values, segFilter);
    `, c103 = "";
    t67 % e36 > 0 && (c103 = `
        if (inIdx < 0 || inIdx >= ${t67}) {
          return initializationValue;
        }
      `);
    let l80 = "";
    t67 % e36 > 0 && (l80 = `
        if (inIdx < 0 || inIdx >= ${t67}) {
          return -1.0;
        }
      `), this.userCode = `
      const float initializationValue = ${r56};

      float getValue(int batch, int inIdx) {
        ${c103}
        return getX(batch, inIdx);
      }

      float getSegmentIdAtIndex(int inIdx) {
        ${l80}
        return getSegmentIds(inIdx);
      }

      void main() {
        ivec2 coords = getOutputCoords();
        int batch = coords[0];
        int outIdx = coords[1];
        int inOffset = int(floor(float(outIdx) / float(
          ${a71})) * float(${e36}));
        int currentSeg = int(mod(float(outIdx), float(${a71})));

        float sumValue = 0.0;

        for (int i = 0; i < ${u86}; i += 4) {
          int inIdx = inOffset + i;
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            getValue(batch, inIdx + 3)
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0
          );

          ${n67}
        }

        int inIdx = inOffset + ${u86};
        if (${d55 === 1}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            initializationValue,
            initializationValue,
            initializationValue
          );

          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            0,
            0,
            0
          );

          ${n67}
        } else if (${d55 === 2}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            initializationValue,
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
              0,
              0
          );

          ${n67}
        } else if (${d55 === 3}) {
          vec4 values = vec4(
            getValue(batch, inIdx),
            getValue(batch, inIdx + 1),
            getValue(batch, inIdx + 2),
            initializationValue
          );

          vec4 segFilter = vec4(
            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,
            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,
            0
          );

          ${n67}
        }
        setOutput(${x76});
      }
    `;
  }
};

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/kernels/UnsortedSegmentSum.mjs
function v36(w45) {
  let { inputs: A35, backend: t67, attrs: C28 } = w45, { x: p103, segmentIds: D42 } = A35, { numSegments: l80 } = C28, h74 = p103.shape.length, e36 = [], u86 = 0, a71 = backend_util_exports.getAxesPermutation([u86], h74), n67 = p103;
  a71 != null && (n67 = h59({ inputs: { x: p103 }, backend: t67, attrs: { perm: a71 } }), e36.push(n67), u86 = backend_util_exports.getInnerMostAxes(1, h74)[0]);
  let P36 = backend_util_exports.segment_util.computeOutShape(n67.shape, u86, l80), R26 = util_exports.sizeFromShape([n67.shape[u86]]), g72 = f68({ inputs: { x: n67 }, backend: t67, attrs: { shape: [-1, R26] } });
  e36.push(g72);
  let _24 = l6(p103.dtype), d55 = (s84, S45, F32, x76, o80) => {
    let N58 = s84.shape[0], c103 = s84.shape[1], I44 = backend_util_exports.segment_util.segOpComputeOptimalWindowSize(c103, o80), T40 = { windowSize: I44, inSize: c103, batchSize: N58, numSegments: o80 }, U24 = new I41(T40, S45), i88 = t67.compileAndRun(U24, [s84, F32], x76);
    if (e36.push(i88), i88.shape[1] === o80) return i88;
    let O21 = g62({ backend: t67, attrs: { start: 0, stop: o80, step: 1, dtype: "float32" } }), k63 = y38({ inputs: { x: O21 }, backend: t67, attrs: { reps: [c103 / I44] } });
    return e36.push(O21), e36.push(k63), d55(i88, S45, k63, x76, o80);
  }, y43 = d55(g72, "unsortedSegmentSum", D42, _24, l80), f85 = f68({ inputs: { x: y43 }, backend: t67, attrs: { shape: P36 } }), m96 = f85;
  if (a71 != null) {
    e36.push(f85);
    let s84 = backend_util_exports.getUndoAxesPermutation(a71);
    m96 = h59({ inputs: { x: m96 }, backend: t67, attrs: { perm: s84 } });
  }
  return e36.forEach((s84) => t67.disposeIntermediateTensorInfo(s84)), m96;
}
var V22 = { kernelName: ie, backendName: "webgl", kernelFunc: v36 };

// https://esm.sh/@tensorflow/tfjs-backend-webgl@4.22.0/denonext/dist/register_all_kernels.mjs
var ai = [k37, P24, p71, s49, a49, E36, P25, N42, I31, I32, p72, s50, c77, p73, N43, D25, k38, D26, G22, m74, P26, y33, f70, k41, l55, D27, t41, V15, g53, b41, S34, x58, b42, B25, g56, D29, D30, i60, p78, x59, x60, k43, g58, C18, N45, w34, w35, b43, I35, j19, l58, G23, m77, i63, x62, x63, x64, i64, g59, c81, c82, a55, A28, q19, V16, D32, U17, l61, c83, c76, p83, s53, p84, i67, N47, R21, m79, c84, f73, p87, c85, l63, c86, l64, k45, N48, V17, A29, D33, k46, M24, C19, P28, N49, P29, b47, f74, i69, z29, w31, C20, b49, f75, T36, m76, w37, b51, T38, x68, N50, L19, N51, V18, h68, w38, f76, s52, c87, t57, o69, i74, b36, u76, g63, d43, b52, h70, w39, a64, c89, C22, S37, u77, s65, N52, p91, m85, i79, k40, F26, p92, V19, E40, w41, S39, g64, U18, V21, l70, p94, c91, d45, i80, R22, I40, k53, f78, b48, k36, p96, p97, N54, P33, et3, H14, T31, b54, v35, V22, T37];
for (let o80 of ai) p3(o80);

// https://esm.sh/@tensorflow/tfjs-converter@4.22.0/denonext/tfjs-converter.mjs
import { Buffer as __Buffer$2 } from "node:buffer";

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/ops_for_converter.mjs
var ops_for_converter_exports = {};
__export(ops_for_converter_exports, {
  OP_SCOPE_SUFFIX: () => p9,
  abs: () => b9,
  acos: () => u8,
  acosh: () => h7,
  add: () => T7,
  addN: () => c11,
  all: () => E7,
  any: () => y9,
  argMax: () => u9,
  argMin: () => u10,
  asin: () => u11,
  asinh: () => h8,
  atan: () => x12,
  atan2: () => E8,
  atanh: () => x13,
  avgPool: () => T8,
  avgPool3d: () => H5,
  basicLSTMCell: () => N7,
  batchNorm: () => F5,
  batchNorm2d: () => g7,
  batchNorm3d: () => g8,
  batchNorm4d: () => g9,
  batchToSpaceND: () => N8,
  bincount: () => $7,
  bitwiseAnd: () => A6,
  booleanMaskAsync: () => q9,
  broadcastArgs: () => f12,
  broadcastTo: () => v10,
  buffer: () => i7,
  cast: () => w12,
  ceil: () => x17,
  clipByValue: () => x18,
  clone: () => x11,
  complex: () => x8,
  concat: () => E9,
  concat1d: () => p19,
  concat2d: () => a9,
  concat3d: () => a10,
  concat4d: () => a11,
  conv1d: () => W5,
  conv2d: () => C5,
  conv2dTranspose: () => u12,
  conv3d: () => T9,
  conv3dTranspose: () => d7,
  cos: () => u13,
  cosh: () => h14,
  cosineWindow: () => M6,
  cumprod: () => E12,
  cumsum: () => N9,
  denseBincount: () => f14,
  depthToSpace: () => l15,
  depthwiseConv2d: () => g11,
  diag: () => a12,
  dilation2d: () => C6,
  div: () => D6,
  divNoNan: () => z6,
  dot: () => z7,
  dropout: () => _10,
  einsum: () => N10,
  elu: () => s12,
  enclosingPowerOfTwo: () => f35,
  ensureShape: () => u17,
  equal: () => E13,
  erf: () => x20,
  euclideanNorm: () => u19,
  exp: () => u20,
  expandDims: () => D7,
  expm1: () => u21,
  eye: () => $9,
  fft: () => l24,
  fill: () => c16,
  floor: () => x24,
  floorDiv: () => b8,
  fused: () => fused_ops_exports,
  gather: () => E15,
  gatherND: () => h25,
  greater: () => G6,
  greaterEqual: () => h18,
  ifft: () => l25,
  imag: () => a16,
  image: () => go2,
  inTopKAsync: () => w18,
  irfft: () => G10,
  isFinite: () => u23,
  isInf: () => x25,
  isNaN: () => x26,
  leakyRelu: () => x27,
  less: () => d11,
  lessEqual: () => b15,
  linalg: () => bo2,
  linspace: () => f18,
  localResponseNormalization: () => T11,
  log: () => x29,
  log1p: () => g13,
  logSigmoid: () => G7,
  logSoftmax: () => A8,
  logSumExp: () => z9,
  logicalAnd: () => g16,
  logicalNot: () => s18,
  logicalOr: () => u25,
  logicalXor: () => b16,
  losses: () => Eo2,
  lowerBound: () => n11,
  matMul: () => N6,
  max: () => d10,
  maxPool: () => O6,
  maxPool3d: () => W6,
  maxPoolWithArgmax: () => P6,
  maximum: () => E18,
  mean: () => E19,
  meshgrid: () => $11,
  min: () => E14,
  minimum: () => G8,
  mirrorPad: () => k14,
  mod: () => T13,
  moments: () => g17,
  movingAverage: () => _9,
  mul: () => y8,
  multiRNNCell: () => w14,
  multinomial: () => D8,
  neg: () => g14,
  norm: () => z8,
  notEqual: () => b18,
  oneHot: () => w15,
  ones: () => c26,
  onesLike: () => k15,
  op: () => u4,
  outerProduct: () => P7,
  pad: () => l20,
  pad1d: () => i16,
  pad2d: () => a17,
  pad3d: () => u28,
  pad4d: () => u29,
  pool: () => z10,
  pow: () => x22,
  prelu: () => x32,
  print: () => t3,
  prod: () => N13,
  raggedGather: () => $14,
  raggedRange: () => N14,
  raggedTensorToTensor: () => E20,
  rand: () => A9,
  randomGamma: () => p33,
  randomNormal: () => w17,
  randomStandardNormal: () => f25,
  randomUniform: () => U6,
  randomUniformInt: () => d14,
  range: () => p35,
  real: () => s21,
  reciprocal: () => x33,
  relu: () => s22,
  relu6: () => s23,
  reshape: () => h9,
  reverse: () => E21,
  reverse1d: () => u33,
  reverse2d: () => v15,
  reverse3d: () => v16,
  reverse4d: () => v17,
  rfft: () => K8,
  round: () => x34,
  rsqrt: () => q8,
  scalar: () => m21,
  scatterND: () => I13,
  searchSorted: () => T12,
  selu: () => l23,
  separableConv2d: () => T16,
  setdiff1dAsync: () => b19,
  sigmoid: () => d6,
  sign: () => g19,
  signal: () => $23,
  sin: () => u34,
  sinh: () => h21,
  slice: () => E10,
  slice1d: () => f27,
  slice2d: () => f28,
  slice3d: () => f29,
  slice4d: () => f30,
  softmax: () => g20,
  softplus: () => l18,
  spaceToBatchND: () => x31,
  sparse: () => Co2,
  sparseToDense: () => g24,
  spectral: () => j9,
  split: () => N17,
  sqrt: () => q6,
  square: () => p24,
  squaredDifference: () => T17,
  squeeze: () => a23,
  stack: () => g21,
  step: () => N18,
  stridedSlice: () => a24,
  string: () => Oo2,
  sub: () => E16,
  sum: () => T10,
  tan: () => x35,
  tanh: () => x16,
  tensor: () => p10,
  tensor1d: () => m25,
  tensor2d: () => h22,
  tensor3d: () => s28,
  tensor4d: () => u36,
  tensor5d: () => h23,
  tensor6d: () => a25,
  tensorScatterUpdate: () => $18,
  tile: () => g12,
  topk: () => x36,
  transpose: () => A10,
  truncatedNormal: () => v18,
  unique: () => v19,
  unsortedSegmentSum: () => N19,
  unstack: () => g22,
  upperBound: () => n12,
  variable: () => m27,
  where: () => G5,
  whereAsync: () => p41,
  zeros: () => e13,
  zerosLike: () => k11
});

// https://esm.sh/@tensorflow/tfjs-converter@4.22.0/denonext/tfjs-converter.mjs
var At2 = Object.defineProperty;
var S40 = (a71, e36) => {
  for (var t67 in e36) At2(a71, t67, { get: e36[t67], enumerable: true });
};
var kt2 = l();
kt2.registerFlag("KEEP_INTERMEDIATE_TENSORS", () => false, (a71) => {
  a71 && console.warn("Keep intermediate tensors is ON. This will print the values of all intermediate tensors during model inference. Not all models support this mode. For details, check e2e/benchmarks/ model_config.js. This significantly impacts performance.");
});
var _22;
(function(a71) {
  a71[a71.DT_INVALID = 0] = "DT_INVALID", a71[a71.DT_FLOAT = 1] = "DT_FLOAT", a71[a71.DT_DOUBLE = 2] = "DT_DOUBLE", a71[a71.DT_INT32 = 3] = "DT_INT32", a71[a71.DT_UINT8 = 4] = "DT_UINT8", a71[a71.DT_INT16 = 5] = "DT_INT16", a71[a71.DT_INT8 = 6] = "DT_INT8", a71[a71.DT_STRING = 7] = "DT_STRING", a71[a71.DT_COMPLEX64 = 8] = "DT_COMPLEX64", a71[a71.DT_INT64 = 9] = "DT_INT64", a71[a71.DT_BOOL = 10] = "DT_BOOL", a71[a71.DT_QINT8 = 11] = "DT_QINT8", a71[a71.DT_QUINT8 = 12] = "DT_QUINT8", a71[a71.DT_QINT32 = 13] = "DT_QINT32", a71[a71.DT_BFLOAT16 = 14] = "DT_BFLOAT16", a71[a71.DT_QINT16 = 15] = "DT_QINT16", a71[a71.DT_QUINT16 = 16] = "DT_QUINT16", a71[a71.DT_UINT16 = 17] = "DT_UINT16", a71[a71.DT_COMPLEX128 = 18] = "DT_COMPLEX128", a71[a71.DT_HALF = 19] = "DT_HALF", a71[a71.DT_RESOURCE = 20] = "DT_RESOURCE", a71[a71.DT_VARIANT = 21] = "DT_VARIANT", a71[a71.DT_UINT32 = 22] = "DT_UINT32", a71[a71.DT_UINT64 = 23] = "DT_UINT64", a71[a71.DT_FLOAT_REF = 101] = "DT_FLOAT_REF", a71[a71.DT_DOUBLE_REF = 102] = "DT_DOUBLE_REF", a71[a71.DT_INT32_REF = 103] = "DT_INT32_REF", a71[a71.DT_UINT8_REF = 104] = "DT_UINT8_REF", a71[a71.DT_INT16_REF = 105] = "DT_INT16_REF", a71[a71.DT_INT8_REF = 106] = "DT_INT8_REF", a71[a71.DT_STRING_REF = 107] = "DT_STRING_REF", a71[a71.DT_COMPLEX64_REF = 108] = "DT_COMPLEX64_REF", a71[a71.DT_INT64_REF = 109] = "DT_INT64_REF", a71[a71.DT_BOOL_REF = 110] = "DT_BOOL_REF", a71[a71.DT_QINT8_REF = 111] = "DT_QINT8_REF", a71[a71.DT_QUINT8_REF = 112] = "DT_QUINT8_REF", a71[a71.DT_QINT32_REF = 113] = "DT_QINT32_REF", a71[a71.DT_BFLOAT16_REF = 114] = "DT_BFLOAT16_REF", a71[a71.DT_QINT16_REF = 115] = "DT_QINT16_REF", a71[a71.DT_QUINT16_REF = 116] = "DT_QUINT16_REF", a71[a71.DT_UINT16_REF = 117] = "DT_UINT16_REF", a71[a71.DT_COMPLEX128_REF = 118] = "DT_COMPLEX128_REF", a71[a71.DT_HALF_REF = 119] = "DT_HALF_REF", a71[a71.DT_RESOURCE_REF = 120] = "DT_RESOURCE_REF", a71[a71.DT_VARIANT_REF = 121] = "DT_VARIANT_REF", a71[a71.DT_UINT32_REF = 122] = "DT_UINT32_REF", a71[a71.DT_UINT64_REF = 123] = "DT_UINT64_REF";
})(_22 || (_22 = {}));
var Fe2;
(function(a71) {
  let e36;
  (function(t67) {
    t67[t67.LEGACY = 0] = "LEGACY", t67[t67.V1 = 1] = "V1", t67[t67.V2 = 2] = "V2";
  })(e36 = a71.CheckpointFormatVersion || (a71.CheckpointFormatVersion = {}));
})(Fe2 || (Fe2 = {}));
var oe6 = {};
function Lt2(a71, e36) {
  let t67 = { tfOpName: a71, category: "custom", inputs: [], attrs: [], customExecutor: e36 };
  oe6[a71] = t67;
}
function H15(a71) {
  return oe6[a71];
}
function Dt2(a71) {
  delete oe6[a71];
}
function r51(a71, e36, t67, s84, n67) {
  let i88 = e36.inputParams[a71];
  if (i88 && i88.inputIndexStart !== void 0) {
    let m96 = i88.inputIndexStart, u86 = i88.inputIndexEnd === 0 ? void 0 : i88.inputIndexEnd === void 0 ? m96 + 1 : i88.inputIndexEnd, o80 = m96 < 0 ? e36.inputNames.length + m96 : m96;
    if (i88.type === "tensor") return b55(e36.inputNames[o80], t67, s84, n67);
    if (i88.type === "tensors") {
      let c103 = e36.inputs.slice(m96, u86);
      return e36.inputNames.slice(m96, u86).filter((N58, f85) => {
        var d55;
        return ((d55 = c103[f85]) === null || d55 === void 0 ? void 0 : d55.op) !== "NoOp";
      }).map((N58) => b55(N58, t67, s84, n67));
    }
    let l80 = b55(e36.inputNames[o80], t67, s84, n67), y43 = l80.dataSync();
    return i88.type === "number" ? y43[0] : util_exports.toNestedArray(l80.shape, y43);
  }
  let p103 = e36.attrParams[a71];
  return p103 && p103.value;
}
function b55(a71, e36, t67, s84) {
  let [n67, i88] = w43(a71, t67);
  if (s84 != null) {
    let m96 = s84.getHashTableHandleByName(n67);
    if (m96 != null) return m96;
  }
  let p103 = t67.currentContextIds.find((m96) => !!e36[U20(n67, m96)]);
  return p103 !== void 0 ? e36[U20(n67, p103)][i88] : void 0;
}
function le4(a71, e36, t67) {
  return e36[U20(a71, t67.currentContextId)];
}
function E41(a71, e36) {
  let [t67, s84, n67] = w43(a71, e36);
  return [U20(t67, e36 && e36.currentContextId), s84, n67];
}
function U20(a71, e36) {
  return e36 ? `${a71}-${e36}` : a71;
}
function w43(a71, e36) {
  if (a71 === "") return ["", 0, void 0];
  let t67 = e36 != null && e36.parseNodeNameCache != null;
  if (t67) {
    let i88 = e36.parseNodeNameCache.get(a71);
    if (i88 != null) return i88;
  }
  let s84 = a71.split(":"), n67;
  if (s84.length === 1) n67 = [a71, 0, void 0];
  else {
    let i88 = s84[0], p103 = s84.length === 3 ? s84[1] : void 0, m96 = Number(s84[s84.length - 1]);
    n67 = [i88, m96, p103];
  }
  return t67 && e36.parseNodeNameCache.set(a71, n67), n67;
}
function F27(a71, e36, t67) {
  let s84 = r51("pad", a71, e36, t67);
  if (s84 === "explicit") {
    s84 = r51("explicitPaddings", a71, e36, t67);
    let n67 = [[0, 0], [0, 0], [0, 0], [0, 0]];
    for (let i88 = 0; i88 < 4; i88++) n67[i88][0] = s84[i88 * 2], n67[i88][1] = s84[i88 * 2 + 1];
    return n67;
  }
  return s84;
}
function A30(a71) {
  return a71.kept ? a71 : x11(a71);
}
var ce4 = {};
S40(ce4, { json: () => zt2 });
var zt2 = [{ tfOpName: "Add", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "AddV2", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "AddN", category: "arithmetic", inputs: [{ start: 0, end: 0, name: "tensors", type: "tensors" }] }, { tfOpName: "BiasAdd", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }, { tfName: "data_format", name: "dataFormat", type: "string", notSupported: true }] }, { tfOpName: "Sub", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "RealDiv", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Div", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "DivNoNan", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "FloorDiv", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Mul", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Maximum", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Minimum", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Pow", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "SquaredDifference", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Mod", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "FloorMod", category: "arithmetic", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }];
var ye = {};
S40(ye, { json: () => Ft4 });
var Ft4 = [{ tfOpName: "Abs", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Acos", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Asin", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Atan", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Atan2", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "y", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Ceil", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "ClipByValue", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "clipValueMin", type: "number" }, { start: 2, name: "clipValueMax", type: "number" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Complex", category: "basic_math", inputs: [{ start: 0, name: "real", type: "tensor" }, { start: 1, name: "imag", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "ComplexAbs", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Cos", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Cosh", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Elu", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Exp", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Floor", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Log", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Imag", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }, { tfName: "Tout", name: "outputType", type: "dtype", notSupported: true }] }, { tfOpName: "Neg", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Real", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }, { tfName: "Tout", name: "outputType", type: "dtype", notSupported: true }] }, { tfOpName: "Prelu", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "alpha", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Relu", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Relu6", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Selu", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Sigmoid", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Sin", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Sinh", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Sqrt", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Rsqrt", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Square", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Tan", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Tanh", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Sign", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Round", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Expm1", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Log1p", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Reciprocal", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Softplus", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Asinh", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Acosh", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Atanh", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Erf", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "LeakyRelu", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "alpha", name: "alpha", type: "number", defaultValue: 0.2 }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "IsNan", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "IsFinite", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "IsInf", category: "basic_math", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }];
var de3 = {};
S40(de3, { json: () => Rt2 });
var Rt2 = [{ tfOpName: "EmptyTensorList", category: "control", inputs: [{ start: 0, name: "elementShape", type: "shape" }, { start: 1, name: "maxNumElements", type: "number" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "LoopCond", category: "control", inputs: [{ start: 0, name: "pred", type: "tensor" }] }, { tfOpName: "Switch", category: "control", inputs: [{ start: 0, name: "data", type: "tensor" }, { start: 1, name: "pred", type: "tensor" }] }, { tfOpName: "Merge", category: "control", inputs: [{ start: 0, end: 0, name: "tensors", type: "tensors" }] }, { tfOpName: "Enter", category: "control", inputs: [{ start: 0, name: "tensor", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }, { tfName: "frame_name", name: "frameName", type: "string" }, { tfName: "is_constant", name: "isConstant", type: "bool" }] }, { tfOpName: "Exit", category: "control", inputs: [{ start: 0, name: "tensor", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "NextIteration", category: "control", inputs: [{ start: 0, name: "tensor", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "TensorArrayV3", category: "control", inputs: [{ start: 0, name: "size", type: "number" }], attrs: [{ tfName: "dtype", name: "dtype", type: "dtype" }, { tfName: "element_shape", name: "elementShape", type: "shape" }, { tfName: "dynamic_size", name: "dynamicSize", type: "bool" }, { tfName: "clear_after_read", name: "clearAfterRead", type: "bool" }, { tfName: "identical_element_shapes", name: "identicalElementShapes", type: "bool" }, { tfName: "tensor_array_name", name: "name", type: "string" }] }, { tfOpName: "TensorArrayWriteV3", category: "control", inputs: [{ start: 0, name: "tensorArrayId", type: "tensor" }, { start: 1, name: "index", type: "number" }, { start: 2, name: "tensor", type: "tensor" }, { start: 3, name: "flowIn", type: "number" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "TensorArrayReadV3", category: "control", inputs: [{ start: 0, name: "tensorArrayId", type: "tensor" }, { start: 1, name: "index", type: "number" }, { start: 2, name: "flowIn", type: "number" }], attrs: [{ tfName: "dtype", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "TensorArrayGatherV3", category: "control", inputs: [{ start: 0, name: "tensorArrayId", type: "tensor" }, { start: 1, name: "indices", type: "number[]" }, { start: 2, name: "flowIn", type: "number" }], attrs: [{ tfName: "dtype", name: "dtype", type: "dtype" }, { tfName: "element_shape", name: "elementShape", type: "shape" }] }, { tfOpName: "TensorArrayScatterV3", category: "control", inputs: [{ start: 0, name: "tensorArrayId", type: "tensor" }, { start: 1, name: "indices", type: "number[]" }, { start: 2, name: "tensor", type: "tensor" }, { start: 3, name: "flowIn", type: "number" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype" }] }, { tfOpName: "TensorArrayConcatV3", category: "control", inputs: [{ start: 0, name: "tensorArrayId", type: "tensor" }, { start: 1, name: "flowIn", type: "number" }], attrs: [{ tfName: "dtype", name: "dtype", type: "dtype" }, { tfName: "element_shape_except0", name: "elementShapeExcept0", type: "shape", notSupported: true }] }, { tfOpName: "TensorArraySplitV3", category: "control", inputs: [{ start: 0, name: "tensorArrayId", type: "tensor" }, { start: 1, name: "tensor", type: "tensor" }, { start: 2, name: "lengths", type: "number[]" }, { start: 3, name: "flowIn", type: "number" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype" }] }, { tfOpName: "TensorArraySizeV3", category: "control", inputs: [{ start: 0, name: "tensorArrayId", type: "tensor" }, { start: 1, name: "flowIn", type: "number" }] }, { tfOpName: "TensorArrayCloseV3", category: "control", inputs: [{ start: 0, name: "tensorArrayId", type: "tensor" }] }, { tfOpName: "StatelessIf", category: "control", inputs: [{ start: 0, name: "cond", type: "tensor" }, { start: 1, end: 0, name: "args", type: "tensors" }], attrs: [{ tfName: "then_branch", name: "thenBranch", type: "func" }, { tfName: "else_branch", name: "elseBranch", type: "func" }] }, { tfOpName: "If", category: "control", inputs: [{ start: 0, name: "cond", type: "tensor" }, { start: 1, end: 0, name: "args", type: "tensors" }], attrs: [{ tfName: "then_branch", name: "thenBranch", type: "func" }, { tfName: "else_branch", name: "elseBranch", type: "func" }] }, { tfOpName: "StatelessWhile", category: "control", inputs: [{ start: 0, end: 0, name: "args", type: "tensors" }], attrs: [{ tfName: "cond", name: "cond", type: "func" }, { tfName: "body", name: "body", type: "func" }] }, { tfOpName: "While", category: "control", inputs: [{ start: 0, end: 0, name: "args", type: "tensors" }], attrs: [{ tfName: "cond", name: "cond", type: "func" }, { tfName: "body", name: "body", type: "func" }] }, { tfOpName: "TensorListScatter", category: "control", inputs: [{ start: 0, name: "tensor", type: "tensor" }, { start: 1, name: "indices", type: "number[]" }, { start: 2, name: "elementShape", type: "shape" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListScatterV2", category: "control", inputs: [{ start: 0, name: "tensor", type: "tensor" }, { start: 1, name: "indices", type: "number[]" }, { start: 2, name: "elementShape", type: "shape" }, { start: 3, name: "numElements", type: "number" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListGather", category: "control", inputs: [{ start: 0, name: "tensorListId", type: "tensor" }, { start: 1, name: "indices", type: "number[]" }, { start: 2, name: "elementShape", type: "shape" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListGetItem", category: "control", inputs: [{ start: 0, name: "tensorListId", type: "tensor" }, { start: 1, name: "index", type: "number" }, { start: 2, name: "elementShape", type: "shape" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListSetItem", category: "control", inputs: [{ start: 0, name: "tensorListId", type: "tensor" }, { start: 1, name: "index", type: "number" }, { start: 2, name: "tensor", type: "tensor" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListReserve", category: "control", inputs: [{ start: 0, name: "elementShape", type: "shape" }, { start: 1, name: "numElements", type: "number" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListFromTensor", category: "control", inputs: [{ start: 0, name: "tensor", type: "tensor" }, { start: 1, name: "elementShape", type: "shape" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListStack", category: "control", inputs: [{ start: 0, name: "tensorListId", type: "tensor" }, { start: 1, name: "elementShape", type: "shape" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }, { tfName: "num_elements", name: "numElements", type: "dtype" }] }, { tfOpName: "TensorListSplit", category: "control", inputs: [{ start: 0, name: "tensor", type: "tensor" }, { start: 1, name: "elementShape", type: "shape" }, { start: 2, name: "lengths", type: "number[]" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListConcat", category: "control", inputs: [{ start: 0, name: "tensorListId", type: "tensor" }], attrs: [{ tfName: "element_shape", name: "elementShape", type: "shape" }, { tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListConcatV2", category: "control", inputs: [{ start: 0, name: "tensorListId", type: "tensor" }], attrs: [{ tfName: "element_shape", name: "elementShape", type: "shape" }, { tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListPopBack", category: "control", inputs: [{ start: 0, name: "tensorListId", type: "tensor" }, { start: 1, name: "elementShape", type: "shape" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListPushBack", category: "control", inputs: [{ start: 0, name: "tensorListId", type: "tensor" }, { start: 1, name: "tensor", type: "tensor" }], attrs: [{ tfName: "element_dtype", name: "elementDType", type: "dtype" }] }, { tfOpName: "TensorListLength", category: "control", inputs: [{ start: 0, name: "tensorListId", type: "tensor" }] }, { tfOpName: "TensorListResize", category: "control", inputs: [{ start: 0, name: "tensorListId", type: "tensor" }, { start: 1, name: "size", type: "number" }] }];
var he3 = {};
S40(he3, { json: () => Pt2 });
var Pt2 = [{ tfOpName: "AvgPool", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "data_format", name: "dataFormat", type: "string", notSupported: true }, { tfName: "ksize", name: "kernelSize", type: "number[]" }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "MaxPool", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "data_format", name: "dataFormat", type: "string", notSupported: true }, { tfName: "ksize", name: "kernelSize", type: "number[]" }, { tfName: "explicit_paddings", name: "explicitPaddings", type: "number[]", defaultValue: [], notSupported: true }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "MaxPoolWithArgmax", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "ksize", name: "kernelSize", type: "number[]" }, { tfName: "include_batch_in_index", name: "includeBatchInIndex", type: "bool" }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "AvgPool3D", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "data_format", name: "dataFormat", type: "string", notSupported: true }, { tfName: "ksize", name: "kernelSize", type: "number[]" }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "MaxPool3D", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "data_format", name: "dataFormat", type: "string", notSupported: true }, { tfName: "ksize", name: "kernelSize", type: "number[]" }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Conv1D", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "filter", type: "tensor" }], attrs: [{ tfName: "stride", name: "stride", type: "number" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "data_format", name: "dataFormat", type: "string", defaultValue: "NWC" }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }, { tfName: "dilation", name: "dilation", type: "number", defaultValue: 1 }] }, { tfOpName: "Conv2D", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "filter", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }, { tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "useCudnnOnGpu", name: "useCudnnOnGpu", type: "bool" }, { tfName: "data_format", name: "dataFormat", type: "string", defaultValue: "NHWC" }, { tfName: "explicit_paddings", name: "explicitPaddings", type: "number[]", defaultValue: [] }, { tfName: "dilations", name: "dilations", type: "number[]" }] }, { tfOpName: "_FusedConv2D", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "filter", type: "tensor" }, { start: 2, end: 0, name: "args", type: "tensors" }], attrs: [{ tfName: "num_args", name: "numArgs", type: "number" }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }, { tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "explicit_paddings", name: "explicitPaddings", type: "number[]", defaultValue: [] }, { tfName: "use_cudnn_on_gpu", name: "useCudnnOnGpu", type: "bool", defaultValue: true }, { tfName: "data_format", name: "dataFormat", type: "string", defaultValue: "NHWC" }, { tfName: "dilations", name: "dilations", type: "number[]", defaultValue: [1, 1, 1, 1] }, { tfName: "fused_ops", name: "fusedOps", type: "string[]", defaultValue: [] }, { tfName: "epsilon", name: "epsilon", type: "number", defaultValue: 1e-4 }, { tfName: "leakyrelu_alpha", name: "leakyreluAlpha", type: "number", defaultValue: 0.2 }] }, { tfOpName: "Conv2DBackpropInput", category: "convolution", inputs: [{ start: 2, name: "x", type: "tensor" }, { start: 1, name: "filter", type: "tensor" }, { start: 0, name: "outputShape", type: "number[]" }], attrs: [{ tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "data_format", name: "dataFormat", type: "string", notSupported: true }, { tfName: "explicit_paddings", name: "explicitPaddings", type: "number[]", defaultValue: [] }, { tfName: "dilations", name: "dilations", type: "number[]", notSupported: true }] }, { tfOpName: "DepthwiseConv2d", category: "convolution", inputs: [{ start: 0, name: "input", type: "tensor" }, { start: 1, name: "filter", type: "tensor" }], attrs: [{ tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "data_format", name: "dataFormat", type: "string", defaultValue: "NHWC" }, { tfName: "explicit_paddings", name: "explicitPaddings", type: "number[]", defaultValue: [] }, { tfName: "dilations", name: "dilations", type: "number[]" }] }, { tfOpName: "DepthwiseConv2dNative", category: "convolution", inputs: [{ start: 0, name: "input", type: "tensor" }, { start: 1, name: "filter", type: "tensor" }], attrs: [{ tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "data_format", name: "dataFormat", type: "string", defaultValue: "NHWC" }, { tfName: "explicit_paddings", name: "explicitPaddings", type: "number[]", defaultValue: [] }, { tfName: "dilations", name: "dilations", type: "number[]" }] }, { tfOpName: "FusedDepthwiseConv2dNative", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "filter", type: "tensor" }, { start: 2, end: 0, name: "args", type: "tensors" }], attrs: [{ tfName: "num_args", name: "numArgs", type: "number" }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }, { tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "data_format", name: "dataFormat", type: "string", defaultValue: "NHWC" }, { tfName: "dilations", name: "dilations", type: "number[]", defaultValue: [1, 1, 1, 1] }, { tfName: "fused_ops", name: "fusedOps", type: "string[]", defaultValue: [] }, { tfName: "explicit_paddings", name: "explicitPaddings", type: "number[]", defaultValue: [] }] }, { tfOpName: "Conv3D", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "filter", type: "tensor" }], attrs: [{ tfName: "strides", name: "strides", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }, { tfName: "data_format", name: "dataFormat", type: "string", defaultValue: "NHWC" }, { tfName: "dilations", name: "dilations", type: "number[]" }] }, { tfOpName: "Dilation2D", category: "convolution", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "filter", type: "tensor" }], attrs: [{ tfName: "strides", name: "strides", type: "number[]" }, { tfName: "rates", name: "dilations", type: "number[]" }, { tfName: "padding", name: "pad", type: "string" }] }];
var fe3 = {};
S40(fe3, { json: () => $t2 });
var $t2 = [{ tfOpName: "Fill", category: "creation", inputs: [{ start: 0, name: "shape", type: "number[]" }, { start: 1, name: "value", type: "number" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype" }] }, { tfOpName: "LinSpace", category: "creation", inputs: [{ start: 0, name: "start", type: "number" }, { start: 1, name: "stop", type: "number" }, { start: 2, name: "num", type: "number" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "OneHot", category: "creation", inputs: [{ start: 0, name: "indices", type: "tensor" }, { start: 1, name: "depth", type: "number" }, { start: 2, name: "onValue", type: "number", defaultValue: 1 }, { start: 3, name: "offValue", type: "number", defaultValue: 0 }], attrs: [{ tfName: "axis", name: "axis", type: "number", notSupported: true }, { tfName: "T", name: "dtype", type: "dtype" }] }, { tfOpName: "Ones", category: "creation", inputs: [{ start: 0, name: "shape", type: "number[]" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype" }] }, { tfOpName: "OnesLike", category: "creation", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "dtype", name: "dtype", type: "dtype" }] }, { tfOpName: "RandomStandardNormal", category: "creation", inputs: [{ start: 0, name: "shape", type: "number[]" }], attrs: [{ tfName: "seed", name: "seed", type: "number", defaultValue: 0 }, { tfName: "seed2", name: "seed2", type: "number", defaultValue: 0, notSupported: true }, { tfName: "dtype", name: "dtype", type: "dtype" }, { tfName: "T", name: "T", type: "number", notSupported: true }] }, { tfOpName: "RandomUniform", category: "creation", inputs: [{ start: 0, name: "shape", type: "number[]" }], attrs: [{ tfName: "minval", name: "minval", type: "number", defaultValue: 0 }, { tfName: "maxval", name: "maxval", type: "number", defaultValue: 1 }, { tfName: "dtype", name: "dtype", type: "dtype" }, { tfName: "seed", name: "seed", type: "number", defaultValue: 0 }, { tfName: "seed2", name: "seed2", type: "number", defaultValue: 0, notSupported: true }, { tfName: "T", name: "T", type: "number", notSupported: true }] }, { tfOpName: "RandomUniformInt", category: "creation", inputs: [{ start: 0, name: "shape", type: "number[]" }], attrs: [{ tfName: "minval", name: "minval", type: "number" }, { tfName: "maxval", name: "maxval", type: "number" }, { tfName: "seed", name: "seed", type: "number", defaultValue: 0 }, { tfName: "seed2", name: "seed2", type: "number", defaultValue: 0, notSupported: true }] }, { tfOpName: "Range", category: "creation", inputs: [{ start: 0, name: "start", type: "number" }, { start: 1, name: "stop", type: "number" }, { start: 2, name: "step", type: "number", defaultValue: 0 }], attrs: [{ tfName: "Tidx", name: "dtype", type: "dtype" }] }, { tfOpName: "TruncatedNormal", category: "creation", inputs: [{ start: 0, name: "shape", type: "number[]" }], attrs: [{ tfName: "means", name: "mean", type: "number", defaultValue: 0 }, { tfName: "stddev", name: "stdDev", type: "number", defaultValue: 1 }, { tfName: "seed", name: "seed", type: "number" }, { tfName: "seed2", name: "seed2", type: "number", defaultValue: 0, notSupported: true }, { tfName: "dtype", name: "dtype", type: "dtype" }, { tfName: "T", name: "T", type: "number", notSupported: true }] }, { tfOpName: "Zeros", category: "creation", inputs: [{ start: 0, name: "shape", type: "number[]" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype" }] }, { tfOpName: "ZerosLike", category: "creation", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype" }] }, { tfOpName: "Multinomial", category: "creation", inputs: [{ start: 0, name: "logits", type: "tensor" }, { start: 1, name: "numSamples", type: "number" }], attrs: [{ tfName: "seed", name: "seed", type: "number" }, { tfName: "seed2", name: "seed2", type: "number" }, { tfName: "T", name: "dtype", type: "dtype" }, { tfName: "output_dtype", name: "output_dtype", type: "dtype" }] }];
var ge2 = {};
S40(ge2, { json: () => Bt2 });
var Bt2 = [{ tfOpName: "NonMaxSuppressionV2", category: "dynamic", inputs: [{ start: 0, name: "boxes", type: "tensor" }, { start: 1, name: "scores", type: "tensor" }, { start: 2, name: "maxOutputSize", type: "number" }, { start: 3, name: "iouThreshold", type: "number" }] }, { tfOpName: "NonMaxSuppressionV3", category: "dynamic", inputs: [{ start: 0, name: "boxes", type: "tensor" }, { start: 1, name: "scores", type: "tensor" }, { start: 2, name: "maxOutputSize", type: "number" }, { start: 3, name: "iouThreshold", type: "number" }, { start: 4, name: "scoreThreshold", type: "number" }] }, { tfOpName: "NonMaxSuppressionV4", category: "dynamic", inputs: [{ start: 0, name: "boxes", type: "tensor" }, { start: 1, name: "scores", type: "tensor" }, { start: 2, name: "maxOutputSize", type: "number" }, { start: 3, name: "iouThreshold", type: "number" }, { start: 4, name: "scoreThreshold", type: "number" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }, { tfName: "T_threshold", name: "threshold", type: "dtype", notSupported: true }, { tfName: "pad_to_max_output_size", name: "padToMaxOutputSize", type: "bool" }] }, { tfOpName: "NonMaxSuppressionV5", category: "dynamic", inputs: [{ start: 0, name: "boxes", type: "tensor" }, { start: 1, name: "scores", type: "tensor" }, { start: 2, name: "maxOutputSize", type: "number" }, { start: 3, name: "iouThreshold", type: "number" }, { start: 4, name: "scoreThreshold", type: "number" }, { start: 5, name: "softNmsSigma", type: "number" }] }, { tfOpName: "Where", category: "dynamic", inputs: [{ start: 0, name: "condition", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "ListDiff", category: "dynamic", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "y", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }];
var Ne = {};
S40(Ne, { json: () => jt2 });
var jt2 = [{ tfOpName: "LowerBound", category: "evaluation", inputs: [{ start: 0, name: "sortedSequence", type: "tensor" }, { start: 1, name: "values", type: "tensor" }] }, { tfOpName: "TopKV2", category: "evaluation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "k", type: "number" }], attrs: [{ tfName: "sorted", name: "sorted", type: "bool" }] }, { tfOpName: "UpperBound", category: "evaluation", inputs: [{ start: 0, name: "sortedSequence", type: "tensor" }, { start: 1, name: "values", type: "tensor" }] }, { tfOpName: "Unique", category: "evaluation", inputs: [{ start: 0, name: "x", type: "tensor" }] }, { tfOpName: "UniqueV2", category: "evaluation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number" }] }];
var Te2 = {};
S40(Te2, { json: () => Gt2 });
var Gt2 = [{ tfOpName: "PlaceholderWithDefault", category: "graph", inputs: [{ start: 0, name: "default", type: "tensor" }], attrs: [{ tfName: "shape", name: "shape", type: "shape" }, { tfName: "dtype", name: "dtype", type: "dtype" }] }, { tfOpName: "Placeholder", category: "graph", attrs: [{ tfName: "shape", name: "shape", type: "shape" }, { tfName: "dtype", name: "dtype", type: "dtype" }] }, { tfOpName: "Const", category: "graph" }, { tfOpName: "Identity", category: "graph", inputs: [{ start: 0, name: "x", type: "tensor" }] }, { tfOpName: "IdentityN", category: "graph", inputs: [{ start: 0, end: 0, name: "x", type: "tensors" }] }, { tfOpName: "Snapshot", category: "graph", inputs: [{ start: 0, name: "x", type: "tensor" }] }, { tfOpName: "Rank", category: "graph", inputs: [{ start: 0, name: "x", type: "tensor" }] }, { tfOpName: "Size", category: "graph", inputs: [{ start: 0, name: "x", type: "tensor" }] }, { tfOpName: "Shape", category: "graph", inputs: [{ start: 0, name: "x", type: "tensor" }] }, { tfOpName: "ShapeN", category: "graph", inputs: [{ start: 0, end: 0, name: "x", type: "tensors" }] }, { tfOpName: "Print", category: "graph", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "data", type: "tensors" }], attrs: [{ tfName: "message", name: "message", type: "string" }, { tfName: "first_n", name: "firstN", type: "number", notSupported: true }, { tfName: "summarize", name: "summarize", type: "number", defaultValue: 3 }] }, { tfOpName: "NoOp", category: "graph", inputs: [] }, { tfOpName: "StopGradient", category: "graph", inputs: [{ start: 0, name: "x", type: "tensor" }] }, { tfOpName: "FakeQuantWithMinMaxVars", category: "graph", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "min", name: "min", type: "number" }, { tfName: "max", name: "max", type: "number" }] }];
var be2 = {};
S40(be2, { json: () => Ht2 });
var Ht2 = [{ tfOpName: "HashTable", category: "hash_table", inputs: [], attrs: [{ tfName: "shared_name", name: "sharedName", type: "string" }, { tfName: "use_node_name_sharing", name: "useNodeNameSharing", type: "bool" }, { tfName: "key_dtype", name: "keyDType", type: "dtype" }, { tfName: "value_dtype", name: "valueDType", type: "dtype" }] }, { tfOpName: "HashTableV2", category: "hash_table", inputs: [], attrs: [{ tfName: "shared_name", name: "sharedName", type: "string" }, { tfName: "use_node_name_sharing", name: "useNodeNameSharing", type: "bool" }, { tfName: "key_dtype", name: "keyDType", type: "dtype" }, { tfName: "value_dtype", name: "valueDType", type: "dtype" }] }, { tfOpName: "LookupTableImport", category: "hash_table", inputs: [{ start: 0, name: "tableHandle", type: "tensor" }, { start: 1, name: "keys", type: "tensor" }, { start: 2, name: "values", type: "tensor" }], attrs: [{ tfName: "Tin", name: "tIn", type: "dtype", notSupported: true }, { tfName: "Tout", name: "tOut", type: "dtype", notSupported: true }] }, { tfOpName: "LookupTableImportV2", category: "hash_table", inputs: [{ start: 0, name: "tableHandle", type: "tensor" }, { start: 1, name: "keys", type: "tensor" }, { start: 2, name: "values", type: "tensor" }], attrs: [{ tfName: "Tin", name: "tIn", type: "dtype", notSupported: true }, { tfName: "Tout", name: "tOut", type: "dtype", notSupported: true }] }, { tfOpName: "LookupTableFind", category: "hash_table", inputs: [{ start: 0, name: "tableHandle", type: "tensor" }, { start: 1, name: "keys", type: "tensor" }, { start: 2, name: "defaultValue", type: "tensor" }], attrs: [{ tfName: "Tin", name: "tIn", type: "dtype", notSupported: true }, { tfName: "Tout", name: "tOut", type: "dtype", notSupported: true }] }, { tfOpName: "LookupTableFindV2", category: "hash_table", inputs: [{ start: 0, name: "tableHandle", type: "tensor" }, { start: 1, name: "keys", type: "tensor" }, { start: 2, name: "defaultValue", type: "tensor" }], attrs: [{ tfName: "Tin", name: "tIn", type: "dtype", notSupported: true }, { tfName: "Tout", name: "tOut", type: "dtype", notSupported: true }] }, { tfOpName: "LookupTableSize", category: "hash_table", inputs: [{ start: 0, name: "tableHandle", type: "tensor" }] }, { tfOpName: "LookupTableSizeV2", category: "hash_table", inputs: [{ start: 0, name: "tableHandle", type: "tensor" }] }, { tfOpName: "InitializeTable", category: "hash_table", inputs: [{ start: 0, name: "tableHandle", type: "tensor" }, { start: 1, name: "keys", type: "tensor" }, { start: 2, name: "values", type: "tensor" }] }, { tfOpName: "InitializeTableV2", category: "hash_table", inputs: [{ start: 0, name: "tableHandle", type: "tensor" }, { start: 1, name: "keys", type: "tensor" }, { start: 2, name: "values", type: "tensor" }] }];
var Se2 = {};
S40(Se2, { json: () => Ut2 });
var Ut2 = [{ tfOpName: "ResizeBilinear", category: "image", inputs: [{ start: 0, name: "images", type: "tensor" }, { start: 1, name: "size", type: "number[]" }], attrs: [{ tfName: "align_corners", name: "alignCorners", type: "bool" }, { tfName: "half_pixel_centers", name: "halfPixelCenters", type: "bool" }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "ResizeNearestNeighbor", category: "image", inputs: [{ start: 0, name: "images", type: "tensor" }, { start: 1, name: "size", type: "number[]" }], attrs: [{ tfName: "align_corners", name: "alignCorners", type: "bool" }, { tfName: "half_pixel_centers", name: "halfPixelCenters", type: "bool" }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "CropAndResize", category: "image", inputs: [{ start: 0, name: "image", type: "tensor" }, { start: 1, name: "boxes", type: "tensor" }, { start: 2, name: "boxInd", type: "tensor" }, { start: 3, name: "cropSize", type: "number[]" }], attrs: [{ tfName: "method", name: "method", type: "string" }, { tfName: "extrapolation_value", name: "extrapolationValue", type: "number" }] }, { tfOpName: "ImageProjectiveTransformV3", category: "image", inputs: [{ start: 0, name: "images", type: "tensor" }, { start: 1, name: "transforms", type: "tensor" }, { start: 2, name: "outputShape", type: "number[]" }, { start: 3, name: "fillValue", type: "number" }], attrs: [{ tfName: "interpolation", name: "interpolation", type: "string" }, { tfName: "fill_mode", name: "fillMode", type: "string" }] }];
var Oe = {};
S40(Oe, { json: () => Wt2 });
var Wt2 = [{ tfOpName: "Equal", category: "logical", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "NotEqual", category: "logical", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Greater", category: "logical", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "GreaterEqual", category: "logical", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Less", category: "logical", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "LessEqual", category: "logical", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "LogicalAnd", category: "logical", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "LogicalNot", category: "logical", inputs: [{ start: 0, name: "a", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "LogicalOr", category: "logical", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Select", category: "logical", inputs: [{ start: 0, name: "condition", type: "tensor" }, { start: 1, name: "a", type: "tensor" }, { start: 2, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "SelectV2", category: "logical", inputs: [{ start: 0, name: "condition", type: "tensor" }, { start: 1, name: "a", type: "tensor" }, { start: 2, name: "b", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "BitwiseAnd", category: "logical", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "y", type: "tensor" }] }];
var we = {};
S40(we, { json: () => qt2 });
var qt2 = [{ tfOpName: "_FusedMatMul", category: "matrices", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }, { start: 2, end: 0, name: "args", type: "tensors" }], attrs: [{ tfName: "num_args", name: "numArgs", type: "number" }, { tfName: "fused_ops", name: "fusedOps", type: "string[]", defaultValue: [] }, { tfName: "epsilon", name: "epsilon", type: "number", defaultValue: 1e-4 }, { tfName: "transpose_a", name: "transposeA", type: "bool", defaultValue: false }, { tfName: "transpose_b", name: "transposeB", type: "bool", defaultValue: false }, { tfName: "leakyrelu_alpha", name: "leakyreluAlpha", type: "number", defaultValue: 0.2 }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "MatMul", category: "matrices", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "transpose_a", name: "transposeA", type: "bool", defaultValue: false }, { tfName: "transpose_b", name: "transposeB", type: "bool", defaultValue: false }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "BatchMatMul", category: "matrices", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "adj_x", name: "transposeA", type: "bool", defaultValue: false }, { tfName: "adj_y", name: "transposeB", type: "bool", defaultValue: false }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "BatchMatMulV2", category: "matrices", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "b", type: "tensor" }], attrs: [{ tfName: "adj_x", name: "transposeA", type: "bool", defaultValue: false }, { tfName: "adj_y", name: "transposeB", type: "bool", defaultValue: false }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Transpose", category: "matrices", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "perm", type: "number[]" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Einsum", category: "matrices", inputs: [{ start: 0, end: 0, name: "tensors", type: "tensors" }], attrs: [{ tfName: "equation", name: "equation", type: "string" }, { tfName: "N", name: "n", type: "number", defaultValue: 2 }, { tfName: "T", name: "dtype", type: "dtype" }] }, { tfOpName: "MatrixBandPart", category: "matrices", inputs: [{ start: 0, name: "a", type: "tensor" }, { start: 1, name: "numLower", type: "tensor" }, { start: 1, name: "numUpper", type: "tensor" }] }];
var _e2 = {};
S40(_e2, { json: () => Kt2 });
var Kt2 = [{ tfOpName: "EuclideanNorm", category: "normalization", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number[]" }], attrs: [{ tfName: "keep_dims", name: "keepDims", type: "bool", defaultValue: false }] }, { tfOpName: "FusedBatchNorm", category: "normalization", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "scale", type: "tensor" }, { start: 2, name: "offset", type: "tensor" }, { start: 3, name: "mean", type: "tensor" }, { start: 4, name: "variance", type: "tensor" }], attrs: [{ tfName: "epsilon", name: "epsilon", type: "number", defaultValue: 1e-3 }, { tfName: "data_format", name: "dataFormat", type: "string", notSupported: true }] }, { tfOpName: "FusedBatchNormV2", category: "normalization", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "scale", type: "tensor" }, { start: 2, name: "offset", type: "tensor" }, { start: 3, name: "mean", type: "tensor" }, { start: 4, name: "variance", type: "tensor" }], attrs: [{ tfName: "epsilon", name: "epsilon", type: "number", defaultValue: 1e-3 }, { tfName: "data_format", name: "dataFormat", type: "string", notSupported: true }] }, { tfOpName: "FusedBatchNormV3", category: "normalization", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "scale", type: "tensor" }, { start: 2, name: "offset", type: "tensor" }, { start: 3, name: "mean", type: "tensor" }, { start: 4, name: "variance", type: "tensor" }], attrs: [{ tfName: "epsilon", name: "epsilon", type: "number", defaultValue: 1e-3 }, { tfName: "data_format", name: "dataFormat", type: "string", notSupported: true }] }, { tfOpName: "LRN", category: "normalization", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "depth_radius", name: "radius", type: "number", defaultValue: 5 }, { tfName: "bias", name: "bias", type: "number", defaultValue: 1 }, { tfName: "alpha", name: "alpha", type: "number", defaultValue: 1 }, { tfName: "beta", name: "beta", type: "number", defaultValue: 0.5 }] }, { tfOpName: "Softmax", category: "normalization", inputs: [{ start: 0, name: "x", type: "tensor" }] }, { tfOpName: "LogSoftmax", category: "normalization", inputs: [{ start: 0, name: "x", type: "tensor" }] }];
var Ie = {};
S40(Ie, { json: () => Yt2 });
var Yt2 = [{ tfOpName: "Bincount", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "size", type: "number" }, { start: 2, name: "weights", type: "tensor" }] }, { tfOpName: "DenseBincount", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "size", type: "number" }, { start: 2, name: "weights", type: "tensor" }], attrs: [{ tfName: "binary_output", name: "binaryOutput", type: "bool" }] }, { tfOpName: "Max", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number[]" }], attrs: [{ tfName: "keep_dims", name: "keepDims", type: "bool" }] }, { tfOpName: "Mean", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number[]" }], attrs: [{ tfName: "keep_dims", name: "keepDims", type: "bool" }] }, { tfOpName: "Min", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number[]" }], attrs: [{ tfName: "keep_dims", name: "keepDims", type: "bool" }] }, { tfOpName: "Sum", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number[]" }], attrs: [{ tfName: "keep_dims", name: "keepDims", type: "bool" }] }, { tfOpName: "All", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number[]" }], attrs: [{ tfName: "keep_dims", name: "keepDims", type: "bool" }] }, { tfOpName: "Any", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number[]" }], attrs: [{ tfName: "keep_dims", name: "keepDims", type: "bool" }] }, { tfOpName: "ArgMax", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number" }] }, { tfOpName: "ArgMin", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number" }] }, { tfOpName: "Prod", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number[]" }], attrs: [{ tfName: "keep_dims", name: "keepDims", type: "bool" }, { tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "Cumprod", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number" }], attrs: [{ tfName: "exclusive", name: "exclusive", type: "bool" }, { tfName: "reverse", name: "reverse", type: "bool" }] }, { tfOpName: "Cumsum", category: "reduction", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number" }], attrs: [{ tfName: "exclusive", name: "exclusive", type: "bool" }, { tfName: "reverse", name: "reverse", type: "bool" }] }];
var Ee2 = {};
S40(Ee2, { json: () => Qt2 });
var Qt2 = [{ tfOpName: "ConcatV2", category: "slice_join", inputs: [{ start: 0, end: -1, name: "tensors", type: "tensors" }, { start: -1, name: "axis", type: "number" }], attrs: [{ tfName: "N", name: "n", type: "number", defaultValue: 2 }] }, { tfOpName: "Concat", category: "slice_join", inputs: [{ start: 1, end: 0, name: "tensors", type: "tensors" }, { start: 0, name: "axis", type: "number" }], attrs: [{ tfName: "N", name: "n", type: "number", defaultValue: 2 }] }, { tfOpName: "GatherV2", category: "slice_join", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "indices", type: "tensor" }, { start: 2, name: "axis", type: "number", defaultValue: 0 }], attrs: [{ tfName: "batch_dims", name: "batchDims", type: "number", defaultValue: 0 }] }, { tfOpName: "Gather", category: "slice_join", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "indices", type: "tensor" }], attrs: [{ tfName: "validate_indices", name: "validateIndices", type: "bool", notSupported: true }] }, { tfOpName: "Reverse", category: "slice_join", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "dims", type: "bool[]" }] }, { tfOpName: "ReverseV2", category: "slice_join", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number[]" }] }, { tfOpName: "Slice", category: "slice_join", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "begin", type: "number[]" }, { start: 2, name: "size", type: "number[]" }] }, { tfOpName: "StridedSlice", category: "slice_join", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "begin", type: "number[]" }, { start: 2, name: "end", type: "number[]" }, { start: 3, name: "strides", type: "number[]" }], attrs: [{ tfName: "begin_mask", name: "beginMask", type: "number", defaultValue: 0 }, { tfName: "end_mask", name: "endMask", type: "number", defaultValue: 0 }, { tfName: "new_axis_mask", name: "newAxisMask", type: "number", defaultValue: 0 }, { tfName: "ellipsis_mask", name: "ellipsisMask", type: "number", defaultValue: 0 }, { tfName: "shrink_axis_mask", name: "shrinkAxisMask", type: "number", defaultValue: 0 }] }, { tfOpName: "Pack", category: "slice_join", inputs: [{ start: 0, end: 0, name: "tensors", type: "tensors" }], attrs: [{ tfName: "axis", name: "axis", type: "number", defaultValue: 0 }] }, { tfOpName: "Unpack", category: "slice_join", inputs: [{ start: 0, name: "tensor", type: "tensor" }], attrs: [{ tfName: "axis", name: "axis", type: "number", defaultValue: 0 }, { tfName: "num", name: "num", type: "number", defaultValue: 0, notSupported: true }] }, { tfOpName: "Tile", category: "slice_join", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "reps", type: "number[]" }] }, { tfOpName: "Split", category: "slice_join", inputs: [{ start: 0, name: "axis", type: "number", defaultValue: 0 }, { start: 1, name: "x", type: "tensor" }], attrs: [{ tfName: "num_split", name: "numOrSizeSplits", type: "number", defaultValue: 1 }] }, { tfOpName: "SplitV", category: "slice_join", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "numOrSizeSplits", type: "number[]" }, { start: 2, name: "axis", type: "number", defaultValue: 0 }] }, { tfOpName: "ScatterNd", category: "slice_join", inputs: [{ start: 0, name: "indices", type: "tensor" }, { start: 1, name: "values", type: "tensor" }, { start: 2, name: "shape", type: "number[]" }] }, { tfOpName: "GatherNd", category: "slice_join", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "indices", type: "tensor" }] }, { tfOpName: "SparseToDense", category: "slice_join", inputs: [{ start: 0, name: "sparseIndices", type: "tensor" }, { start: 1, name: "outputShape", type: "number[]" }, { start: 2, name: "sparseValues", type: "tensor" }, { start: 3, name: "defaultValue", type: "tensor" }], attrs: [{ tfName: "validate_indices", name: "validateIndices", type: "bool", defaultValue: false, notSupported: true }] }, { tfOpName: "TensorScatterUpdate", category: "slice_join", inputs: [{ start: 0, name: "tensor", type: "tensor" }, { start: 1, name: "indices", type: "tensor" }, { start: 2, name: "values", type: "tensor" }] }];
var Ae2 = {};
S40(Ae2, { json: () => Xt2 });
var Xt2 = [{ tfOpName: "SparseFillEmptyRows", category: "sparse", inputs: [{ start: 0, name: "indices", type: "tensor" }, { start: 1, name: "values", type: "tensor" }, { start: 2, name: "denseShape", type: "tensor" }, { start: 3, name: "defaultValue", type: "tensor" }] }, { tfOpName: "SparseReshape", category: "sparse", inputs: [{ start: 0, name: "inputIndices", type: "tensor" }, { start: 1, name: "inputShape", type: "tensor" }, { start: 2, name: "newShape", type: "tensor" }], attrs: [{ tfName: "T", name: "dtype", type: "dtype", notSupported: true }] }, { tfOpName: "SparseSegmentMean", category: "sparse", inputs: [{ start: 0, name: "data", type: "tensor" }, { start: 1, name: "indices", type: "tensor" }, { start: 2, name: "segmentIds", type: "tensor" }] }, { tfOpName: "SparseSegmentSum", category: "sparse", inputs: [{ start: 0, name: "data", type: "tensor" }, { start: 1, name: "indices", type: "tensor" }, { start: 2, name: "segmentIds", type: "tensor" }] }];
var ve = {};
S40(ve, { json: () => Jt2 });
var Jt2 = [{ tfOpName: "FFT", category: "spectral", inputs: [{ start: 0, name: "x", type: "tensor" }] }, { tfOpName: "IFFT", category: "spectral", inputs: [{ start: 0, name: "x", type: "tensor" }] }, { tfOpName: "RFFT", category: "spectral", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "fft_length", type: "number", notSupported: true }] }, { tfOpName: "IRFFT", category: "spectral", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "fft_length", type: "number", notSupported: true }] }];
var ke = {};
S40(ke, { json: () => Zt2 });
var Zt2 = [{ tfOpName: "StaticRegexReplace", category: "string", inputs: [{ start: 0, name: "input", type: "tensor" }], attrs: [{ tfName: "pattern", name: "pattern", type: "string" }, { tfName: "rewrite", name: "rewrite", type: "string" }, { tfName: "replace_global", name: "replaceGlobal", type: "bool" }] }, { tfOpName: "StringNGrams", category: "string", inputs: [{ start: 0, name: "data", type: "tensor" }, { start: 1, name: "dataSplits", type: "tensor" }], attrs: [{ tfName: "separator", name: "separator", type: "string" }, { tfName: "ngram_widths", name: "nGramWidths", type: "number[]" }, { tfName: "left_pad", name: "leftPad", type: "string" }, { tfName: "right_pad", name: "rightPad", type: "string" }, { tfName: "pad_width", name: "padWidth", type: "number" }, { tfName: "preserve_short_sequences", name: "preserveShortSequences", type: "bool" }], outputs: ["ngrams", "ngrams_splits"] }, { tfOpName: "StringSplit", category: "string", inputs: [{ start: 0, name: "input", type: "tensor" }, { start: 1, name: "delimiter", type: "tensor" }], attrs: [{ tfName: "skip_empty", name: "skipEmpty", type: "bool" }], outputs: ["indices", "values", "shape"] }, { tfOpName: "StringToHashBucketFast", category: "string", inputs: [{ start: 0, name: "input", type: "tensor" }], attrs: [{ tfName: "num_buckets", name: "numBuckets", type: "number" }] }];
var Ve = {};
S40(Ve, { json: () => Mt2 });
var Mt2 = [{ tfOpName: "Cast", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "SrcT", name: "sdtype", type: "dtype", notSupported: true }, { tfName: "DstT", name: "dtype", type: "dtype" }] }, { tfOpName: "ExpandDims", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "axis", type: "number" }] }, { tfOpName: "MirrorPad", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "padding", type: "number[]" }], attrs: [{ tfName: "mode", name: "mode", type: "string" }] }, { tfOpName: "Pad", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "padding", type: "number[]" }], attrs: [{ tfName: "constant_value", name: "constantValue", type: "number", defaultValue: 0 }] }, { tfOpName: "PadV2", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "padding", type: "number[]" }, { start: 2, name: "constantValue", type: "number", defaultValue: 0 }] }, { tfOpName: "Reshape", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "shape", type: "number[]" }] }, { tfOpName: "EnsureShape", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "shape", type: "number[]" }] }, { tfOpName: "Squeeze", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "axis", tfDeprecatedName: "squeeze_dims", name: "axis", type: "number[]" }] }, { tfOpName: "SpaceToBatchND", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "blockShape", type: "number[]" }, { start: 2, name: "paddings", type: "number[]" }] }, { tfOpName: "BatchToSpaceND", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "blockShape", type: "number[]" }, { start: 2, name: "crops", type: "number[]" }] }, { tfOpName: "DepthToSpace", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }], attrs: [{ tfName: "block_size", name: "blockSize", type: "number" }, { tfName: "data_format", name: "dataFormat", type: "string" }] }, { tfOpName: "BroadcastTo", category: "transformation", inputs: [{ start: 0, name: "x", type: "tensor" }, { start: 1, name: "shape", type: "number[]" }], attrs: [] }, { tfOpName: "BroadcastArgs", category: "transformation", inputs: [{ start: 0, name: "s0", type: "tensor" }, { start: 1, name: "s1", type: "tensor" }], attrs: [] }];
var R23 = class {
  static get Instance() {
    return this._instance || (this._instance = new this());
  }
  constructor() {
    let e36 = [ce4, ye, de3, he3, fe3, ge2, Ne, Te2, be2, Se2, Oe, we, _e2, Ie, Ee2, Ae2, ve, ke, Ve], t67 = [].concat(...e36.map((s84) => s84.json));
    this.opMappers = t67.reduce((s84, n67) => (s84[n67.tfOpName] = n67, s84), {});
  }
  transformGraph(e36, t67 = {}) {
    let s84 = e36.node, n67 = [], i88 = [], p103 = [], m96 = s84.reduce((f85, d55) => (f85[d55.name] = this.mapNode(d55), d55.op.startsWith("Placeholder") ? n67.push(f85[d55.name]) : d55.op === "Const" ? i88.push(f85[d55.name]) : (d55.input == null || d55.input.length === 0) && p103.push(f85[d55.name]), f85), {}), u86 = [], o80 = [], l80 = {}, y43 = {};
    t67 != null && (l80 = this.mapSignatureEntries(t67.inputs), y43 = this.mapSignatureEntries(t67.outputs));
    let c103 = Object.keys(m96);
    c103.forEach((f85) => {
      let d55 = m96[f85];
      d55.inputNames.forEach((g72, O21) => {
        let [v42, , T40] = E41(g72), L22 = m96[v42];
        if (L22.outputs != null) {
          let j22 = L22.outputs.indexOf(T40);
          if (j22 !== -1) {
            let G30 = `${v42}:${j22}`;
            d55.inputNames[O21] = G30;
          }
        }
        d55.inputs.push(L22), L22.children.push(d55);
      });
    }), Object.keys(y43).length === 0 ? c103.forEach((f85) => {
      let d55 = m96[f85];
      d55.children.length === 0 && o80.push(d55);
    }) : Object.keys(y43).forEach((f85) => {
      let [d55] = E41(f85), g72 = m96[d55];
      g72 != null && (g72.signatureKey = y43[f85], o80.push(g72));
    }), Object.keys(l80).length > 0 ? Object.keys(l80).forEach((f85) => {
      let [d55] = E41(f85), g72 = m96[d55];
      g72 && (g72.signatureKey = l80[f85], u86.push(g72));
    }) : u86 = n67;
    let h74 = {};
    e36.library != null && e36.library.function != null && (h74 = e36.library.function.reduce((f85, d55) => (f85[d55.signature.name] = this.mapFunction(d55), f85), {}));
    let N58 = { nodes: m96, inputs: u86, outputs: o80, weights: i88, placeholders: n67, signature: t67, functions: h74 };
    return p103.length > 0 && (N58.initNodes = p103), N58;
  }
  mapSignatureEntries(e36) {
    return Object.keys(e36 || {}).reduce((t67, s84) => (t67[e36[s84].name] = s84, t67), {});
  }
  mapNode(e36) {
    let t67 = H15(e36.op) || this.opMappers[e36.op] || {};
    e36.attr == null && (e36.attr = {});
    let s84 = { name: e36.name, op: e36.op, category: t67.category, inputNames: (e36.input || []).map((n67) => n67.startsWith("^") ? n67.slice(1) : n67), inputs: [], children: [], inputParams: {}, attrParams: {}, rawAttrs: e36.attr, outputs: t67.outputs };
    return t67.inputs != null && (s84.inputParams = t67.inputs.reduce((n67, i88) => (n67[i88.name] = { type: i88.type, inputIndexStart: i88.start, inputIndexEnd: i88.end }, n67), {})), t67.attrs != null && (s84.attrParams = t67.attrs.reduce((n67, i88) => {
      let p103 = i88.type, m96;
      switch (i88.type) {
        case "string":
          m96 = W13(e36.attr, i88.tfName, i88.defaultValue), m96 === void 0 && i88.tfDeprecatedName && (m96 = W13(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "string[]":
          m96 = Z13(e36.attr, i88.tfName, i88.defaultValue), m96 === void 0 && i88.tfDeprecatedName && (m96 = Z13(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "number":
          m96 = K17(e36.attr, i88.tfName, i88.defaultValue || 0), m96 === void 0 && i88.tfDeprecatedName && (m96 = K17(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "number[]":
          m96 = J13(e36.attr, i88.tfName, i88.defaultValue), m96 === void 0 && i88.tfDeprecatedName && (m96 = J13(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "bool":
          m96 = q20(e36.attr, i88.tfName, i88.defaultValue), m96 === void 0 && i88.tfDeprecatedName && (m96 = q20(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "bool[]":
          m96 = ee5(e36.attr, i88.tfName, i88.defaultValue), m96 === void 0 && i88.tfDeprecatedName && (m96 = ee5(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "shape":
          m96 = X18(e36.attr, i88.tfName, i88.defaultValue), m96 === void 0 && i88.tfDeprecatedName && (m96 = X18(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "shape[]":
          m96 = M27(e36.attr, i88.tfName, i88.defaultValue), m96 === void 0 && i88.tfDeprecatedName && (m96 = M27(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "dtype":
          m96 = Y11(e36.attr, i88.tfName, i88.defaultValue), m96 === void 0 && i88.tfDeprecatedName && (m96 = Y11(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "dtype[]":
          m96 = Q10(e36.attr, i88.tfName, i88.defaultValue), m96 === void 0 && i88.tfDeprecatedName && (m96 = Q10(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "func":
          m96 = Re3(e36.attr, i88.tfName, i88.defaultValue), m96 === void 0 && i88.tfDeprecatedName && (m96 = Re3(e36.attr, i88.tfDeprecatedName, i88.defaultValue));
          break;
        case "tensor":
        case "tensors":
          break;
        default:
          throw new Error(`Unsupported param type: ${i88.type} for op: ${e36.op}`);
      }
      return n67[i88.name] = { value: m96, type: p103 }, n67;
    }, {})), s84;
  }
  mapFunction(e36) {
    let t67 = e36.nodeDef, s84 = [], n67 = [], i88 = {};
    t67 != null && (i88 = t67.reduce((y43, c103) => (y43[c103.name] = this.mapNode(c103), c103.op === "Const" && n67.push(y43[c103.name]), y43), {}));
    let p103 = [], m96 = [];
    e36.signature.inputArg.forEach((y43) => {
      let [c103] = E41(y43.name), h74 = { name: c103, op: "Placeholder", inputs: [], inputNames: [], category: "graph", inputParams: {}, attrParams: { dtype: { value: Le(y43.type), type: "dtype" } }, children: [] };
      h74.signatureKey = y43.name, p103.push(h74), i88[c103] = h74;
    }), Object.keys(i88).forEach((y43) => {
      let c103 = i88[y43];
      c103.inputNames.forEach((h74, N58) => {
        let [f85, , d55] = E41(h74), g72 = i88[f85];
        if (g72.outputs != null) {
          let O21 = g72.outputs.indexOf(d55);
          if (O21 !== -1) {
            let v42 = `${f85}:${O21}`;
            c103.inputNames[N58] = v42;
          }
        }
        c103.inputs.push(g72), g72.children.push(c103);
      });
    });
    let o80 = e36.ret;
    e36.signature.outputArg.forEach((y43) => {
      let [c103, h74] = E41(o80[y43.name]), N58 = i88[c103];
      N58 != null && (N58.defaultOutput = h74, m96.push(N58));
    });
    let l80 = this.mapArgsToSignature(e36);
    return { nodes: i88, inputs: p103, outputs: m96, weights: n67, placeholders: s84, signature: l80 };
  }
  mapArgsToSignature(e36) {
    return { methodName: e36.signature.name, inputs: e36.signature.inputArg.reduce((t67, s84) => (t67[s84.name] = this.mapArgToTensorInfo(s84), t67), {}), outputs: e36.signature.outputArg.reduce((t67, s84) => (t67[s84.name] = this.mapArgToTensorInfo(s84, e36.ret), t67), {}) };
  }
  mapArgToTensorInfo(e36, t67) {
    let s84 = e36.name;
    return t67 != null && (s84 = t67[s84]), { name: s84, dtype: e36.type };
  }
};
function ta(a71) {
  let e36 = l().global;
  if (typeof e36.atob < "u") return e36.atob(a71);
  if (typeof __Buffer$2 < "u") return new __Buffer$2(a71, "base64").toString();
  throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()");
}
function Pe(a71, e36) {
  let t67 = Array.isArray(a71) ? String.fromCharCode.apply(null, a71) : ta(a71);
  return e36 ? t67 : t67.toLowerCase();
}
function W13(a71, e36, t67, s84 = false) {
  let n67 = a71[e36];
  return n67 != null ? Pe(n67.s, s84) : t67;
}
function q20(a71, e36, t67) {
  let s84 = a71[e36];
  return s84 ? s84.b : t67;
}
function K17(a71, e36, t67) {
  let s84 = a71[e36] || {}, n67 = s84.i != null ? s84.i : s84.f != null ? s84.f : t67;
  return typeof n67 == "number" ? n67 : parseInt(n67, 10);
}
function Le(a71) {
  switch (typeof a71 == "string" && (a71 = _22[a71]), a71) {
    case _22.DT_FLOAT:
    case _22.DT_HALF:
      return "float32";
    case _22.DT_INT32:
    case _22.DT_INT64:
    case _22.DT_INT8:
    case _22.DT_UINT8:
      return "int32";
    case _22.DT_BOOL:
      return "bool";
    case _22.DT_DOUBLE:
      return "float32";
    case _22.DT_STRING:
      return "string";
    case _22.DT_COMPLEX64:
    case _22.DT_COMPLEX128:
      return "complex64";
    default:
      return null;
  }
}
function Re3(a71, e36, t67) {
  let s84 = a71[e36];
  return s84 && s84.func ? s84.func.name : t67;
}
function Y11(a71, e36, t67) {
  let s84 = a71[e36];
  return s84 && s84.type ? Le(s84.type) : t67;
}
function Q10(a71, e36, t67) {
  let s84 = a71[e36];
  return s84 && s84.list && s84.list.type ? s84.list.type.map((n67) => Le(n67)) : t67;
}
function $e(a71) {
  if (!a71.unknownRank) return a71.dim != null ? a71.dim.map((e36) => typeof e36.size == "number" ? e36.size : parseInt(e36.size, 10)) : [];
}
function X18(a71, e36, t67) {
  let s84 = a71[e36];
  return s84 && s84.shape ? $e(s84.shape) : t67;
}
function J13(a71, e36, t67) {
  let s84 = a71[e36];
  return s84 ? ((s84.list.f && s84.list.f.length ? s84.list.f : s84.list.i) || []).map((n67) => typeof n67 == "number" ? n67 : parseInt(n67, 10)) : t67;
}
function Z13(a71, e36, t67, s84 = false) {
  let n67 = a71[e36];
  return n67 && n67.list && n67.list.s ? n67.list.s.map((i88) => Pe(i88, s84)) : t67;
}
function M27(a71, e36, t67) {
  let s84 = a71[e36];
  return s84 && s84.list && s84.list.shape ? s84.list.shape.map((n67) => $e(n67)) : t67;
}
function ee5(a71, e36, t67) {
  let s84 = a71[e36];
  return s84 && s84.list && s84.list.b ? s84.list.b : t67;
}
var te5 = class {
  constructor(e36, t67, s84) {
    this.node = e36, this.tensorMap = t67, this.context = s84, this.inputs = [], this.attrs = {}, this.inputs = e36.inputNames.map((n67) => this.getInput(n67)), e36.rawAttrs != null && (this.attrs = Object.keys(e36.rawAttrs).reduce((n67, i88) => (n67[i88] = this.getAttr(i88), n67), {}));
  }
  getInput(e36) {
    return b55(e36, this.tensorMap, this.context);
  }
  getAttr(e36, t67) {
    let s84 = this.node.rawAttrs[e36];
    if (s84.tensor != null) return b55(e36, this.tensorMap, this.context);
    if (s84.i != null || s84.f != null) return K17(this.node.rawAttrs, e36, t67);
    if (s84.s != null) return W13(this.node.rawAttrs, e36, t67);
    if (s84.b != null) return q20(this.node.rawAttrs, e36, t67);
    if (s84.shape != null) return X18(this.node.rawAttrs, e36, t67);
    if (s84.type != null) return Y11(this.node.rawAttrs, e36, t67);
    if (s84.list != null) {
      if (s84.list.i != null || s84.list.f != null) return J13(this.node.rawAttrs, e36, t67);
      if (s84.list.s != null) return Z13(this.node.rawAttrs, e36, t67);
      if (s84.list.shape != null) return M27(this.node.rawAttrs, e36, t67);
      if (s84.list.b != null) return ee5(this.node.rawAttrs, e36, t67);
      if (s84.list.type != null) return Q10(this.node.rawAttrs, e36, t67);
    }
    return t67;
  }
};
var Be = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "BiasAdd":
    case "AddV2":
    case "Add":
      return [s84.add(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "AddN":
      return [s84.addN(r51("tensors", a71, e36, t67))];
    case "FloorMod":
    case "Mod":
      return [s84.mod(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "Mul":
      return [s84.mul(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "RealDiv":
    case "Div":
      return [s84.div(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "DivNoNan":
      return [s84.divNoNan(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "FloorDiv":
      return [s84.floorDiv(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "Sub":
      return [s84.sub(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "Minimum":
      return [s84.minimum(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "Maximum":
      return [s84.maximum(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "Pow":
      return [s84.pow(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "SquaredDifference":
      return [s84.squaredDifference(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var je = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "Abs":
    case "ComplexAbs":
      return [s84.abs(r51("x", a71, e36, t67))];
    case "Acos":
      return [s84.acos(r51("x", a71, e36, t67))];
    case "Acosh":
      return [s84.acosh(r51("x", a71, e36, t67))];
    case "Asin":
      return [s84.asin(r51("x", a71, e36, t67))];
    case "Asinh":
      return [s84.asinh(r51("x", a71, e36, t67))];
    case "Atan":
      return [s84.atan(r51("x", a71, e36, t67))];
    case "Atan2":
      return [s84.atan2(r51("x", a71, e36, t67), r51("y", a71, e36, t67))];
    case "Atanh":
      return [s84.atanh(r51("x", a71, e36, t67))];
    case "Ceil":
      return [s84.ceil(r51("x", a71, e36, t67))];
    case "Complex":
      return [s84.complex(r51("real", a71, e36, t67), r51("imag", a71, e36, t67))];
    case "Cos":
      return [s84.cos(r51("x", a71, e36, t67))];
    case "Cosh":
      return [s84.cosh(r51("x", a71, e36, t67))];
    case "Elu":
      return [s84.elu(r51("x", a71, e36, t67))];
    case "Erf":
      return [s84.erf(r51("x", a71, e36, t67))];
    case "Exp":
      return [s84.exp(r51("x", a71, e36, t67))];
    case "Expm1":
      return [s84.expm1(r51("x", a71, e36, t67))];
    case "Floor":
      return [s84.floor(r51("x", a71, e36, t67))];
    case "Log":
      return [s84.log(r51("x", a71, e36, t67))];
    case "Log1p":
      return [s84.log1p(r51("x", a71, e36, t67))];
    case "Imag":
      return [s84.imag(r51("x", a71, e36, t67))];
    case "Neg":
      return [s84.neg(r51("x", a71, e36, t67))];
    case "Reciprocal":
      return [s84.reciprocal(r51("x", a71, e36, t67))];
    case "Real":
      return [s84.real(r51("x", a71, e36, t67))];
    case "Relu":
      return [s84.relu(r51("x", a71, e36, t67))];
    case "Round":
      return [s84.round(r51("x", a71, e36, t67))];
    case "Selu":
      return [s84.selu(r51("x", a71, e36, t67))];
    case "Sigmoid":
      return [s84.sigmoid(r51("x", a71, e36, t67))];
    case "Sin":
      return [s84.sin(r51("x", a71, e36, t67))];
    case "Sign":
      return [s84.sign(r51("x", a71, e36, t67))];
    case "Sinh":
      return [s84.sinh(r51("x", a71, e36, t67))];
    case "Softplus":
      return [s84.softplus(r51("x", a71, e36, t67))];
    case "Sqrt":
      return [s84.sqrt(r51("x", a71, e36, t67))];
    case "Square":
      return [s84.square(r51("x", a71, e36, t67))];
    case "Tanh":
      return [s84.tanh(r51("x", a71, e36, t67))];
    case "Tan":
      return [s84.tan(r51("x", a71, e36, t67))];
    case "ClipByValue":
      return [s84.clipByValue(r51("x", a71, e36, t67), r51("clipValueMin", a71, e36, t67), r51("clipValueMax", a71, e36, t67))];
    case "Relu6":
      return [s84.relu6(r51("x", a71, e36, t67))];
    case "Rsqrt":
      return [s84.rsqrt(b55(a71.inputNames[0], e36, t67))];
    case "LeakyRelu":
      return [s84.leakyRelu(r51("x", a71, e36, t67), r51("alpha", a71, e36, t67))];
    case "Prelu":
      return [s84.prelu(r51("x", a71, e36, t67), r51("alpha", a71, e36, t67))];
    case "IsNan":
      return [s84.isNaN(b55(a71.inputNames[0], e36, t67))];
    case "IsInf":
      return [s84.isInf(b55(a71.inputNames[0], e36, t67))];
    case "IsFinite":
      return [s84.isFinite(b55(a71.inputNames[0], e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
function I42(a71, e36, t67 = "") {
  if (!(typeof a71 == "number" || typeof e36 == "number")) {
    util_exports.assert(a71.length === e36.length, () => t67 + ` Shapes ${a71} and ${e36} must match`);
    for (let s84 = 0; s84 < a71.length; s84++) {
      let n67 = a71[s84], i88 = e36[s84];
      util_exports.assert(n67 < 0 || i88 < 0 || n67 === i88, () => t67 + ` Shapes ${a71} and ${e36} must match`);
    }
  }
}
function He(a71) {
  return !(typeof a71 == "number" || a71.some((e36) => e36 < 0));
}
function D34(a71, e36, t67) {
  let s84 = ae5(a71, t67), n67 = !He(s84);
  if (n67 && e36.length === 0) throw new Error(`Tried to calculate elements of an empty list with non-fully-defined elementShape: ${s84}`);
  if (n67 && e36.forEach((i88) => {
    s84 = ae5(i88.shape, s84);
  }), !He(s84)) throw new Error(`Non-fully-defined elementShape: ${s84}`);
  return s84;
}
function ae5(a71, e36) {
  if (typeof a71 == "number") return e36;
  if (typeof e36 == "number") return a71;
  if (a71.length !== e36.length) throw new Error(`Incompatible ranks during merge: ${a71} vs. ${e36}`);
  let t67 = [];
  for (let s84 = 0; s84 < a71.length; ++s84) {
    let n67 = a71[s84], i88 = e36[s84];
    if (n67 >= 0 && i88 >= 0 && n67 !== i88) throw new Error(`Incompatible shape during merge: ${a71} vs. ${e36}`);
    t67[s84] = n67 >= 0 ? n67 : i88;
  }
  return t67;
}
var se4 = class {
  constructor(e36, t67, s84, n67, i88, p103, m96) {
    this.name = e36, this.dtype = t67, this.maxSize = s84, this.elementShape = n67, this.identicalElementShapes = i88, this.dynamicSize = p103, this.clearAfterRead = m96, this.tensors = [], this.closed_ = false, this.idTensor = m21(0), N3(this.idTensor);
  }
  get id() {
    return this.idTensor.id;
  }
  get closed() {
    return this.closed_;
  }
  clearAndClose(e36) {
    this.tensors.forEach((t67) => {
      (e36 == null || !e36.has(t67.tensor.id)) && t67.tensor.dispose();
    }), this.tensors = [], this.closed_ = true, this.idTensor.dispose();
  }
  size() {
    return this.tensors.length;
  }
  read(e36) {
    if (this.closed_) throw new Error(`TensorArray ${this.name} has already been closed.`);
    if (e36 < 0 || e36 >= this.size()) throw new Error(`Tried to read from index ${e36}, but array size is: ${this.size()}`);
    let t67 = this.tensors[e36];
    if (t67.cleared) throw new Error(`TensorArray ${this.name}: Could not read index ${e36} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);
    return this.clearAfterRead && (t67.cleared = true), t67.read = true, t67.tensor;
  }
  readMany(e36) {
    return e36.map((t67) => this.read(t67));
  }
  write(e36, t67) {
    if (this.closed_) throw new Error(`TensorArray ${this.name} has already been closed.`);
    if (e36 < 0 || !this.dynamicSize && e36 >= this.maxSize) throw new Error(`Tried to write to index ${e36}, but array is not resizeable and size is: ${this.maxSize}`);
    let s84 = this.tensors[e36] || {};
    if (t67.dtype !== this.dtype) throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e36},
          because the value dtype is ${t67.dtype}, but TensorArray dtype is ${this.dtype}.`);
    if (this.size() === 0 && (this.elementShape == null || this.elementShape.length === 0) && (this.elementShape = t67.shape), I42(this.elementShape, t67.shape, `TensorArray ${this.name}: Could not write to TensorArray index ${e36}.`), s84.read) throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e36}, because it has already been read.`);
    if (s84.written) throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e36}, because it has already been written.`);
    s84.tensor = t67, N3(t67), s84.written = true, this.tensors[e36] = s84;
  }
  writeMany(e36, t67) {
    if (e36.length !== t67.length) throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${e36.length} is not the same as tensors size: ${t67.length}.`);
    e36.forEach((s84, n67) => this.write(s84, t67[n67]));
  }
  gather(e36, t67) {
    if (t67 && t67 !== this.dtype) throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${t67}`);
    if (e36) e36 = e36.slice(0, this.size());
    else {
      e36 = [];
      for (let n67 = 0; n67 < this.size(); n67++) e36.push(n67);
    }
    if (e36.length === 0) return p10([], [0].concat(this.elementShape));
    let s84 = this.readMany(e36);
    return I42(this.elementShape, s84[0].shape, "TensorArray shape mismatch: "), g21(s84, 0);
  }
  concat(e36) {
    if (e36 && e36 !== this.dtype) throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${e36}`);
    if (this.size() === 0) return p10([], [0].concat(this.elementShape));
    let t67 = [];
    for (let n67 = 0; n67 < this.size(); n67++) t67.push(n67);
    let s84 = this.readMany(t67);
    return I42(this.elementShape, s84[0].shape, `TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${s84[0].shape})`), E9(s84, 0);
  }
  scatter(e36, t67) {
    if (t67.dtype !== this.dtype) throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t67.dtype}`);
    if (e36.length !== t67.shape[0]) throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e36.length} vs. ${t67.shape[0]}`);
    let s84 = Math.max(...e36);
    if (!this.dynamicSize && s84 >= this.maxSize) throw new Error(`Max index must be < array size (${s84}  vs. ${this.maxSize})`);
    this.writeMany(e36, g22(t67, 0));
  }
  split(e36, t67) {
    if (t67.dtype !== this.dtype) throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t67.dtype}`);
    let s84 = 0, n67 = e36.map((u86) => (s84 += u86, s84));
    if (s84 !== t67.shape[0]) throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${s84}, and tensor's shape is: ${t67.shape}`);
    if (!this.dynamicSize && e36.length !== this.maxSize) throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${e36.length}), and the TensorArray is not marked as dynamically resizeable`);
    let i88 = s84 === 0 ? 0 : t67.size / s84, p103 = [];
    g4(() => {
      t67 = h9(t67, [1, s84, i88]);
      for (let u86 = 0; u86 < e36.length; ++u86) {
        let l80 = [0, u86 === 0 ? 0 : n67[u86 - 1], 0], y43 = [1, e36[u86], i88];
        p103[u86] = h9(E10(t67, l80, y43), this.elementShape);
      }
      return p103;
    });
    let m96 = [];
    for (let u86 = 0; u86 < e36.length; u86++) m96[u86] = u86;
    this.writeMany(m96, p103);
  }
};
var x70 = class a66 {
  get id() {
    return this.idTensor.id;
  }
  constructor(e36, t67, s84, n67 = -1) {
    this.tensors = e36, this.elementShape = t67, this.elementDtype = s84, e36?.forEach((i88) => {
      if (s84 !== i88.dtype) throw new Error(`Invalid data types; op elements ${s84}, but list elements ${i88.dtype}`);
      I42(t67, i88.shape, "TensorList shape mismatch: "), N3(i88);
    }), this.idTensor = m21(0), this.maxNumElements = n67, N3(this.idTensor);
  }
  copy() {
    return new a66([...this.tensors], this.elementShape, this.elementDtype);
  }
  clearAndClose(e36) {
    this.tensors.forEach((t67) => {
      (e36 == null || !e36.has(t67.id)) && t67.dispose();
    }), this.tensors.length = 0, this.idTensor.dispose();
  }
  size() {
    return this.tensors.length;
  }
  stack(e36, t67, s84 = -1) {
    if (t67 !== this.elementDtype) throw new Error(`Invalid data types; op elements ${t67}, but list elements ${this.elementDtype}`);
    if (s84 !== -1 && this.tensors.length !== s84) throw new Error(`Operation expected a list with ${s84} elements but got a list with ${this.tensors.length} elements.`);
    I42(e36, this.elementShape, "TensorList shape mismatch: ");
    let n67 = D34(this.elementShape, this.tensors, e36);
    return g4(() => {
      let i88 = this.tensors.map((p103) => h9(p103, n67));
      return g21(i88, 0);
    });
  }
  popBack(e36, t67) {
    if (t67 !== this.elementDtype) throw new Error(`Invalid data types; op elements ${t67}, but list elements ${this.elementDtype}`);
    if (this.size() === 0) throw new Error("Trying to pop from an empty list.");
    let s84 = D34(this.elementShape, this.tensors, e36), n67 = this.tensors.pop();
    return n67.kept = false, I42(n67.shape, e36, "TensorList shape mismatch: "), h9(n67, s84);
  }
  pushBack(e36) {
    if (e36.dtype !== this.elementDtype) throw new Error(`Invalid data types; op elements ${e36.dtype}, but list elements ${this.elementDtype}`);
    if (I42(e36.shape, this.elementShape, "TensorList shape mismatch: "), this.maxNumElements === this.size()) throw new Error("Trying to push element into a full list.");
    N3(e36), this.tensors.push(e36);
  }
  resize(e36) {
    if (e36 < 0) throw new Error(`TensorListResize expects size to be non-negative. Got: ${e36}`);
    if (this.maxNumElements !== -1 && e36 > this.maxNumElements) throw new Error(`TensorListResize input size ${e36} is greater maxNumElement ${this.maxNumElements}.`);
    let t67 = new a66([], this.elementShape, this.elementDtype, this.maxNumElements);
    t67.tensors.length = e36;
    for (let s84 = 0; s84 < Math.min(this.tensors.length, e36); ++s84) t67.tensors[s84] = this.tensors[s84];
    return t67;
  }
  getItem(e36, t67, s84) {
    if (s84 !== this.elementDtype) throw new Error(`Invalid data types; op elements ${s84}, but list elements ${this.elementDtype}`);
    if (e36 < 0 || e36 > this.tensors.length) throw new Error(`Trying to access element ${e36} in a list with ${this.tensors.length} elements.`);
    if (this.tensors[e36] == null) throw new Error(`element at index ${e36} is null.`);
    I42(this.tensors[e36].shape, t67, "TensorList shape mismatch: ");
    let n67 = D34(this.elementShape, this.tensors, t67);
    return h9(this.tensors[e36], n67);
  }
  setItem(e36, t67) {
    if (t67.dtype !== this.elementDtype) throw new Error(`Invalid data types; op elements ${t67.dtype}, but list elements ${this.elementDtype}`);
    if (e36 < 0 || this.maxNumElements !== -1 && e36 >= this.maxNumElements) throw new Error(`Trying to set element ${e36} in a list with max ${this.maxNumElements} elements.`);
    I42(this.elementShape, t67.shape, "TensorList shape mismatch: "), N3(t67), this.tensors[e36] != null && (this.tensors[e36].kept = false), this.tensors[e36] = t67;
  }
  gather(e36, t67, s84) {
    if (t67 !== this.elementDtype) throw new Error(`Invalid data types; op elements ${t67}, but list elements ${this.elementDtype}`);
    I42(this.elementShape, s84, "TensorList shape mismatch: "), e36 = e36.slice(0, this.size());
    let n67 = D34(this.elementShape, this.tensors, s84);
    return e36.length === 0 ? p10([], [0].concat(n67)) : g4(() => {
      let i88 = e36.map((p103) => h9(this.tensors[p103], n67));
      return g21(i88, 0);
    });
  }
  concat(e36, t67) {
    if (e36 && e36 !== this.elementDtype) throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${e36}`);
    I42(this.elementShape, t67, "TensorList shape mismatch: ");
    let s84 = D34(this.elementShape, this.tensors, t67);
    return this.size() === 0 ? p10([], [0].concat(s84)) : g4(() => {
      let n67 = this.tensors.map((i88) => h9(i88, s84));
      return E9(n67, 0);
    });
  }
};
function Xe(a71, e36, t67) {
  let s84 = a71.dtype;
  if (a71.shape.length < 1) throw new Error(`Tensor must be at least a vector, but saw shape: ${a71.shape}`);
  if (a71.dtype !== t67) throw new Error(`Invalid data types; op elements ${a71.dtype}, but list elements ${t67}`);
  let n67 = a71.shape.slice(1);
  I42(n67, e36, "TensorList shape mismatch: ");
  let i88 = g22(a71);
  return new x70(i88, e36, s84);
}
function Je(a71, e36, t67, s84) {
  return new x70([], a71, e36, s84);
}
function Ze(a71, e36, t67, s84) {
  if (e36.length !== a71.shape[0]) throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e36.length} vs. ${a71.shape[0]}`);
  let n67 = Math.max(...e36);
  if (s84 != null && s84 !== -1 && n67 >= s84) throw new Error(`Max index must be < array size (${n67}  vs. ${s84})`);
  let i88 = new x70([], t67, a71.dtype, s84), p103 = g22(a71, 0);
  return e36.forEach((m96, u86) => {
    i88.setItem(m96, p103[u86]);
  }), i88;
}
function Me(a71, e36, t67) {
  let s84 = 0, n67 = e36.map((l80) => (s84 += l80, s84));
  if (s84 !== a71.shape[0]) throw new Error(`Expected sum of lengths to be equal to
          tensor.shape[0], but sum of lengths is
        ${s84}, and tensor's shape is: ${a71.shape}`);
  let i88 = a71.shape.slice(1), p103 = ae5(i88, t67), m96 = s84 === 0 ? 0 : a71.size / s84, u86 = g4(() => {
    let l80 = [];
    a71 = h9(a71, [1, s84, m96]);
    for (let y43 = 0; y43 < e36.length; ++y43) {
      let h74 = [0, y43 === 0 ? 0 : n67[y43 - 1], 0], N58 = [1, e36[y43], m96];
      l80[y43] = h9(E10(a71, h74, N58), p103);
    }
    return a71.dispose(), l80;
  }), o80 = new x70([], t67, a71.dtype, e36.length);
  for (let l80 = 0; l80 < u86.length; l80++) o80.setItem(l80, u86[l80]);
  return o80;
}
var et4 = async (a71, e36, t67) => {
  switch (a71.op) {
    case "If":
    case "StatelessIf": {
      let s84 = r51("thenBranch", a71, e36, t67), n67 = r51("elseBranch", a71, e36, t67), i88 = r51("cond", a71, e36, t67), p103 = r51("args", a71, e36, t67);
      return (await i88.data())[0] ? t67.functionMap[s84].executeFunctionAsync(p103, t67.tensorArrayMap, t67.tensorListMap) : t67.functionMap[n67].executeFunctionAsync(p103, t67.tensorArrayMap, t67.tensorListMap);
    }
    case "While":
    case "StatelessWhile": {
      let s84 = r51("body", a71, e36, t67), n67 = r51("cond", a71, e36, t67), i88 = r51("args", a71, e36, t67), p103 = await t67.functionMap[n67].executeFunctionAsync(i88, t67.tensorArrayMap, t67.tensorListMap), m96 = i88.map((l80) => l80.id), u86 = await p103[0].data();
      p103.forEach((l80) => {
        !l80.kept && m96.indexOf(l80.id) === -1 && l80.dispose();
      });
      let o80 = i88;
      for (; u86[0]; ) {
        let l80 = o80;
        o80 = await t67.functionMap[s84].executeFunctionAsync(o80, t67.tensorArrayMap, t67.tensorListMap);
        let y43 = o80.map((h74) => h74.id);
        l80.forEach((h74) => {
          !h74.kept && m96.indexOf(h74.id) === -1 && y43.indexOf(h74.id) === -1 && h74.dispose();
        });
        let c103 = await t67.functionMap[n67].executeFunctionAsync(o80, t67.tensorArrayMap, t67.tensorListMap);
        u86 = await c103[0].data(), c103.forEach((h74) => {
          !h74.kept && m96.indexOf(h74.id) === -1 && y43.indexOf(h74.id) === -1 && h74.dispose();
        });
      }
      return o80;
    }
    case "LoopCond": {
      let s84 = r51("pred", a71, e36, t67);
      return [A30(s84)];
    }
    case "Switch": {
      let s84 = r51("pred", a71, e36, t67), n67 = r51("data", a71, e36, t67);
      return n67.kept || (n67 = A30(n67)), (await s84.data())[0] ? [void 0, n67] : [n67, void 0];
    }
    case "Merge": {
      let s84 = a71.inputNames.find((n67) => b55(n67, e36, t67) !== void 0);
      if (s84) {
        let n67 = b55(s84, e36, t67);
        return [A30(n67)];
      }
      return;
    }
    case "Enter": {
      let s84 = r51("frameName", a71, e36, t67), n67 = r51("tensor", a71, e36, t67);
      return t67.enterFrame(s84), [A30(n67)];
    }
    case "Exit": {
      let s84 = r51("tensor", a71, e36, t67);
      return t67.exitFrame(), [A30(s84)];
    }
    case "NextIteration": {
      let s84 = r51("tensor", a71, e36, t67);
      return t67.nextIteration(), [A30(s84)];
    }
    case "TensorArrayV3": {
      let s84 = r51("size", a71, e36, t67), n67 = r51("dtype", a71, e36, t67), i88 = r51("elementShape", a71, e36, t67), p103 = r51("dynamicSize", a71, e36, t67), m96 = r51("clearAfterRead", a71, e36, t67), u86 = r51("identicalElementShapes", a71, e36, t67), o80 = r51("name", a71, e36, t67), l80 = new se4(o80, n67, s84, i88, u86, p103, m96);
      return t67.addTensorArray(l80), [l80.idTensor, m21(1)];
    }
    case "TensorArrayWriteV3": {
      let s84 = r51("tensorArrayId", a71, e36, t67), n67 = r51("index", a71, e36, t67), i88 = r51("tensor", a71, e36, t67), p103 = t67.getTensorArray(s84.id);
      return p103.write(n67, i88), [p103.idTensor];
    }
    case "TensorArrayReadV3": {
      let s84 = r51("tensorArrayId", a71, e36, t67), n67 = r51("index", a71, e36, t67);
      return [t67.getTensorArray(s84.id).read(n67)];
    }
    case "TensorArrayGatherV3": {
      let s84 = r51("tensorArrayId", a71, e36, t67), n67 = r51("indices", a71, e36, t67), i88 = r51("dtype", a71, e36, t67);
      return [t67.getTensorArray(s84.id).gather(n67, i88)];
    }
    case "TensorArrayScatterV3": {
      let s84 = r51("tensorArrayId", a71, e36, t67), n67 = r51("indices", a71, e36, t67), i88 = r51("tensor", a71, e36, t67), p103 = t67.getTensorArray(s84.id);
      return p103.scatter(n67, i88), [p103.idTensor];
    }
    case "TensorArrayConcatV3": {
      let s84 = r51("tensorArrayId", a71, e36, t67), n67 = t67.getTensorArray(s84.id), i88 = r51("dtype", a71, e36, t67);
      return [n67.concat(i88)];
    }
    case "TensorArraySplitV3": {
      let s84 = r51("tensorArrayId", a71, e36, t67), n67 = r51("tensor", a71, e36, t67), i88 = r51("lengths", a71, e36, t67), p103 = t67.getTensorArray(s84.id);
      return p103.split(i88, n67), [p103.idTensor];
    }
    case "TensorArraySizeV3": {
      let s84 = r51("tensorArrayId", a71, e36, t67), n67 = t67.getTensorArray(s84.id);
      return [m21(n67.size(), "int32")];
    }
    case "TensorArrayCloseV3": {
      let s84 = r51("tensorArrayId", a71, e36, t67), n67 = t67.getTensorArray(s84.id);
      return n67.clearAndClose(), [n67.idTensor];
    }
    case "TensorListSetItem": {
      let s84 = r51("tensorListId", a71, e36, t67), n67 = r51("index", a71, e36, t67), i88 = r51("tensor", a71, e36, t67), p103 = t67.getTensorList(s84.id);
      return p103.setItem(n67, i88), [p103.idTensor];
    }
    case "TensorListGetItem": {
      let s84 = r51("tensorListId", a71, e36, t67), n67 = r51("index", a71, e36, t67), i88 = r51("elementShape", a71, e36, t67), p103 = r51("elementDType", a71, e36, t67);
      return [t67.getTensorList(s84.id).getItem(n67, i88, p103)];
    }
    case "TensorListScatterV2":
    case "TensorListScatter": {
      let s84 = r51("indices", a71, e36, t67), n67 = r51("tensor", a71, e36, t67), i88 = r51("elementShape", a71, e36, t67), p103 = r51("numElements", a71, e36, t67), m96 = Ze(n67, s84, i88, p103);
      return t67.addTensorList(m96), [m96.idTensor];
    }
    case "TensorListReserve":
    case "EmptyTensorList": {
      let s84 = r51("elementShape", a71, e36, t67), n67 = r51("elementDType", a71, e36, t67), i88;
      a71.op === "TensorListReserve" ? i88 = "numElements" : i88 = "maxNumElements";
      let p103 = r51(i88, a71, e36, t67), m96 = a71.op === "TensorListReserve" ? -1 : p103, u86 = Je(s84, n67, p103, m96);
      return t67.addTensorList(u86), [u86.idTensor];
    }
    case "TensorListGather": {
      let s84 = r51("tensorListId", a71, e36, t67), n67 = r51("indices", a71, e36, t67), i88 = r51("elementShape", a71, e36, t67), p103 = r51("elementDType", a71, e36, t67);
      return [t67.getTensorList(s84.id).gather(n67, p103, i88)];
    }
    case "TensorListStack": {
      let s84 = r51("tensorListId", a71, e36, t67), n67 = r51("elementShape", a71, e36, t67), i88 = r51("elementDType", a71, e36, t67), p103 = r51("numElements", a71, e36, t67);
      return [t67.getTensorList(s84.id).stack(n67, i88, p103)];
    }
    case "TensorListFromTensor": {
      let s84 = r51("tensor", a71, e36, t67), n67 = r51("elementShape", a71, e36, t67), i88 = r51("elementDType", a71, e36, t67), p103 = Xe(s84, n67, i88);
      return t67.addTensorList(p103), [p103.idTensor];
    }
    case "TensorListConcat":
    case "TensorListConcatV2": {
      let s84 = r51("tensorListId", a71, e36, t67), n67 = t67.getTensorList(s84.id), i88 = r51("dtype", a71, e36, t67), p103 = r51("elementShape", a71, e36, t67);
      return [n67.concat(i88, p103)];
    }
    case "TensorListPushBack": {
      let s84 = r51("tensorListId", a71, e36, t67), n67 = r51("tensor", a71, e36, t67), i88 = t67.getTensorList(s84.id);
      return i88.pushBack(n67), [i88.idTensor];
    }
    case "TensorListPopBack": {
      let s84 = r51("tensorListId", a71, e36, t67), n67 = r51("elementShape", a71, e36, t67), i88 = r51("elementDType", a71, e36, t67);
      return [t67.getTensorList(s84.id).popBack(n67, i88)];
    }
    case "TensorListSplit": {
      let s84 = r51("tensor", a71, e36, t67), n67 = r51("elementShape", a71, e36, t67), i88 = r51("lengths", a71, e36, t67), p103 = Me(s84, i88, n67);
      return t67.addTensorList(p103), [p103.idTensor];
    }
    case "TensorListLength": {
      let s84 = r51("tensorListId", a71, e36, t67), n67 = t67.getTensorList(s84.id);
      return [m21(n67.size(), "int32")];
    }
    case "TensorListResize": {
      let s84 = r51("tensorListId", a71, e36, t67), n67 = r51("size", a71, e36, t67), p103 = t67.getTensorList(s84.id).resize(n67);
      return t67.addTensorList(p103), [p103.idTensor];
    }
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
function tt2(a71, e36, t67) {
  let [s84, n67] = r51("fusedOps", a71, e36, t67), i88 = s84 === "biasadd", p103 = !i88, m96 = n67 === "prelu", u86 = s84 === "fusedbatchnorm", o80 = r51("numArgs", a71, e36, t67);
  if (i88) {
    if (m96 && o80 !== 2) throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
    if (!m96 && i88 && o80 !== 1) throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.");
  }
  if (u86) throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");
  let l80 = r51("strides", a71, e36, t67), y43 = F27(a71, e36, t67), c103 = r51("dataFormat", a71, e36, t67).toUpperCase(), h74 = r51("dilations", a71, e36, t67), [N58, f85] = r51("args", a71, e36, t67);
  p103 && (f85 = N58, N58 = void 0);
  let d55 = r51("leakyreluAlpha", a71, e36, t67);
  return { stride: l80, pad: y43, dataFormat: c103, dilations: h74, biasArg: N58, preluArg: f85, activationFunc: n67, leakyreluAlpha: d55 };
}
var at5 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "Conv1D": {
      let n67 = r51("stride", a71, e36, t67), i88 = r51("pad", a71, e36, t67), p103 = r51("dataFormat", a71, e36, t67).toUpperCase(), m96 = r51("dilation", a71, e36, t67);
      return [s84.conv1d(r51("x", a71, e36, t67), r51("filter", a71, e36, t67), n67, i88, p103, m96)];
    }
    case "Conv2D": {
      let n67 = r51("strides", a71, e36, t67), i88 = F27(a71, e36, t67), p103 = r51("dataFormat", a71, e36, t67).toUpperCase(), m96 = r51("dilations", a71, e36, t67);
      return [s84.conv2d(r51("x", a71, e36, t67), r51("filter", a71, e36, t67), [n67[1], n67[2]], i88, p103, [m96[1], m96[2]])];
    }
    case "_FusedConv2D": {
      let { stride: n67, pad: i88, dataFormat: p103, dilations: m96, biasArg: u86, preluArg: o80, activationFunc: l80, leakyreluAlpha: y43 } = tt2(a71, e36, t67);
      return [s84.fused.conv2d({ x: r51("x", a71, e36, t67), filter: r51("filter", a71, e36, t67), strides: [n67[1], n67[2]], pad: i88, dataFormat: p103, dilations: [m96[1], m96[2]], bias: u86, activation: l80, preluActivationWeights: o80, leakyreluAlpha: y43 })];
    }
    case "FusedDepthwiseConv2dNative": {
      let { stride: n67, pad: i88, dataFormat: p103, dilations: m96, biasArg: u86, preluArg: o80, activationFunc: l80, leakyreluAlpha: y43 } = tt2(a71, e36, t67);
      return [s84.fused.depthwiseConv2d({ x: r51("x", a71, e36, t67), filter: r51("filter", a71, e36, t67), strides: [n67[1], n67[2]], pad: i88, dataFormat: p103, dilations: [m96[1], m96[2]], bias: u86, activation: l80, preluActivationWeights: o80, leakyreluAlpha: y43 })];
    }
    case "Conv2DBackpropInput":
    case "Conv2dTranspose": {
      let n67 = r51("outputShape", a71, e36, t67), i88 = r51("strides", a71, e36, t67), p103 = F27(a71, e36, t67);
      return [s84.conv2dTranspose(r51("x", a71, e36, t67), r51("filter", a71, e36, t67), n67, [i88[1], i88[2]], p103)];
    }
    case "DepthwiseConv2dNative":
    case "DepthwiseConv2d": {
      let n67 = r51("strides", a71, e36, t67), i88 = F27(a71, e36, t67), p103 = r51("dilations", a71, e36, t67), m96 = r51("dataFormat", a71, e36, t67).toUpperCase();
      return [s84.depthwiseConv2d(r51("input", a71, e36, t67), r51("filter", a71, e36, t67), [n67[1], n67[2]], i88, m96, [p103[1], p103[2]])];
    }
    case "Conv3D": {
      let n67 = r51("strides", a71, e36, t67), i88 = r51("pad", a71, e36, t67), p103 = r51("dataFormat", a71, e36, t67).toUpperCase(), m96 = r51("dilations", a71, e36, t67);
      return [s84.conv3d(r51("x", a71, e36, t67), r51("filter", a71, e36, t67), [n67[1], n67[2], n67[3]], i88, p103, [m96[1], m96[2], m96[3]])];
    }
    case "AvgPool": {
      let n67 = r51("strides", a71, e36, t67), i88 = r51("pad", a71, e36, t67), p103 = r51("kernelSize", a71, e36, t67);
      return [s84.avgPool(r51("x", a71, e36, t67), [p103[1], p103[2]], [n67[1], n67[2]], i88)];
    }
    case "MaxPool": {
      let n67 = r51("strides", a71, e36, t67), i88 = r51("pad", a71, e36, t67), p103 = r51("kernelSize", a71, e36, t67);
      return [s84.maxPool(r51("x", a71, e36, t67), [p103[1], p103[2]], [n67[1], n67[2]], i88)];
    }
    case "MaxPoolWithArgmax": {
      let n67 = r51("strides", a71, e36, t67), i88 = r51("pad", a71, e36, t67), p103 = r51("kernelSize", a71, e36, t67), m96 = r51("includeBatchInIndex", a71, e36, t67), { result: u86, indexes: o80 } = s84.maxPoolWithArgmax(r51("x", a71, e36, t67), [p103[1], p103[2]], [n67[1], n67[2]], i88, m96);
      return [u86, o80];
    }
    case "AvgPool3D": {
      let n67 = r51("strides", a71, e36, t67), i88 = r51("pad", a71, e36, t67), p103 = r51("kernelSize", a71, e36, t67);
      return [s84.avgPool3d(r51("x", a71, e36, t67), [p103[1], p103[2], p103[3]], [n67[1], n67[2], n67[3]], i88)];
    }
    case "MaxPool3D": {
      let n67 = r51("strides", a71, e36, t67), i88 = r51("pad", a71, e36, t67), p103 = r51("kernelSize", a71, e36, t67);
      return [s84.maxPool3d(r51("x", a71, e36, t67), [p103[1], p103[2], p103[3]], [n67[1], n67[2], n67[3]], i88)];
    }
    case "Dilation2D": {
      let n67 = r51("strides", a71, e36, t67), i88 = r51("pad", a71, e36, t67), p103 = r51("dilations", a71, e36, t67), m96 = n67[1], u86 = n67[2], o80 = p103[1], l80 = p103[2];
      return [s84.dilation2d(r51("x", a71, e36, t67), r51("filter", a71, e36, t67), [m96, u86], i88, [o80, l80], "NHWC")];
    }
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var st5 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "Fill": {
      let n67 = r51("shape", a71, e36, t67), i88 = r51("dtype", a71, e36, t67), p103 = r51("value", a71, e36, t67);
      return [s84.fill(n67, p103, i88)];
    }
    case "LinSpace": {
      let n67 = r51("start", a71, e36, t67), i88 = r51("stop", a71, e36, t67), p103 = r51("num", a71, e36, t67);
      return [s84.linspace(n67, i88, p103)];
    }
    case "Multinomial": {
      let n67 = r51("logits", a71, e36, t67), i88 = r51("numSamples", a71, e36, t67), p103 = r51("seed", a71, e36, t67);
      return [s84.multinomial(n67, i88, p103)];
    }
    case "OneHot": {
      let n67 = r51("indices", a71, e36, t67), i88 = r51("depth", a71, e36, t67), p103 = r51("onValue", a71, e36, t67), m96 = r51("offValue", a71, e36, t67), u86 = r51("dtype", a71, e36, t67);
      return [s84.oneHot(n67, i88, p103, m96, u86)];
    }
    case "Ones":
      return [s84.ones(r51("shape", a71, e36, t67), r51("dtype", a71, e36, t67))];
    case "OnesLike":
      return [s84.onesLike(r51("x", a71, e36, t67))];
    case "RandomStandardNormal":
      return [s84.randomStandardNormal(r51("shape", a71, e36, t67), r51("dtype", a71, e36, t67), r51("seed", a71, e36, t67))];
    case "RandomUniform":
      return [s84.randomUniform(r51("shape", a71, e36, t67), r51("minval", a71, e36, t67), r51("maxval", a71, e36, t67), r51("dtype", a71, e36, t67))];
    case "RandomUniformInt":
      return [s84.randomUniformInt(r51("shape", a71, e36, t67), r51("minval", a71, e36, t67), r51("maxval", a71, e36, t67), r51("seed", a71, e36, t67))];
    case "Range": {
      let n67 = r51("start", a71, e36, t67), i88 = r51("stop", a71, e36, t67), p103 = r51("step", a71, e36, t67);
      return [s84.range(n67, i88, p103, r51("dtype", a71, e36, t67))];
    }
    case "TruncatedNormal": {
      let n67 = r51("shape", a71, e36, t67), i88 = r51("mean", a71, e36, t67), p103 = r51("stdDev", a71, e36, t67), m96 = r51("seed", a71, e36, t67);
      return [s84.truncatedNormal(n67, i88, p103, r51("dtype", a71, e36, t67), m96)];
    }
    case "Zeros":
      return [s84.zeros(r51("shape", a71, e36, t67), r51("dtype", a71, e36, t67))];
    case "ZerosLike":
      return [s84.zerosLike(r51("x", a71, e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
function xe4(a71, e36, t67) {
  let s84 = r51("boxes", a71, e36, t67), n67 = r51("scores", a71, e36, t67), i88 = r51("maxOutputSize", a71, e36, t67), p103 = r51("iouThreshold", a71, e36, t67), m96 = r51("scoreThreshold", a71, e36, t67), u86 = r51("softNmsSigma", a71, e36, t67);
  return { boxes: s84, scores: n67, maxOutputSize: i88, iouThreshold: p103, scoreThreshold: m96, softNmsSigma: u86 };
}
var rt6 = async (a71, e36, t67, s84, n67 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "NonMaxSuppressionV5": {
      let { boxes: i88, scores: p103, maxOutputSize: m96, iouThreshold: u86, scoreThreshold: o80, softNmsSigma: l80 } = xe4(a71, e36, t67), y43 = await n67.image.nonMaxSuppressionWithScoreAsync(i88, p103, m96, u86, o80, l80);
      return [y43.selectedIndices, y43.selectedScores];
    }
    case "NonMaxSuppressionV4": {
      let { boxes: i88, scores: p103, maxOutputSize: m96, iouThreshold: u86, scoreThreshold: o80 } = xe4(a71, e36, t67), l80 = r51("padToMaxOutputSize", a71, e36, t67), y43 = await n67.image.nonMaxSuppressionPaddedAsync(i88, p103, m96, u86, o80, l80);
      return [y43.selectedIndices, y43.validOutputs];
    }
    case "NonMaxSuppressionV3":
    case "NonMaxSuppressionV2": {
      let { boxes: i88, scores: p103, maxOutputSize: m96, iouThreshold: u86, scoreThreshold: o80 } = xe4(a71, e36, t67);
      return [await n67.image.nonMaxSuppressionAsync(i88, p103, m96, u86, o80)];
    }
    case "Where": {
      let i88 = n67.cast(r51("condition", a71, e36, t67), "bool"), p103 = [await n67.whereAsync(i88)];
      return i88.dispose(), p103;
    }
    case "ListDiff":
      return n67.setdiff1dAsync(r51("x", a71, e36, t67), r51("y", a71, e36, t67));
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var nt3 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "LowerBound": {
      let n67 = r51("sortedSequence", a71, e36, t67), i88 = r51("values", a71, e36, t67);
      return [s84.lowerBound(n67, i88)];
    }
    case "TopKV2": {
      let n67 = r51("x", a71, e36, t67), i88 = r51("k", a71, e36, t67), p103 = r51("sorted", a71, e36, t67), m96 = s84.topk(n67, i88, p103);
      return [m96.values, m96.indices];
    }
    case "UpperBound": {
      let n67 = r51("sortedSequence", a71, e36, t67), i88 = r51("values", a71, e36, t67);
      return [s84.upperBound(n67, i88)];
    }
    case "Unique": {
      let n67 = r51("x", a71, e36, t67), i88 = s84.unique(n67);
      return [i88.values, i88.indices];
    }
    case "UniqueV2": {
      let n67 = r51("x", a71, e36, t67), i88 = r51("axis", a71, e36, t67), p103 = s84.unique(n67, i88);
      return [p103.values, p103.indices];
    }
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var it3 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "Const":
      return e36[a71.name];
    case "PlaceholderWithDefault":
      let n67 = r51("default", a71, e36, t67);
      return [b55(a71.name, e36, t67) || n67];
    case "Placeholder":
      return [b55(a71.name, e36, t67)];
    case "Identity":
    case "StopGradient":
    case "FakeQuantWithMinMaxVars": {
      let l80 = r51("x", a71, e36, t67);
      return [A30(l80)];
    }
    case "IdentityN":
      return r51("x", a71, e36, t67).map((l80) => A30(l80));
    case "Snapshot":
      let i88 = r51("x", a71, e36, t67);
      return [A30(i88)];
    case "Shape":
      return [s84.tensor1d(r51("x", a71, e36, t67).shape, "int32")];
    case "ShapeN":
      return r51("x", a71, e36, t67).map((l80) => s84.tensor1d(l80.shape));
    case "Size":
      return [s84.scalar(r51("x", a71, e36, t67).size, "int32")];
    case "Rank":
      return [s84.scalar(r51("x", a71, e36, t67).rank, "int32")];
    case "NoOp":
      return [s84.scalar(1)];
    case "Print":
      let p103 = r51("x", a71, e36, t67), m96 = r51("data", a71, e36, t67), u86 = r51("message", a71, e36, t67), o80 = r51("summarize", a71, e36, t67);
      console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance."), console.log(u86);
      for (let l80 = 0; l80 < m96.length; l80++) console.log(Array.prototype.slice.call(m96[l80].dataSync()).slice(0, o80));
      return [p103];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var ie7 = class {
  get id() {
    return this.handle.id;
  }
  constructor(e36, t67) {
    this.keyDType = e36, this.valueDType = t67, this.handle = m21(0), this.tensorMap = /* @__PURE__ */ new Map(), N3(this.handle);
  }
  clearAndClose() {
    this.tensorMap.forEach((e36) => e36.dispose()), this.tensorMap.clear(), this.handle.dispose();
  }
  size() {
    return this.tensorMap.size;
  }
  tensorSize() {
    return m21(this.size(), "int32");
  }
  async import(e36, t67) {
    this.checkKeyAndValueTensor(e36, t67);
    let s84 = await e36.data();
    return this.tensorMap.forEach((n67) => n67.dispose()), this.tensorMap.clear(), g4(() => {
      let n67 = g22(t67), i88 = s84.length, p103 = n67.length;
      util_exports.assert(i88 === p103, () => `The number of elements doesn't match, keys has ${i88} elements, the values has ${p103} elements.`);
      for (let m96 = 0; m96 < i88; m96++) {
        let u86 = s84[m96], o80 = n67[m96];
        N3(o80), this.tensorMap.set(u86, o80);
      }
      return this.handle;
    });
  }
  async find(e36, t67) {
    this.checkKeyAndValueTensor(e36, t67);
    let s84 = await e36.data();
    return g4(() => {
      let n67 = [];
      for (let i88 = 0; i88 < s84.length; i88++) {
        let p103 = s84[i88], m96 = this.findWithDefault(p103, t67);
        n67.push(m96);
      }
      return g21(n67);
    });
  }
  findWithDefault(e36, t67) {
    let s84 = this.tensorMap.get(e36);
    return s84 ?? t67;
  }
  checkKeyAndValueTensor(e36, t67) {
    if (e36.dtype !== this.keyDType) throw new Error(`Expect key dtype ${this.keyDType}, but got ${e36.dtype}`);
    if (t67.dtype !== this.valueDType) throw new Error(`Expect value dtype ${this.valueDType}, but got ${t67.dtype}`);
  }
};
var ot5 = async (a71, e36, t67, s84) => {
  switch (a71.op) {
    case "HashTable":
    case "HashTableV2": {
      let n67 = s84.getHashTableHandleByName(a71.name);
      if (n67 != null) return [n67];
      {
        let i88 = r51("keyDType", a71, e36, t67), p103 = r51("valueDType", a71, e36, t67), m96 = new ie7(i88, p103);
        return s84.addHashTable(a71.name, m96), [m96.handle];
      }
    }
    case "InitializeTable":
    case "InitializeTableV2":
    case "LookupTableImport":
    case "LookupTableImportV2": {
      let n67 = r51("tableHandle", a71, e36, t67, s84), i88 = r51("keys", a71, e36, t67), p103 = r51("values", a71, e36, t67);
      return [await s84.getHashTableById(n67.id).import(i88, p103)];
    }
    case "LookupTableFind":
    case "LookupTableFindV2": {
      let n67 = r51("tableHandle", a71, e36, t67, s84), i88 = r51("keys", a71, e36, t67), p103 = r51("defaultValue", a71, e36, t67);
      return [await s84.getHashTableById(n67.id).find(i88, p103)];
    }
    case "LookupTableSize":
    case "LookupTableSizeV2": {
      let n67 = r51("tableHandle", a71, e36, t67, s84);
      return [s84.getHashTableById(n67.id).tensorSize()];
    }
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var lt5 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "ResizeBilinear": {
      let n67 = r51("images", a71, e36, t67), i88 = r51("size", a71, e36, t67), p103 = r51("alignCorners", a71, e36, t67), m96 = r51("halfPixelCenters", a71, e36, t67);
      return [s84.image.resizeBilinear(n67, [i88[0], i88[1]], p103, m96)];
    }
    case "ResizeNearestNeighbor": {
      let n67 = r51("images", a71, e36, t67), i88 = r51("size", a71, e36, t67), p103 = r51("alignCorners", a71, e36, t67), m96 = r51("halfPixelCenters", a71, e36, t67);
      return [s84.image.resizeNearestNeighbor(n67, [i88[0], i88[1]], p103, m96)];
    }
    case "CropAndResize": {
      let n67 = r51("image", a71, e36, t67), i88 = r51("boxes", a71, e36, t67), p103 = r51("boxInd", a71, e36, t67), m96 = r51("cropSize", a71, e36, t67), u86 = r51("method", a71, e36, t67), o80 = r51("extrapolationValue", a71, e36, t67);
      return [s84.image.cropAndResize(n67, i88, p103, m96, u86, o80)];
    }
    case "ImageProjectiveTransformV3": {
      let n67 = r51("images", a71, e36, t67), i88 = r51("transforms", a71, e36, t67), p103 = r51("outputShape", a71, e36, t67), m96 = r51("fillValue", a71, e36, t67), u86 = r51("interpolation", a71, e36, t67), o80 = r51("fillMode", a71, e36, t67);
      return [s84.image.transform(n67, i88, u86.toLowerCase(), o80.toLowerCase(), m96, p103)];
    }
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var ct3 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "Equal":
      return [s84.equal(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "NotEqual":
      return [s84.notEqual(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "Greater":
      return [s84.greater(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "GreaterEqual":
      return [s84.greaterEqual(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "Less":
      return [s84.less(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "LessEqual":
      return [s84.lessEqual(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "LogicalAnd":
      return [s84.logicalAnd(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "LogicalNot":
      return [s84.logicalNot(r51("a", a71, e36, t67))];
    case "LogicalOr":
      return [s84.logicalOr(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "Select":
    case "SelectV2":
      return [s84.where(r51("condition", a71, e36, t67), r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    case "BitwiseAnd":
      return [s84.bitwiseAnd(r51("a", a71, e36, t67), r51("b", a71, e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var yt4 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "BatchMatMul":
    case "BatchMatMulV2":
    case "MatMul":
      return [s84.matMul(r51("a", a71, e36, t67), r51("b", a71, e36, t67), r51("transposeA", a71, e36, t67), r51("transposeB", a71, e36, t67))];
    case "Einsum":
      return [s84.einsum(r51("equation", a71, e36, t67), ...r51("tensors", a71, e36, t67))];
    case "Transpose":
      return [s84.transpose(r51("x", a71, e36, t67), r51("perm", a71, e36, t67))];
    case "_FusedMatMul":
      let [n67, i88] = r51("fusedOps", a71, e36, t67), p103 = n67 === "biasadd", m96 = i88 === "prelu", u86 = r51("numArgs", a71, e36, t67), o80 = r51("leakyreluAlpha", a71, e36, t67);
      if (p103) {
        if (m96 && u86 !== 2) throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
        if (!m96 && u86 !== 1) throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.");
      }
      let [l80, y43] = r51("args", a71, e36, t67);
      return [s84.fused.matMul({ a: r51("a", a71, e36, t67), b: r51("b", a71, e36, t67), transposeA: r51("transposeA", a71, e36, t67), transposeB: r51("transposeB", a71, e36, t67), bias: l80, activation: i88, preluActivationWeights: y43, leakyreluAlpha: o80 })];
    case "MatrixBandPart":
      return [s84.linalg.bandPart(r51("a", a71, e36, t67), r51("numLower", a71, e36, t67), r51("numUpper", a71, e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var dt3 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "EuclideanNorm":
      return [s84.euclideanNorm(r51("x", a71, e36, t67), r51("axis", a71, e36, t67), r51("keepDims", a71, e36, t67))];
    case "FusedBatchNorm":
    case "FusedBatchNormV2":
      return [s84.batchNorm(r51("x", a71, e36, t67), r51("mean", a71, e36, t67), r51("variance", a71, e36, t67), r51("offset", a71, e36, t67), r51("scale", a71, e36, t67), r51("epsilon", a71, e36, t67))];
    case "FusedBatchNormV3":
      return [s84.batchNorm(r51("x", a71, e36, t67), r51("mean", a71, e36, t67), r51("variance", a71, e36, t67), r51("offset", a71, e36, t67), r51("scale", a71, e36, t67), r51("epsilon", a71, e36, t67))];
    case "LRN":
      return [s84.localResponseNormalization(r51("x", a71, e36, t67), r51("radius", a71, e36, t67), r51("bias", a71, e36, t67), r51("alpha", a71, e36, t67), r51("beta", a71, e36, t67))];
    case "Softmax":
      return [s84.softmax(r51("x", a71, e36, t67))];
    case "LogSoftmax":
      return [s84.logSoftmax(r51("x", a71, e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var ht5 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "RaggedGather": {
      let { outputNestedSplits: n67, outputDenseValues: i88 } = s84.raggedGather(r51("paramsNestedSplits", a71, e36, t67), r51("paramsDenseValues", a71, e36, t67), r51("indices", a71, e36, t67), r51("outputRaggedRank", a71, e36, t67));
      return n67.concat(i88);
    }
    case "RaggedRange": {
      let { rtNestedSplits: n67, rtDenseValues: i88 } = s84.raggedRange(r51("starts", a71, e36, t67), r51("limits", a71, e36, t67), r51("splits", a71, e36, t67));
      return [n67, i88];
    }
    case "RaggedTensorToTensor":
      return [s84.raggedTensorToTensor(r51("shape", a71, e36, t67), r51("values", a71, e36, t67), r51("defaultValue", a71, e36, t67), r51("rowPartitionTensors", a71, e36, t67), r51("rowPartitionTypes", a71, e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var ft4 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "Max": {
      let m96 = r51("axis", a71, e36, t67), u86 = r51("keepDims", a71, e36, t67);
      return [s84.max(r51("x", a71, e36, t67), m96, u86)];
    }
    case "Mean": {
      let m96 = r51("axis", a71, e36, t67), u86 = r51("keepDims", a71, e36, t67);
      return [s84.mean(r51("x", a71, e36, t67), m96, u86)];
    }
    case "Min": {
      let m96 = r51("axis", a71, e36, t67), u86 = r51("keepDims", a71, e36, t67);
      return [s84.min(r51("x", a71, e36, t67), m96, u86)];
    }
    case "Sum": {
      let m96 = r51("axis", a71, e36, t67), u86 = r51("keepDims", a71, e36, t67);
      return [s84.sum(r51("x", a71, e36, t67), m96, u86)];
    }
    case "All": {
      let m96 = r51("axis", a71, e36, t67), u86 = r51("keepDims", a71, e36, t67);
      return [s84.all(r51("x", a71, e36, t67), m96, u86)];
    }
    case "Any": {
      let m96 = r51("axis", a71, e36, t67), u86 = r51("keepDims", a71, e36, t67);
      return [s84.any(r51("x", a71, e36, t67), m96, u86)];
    }
    case "ArgMax": {
      let m96 = r51("axis", a71, e36, t67);
      return [s84.argMax(r51("x", a71, e36, t67), m96)];
    }
    case "ArgMin": {
      let m96 = r51("axis", a71, e36, t67);
      return [s84.argMin(r51("x", a71, e36, t67), m96)];
    }
    case "Prod": {
      let m96 = r51("axis", a71, e36, t67), u86 = r51("keepDims", a71, e36, t67);
      return [s84.prod(r51("x", a71, e36, t67), m96, u86)];
    }
    case "Cumprod": {
      let m96 = r51("axis", a71, e36, t67), u86 = r51("exclusive", a71, e36, t67), o80 = r51("reverse", a71, e36, t67);
      return [s84.cumprod(r51("x", a71, e36, t67), m96, u86, o80)];
    }
    case "Cumsum": {
      let m96 = r51("axis", a71, e36, t67), u86 = r51("exclusive", a71, e36, t67), o80 = r51("reverse", a71, e36, t67);
      return [s84.cumsum(r51("x", a71, e36, t67), m96, u86, o80)];
    }
    case "Bincount":
      let n67 = r51("x", a71, e36, t67), i88 = r51("weights", a71, e36, t67), p103 = r51("size", a71, e36, t67);
      return [s84.bincount(n67, i88, p103)];
    case "DenseBincount": {
      let m96 = r51("x", a71, e36, t67), u86 = r51("weights", a71, e36, t67), o80 = r51("size", a71, e36, t67), l80 = r51("binaryOutput", a71, e36, t67);
      return [s84.denseBincount(m96, u86, o80, l80)];
    }
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var Nt3 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "ConcatV2":
    case "Concat": {
      let n67 = r51("n", a71, e36, t67), i88 = r51("axis", a71, e36, t67), p103 = r51("tensors", a71, e36, t67);
      return p103 = p103.slice(0, n67), [s84.concat(p103, i88)];
    }
    case "Gather": {
      let n67 = r51("x", a71, e36, t67), i88 = r51("indices", a71, e36, t67);
      return [s84.gather(n67, s84.cast(i88, "int32"), 0)];
    }
    case "GatherV2": {
      let n67 = r51("axis", a71, e36, t67), i88 = r51("batchDims", a71, e36, t67), p103 = r51("x", a71, e36, t67), m96 = r51("indices", a71, e36, t67);
      return [s84.gather(p103, s84.cast(m96, "int32"), n67, i88)];
    }
    case "Reverse": {
      let n67 = r51("dims", a71, e36, t67), i88 = [];
      for (let m96 = 0; m96 < n67.length; m96++) n67[m96] && i88.push(m96);
      let p103 = r51("x", a71, e36, t67);
      return [s84.reverse(p103, i88)];
    }
    case "ReverseV2": {
      let n67 = r51("axis", a71, e36, t67), i88 = r51("x", a71, e36, t67);
      return [s84.reverse(i88, n67)];
    }
    case "Slice": {
      let n67 = r51("begin", a71, e36, t67), i88 = r51("size", a71, e36, t67);
      return [s84.slice(r51("x", a71, e36, t67), n67, i88)];
    }
    case "StridedSlice": {
      let n67 = r51("begin", a71, e36, t67), i88 = r51("end", a71, e36, t67), p103 = r51("strides", a71, e36, t67), m96 = r51("beginMask", a71, e36, t67), u86 = r51("endMask", a71, e36, t67), o80 = r51("ellipsisMask", a71, e36, t67), l80 = r51("newAxisMask", a71, e36, t67), y43 = r51("shrinkAxisMask", a71, e36, t67), c103 = r51("x", a71, e36, t67);
      return [s84.stridedSlice(c103, n67, i88, p103, m96, u86, o80, l80, y43)];
    }
    case "Pack":
      return g4(() => {
        let n67 = r51("axis", a71, e36, t67), i88 = r51("tensors", a71, e36, t67), p103 = i88[0].shape, m96 = s84.squeeze(i88[0]).shape, u86 = i88.map((o80) => {
          let l80 = util_exports.arraysEqual(o80.shape, p103);
          if (!l80 && !util_exports.arraysEqual(s84.squeeze(o80).shape, m96)) throw new Error("the input tensors shape does not match");
          return l80 ? o80 : s84.reshape(o80, p103);
        });
        return [s84.stack(u86, n67)];
      });
    case "Unpack": {
      let n67 = r51("axis", a71, e36, t67), i88 = r51("tensor", a71, e36, t67);
      return s84.unstack(i88, n67);
    }
    case "Tile": {
      let n67 = r51("reps", a71, e36, t67);
      return [s84.tile(r51("x", a71, e36, t67), n67)];
    }
    case "Split":
    case "SplitV": {
      let n67 = r51("axis", a71, e36, t67), i88 = r51("numOrSizeSplits", a71, e36, t67), p103 = r51("x", a71, e36, t67);
      return s84.split(p103, i88, n67);
    }
    case "ScatterNd": {
      let n67 = r51("indices", a71, e36, t67), i88 = r51("values", a71, e36, t67), p103 = r51("shape", a71, e36, t67);
      return [s84.scatterND(n67, i88, p103)];
    }
    case "GatherNd": {
      let n67 = r51("x", a71, e36, t67), i88 = r51("indices", a71, e36, t67);
      return [s84.gatherND(n67, i88)];
    }
    case "SparseToDense": {
      let n67 = r51("sparseIndices", a71, e36, t67), i88 = r51("outputShape", a71, e36, t67), p103 = r51("sparseValues", a71, e36, t67), m96 = r51("defaultValue", a71, e36, t67);
      return [s84.sparseToDense(n67, p103, i88, p103.dtype === m96.dtype ? m96 : s84.cast(m96, p103.dtype))];
    }
    case "TensorScatterUpdate": {
      let n67 = r51("indices", a71, e36, t67), i88 = r51("values", a71, e36, t67), p103 = r51("tensor", a71, e36, t67);
      return [s84.tensorScatterUpdate(p103, n67, i88)];
    }
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var Tt2 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "SparseFillEmptyRows": {
      let { outputIndices: n67, outputValues: i88, emptyRowIndicator: p103, reverseIndexMap: m96 } = s84.sparse.sparseFillEmptyRows(r51("indices", a71, e36, t67), r51("values", a71, e36, t67), r51("denseShape", a71, e36, t67), r51("defaultValue", a71, e36, t67));
      return [n67, i88, p103, m96];
    }
    case "SparseReshape": {
      let { outputIndices: n67, outputShape: i88 } = s84.sparse.sparseReshape(r51("inputIndices", a71, e36, t67), r51("inputShape", a71, e36, t67), r51("newShape", a71, e36, t67));
      return [n67, i88];
    }
    case "SparseSegmentMean":
      return [s84.sparse.sparseSegmentMean(r51("data", a71, e36, t67), r51("indices", a71, e36, t67), r51("segmentIds", a71, e36, t67))];
    case "SparseSegmentSum":
      return [s84.sparse.sparseSegmentSum(r51("data", a71, e36, t67), r51("indices", a71, e36, t67), r51("segmentIds", a71, e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var bt2 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "FFT":
      return [s84.fft(r51("x", a71, e36, t67))];
    case "IFFT":
      return [s84.ifft(r51("x", a71, e36, t67))];
    case "RFFT":
      return [s84.rfft(r51("x", a71, e36, t67))];
    case "IRFFT":
      return [s84.irfft(r51("x", a71, e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var St2 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "StaticRegexReplace":
      return [s84.string.staticRegexReplace(r51("input", a71, e36, t67), r51("pattern", a71, e36, t67), r51("rewrite", a71, e36, t67), r51("replaceGlobal", a71, e36, t67))];
    case "StringNGrams": {
      let { nGrams: n67, nGramsSplits: i88 } = s84.string.stringNGrams(r51("data", a71, e36, t67), r51("dataSplits", a71, e36, t67), r51("separator", a71, e36, t67), r51("nGramWidths", a71, e36, t67), r51("leftPad", a71, e36, t67), r51("rightPad", a71, e36, t67), r51("padWidth", a71, e36, t67), r51("preserveShortSequences", a71, e36, t67));
      return [n67, i88];
    }
    case "StringSplit": {
      let { indices: n67, values: i88, shape: p103 } = s84.string.stringSplit(r51("input", a71, e36, t67), r51("delimiter", a71, e36, t67), r51("skipEmpty", a71, e36, t67));
      return [n67, i88, p103];
    }
    case "StringToHashBucketFast":
      return [s84.string.stringToHashBucketFast(r51("input", a71, e36, t67), r51("numBuckets", a71, e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
var Ot3 = (a71, e36, t67, s84 = ops_for_converter_exports) => {
  switch (a71.op) {
    case "Cast":
      return [s84.cast(r51("x", a71, e36, t67), r51("dtype", a71, e36, t67))];
    case "ExpandDims": {
      let n67 = r51("axis", a71, e36, t67);
      return [s84.expandDims(r51("x", a71, e36, t67), n67)];
    }
    case "Squeeze": {
      let n67 = r51("axis", a71, e36, t67);
      return [s84.squeeze(r51("x", a71, e36, t67), n67)];
    }
    case "Reshape":
      return [s84.reshape(r51("x", a71, e36, t67), r51("shape", a71, e36, t67))];
    case "EnsureShape":
      return [s84.ensureShape(r51("x", a71, e36, t67), r51("shape", a71, e36, t67))];
    case "MirrorPad":
      return [s84.mirrorPad(r51("x", a71, e36, t67), r51("padding", a71, e36, t67), r51("mode", a71, e36, t67))];
    case "PadV2":
    case "Pad":
      return [s84.pad(r51("x", a71, e36, t67), r51("padding", a71, e36, t67), r51("constantValue", a71, e36, t67))];
    case "SpaceToBatchND": {
      let n67 = r51("blockShape", a71, e36, t67), i88 = r51("paddings", a71, e36, t67);
      return [s84.spaceToBatchND(r51("x", a71, e36, t67), n67, i88)];
    }
    case "BatchToSpaceND": {
      let n67 = r51("blockShape", a71, e36, t67), i88 = r51("crops", a71, e36, t67);
      return [s84.batchToSpaceND(r51("x", a71, e36, t67), n67, i88)];
    }
    case "DepthToSpace": {
      let n67 = r51("blockSize", a71, e36, t67), i88 = r51("dataFormat", a71, e36, t67).toUpperCase();
      return [s84.depthToSpace(r51("x", a71, e36, t67), n67, i88)];
    }
    case "BroadcastTo":
      return [s84.broadcastTo(r51("x", a71, e36, t67), r51("shape", a71, e36, t67))];
    case "BroadcastArgs":
      return [s84.broadcastArgs(r51("s0", a71, e36, t67), r51("s1", a71, e36, t67))];
    default:
      throw TypeError(`Node type ${a71.op} is not implemented`);
  }
};
function Ce(a71, e36, t67, s84, n67 = g4) {
  let i88 = ((p103, m96, u86) => {
    switch (p103.category) {
      case "arithmetic":
        return n67(() => Be(p103, m96, u86));
      case "basic_math":
        return n67(() => je(p103, m96, u86));
      case "control":
        return et4(p103, m96, u86);
      case "convolution":
        return n67(() => at5(p103, m96, u86));
      case "creation":
        return n67(() => st5(p103, m96, u86));
      case "dynamic":
        return rt6(p103, m96, u86);
      case "evaluation":
        return n67(() => nt3(p103, m96, u86));
      case "image":
        return n67(() => lt5(p103, m96, u86));
      case "graph":
        return n67(() => it3(p103, m96, u86));
      case "logical":
        return n67(() => ct3(p103, m96, u86));
      case "matrices":
        return n67(() => yt4(p103, m96, u86));
      case "normalization":
        return n67(() => dt3(p103, m96, u86));
      case "ragged":
        return n67(() => ht5(p103, m96, u86));
      case "reduction":
        return n67(() => ft4(p103, m96, u86));
      case "slice_join":
        return n67(() => Nt3(p103, m96, u86));
      case "sparse":
        return n67(() => Tt2(p103, m96, u86));
      case "spectral":
        return n67(() => bt2(p103, m96, u86));
      case "string":
        return n67(() => St2(p103, m96, u86));
      case "transformation":
        return n67(() => Ot3(p103, m96, u86));
      case "hash_table":
        return ot5(p103, m96, u86, s84);
      case "custom":
        let o80 = H15(p103.op);
        if (o80 && o80.customExecutor) return o80.customExecutor(new te5(p103, m96, u86));
        throw TypeError(`Custom op ${p103.op} is not registered.`);
      default:
        throw TypeError(`Unknown op '${p103.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`);
    }
  })(a71, e36, t67);
  return util_exports.isPromise(i88) ? i88.then((p103) => [].concat(p103)) : [].concat(i88);
}
var P34 = class {
  constructor(e36 = {}, t67 = {}, s84 = {}, n67 = {}, i88) {
    this.weightMap = e36, this.tensorArrayMap = t67, this.tensorListMap = s84, this.functionMap = n67, this.parseNodeNameCache = i88, this.rootContext = { id: 0, frameName: "", iterationId: 0 }, this.contexts = [this.rootContext], this.lastId = 0, this.generateCurrentContextIds();
  }
  newFrame(e36, t67) {
    return { id: e36, frameName: t67, iterationId: 0 };
  }
  set currentContext(e36) {
    this.contexts !== e36 && (this.contexts = e36, this.generateCurrentContextIds());
  }
  get currentContext() {
    return this.contexts;
  }
  get currentContextId() {
    return this._currentContextIds[0];
  }
  get currentContextIds() {
    return this._currentContextIds;
  }
  generateCurrentContextIds() {
    let e36 = [];
    for (let t67 = 0; t67 < this.contexts.length - 1; t67++) {
      let s84 = this.contexts.slice(0, this.contexts.length - t67);
      e36.push(this.contextIdforContexts(s84));
    }
    e36.push(""), this._currentContextIds = e36;
  }
  contextIdforContexts(e36) {
    return e36 ? e36.map((t67) => t67.id === 0 && t67.iterationId === 0 ? "" : `${t67.frameName}-${t67.iterationId}`).join("/") : "";
  }
  enterFrame(e36) {
    this.contexts && (this.lastId++, this.contexts = this.contexts.slice(), this.contexts.push(this.newFrame(this.lastId, e36)), this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)));
  }
  exitFrame() {
    if (this.contexts && this.contexts.length > 1) this.contexts = this.contexts.slice(), this.contexts.splice(-1), this.currentContextIds.shift();
    else throw new Error("Cannot exit frame, the context is empty");
  }
  nextIteration() {
    if (this.contexts && this.contexts.length > 0) {
      this.contexts = this.contexts.slice(), this.lastId++;
      let e36 = Object.assign({}, this.contexts[this.contexts.length - 1]);
      e36.iterationId += 1, e36.id = this.lastId, this.contexts.splice(-1, 1, e36), this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));
    } else throw new Error("Cannot increase frame iteration, the context is empty");
  }
  getWeight(e36) {
    return this.weightMap[e36];
  }
  addTensorArray(e36) {
    this.tensorArrayMap[e36.id] = e36;
  }
  getTensorArray(e36) {
    return this.tensorArrayMap[e36];
  }
  addTensorList(e36) {
    this.tensorListMap[e36.id] = e36;
  }
  getTensorList(e36) {
    return this.tensorListMap[e36];
  }
  dispose(e36) {
    for (let t67 in this.tensorArrayMap) this.tensorArrayMap[t67].clearAndClose(e36);
    for (let t67 in this.tensorListMap) this.tensorListMap[t67].clearAndClose(e36);
  }
};
function ze(a71, e36, t67, s84) {
  let n67 = /* @__PURE__ */ new Set(), i88 = [], p103 = null, m96 = null, u86 = /* @__PURE__ */ new Set(), o80 = new Set(Object.keys(a71).map((c103) => w43(c103)[0]));
  s84 = s84 || [];
  let l80 = new Set(s84.map((c103) => w43(c103.name)[0])), y43 = [...e36];
  for (; y43.length > 0; ) {
    let c103 = y43.pop();
    if ((k54(c103) || ns(c103) || is(c103)) && p103 == null && (p103 = c103, m96 = p103.children.map((h74) => h74.name).filter((h74) => n67.has(h74))), n67.add(c103.name), t67[c103.name] == null && !o80.has(c103.name) && !l80.has(c103.name)) {
      if (c103.inputs.length === 0) {
        i88.push(c103.name);
        continue;
      }
      c103.inputs.forEach((h74) => {
        u86.has(h74.name) || (u86.add(h74.name), y43.push(h74));
      });
    }
  }
  return { inputs: a71, outputs: e36, usedNodes: n67, missingInputs: i88, dynamicNode: p103, syncInputs: m96 };
}
function wt3(a71, e36) {
  let { usedNodes: t67, inputs: s84 } = e36, n67 = Object.keys(s84).map((d55) => w43(d55)[0]).map((d55) => a71.nodes[d55]), i88 = a71.initNodes || [], p103 = (d55) => t67.has(typeof d55 == "string" ? d55 : d55.name);
  function m96(d55) {
    return [...new Map(d55.map((g72) => [g72.name, g72])).values()];
  }
  let u86 = m96([...n67, ...a71.weights, ...i88]).filter(p103), o80 = m96([...u86, ...Object.values(a71.nodes)]).filter(p103), l80 = new Map(o80.map((d55) => [d55.name, d55])), y43 = {};
  for (let d55 of o80) {
    y43[d55.name] = y43[d55.name] || 0;
    for (let g72 of d55.children) p103(g72) || (y43[g72.name] = Number.POSITIVE_INFINITY), y43[g72.name] = (y43[g72.name] || 0) + 1;
  }
  let c103 = Object.entries(y43).filter(([, d55]) => d55 === 0).map(([d55]) => d55), h74 = [...c103];
  for (; c103.length > 0; ) {
    let d55 = c103.pop(), g72 = l80.get(d55);
    for (let O21 of g72.children.filter(p103)) --y43[O21.name] === 0 && (h74.push(O21.name), c103.push(O21.name));
  }
  let N58 = h74.map((d55) => l80.get(d55)), f85 = es(N58, u86);
  return ts(f85, u86), f85;
}
function es(a71, e36) {
  let t67 = new Map(a71.map((p103) => [p103.name, p103])), s84 = e36.map((p103) => p103.name), n67 = new Set(s84);
  for (; s84.length > 0; ) {
    let p103 = s84.pop(), m96 = t67.get(p103);
    for (let u86 of m96.children) !t67.has(u86.name) || n67.has(u86.name) || (n67.add(u86.name), s84.push(u86.name));
  }
  return a71.filter((p103) => n67.has(p103.name));
}
var C24 = class extends Error {
  constructor(e36) {
    super(`NodesExecutionOrderError: ${e36}`);
  }
};
function ts(a71, e36) {
  let t67 = new Map(a71.map((m96, u86) => [m96.name, u86])), s84 = new Set(e36.map((m96) => m96.name)), n67 = (m96) => s84.has(typeof m96 == "string" ? m96 : m96.name), i88 = new Set(a71.map((m96) => m96.name)), p103 = (m96) => i88.has(typeof m96 == "string" ? m96 : m96.name);
  for (let m96 of a71) {
    for (let u86 of m96.children.filter(p103)) {
      if (!t67.has(u86.name)) throw new C24(`Child ${u86.name} of node ${m96.name} is unreachable.`);
      if (t67.get(m96.name) > t67.get(u86.name)) throw new C24(`Node ${m96.name} is scheduled to run after its child ${u86.name}.`);
    }
    if (!n67(m96)) for (let u86 of m96.inputs) {
      if (!t67.has(u86.name)) throw new C24(`Input ${u86.name} of node ${m96.name} is unreachable.`);
      if (t67.get(u86.name) > t67.get(m96.name)) throw new C24(`Node ${m96.name} is scheduled to run before its input ${u86.name}.`);
    }
  }
}
function _t3(a71) {
  let e36 = new Map(a71.map((m96, u86) => [m96.name, u86])), t67 = Number.MAX_SAFE_INTEGER, s84 = a71.map((m96, u86) => k54(m96) ? t67 : u86), n67 = (m96) => {
    let u86 = s84[e36.get(m96.name)];
    return u86 ?? -1;
  }, i88 = a71.map((m96, u86) => m96.children.map(n67).reduce((o80, l80) => Math.max(o80, l80), s84[u86])), p103 = /* @__PURE__ */ new Map();
  for (let m96 = 0; m96 < a71.length; ++m96) {
    let u86 = i88[m96];
    if (u86 === t67) continue;
    let o80 = a71[m96], l80 = a71[u86];
    p103.has(l80.name) || p103.set(l80.name, []), p103.get(l80.name).push(o80);
  }
  return p103;
}
var as = /* @__PURE__ */ new Set(["Switch", "Merge", "Enter", "Exit", "NextIteration", "StatelessIf", "StatelessWhile", "if", "While"]);
var ss = /* @__PURE__ */ new Set(["NonMaxSuppressionV2", "NonMaxSuppressionV3", "NonMaxSuppressionV5", "Where"]);
var rs = /* @__PURE__ */ new Set(["HashTable", "HashTableV2", "LookupTableImport", "LookupTableImportV2", "LookupTableFind", "LookupTableFindV2", "LookupTableSize", "LookupTableSizeV2"]);
function k54(a71) {
  return as.has(a71.op);
}
function ns(a71) {
  return ss.has(a71.op);
}
function is(a71) {
  return rs.has(a71.op);
}
var $34 = class a67 {
  get weightIds() {
    return this.parent ? this.parent.weightIds : this._weightIds;
  }
  get functionExecutorMap() {
    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;
  }
  get weightMap() {
    return this.parent ? this.parent.weightMap : this._weightMap;
  }
  set weightMap(e36) {
    let t67 = Object.keys(e36).map((s84) => e36[s84].map((n67) => n67.id));
    this._weightIds = [].concat(...t67), this._weightMap = e36;
  }
  set resourceManager(e36) {
    this._resourceManager = e36;
  }
  get inputs() {
    return this._inputs.map((e36) => ({ name: e36.name, shape: e36.attrParams.shape ? e36.attrParams.shape.value : void 0, dtype: e36.attrParams.dtype ? e36.attrParams.dtype.value : void 0 }));
  }
  get outputs() {
    return this._outputs.map((e36) => ({ name: e36.name, shape: e36.attrParams.shape ? e36.attrParams.shape.value : void 0, dtype: e36.attrParams.dtype ? e36.attrParams.dtype.value : void 0 }));
  }
  get inputNodes() {
    return this._inputs.map((e36) => e36.signatureKey || e36.name);
  }
  get outputNodes() {
    return this._outputs.map((e36) => {
      let t67 = e36.signatureKey || e36.name;
      return e36.defaultOutput ? `${t67}:${e36.defaultOutput}` : t67;
    });
  }
  get functions() {
    return Object.keys(this._functions).reduce((e36, t67) => (e36[t67] = this._functions[t67].signature, e36), {});
  }
  constructor(e36, t67) {
    this.graph = e36, this.parent = t67, this.compiledMap = /* @__PURE__ */ new Map(), this.parseNodeNameCache = /* @__PURE__ */ new Map(), this._weightMap = {}, this.SEPARATOR = ",", this._functions = {}, this._functionExecutorMap = {}, this.keepIntermediateTensors = false, this._outputs = e36.outputs, this._inputs = e36.inputs, this._initNodes = e36.initNodes, this._signature = e36.signature, this._functions = e36.functions, e36.functions != null && Object.keys(e36.functions).forEach((s84) => {
      this._functionExecutorMap[s84] = new a67(e36.functions[s84], this);
    });
  }
  getCompilationKey(e36, t67) {
    let s84 = e36.map((i88) => i88.name).sort(), n67 = t67.map((i88) => i88.name).sort();
    return s84.join(this.SEPARATOR) + "--" + n67.join(this.SEPARATOR);
  }
  compile(e36, t67) {
    let s84 = ze(e36, t67, this.weightMap, this._initNodes), { missingInputs: n67, dynamicNode: i88, syncInputs: p103 } = s84;
    if (i88 != null) throw new Error(`This execution contains the node '${i88.name}', which has the dynamic op '${i88.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${p103}]`);
    if (n67.length > 0) {
      let o80 = t67.map((y43) => y43.name), l80 = Object.keys(e36);
      throw new Error(`Cannot compute the outputs [${o80}] from the provided inputs [${l80}]. Missing the following inputs: [${n67}]`);
    }
    let m96 = wt3(this.graph, s84), u86 = _t3(m96);
    return { orderedNodes: m96, nodeLiveUntilMap: u86 };
  }
  cloneAndKeepTensor(e36) {
    if (e36 == null) return null;
    let t67 = e36.clone();
    return N3(t67), t67;
  }
  cloneTensorList(e36) {
    return e36 ? e36.map((s84) => this.cloneAndKeepTensor(s84)) : null;
  }
  cloneTensorMap(e36) {
    return Object.fromEntries(Object.entries(e36).map(([t67, s84]) => [t67, this.cloneTensorList(s84)]));
  }
  execute(e36, t67) {
    this.disposeIntermediateTensors(), e36 = this.mapInputs(e36);
    let s84 = Object.keys(e36).sort();
    this.checkInputs(e36), this.checkInputShapeAndType(e36), t67 = this.mapOutputs(t67), this.checkOutputs(t67);
    let n67 = s84.map((c103) => this.graph.nodes[w43(c103)[0]]), i88 = t67.map((c103) => w43(c103)[0]), p103 = new Set(i88), m96 = i88.map((c103) => this.graph.nodes[c103]);
    m96.length === 0 && (m96 = this._outputs);
    let u86 = this.getCompilationKey(n67, m96), o80 = this.compiledMap.get(u86);
    o80 == null && (o80 = this.compile(e36, m96), this.compiledMap.set(u86, o80));
    try {
      this.keepIntermediateTensors = l().getBool("KEEP_INTERMEDIATE_TENSORS");
    } catch (c103) {
      this.keepIntermediateTensors = false, console.warn(c103.message);
    }
    let l80 = {}, y43 = {};
    return g4(() => {
      let c103 = new P34(this.weightMap, l80, y43, this.functionExecutorMap, this.parseNodeNameCache), h74 = Object.assign({}, this.weightMap);
      this.keepIntermediateTensors && (this.clonedTensorsMap = this.cloneTensorMap(this.weightMap)), Object.keys(e36).forEach((g72) => {
        let [O21, v42] = w43(g72, c103), T40 = [];
        T40[v42] = e36[g72], h74[O21] = T40, this.keepIntermediateTensors && (this.clonedTensorsMap[O21] = this.cloneTensorList(T40));
      });
      let N58 = this.getFrozenTensorIds(h74), { orderedNodes: f85, nodeLiveUntilMap: d55 } = o80;
      for (let g72 of f85) {
        if (h74[g72.name]) continue;
        let O21 = Ce(g72, h74, c103, this._resourceManager);
        if (util_exports.isPromise(O21)) throw new Error(`The execution of the op '${g72.op}' returned a promise. Please use model.executeAsync() instead.`);
        h74[g72.name] = O21, this.keepIntermediateTensors && (this.clonedTensorsMap[g72.name] = this.cloneTensorList(O21)), this.checkTensorForDisposalWithNodeLiveUntilInfo(g72, h74, c103, N58, p103, d55.get(g72.name));
      }
      return this.parent == null && c103.dispose(N58), t67.map((g72) => b55(g72, h74, c103));
    });
  }
  getFrozenTensorIds(e36) {
    let t67 = [].concat.apply([], Object.keys(e36).map((s84) => e36[s84]).map((s84) => s84.map((n67) => n67.id)));
    return new Set(t67);
  }
  checkTensorForDisposal(e36, t67, s84, n67, i88, p103, m96) {
    if (!(k54(t67) || p103.has(e36))) {
      for (let u86 of s84[e36]) u86 != null && (m96[u86.id] = (m96[u86.id] || 0) + t67.children.length);
      for (let u86 of t67.inputs) {
        if (k54(u86)) continue;
        let o80 = le4(u86.name, s84, n67);
        if (o80 != null) for (let l80 of o80) {
          if (!l80 || l80.kept || i88.has(l80.id)) continue;
          let y43 = m96[l80.id];
          y43 === 1 ? (l80.dispose(), delete m96[l80.id]) : y43 != null && m96[l80.id]--;
        }
      }
    }
  }
  checkTensorForDisposalWithNodeLiveUntilInfo(e36, t67, s84, n67, i88, p103) {
    function m96(u86) {
      return k54(u86) || i88.has(u86.name);
    }
    if (!(k54(e36) || p103 == null)) for (let u86 of p103) {
      if (m96(u86)) continue;
      let o80 = le4(u86.name, t67, s84);
      for (let l80 of o80) !l80 || l80.kept || n67.has(l80.id) || l80.dispose();
    }
  }
  async executeAsync(e36, t67) {
    return this._executeAsync(e36, t67);
  }
  disposeIntermediateTensors() {
    this.clonedTensorsMap && (Object.values(this.clonedTensorsMap).forEach((e36) => {
      for (let t67 of e36) t67 && !t67.isDisposed && t67.dispose();
    }), this.clonedTensorsMap = null);
  }
  getIntermediateTensors() {
    return this.clonedTensorsMap;
  }
  async _executeAsync(e36, t67, s84 = false, n67 = {}, i88 = {}) {
    this.disposeIntermediateTensors(), s84 || (e36 = this.mapInputs(e36), this.checkInputs(e36), this.checkInputShapeAndType(e36), t67 = this.mapOutputs(t67), this.checkOutputs(t67));
    try {
      this.keepIntermediateTensors = l().getBool("KEEP_INTERMEDIATE_TENSORS");
    } catch (c103) {
      this.keepIntermediateTensors = false, console.warn(c103.message);
    }
    let p103 = new P34(this.weightMap, n67, i88, this.functionExecutorMap, this.parseNodeNameCache);
    this.keepIntermediateTensors && (this.clonedTensorsMap = this.cloneTensorMap(this.weightMap));
    let m96 = await this.executeWithControlFlow(e36, p103, t67, s84), u86 = t67.map((c103) => b55(c103, m96, p103)), o80 = u86.map((c103) => c103.id), l80 = Object.keys(e36).map((c103) => e36[c103].id), y43 = /* @__PURE__ */ new Set([...o80, ...l80, ...this.weightIds]);
    return Object.values(m96).forEach((c103) => {
      c103.forEach((h74) => {
        h74 && !h74.isDisposed && !y43.has(h74.id) && h74.dispose();
      });
    }), this.parent == null && p103.dispose(y43), u86;
  }
  async executeFunctionAsync(e36, t67, s84) {
    let n67 = e36.reduce((i88, p103, m96) => (i88[this.inputs[m96].name] = p103, i88), {});
    return this._executeAsync(n67, this.outputNodes, true, t67, s84);
  }
  async executeWithControlFlow(e36, t67, s84, n67) {
    let i88 = Object.keys(e36), p103 = i88.map((T40) => this.graph.nodes[w43(T40)[0]]), m96 = s84.map((T40) => w43(T40)[0]), u86 = new Set(m96), o80 = m96.map((T40) => this.graph.nodes[T40]);
    o80.length === 0 && (o80 = this._outputs);
    let { usedNodes: l80, missingInputs: y43, dynamicNode: c103, syncInputs: h74 } = ze(e36, o80, this.weightMap, this._initNodes), N58 = [...p103, ...this.graph.weights, ...this._initNodes || []].map((T40) => ({ node: T40, contexts: t67.currentContext })), f85 = Object.assign({}, this.weightMap);
    Object.keys(e36).forEach((T40) => {
      let [L22, j22] = w43(T40), G30 = [];
      G30[j22] = e36[T40], f85[L22] = G30;
    });
    let d55 = {}, g72 = this.getFrozenTensorIds(f85), O21 = {};
    for (; N58.length > 0; ) {
      let T40 = this.processStack(p103, N58, t67, f85, O21, g72, u86, d55, l80);
      await Promise.all(T40);
    }
    c103 == null && !n67 && console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");
    let v42 = o80.filter((T40) => !k54(T40) && !b55(T40.name, f85, t67)).map((T40) => T40.name);
    if (v42.length > 0) {
      let T40 = "";
      throw c103 != null && (T40 = `Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${h74}]`), new Error(`Cannot compute the outputs [${v42}] from the provided inputs [${i88}]. Consider providing the following inputs: [${y43}]. ${T40}`);
    }
    return f85;
  }
  processStack(e36, t67, s84, n67, i88, p103, m96, u86, o80) {
    let l80 = [];
    for (; t67.length > 0; ) {
      let y43 = t67.pop();
      s84.currentContext = y43.contexts;
      let c103 = "";
      if (y43.node.op === "Enter" && r51("isConstant", y43.node, n67, s84) && ([c103] = E41(y43.node.name, s84)), n67[y43.node.name] == null) {
        let h74 = Ce(y43.node, n67, s84, this._resourceManager);
        c103 || ([c103] = E41(y43.node.name, s84));
        let N58 = s84.currentContext;
        util_exports.isPromise(h74) ? l80.push(h74.then((f85) => (n67[c103] = f85, this.keepIntermediateTensors && (this.clonedTensorsMap[c103] = this.cloneTensorList(f85)), s84.currentContext = N58, this.checkTensorForDisposal(c103, y43.node, n67, s84, p103, m96, u86), this.processChildNodes(y43.node, t67, s84, n67, i88, o80), f85))) : (n67[c103] = h74, this.keepIntermediateTensors && (this.clonedTensorsMap[c103] = this.cloneTensorList(h74)), this.checkTensorForDisposal(c103, y43.node, n67, s84, p103, m96, u86), this.processChildNodes(y43.node, t67, s84, n67, i88, o80));
      } else this.processChildNodes(y43.node, t67, s84, n67, i88, o80);
    }
    return l80;
  }
  processChildNodes(e36, t67, s84, n67, i88, p103) {
    e36.children.forEach((m96) => {
      let [u86] = E41(m96.name, s84);
      i88[u86] || !p103.has(m96.name) || (m96.op === "Merge" ? m96.inputNames.some((o80) => !!b55(o80, n67, s84)) && (i88[u86] = true, t67.push({ contexts: s84.currentContext, node: m96 })) : m96.inputNames.every((o80) => !!b55(o80, n67, s84)) && (i88[u86] = true, t67.push({ contexts: s84.currentContext, node: m96 })));
    });
  }
  dispose() {
    Object.keys(this.weightMap).forEach((e36) => this.weightMap[e36].forEach((t67) => t67.dispose()));
  }
  checkInputShapeAndType(e36) {
    Object.keys(e36).forEach((t67) => {
      let s84 = e36[t67], [n67] = w43(t67), i88 = this.graph.nodes[n67];
      if (i88.attrParams.shape && i88.attrParams.shape.value) {
        let p103 = i88.attrParams.shape.value, m96 = p103.length === s84.shape.length && s84.shape.every((u86, o80) => p103[o80] === -1 || p103[o80] === u86);
        util_exports.assert(m96, () => `The shape of dict['${i88.name}'] provided in model.execute(dict) must be [${p103}], but was [${s84.shape}]`);
      }
      i88.attrParams.dtype && i88.attrParams.dtype.value && util_exports.assert(s84.dtype === i88.attrParams.dtype.value, () => `The dtype of dict['${i88.name}'] provided in model.execute(dict) must be ${i88.attrParams.dtype.value}, but was ${s84.dtype}`);
    });
  }
  mapInputs(e36) {
    var t67, s84;
    let n67 = {};
    for (let i88 in e36) {
      let p103 = (s84 = (t67 = this._signature) === null || t67 === void 0 ? void 0 : t67.inputs) === null || s84 === void 0 ? void 0 : s84[i88];
      p103 != null ? n67[p103.name] = e36[i88] : n67[i88] = e36[i88];
    }
    return n67;
  }
  checkInputs(e36) {
    let t67 = Object.keys(e36).filter((s84) => {
      let [n67] = w43(s84);
      return this.graph.nodes[n67] == null;
    });
    if (t67.length > 0) throw new Error(`The dict provided in model.execute(dict) has keys: [${t67}] that are not part of graph`);
  }
  mapOutputs(e36) {
    return e36.map((t67) => {
      var s84, n67;
      let i88 = (n67 = (s84 = this._signature) === null || s84 === void 0 ? void 0 : s84.outputs) === null || n67 === void 0 ? void 0 : n67[t67];
      return i88 != null ? i88.name : t67;
    }, {});
  }
  checkOutputs(e36) {
    e36.forEach((t67) => {
      let [s84] = w43(t67);
      if (!this.graph.nodes[s84]) throw new Error(`The output '${t67}' is not found in the graph`);
    });
  }
};
var ue5 = class {
  constructor(e36 = {}, t67 = {}) {
    this.hashTableNameToHandle = e36, this.hashTableMap = t67;
  }
  addHashTable(e36, t67) {
    this.hashTableNameToHandle[e36] = t67.handle, this.hashTableMap[t67.id] = t67;
  }
  getHashTableHandleByName(e36) {
    return this.hashTableNameToHandle[e36];
  }
  getHashTableById(e36) {
    return this.hashTableMap[e36];
  }
  dispose() {
    for (let e36 in this.hashTableMap) this.hashTableMap[e36].clearAndClose(), delete this.hashTableMap[e36];
    for (let e36 in this.hashTableNameToHandle) this.hashTableNameToHandle[e36].dispose(), delete this.hashTableNameToHandle[e36];
  }
};
var cs = "?tfjs-format=file";
var ys = "model.json";
var B27 = class {
  get modelVersion() {
    return this.version;
  }
  get inputNodes() {
    return this.executor.inputNodes;
  }
  get outputNodes() {
    return this.executor.outputNodes;
  }
  get inputs() {
    return this.executor.inputs;
  }
  get outputs() {
    return this.executor.outputs;
  }
  get weights() {
    return this.executor.weightMap;
  }
  get metadata() {
    return this.artifacts.userDefinedMetadata;
  }
  get modelSignature() {
    return this.signature;
  }
  get modelStructuredOutputKeys() {
    return this.structuredOutputKeys;
  }
  constructor(e36, t67 = {}, s84 = io_exports) {
    this.modelUrl = e36, this.loadOptions = t67, this.version = "n/a", this.io = s84, t67 == null && (this.loadOptions = {}), this.resourceManager = new ue5();
  }
  findIOHandler() {
    let e36 = this.modelUrl;
    if (e36.load != null) this.handler = e36;
    else if (this.loadOptions.requestInit != null) this.handler = this.io.browserHTTPRequest(e36, this.loadOptions);
    else {
      let t67 = this.io.getLoadHandlers(e36, this.loadOptions);
      if (t67.length === 0) t67.push(this.io.browserHTTPRequest(e36, this.loadOptions));
      else if (t67.length > 1) throw new Error(`Found more than one (${t67.length}) load handlers for URL '${[e36]}'`);
      this.handler = t67[0];
    }
  }
  load() {
    if (this.findIOHandler(), this.handler.load == null) throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
    let e36 = this.handler.load();
    return util_exports.isPromise(e36) ? e36.then((t67) => t67.getWeightStream == null ? this.loadSync(t67) : this.loadStreaming(t67)) : this.loadSync(e36);
  }
  loadSync(e36) {
    let t67 = this.io.decodeWeights(e36.weightData, e36.weightSpecs);
    return this.loadWithWeightMap(e36, t67);
  }
  async loadStreaming(e36) {
    if (e36.getWeightStream == null) throw new Error("Model artifacts missing streamWeights function");
    let t67 = await X4(e36.getWeightStream(), e36.weightSpecs);
    return this.loadWithWeightMap(e36, t67);
  }
  loadWithWeightMap(e36, t67) {
    this.artifacts = e36;
    let s84 = this.artifacts.modelTopology, n67 = this.artifacts.signature;
    if (this.artifacts.userDefinedMetadata != null) {
      let i88 = this.artifacts.userDefinedMetadata;
      i88.signature != null && (n67 = i88.signature), i88.structuredOutputKeys != null && (this.structuredOutputKeys = i88.structuredOutputKeys);
    }
    if (this.signature = n67, this.version = `${s84.versions.producer}.${s84.versions.minConsumer}`, this.executor = new $34(R23.Instance.transformGraph(s84, this.signature)), this.executor.weightMap = this.convertTensorMapToTensorsMap(t67), this.executor.resourceManager = this.resourceManager, e36.modelInitializer != null && e36.modelInitializer.node != null) {
      let i88 = R23.Instance.transformGraph(e36.modelInitializer);
      this.initializer = new $34(i88), this.initializer.weightMap = this.executor.weightMap, this.initializer.resourceManager = this.resourceManager, this.initializerSignature = e36.initializerSignature;
    }
    return true;
  }
  async save(e36, t67) {
    if (typeof e36 == "string") {
      let s84 = this.io.getSaveHandlers(e36);
      if (s84.length === 0) throw new Error(`Cannot find any save handlers for URL '${e36}'`);
      if (s84.length > 1) throw new Error(`Found more than one (${s84.length}) save handlers for URL '${e36}'`);
      e36 = s84[0];
    }
    if (e36.save == null) throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
    return e36.save(this.artifacts);
  }
  addStructuredOutputNames(e36) {
    if (this.structuredOutputKeys) {
      let t67 = e36 instanceof o5 ? [e36] : e36, s84 = {};
      return t67.forEach((n67, i88) => s84[this.structuredOutputKeys[i88]] = n67), s84;
    }
    return e36;
  }
  predict(e36, t67) {
    let s84 = this.execute(e36, this.outputNodes);
    return this.addStructuredOutputNames(s84);
  }
  async predictAsync(e36, t67) {
    let s84 = await this.executeAsync(e36, this.outputNodes);
    return this.addStructuredOutputNames(s84);
  }
  normalizeInputs(e36) {
    var t67;
    if (!(e36 instanceof o5) && !Array.isArray(e36)) {
      let i88 = (t67 = this.signature) === null || t67 === void 0 ? void 0 : t67.inputs;
      if (i88 != null) for (let p103 in i88) {
        let m96 = i88[p103];
        m96.resourceId != null && (e36[p103] = this.resourceIdToCapturedInput[m96.resourceId]);
      }
      return e36;
    }
    e36 = Array.isArray(e36) ? e36 : [e36];
    let s84 = Object.keys(this.resourceIdToCapturedInput).length;
    if (e36.length + s84 !== this.inputNodes.length) throw new Error(`Input tensor count mismatch, the graph model has ${this.inputNodes.length - s84} non-resource placeholders, while there are ${e36.length} input tensors provided.`);
    let n67 = 0;
    return this.inputNodes.reduce((i88, p103) => {
      var m96, u86, o80;
      let l80 = (o80 = (u86 = (m96 = this.signature) === null || m96 === void 0 ? void 0 : m96.inputs) === null || u86 === void 0 ? void 0 : u86[p103]) === null || o80 === void 0 ? void 0 : o80.resourceId;
      return l80 != null ? i88[p103] = this.resourceIdToCapturedInput[l80] : i88[p103] = e36[n67++], i88;
    }, {});
  }
  normalizeOutputs(e36) {
    return e36 = e36 || this.outputNodes, Array.isArray(e36) ? e36 : [e36];
  }
  executeInitializerGraph() {
    return this.initializer == null ? [] : this.initializerSignature == null ? this.initializer.execute({}, []) : this.initializer.execute({}, Object.keys(this.initializerSignature.outputs));
  }
  async executeInitializerGraphAsync() {
    return this.initializer == null ? [] : this.initializerSignature == null ? this.initializer.executeAsync({}, []) : this.initializer.executeAsync({}, Object.keys(this.initializerSignature.outputs));
  }
  setResourceIdToCapturedInput(e36) {
    if (this.resourceIdToCapturedInput = {}, this.initializerSignature) {
      let t67 = this.initializerSignature.outputs, s84 = Object.keys(t67);
      for (let n67 = 0; n67 < s84.length; n67++) {
        let i88 = s84[n67], p103 = t67[i88];
        this.resourceIdToCapturedInput[p103.resourceId] = e36[n67];
      }
    }
  }
  execute(e36, t67) {
    this.resourceIdToCapturedInput == null && this.setResourceIdToCapturedInput(this.executeInitializerGraph()), e36 = this.normalizeInputs(e36), t67 = this.normalizeOutputs(t67);
    let s84 = this.executor.execute(e36, t67);
    return s84.length > 1 ? s84 : s84[0];
  }
  async executeAsync(e36, t67) {
    this.resourceIdToCapturedInput == null && this.setResourceIdToCapturedInput(await this.executeInitializerGraphAsync()), e36 = this.normalizeInputs(e36), t67 = this.normalizeOutputs(t67);
    let s84 = await this.executor.executeAsync(e36, t67);
    return s84.length > 1 ? s84 : s84[0];
  }
  getIntermediateTensors() {
    return this.executor.getIntermediateTensors();
  }
  disposeIntermediateTensors() {
    this.executor.disposeIntermediateTensors();
  }
  convertTensorMapToTensorsMap(e36) {
    return Object.keys(e36).reduce((t67, s84) => (t67[s84] = [e36[s84]], t67), {});
  }
  dispose() {
    this.executor.dispose(), this.initializer && (this.initializer.dispose(), this.resourceIdToCapturedInput && E4(this.resourceIdToCapturedInput)), this.resourceManager.dispose();
  }
};
async function ds(a71, e36 = {}, t67 = io_exports) {
  if (a71 == null) throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");
  e36 == null && (e36 = {}), e36.fromTFHub && typeof a71 == "string" && (a71 = fs(a71));
  let s84 = new B27(a71, e36, t67);
  return await s84.load(), s84;
}
function hs2(a71) {
  if (a71 == null) throw new Error("modelUrl in loadGraphModelSync() cannot be null. Please provide model artifacts or an IOHandler that loads the model");
  let e36;
  if (a71 instanceof Array) {
    let [s84, n67] = a71;
    if (!s84) throw new Error("modelJSON must be the first element of the array");
    if (!n67 || !(n67 instanceof ArrayBuffer)) throw new Error("An ArrayBuffer of weights must be the second element of the array");
    if (!("modelTopology" in s84)) throw new Error("Model JSON is missing 'modelTopology'");
    if (!("weightsManifest" in s84)) throw new Error("Model JSON is missing 'weightsManifest'");
    let i88 = io_exports.getWeightSpecs(s84.weightsManifest), p103 = io_exports.getModelArtifactsForJSONSync(s84, i88, n67);
    e36 = io_exports.fromMemorySync(p103);
  } else if ("load" in a71) e36 = a71;
  else if ("modelTopology" in a71 && "weightSpecs" in a71 && "weightData" in a71) e36 = io_exports.fromMemorySync(a71);
  else throw new Error("Unknown model format");
  let t67 = new B27(e36);
  return t67.load(), t67;
}
function fs(a71) {
  return a71.endsWith("/") || (a71 = a71 + "/"), `${a71}${ys}${cs}`;
}
var gs = "4.22.0";

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/abs.mjs
m5().prototype.abs = function() {
  return this.throwIfDisposed(), b9(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/acos.mjs
m5().prototype.acos = function() {
  return this.throwIfDisposed(), u8(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/acosh.mjs
m5().prototype.acosh = function() {
  return this.throwIfDisposed(), h7(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/add.mjs
m5().prototype.add = function(o80) {
  return this.throwIfDisposed(), T7(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/all.mjs
m5().prototype.all = function(o80, t67) {
  return this.throwIfDisposed(), E7(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/any.mjs
m5().prototype.any = function(o80, t67) {
  return this.throwIfDisposed(), y9(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/arg_max.mjs
m5().prototype.argMax = function(o80) {
  return this.throwIfDisposed(), u9(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/arg_min.mjs
m5().prototype.argMin = function(o80) {
  return this.throwIfDisposed(), u10(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/as_scalar.mjs
m5().prototype.asScalar = function() {
  return this.throwIfDisposed(), c(this.size === 1, () => "The array must have only 1 element."), h9(this, []);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/as_type.mjs
m5().prototype.asType = function(o80) {
  return this.throwIfDisposed(), w12(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/as1d.mjs
m5().prototype.as1D = function() {
  return this.throwIfDisposed(), h9(this, [this.size]);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/as2d.mjs
m5().prototype.as2D = function(o80, r56) {
  return this.throwIfDisposed(), h9(this, [o80, r56]);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/as3d.mjs
m5().prototype.as3D = function(o80, r56, t67) {
  return this.throwIfDisposed(), h9(this, [o80, r56, t67]);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/as4d.mjs
m5().prototype.as4D = function(o80, r56, t67, s84) {
  return this.throwIfDisposed(), h9(this, [o80, r56, t67, s84]);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/as5d.mjs
m5().prototype.as5D = function(o80, r56, t67, s84, e36) {
  return this.throwIfDisposed(), h9(this, [o80, r56, t67, s84, e36]);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/asin.mjs
m5().prototype.asin = function() {
  return this.throwIfDisposed(), u11(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/asinh.mjs
m5().prototype.asinh = function() {
  return this.throwIfDisposed(), h8(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/atan.mjs
m5().prototype.atan = function() {
  return this.throwIfDisposed(), x12(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/atan2.mjs
m5().prototype.atan2 = function(t67) {
  return this.throwIfDisposed(), E8(this, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/atanh.mjs
m5().prototype.atanh = function() {
  return this.throwIfDisposed(), x13(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/avg_pool.mjs
m5().prototype.avgPool = function(o80, t67, r56, s84) {
  return this.throwIfDisposed(), T8(this, o80, t67, r56, s84);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/batch_to_space_nd.mjs
m5().prototype.batchToSpaceND = function(o80, t67) {
  return this.throwIfDisposed(), N8(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/batchnorm.mjs
m5().prototype.batchNorm = function(o80, t67, r56, s84, i88) {
  return this.throwIfDisposed(), F5(this, o80, t67, r56, s84, i88);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/broadcast_to.mjs
m5().prototype.broadcastTo = function(o80) {
  return this.throwIfDisposed(), v10(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/cast.mjs
m5().prototype.cast = function(t67) {
  return this.throwIfDisposed(), w12(this, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/ceil.mjs
m5().prototype.ceil = function() {
  return this.throwIfDisposed(), x17(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/clip_by_value.mjs
m5().prototype.clipByValue = function(o80, t67) {
  return this.throwIfDisposed(), x18(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/concat.mjs
m5().prototype.concat = function(o80, t67) {
  return this.throwIfDisposed(), o80 instanceof o5 && (o80 = [o80]), E9([this, ...o80], t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/conv1d.mjs
m5().prototype.conv1d = function(o80, t67, r56, s84, i88, n67) {
  return this.throwIfDisposed(), W5(this, o80, t67, r56, s84, i88, n67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/conv2d_transpose.mjs
m5().prototype.conv2dTranspose = function(o80, r56, s84, t67, n67) {
  return this.throwIfDisposed(), u12(this, o80, r56, s84, t67, n67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/conv2d.mjs
m5().prototype.conv2d = function(o80, t67, r56, s84, i88, n67) {
  return this.throwIfDisposed(), C5(this, o80, t67, r56, s84, i88, n67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/cos.mjs
m5().prototype.cos = function() {
  return this.throwIfDisposed(), u13(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/cosh.mjs
m5().prototype.cosh = function() {
  return this.throwIfDisposed(), h14(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/cumprod.mjs
m5().prototype.cumprod = function(o80, r56, t67) {
  return this.throwIfDisposed(), E12(this, o80, r56, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/cumsum.mjs
m5().prototype.cumsum = function(o80, t67, r56) {
  return this.throwIfDisposed(), N9(this, o80, t67, r56);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/depth_to_space.mjs
m5().prototype.depthToSpace = function(o80, t67) {
  return this.throwIfDisposed(), l15(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/depthwise_conv2d.mjs
m5().prototype.depthwiseConv2d = function(o80, t67, e36, r56, s84, i88) {
  return this.throwIfDisposed(), g11(this, o80, t67, e36, r56, s84, i88);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/dilation2d.mjs
m5().prototype.dilation2d = function(o80, t67, i88, r56, s84) {
  return this.throwIfDisposed(), C6(this, o80, t67, i88, r56, s84);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/div_no_nan.mjs
m5().prototype.divNoNan = function(o80) {
  return this.throwIfDisposed(), z6(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/div.mjs
m5().prototype.div = function(o80) {
  return this.throwIfDisposed(), D6(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/dot.mjs
m5().prototype.dot = function(o80) {
  return this.throwIfDisposed(), z7(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/elu.mjs
m5().prototype.elu = function() {
  return this.throwIfDisposed(), s12(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/equal.mjs
m5().prototype.equal = function(o80) {
  return this.throwIfDisposed(), E13(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/erf.mjs
m5().prototype.erf = function() {
  return this.throwIfDisposed(), x20(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/euclidean_norm.mjs
m5().prototype.euclideanNorm = function(o80, r56) {
  return this.throwIfDisposed(), u19(this, o80, r56);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/exp.mjs
m5().prototype.exp = function() {
  return this.throwIfDisposed(), u20(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/expand_dims.mjs
m5().prototype.expandDims = function(o80) {
  return this.throwIfDisposed(), D7(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/expm1.mjs
m5().prototype.expm1 = function() {
  return this.throwIfDisposed(), u21(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/fft.mjs
m5().prototype.fft = function() {
  return this.throwIfDisposed(), l24(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/flatten.mjs
m5().prototype.flatten = function() {
  return this.throwIfDisposed(), h9(this, [this.size]);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/floor.mjs
m5().prototype.floor = function() {
  return this.throwIfDisposed(), x24(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/floorDiv.mjs
m5().prototype.floorDiv = function(o80) {
  return this.throwIfDisposed(), b8(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/gather.mjs
m5().prototype.gather = function(t67, o80, r56) {
  return this.throwIfDisposed(), E15(this, t67, o80, r56);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/greater_equal.mjs
m5().prototype.greaterEqual = function(r56) {
  return this.throwIfDisposed(), h18(this, r56);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/greater.mjs
m5().prototype.greater = function(r56) {
  return this.throwIfDisposed(), G6(this, r56);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/ifft.mjs
m5().prototype.ifft = function() {
  return this.throwIfDisposed(), l25(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/irfft.mjs
m5().prototype.irfft = function() {
  return this.throwIfDisposed(), G10(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/is_finite.mjs
m5().prototype.isFinite = function() {
  return this.throwIfDisposed(), u23(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/is_inf.mjs
m5().prototype.isInf = function() {
  return this.throwIfDisposed(), x25(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/is_nan.mjs
m5().prototype.isNaN = function() {
  return this.throwIfDisposed(), x26(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/leaky_relu.mjs
m5().prototype.leakyRelu = function(o80) {
  return this.throwIfDisposed(), x27(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/less_equal.mjs
m5().prototype.lessEqual = function(o80) {
  return this.throwIfDisposed(), b15(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/less.mjs
m5().prototype.less = function(o80) {
  return this.throwIfDisposed(), d11(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/local_response_normalization.mjs
m5().prototype.localResponseNormalization = function(o80, t67, r56, s84) {
  return this.throwIfDisposed(), T11(this, o80, t67, r56, s84);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/log_sigmoid.mjs
m5().prototype.logSigmoid = function() {
  return this.throwIfDisposed(), G7(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/log_softmax.mjs
m5().prototype.logSoftmax = function(o80) {
  return this.throwIfDisposed(), A8(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/log_sum_exp.mjs
m5().prototype.logSumExp = function(o80, t67) {
  return this.throwIfDisposed(), z9(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/log.mjs
m5().prototype.log = function() {
  return this.throwIfDisposed(), x29(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/log1p.mjs
m5().prototype.log1p = function() {
  return this.throwIfDisposed(), g13(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/logical_and.mjs
m5().prototype.logicalAnd = function(o80) {
  return this.throwIfDisposed(), g16(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/logical_not.mjs
m5().prototype.logicalNot = function() {
  return this.throwIfDisposed(), s18(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/logical_or.mjs
m5().prototype.logicalOr = function(o80) {
  return this.throwIfDisposed(), u25(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/logical_xor.mjs
m5().prototype.logicalXor = function(o80) {
  return this.throwIfDisposed(), b16(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/mat_mul.mjs
m5().prototype.matMul = function(t67, o80, r56) {
  return this.throwIfDisposed(), N6(this, t67, o80, r56);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/max_pool.mjs
m5().prototype.maxPool = function(o80, t67, r56, s84) {
  return this.throwIfDisposed(), O6(this, o80, t67, r56, s84);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/max.mjs
m5().prototype.max = function(o80, t67) {
  return this.throwIfDisposed(), d10(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/maximum.mjs
m5().prototype.maximum = function(o80) {
  return this.throwIfDisposed(), E18(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/mean.mjs
m5().prototype.mean = function(o80, t67) {
  return this.throwIfDisposed(), E19(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/min.mjs
m5().prototype.min = function(o80, t67) {
  return this.throwIfDisposed(), E14(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/minimum.mjs
m5().prototype.minimum = function(o80) {
  return this.throwIfDisposed(), G8(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/mirror_pad.mjs
m5().prototype.mirrorPad = function(r56, o80) {
  return this.throwIfDisposed(), k14(this, r56, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/mod.mjs
m5().prototype.mod = function(o80) {
  return this.throwIfDisposed(), T13(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/mul.mjs
m5().prototype.mul = function(o80) {
  return this.throwIfDisposed(), y8(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/neg.mjs
m5().prototype.neg = function() {
  return this.throwIfDisposed(), g14(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/norm.mjs
m5().prototype.norm = function(o80, r56, t67) {
  return this.throwIfDisposed(), z8(this, o80, r56, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/not_equal.mjs
m5().prototype.notEqual = function(o80) {
  return this.throwIfDisposed(), b18(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/one_hot.mjs
m5().prototype.oneHot = function(o80, t67 = 1, r56 = 0) {
  return this.throwIfDisposed(), w15(this, o80, t67, r56);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/ones_like.mjs
m5().prototype.onesLike = function() {
  return this.throwIfDisposed(), k15(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/pad.mjs
m5().prototype.pad = function(o80, t67) {
  return this.throwIfDisposed(), l20(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/pool.mjs
m5().prototype.pool = function(o80, t67, r56, p103, s84, i88) {
  return this.throwIfDisposed(), z10(this, o80, t67, r56, p103, s84, i88);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/pow.mjs
m5().prototype.pow = function(o80) {
  return this.throwIfDisposed(), x22(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/prelu.mjs
m5().prototype.prelu = function(o80) {
  return this.throwIfDisposed(), x32(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/prod.mjs
m5().prototype.prod = function(o80, r56) {
  return this.throwIfDisposed(), N13(this, o80, r56);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/reciprocal.mjs
m5().prototype.reciprocal = function() {
  return this.throwIfDisposed(), x33(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/relu.mjs
m5().prototype.relu = function() {
  return this.throwIfDisposed(), s22(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/relu6.mjs
m5().prototype.relu6 = function() {
  return this.throwIfDisposed(), s23(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/reshape_as.mjs
m5().prototype.reshapeAs = function(o80) {
  return this.throwIfDisposed(), h9(this, o80.shape);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/reshape.mjs
m5().prototype.reshape = function(o80) {
  return this.throwIfDisposed(), h9(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/resize_bilinear.mjs
m5().prototype.resizeBilinear = function(r56, i88, e36) {
  return this.throwIfDisposed(), T21(this, r56, i88, e36);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/resize_nearest_neighbor.mjs
m5().prototype.resizeNearestNeighbor = function(e36, r56, o80) {
  return this.throwIfDisposed(), y13(this, e36, r56, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/reverse.mjs
m5().prototype.reverse = function(r56) {
  return this.throwIfDisposed(), E21(this, r56);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/rfft.mjs
m5().prototype.rfft = function() {
  return this.throwIfDisposed(), K8(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/round.mjs
m5().prototype.round = function() {
  return this.throwIfDisposed(), x34(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/rsqrt.mjs
m5().prototype.rsqrt = function() {
  return this.throwIfDisposed(), q8(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/selu.mjs
m5().prototype.selu = function() {
  return this.throwIfDisposed(), l23(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/separable_conv2d.mjs
m5().prototype.separableConv2d = function(o80, r56, t67, e36, s84, p103) {
  return this.throwIfDisposed(), T16(this, o80, r56, t67, e36, s84, p103);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/sigmoid.mjs
m5().prototype.sigmoid = function() {
  return this.throwIfDisposed(), d6(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/sign.mjs
m5().prototype.sign = function() {
  return this.throwIfDisposed(), g19(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/sin.mjs
m5().prototype.sin = function() {
  return this.throwIfDisposed(), u34(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/sinh.mjs
m5().prototype.sinh = function() {
  return this.throwIfDisposed(), h21(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/slice.mjs
m5().prototype.slice = function(o80, t67) {
  return this.throwIfDisposed(), E10(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/softmax.mjs
m5().prototype.softmax = function(o80) {
  return this.throwIfDisposed(), g20(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/softplus.mjs
m5().prototype.softplus = function() {
  return this.throwIfDisposed(), l18(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/space_to_batch_nd.mjs
m5().prototype.spaceToBatchND = function(o80, t67) {
  return this.throwIfDisposed(), x31(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/split.mjs
m5().prototype.split = function(t67, o80) {
  return this.throwIfDisposed(), N17(this, t67, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/sqrt.mjs
m5().prototype.sqrt = function() {
  return this.throwIfDisposed(), q6(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/square.mjs
m5().prototype.square = function() {
  return this.throwIfDisposed(), p24(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/squared_difference.mjs
m5().prototype.squaredDifference = function(e36) {
  return this.throwIfDisposed(), T17(this, e36);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/squeeze.mjs
m5().prototype.squeeze = function(e36) {
  return this.throwIfDisposed(), a23(this, e36);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/stack.mjs
m5().prototype.stack = function(t67, o80) {
  this.throwIfDisposed();
  let s84 = t67 instanceof o5 ? [this, t67] : [this, ...t67];
  return g21(s84, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/step.mjs
m5().prototype.step = function(t67) {
  return this.throwIfDisposed(), N18(this, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/strided_slice.mjs
m5().prototype.stridedSlice = function(t67, o80, r56, i88, e36, s84, d55, l80) {
  return this.throwIfDisposed(), a24(this, t67, o80, r56, i88, e36, s84, d55, l80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/sub.mjs
m5().prototype.sub = function(o80) {
  return this.throwIfDisposed(), E16(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/sum.mjs
m5().prototype.sum = function(o80, t67) {
  return this.throwIfDisposed(), T10(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/tan.mjs
m5().prototype.tan = function() {
  return this.throwIfDisposed(), x35(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/tanh.mjs
m5().prototype.tanh = function() {
  return this.throwIfDisposed(), x16(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/tile.mjs
m5().prototype.tile = function(t67) {
  return this.throwIfDisposed(), g12(this, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/to_bool.mjs
m5().prototype.toBool = function() {
  return this.throwIfDisposed(), w12(this, "bool");
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/to_float.mjs
m5().prototype.toFloat = function() {
  return this.throwIfDisposed(), w12(this, "float32");
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/to_int.mjs
m5().prototype.toInt = function() {
  return this.throwIfDisposed(), w12(this, "int32");
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/topk.mjs
m5().prototype.topk = function(o80, t67) {
  return this.throwIfDisposed(), x36(this, o80, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/transpose.mjs
m5().prototype.transpose = function(o80) {
  return this.throwIfDisposed(), A10(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/unique.mjs
m5().prototype.unique = function(o80) {
  return this.throwIfDisposed(), v19(this, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/unsorted_segment_sum.mjs
m5().prototype.unsortedSegmentSum = function(t67, o80) {
  return this.throwIfDisposed(), N19(this, t67, o80);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/unstack.mjs
m5().prototype.unstack = function(t67) {
  return this.throwIfDisposed(), g22(this, t67);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/where.mjs
m5().prototype.where = function(o80, r56) {
  return this.throwIfDisposed(), G5(o80, this, r56);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/public/chained_ops/zeros_like.mjs
m5().prototype.zerosLike = function() {
  return this.throwIfDisposed(), k11(this);
};

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Abs_grad.mjs
var c92 = { kernelName: o3, inputsToSave: ["x"], gradFunc: (o80, r56) => {
  let [t67] = r56;
  return { x: () => y8(o80, N18(w12(t67, "float32"), -1)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Acos_grad.mjs
var A31 = { kernelName: t, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [t67] = o80;
  return { x: () => {
    let m96 = p24(w12(t67, "float32")), s84 = q6(E16(m21(1), m96));
    return g14(D6(r56, s84));
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Acosh_grad.mjs
var h72 = { kernelName: e2, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [t67] = o80;
  return { x: () => {
    let m96 = q6(E16(p24(w12(t67, "float32")), 1));
    return D6(r56, m96);
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Add_grad.mjs
var b56 = { kernelName: r, inputsToSave: ["a", "b"], gradFunc: (o80, p103) => {
  let [s84, a71] = p103, d55 = u14(s84.shape, a71.shape);
  return { a: () => {
    let e36 = o80, t67 = f15(s84.shape, d55);
    return t67.length > 0 && (e36 = T10(e36, t67)), h9(e36, s84.shape);
  }, b: () => {
    let e36 = o80, t67 = f15(a71.shape, d55);
    return t67.length > 0 && (e36 = T10(e36, t67)), h9(e36, a71.shape);
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/AddN_grad.mjs
var c93 = { kernelName: n4, saveAllInputs: true, gradFunc: (e36, n67) => {
  let r56 = {};
  return n67.forEach((t67, o80) => {
    r56[o80] = () => e36.clone();
  }), r56;
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/ArgMax_grad.mjs
var i82 = { kernelName: c3, inputsToSave: ["x"], gradFunc: (n67, r56) => {
  let [o80] = r56;
  return { x: () => k11(o80) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/ArgMin_grad.mjs
var m87 = { kernelName: a4, inputsToSave: ["x"], gradFunc: (i88, r56) => {
  let [o80] = r56;
  return { x: () => k11(o80) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Asin_grad.mjs
var q21 = { kernelName: x2, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [m96] = o80;
  return { x: () => D6(r56, q6(E16(m21(1), p24(w12(m96, "float32"))))) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Asinh_grad.mjs
var q22 = { kernelName: i, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [t67] = o80;
  return { x: () => {
    let m96 = q6(T7(m21(1), p24(w12(t67, "float32"))));
    return D6(r56, m96);
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Atan2_grad.mjs
var R24 = { kernelName: u, inputsToSave: ["a", "b"], gradFunc: (n67, h74) => {
  let [r56, t67] = h74, m96 = u14(r56.shape, t67.shape);
  return { a: () => {
    let a71 = T7(p24(r56), p24(t67)), e36 = y8(n67, D6(t67, a71)), o80 = f15(r56.shape, m96);
    return o80.length > 0 && (e36 = T10(e36, o80)), h9(e36, r56.shape);
  }, b: () => {
    let a71 = T7(p24(r56), p24(t67)), e36 = g14(y8(n67, D6(r56, a71))), o80 = f15(t67.shape, m96);
    return o80.length > 0 && (e36 = T10(e36, o80)), h9(e36, t67.shape);
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Atan_grad.mjs
var u81 = { kernelName: l2, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [t67] = o80;
  return { x: () => D6(r56, T7(p24(w12(t67, "float32")), 1)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Atanh_grad.mjs
var l72 = { kernelName: d2, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [t67] = o80;
  return { x: () => D6(r56, E16(m21(1), p24(w12(t67, "float32")))) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/avg_pool_3d_grad.mjs
function y40(l80, m96, h74, f85, p103, i88) {
  let o80 = S5(l80, "dy", "avgPool3dGrad"), r56 = S5(m96, "input", "avgPool3dGrad"), t67 = o80, e36 = r56, d55 = false;
  r56.rank === 4 && (d55 = true, t67 = h9(o80, [1, o80.shape[0], o80.shape[1], o80.shape[2], o80.shape[3]]), e36 = h9(r56, [1, r56.shape[0], r56.shape[1], r56.shape[2], r56.shape[3]])), c(t67.rank === 5, () => `Error in avgPool3dGrad: dy must be rank 5 but got rank ${t67.rank}.`), c(e36.rank === 5, () => `Error in avgPool3dGrad: input must be rank 5 but got rank ${e36.rank}.`), z5("avgPool3dGrad", p103, i88);
  let c103 = { dy: t67, input: e36 }, g72 = { filterSize: h74, strides: f85, pad: p103, dimRoundingMode: i88 }, a71 = v3.runKernel(m, c103, g72);
  return d55 ? h9(a71, [a71.shape[1], a71.shape[2], a71.shape[3], a71.shape[4]]) : a71;
}
var x71 = u4({ avgPool3dGrad_: y40 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/AvgPool3D_grad.mjs
var p99 = { kernelName: D2, inputsToSave: ["x"], gradFunc: (o80, r56, e36) => {
  let [n67] = r56, { filterSize: t67, strides: d55, pad: i88, dimRoundingMode: a71 } = e36;
  return { x: () => x71(o80, n67, t67, d55, i88, a71) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/avg_pool_grad.mjs
function G25(u86, l80, d55, k63, m96) {
  let o80 = S5(u86, "dy", "avgPoolGrad"), r56 = S5(l80, "input", "avgPoolGrad");
  c(r56.rank === o80.rank, () => `Rank of input (${r56.rank}) does not match rank of dy (${o80.rank})`);
  let t67 = r56, n67 = o80, p103 = false;
  r56.rank === 3 && (p103 = true, t67 = h9(r56, [1, r56.shape[0], r56.shape[1], r56.shape[2]]), n67 = h9(o80, [1, o80.shape[0], o80.shape[1], o80.shape[2]])), c(n67.rank === 4, () => `Error in avgPoolGrad: dy must be rank 4 but got rank ${n67.rank}.`), c(t67.rank === 4, () => `Error in avgPoolGrad: input must be rank 4 but got rank ${t67.rank}.`);
  let f85 = { dy: n67, input: t67 }, h74 = { filterSize: d55, strides: k63, pad: m96 }, a71 = v3.runKernel(g2, f85, h74);
  return p103 ? h9(a71, [a71.shape[1], a71.shape[2], a71.shape[3]]) : a71;
}
var D35 = u4({ avgPoolGrad_: G25 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/AvgPool_grad.mjs
var m88 = { kernelName: S2, inputsToSave: ["x"], gradFunc: (o80, r56, t67) => {
  let [e36] = r56, { filterSize: a71, strides: n67, pad: i88 } = t67;
  return { x: () => D35(o80, e36, a71, n67, i88) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/BatchMatMul_grad.mjs
var i83 = { kernelName: R2, inputsToSave: ["a", "b"], gradFunc: (e36, l80, f85) => {
  let [t67, a71] = l80, { transposeA: s84, transposeB: u86 } = f85;
  return !s84 && !u86 ? { a: () => N6(e36, a71, false, true), b: () => N6(t67, e36, true, false) } : !s84 && u86 ? { a: () => N6(e36, a71, false, false), b: () => N6(e36, t67, true, false) } : s84 && !u86 ? { a: () => N6(a71, e36, false, true), b: () => N6(t67, e36, false, false) } : { a: () => N6(a71, e36, true, true), b: () => N6(e36, t67, true, true) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/BatchToSpaceND_grad.mjs
var s67 = { kernelName: h3, gradFunc: (o80, p103, a71) => {
  let { blockShape: c103, crops: r56 } = a71;
  return { x: () => x31(o80, c103, r56) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/BroadcastTo_grad.mjs
var h73 = { kernelName: B2, gradFunc: (n67, f85, c103) => {
  let e36 = c103, t67 = e36.inputShape, r56 = e36.shape, a71 = Array.from(r56);
  for (let o80 = t67.length - 1; o80 >= 0; o80--) if (t67[o80] === r56[o80]) a71[o80] = 1;
  else if (t67[o80] !== 1) throw new Error(`broadcastTo(): [${t67}] cannot be broadcast to [${r56}].`);
  let s84 = [];
  for (let o80 = 0; o80 < a71.length; o80++) a71[o80] > 1 && s84.push(o80);
  return { x: () => T10(n67, s84, true) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Cast_grad.mjs
var o79 = { kernelName: C2, gradFunc: (r56) => ({ x: () => r56.clone() }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Ceil_grad.mjs
var n64 = { kernelName: v2, gradFunc: (r56) => ({ x: () => k11(r56) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/ClipByValue_grad.mjs
var k55 = { kernelName: F2, inputsToSave: ["x"], gradFunc: (r56, e36, i88) => {
  let [o80] = e36, { clipValueMin: l80, clipValueMax: a71 } = i88;
  return { x: () => G5(g16(h18(o80, l80), b15(o80, a71)), r56, k11(r56)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/ComplexAbs_grad.mjs
var m89 = { kernelName: T2, inputsToSave: ["x"], gradFunc: c92.gradFunc };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Concat_grad.mjs
var d46 = { kernelName: L2, saveAllInputs: true, gradFunc: (t67, r56, a71) => {
  let e36 = r56.map((s84) => s84.shape), { axis: n67 } = a71, o80 = x(n67, r56[0].shape)[0], p103 = e36.map((s84) => s84[o80]);
  return N17(t67, p103, o80).map((s84) => () => s84);
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Conv2D_grad.mjs
var g66 = { kernelName: k2, inputsToSave: ["x", "filter"], gradFunc: (t67, l80, c103) => {
  let [r56, o80] = l80, { dilations: e36, strides: i88, pad: n67, dataFormat: a71 } = c103;
  return c(R6(e36), () => `Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${e36}'`), { x: () => B8(r56.shape, t67, o80, i88, n67, a71), filter: () => N21(r56, t67, o80.shape, i88, n67, a71) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Conv2DBackpropInput_grad.mjs
var v37 = { kernelName: E2, inputsToSave: ["dy", "filter"], gradFunc: (o80, a71, i88) => {
  let [c103, r56] = a71, { strides: t67, pad: n67, dataFormat: p103, dimRoundingMode: e36 } = i88;
  return { dy: () => C5(o80, r56, t67, n67, p103, 1, e36), filter: () => N21(o80, c103, r56.shape, t67, n67, p103, e36) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/conv3d_backprop_filter.mjs
function D36(r56, o80, t67, a71, i88) {
  let s84 = r56;
  r56.rank === 4 && (s84 = h9(r56, [1, r56.shape[0], r56.shape[1], r56.shape[2], r56.shape[3]]));
  let e36 = o80;
  e36.rank === 4 && (e36 = h9(o80, [1, o80.shape[0], o80.shape[1], o80.shape[2], o80.shape[3]])), c(s84.rank === 5, () => `Error in conv3dDerFilter: input must be rank 5, but got shape ${s84.shape}.`), c(e36.rank === 5, () => `Error in conv3dDerFilter: dy must be rank 5, but got shape ${e36.shape}.`), c(t67.length === 5, () => `Error in conv3dDerFilter: filterShape must be length 5, but got ${t67}.`), c(s84.shape[4] === t67[3], () => `Error in conv3dDerFilter: depth of input ${s84.shape[4]}) must match input depth in filter (${t67[3]}.`), c(e36.shape[4] === t67[4], () => `Error in conv3dDerFilter: depth of dy (${e36.shape[4]}) must match output depth for filter (${t67[4]}).`);
  let u86 = { x: s84, dy: e36 }, h74 = { strides: a71, pad: i88, filterShape: t67 };
  return v3.runKernel(I2, u86, h74);
}
var F28 = u4({ conv3DBackpropFilter_: D36 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Conv3D_grad.mjs
var g67 = { kernelName: f3, inputsToSave: ["x", "filter"], gradFunc: (r56, p103, s84) => {
  let { dilations: t67, strides: o80, pad: e36 } = s84;
  c(R6(t67), () => `Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${t67}'`);
  let [i88, n67] = p103;
  return { x: () => b13(i88.shape, r56, n67, o80, e36), filter: () => F28(i88, r56, n67.shape, o80, e36) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Cos_grad.mjs
var x72 = { kernelName: w2, inputsToSave: ["x"], gradFunc: (o80, r56) => {
  let [m96] = r56;
  return { x: () => y8(g14(u34(w12(m96, "float32"))), o80) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Cosh_grad.mjs
var c94 = { kernelName: V2, inputsToSave: ["x"], gradFunc: (o80, r56) => {
  let [t67] = r56;
  return { x: () => y8(h21(w12(t67, "float32")), o80) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Cumsum_grad.mjs
var d47 = { kernelName: b2, inputsToSave: ["x"], gradFunc: (e36, m96, n67) => {
  let [u86] = m96, { axis: t67, exclusive: s84, reverse: i88 } = n67;
  return { x: () => {
    let o80 = x21([t67], u86.rank), r56 = N9(e36, t67, s84, !i88);
    return o80 != null && (r56 = A10(r56, o80)), r56;
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/DepthwiseConv2dNative_grad.mjs
var k56 = { kernelName: H2, inputsToSave: ["x", "filter"], gradFunc: (d55, l80, u86) => {
  let { dilations: p103, strides: o80, pad: a71, dimRoundingMode: s84 } = u86, t67 = p103 ?? [1, 1];
  c(R6(t67), () => `Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${t67}'`);
  let [e36, i88] = l80;
  return c(e36.rank === 4, () => `Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${e36.rank}.`), c(i88.rank === 4, () => `Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${i88.rank}.`), c(e36.shape[3] === i88.shape[2], () => `Error in gradient of depthwiseConv2d: number of input channels (${e36.shape[3]}) must match the inChannels dimension in filter ${i88.shape[2]}.`), c(Z6(o80, t67), () => `Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${o80} and dilations '${t67}'.`), z5("depthwiseConv2d", a71, s84), { x: () => B11(e36.shape, d55, i88, o80, a71, t67, s84), filter: () => B10(e36, d55, i88.shape, o80, a71, t67, s84) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Dilation2D_grad.mjs
var D37 = { kernelName: Z2, inputsToSave: ["x", "filter"], gradFunc: (n67, e36, r56) => {
  let [t67, i88] = e36, l80 = { x: t67, filter: i88, dy: n67 }, p103 = { x: t67, filter: i88, dy: n67 };
  return { x: () => v3.runKernel(_2, l80, r56), filter: () => v3.runKernel(j2, p103, r56) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Elu_grad.mjs
var p100 = { kernelName: $2, outputsToSave: [true], gradFunc: (r56, o80) => {
  let [t67] = o80, e36 = { dy: r56, y: t67 };
  return { x: () => v3.runKernel(oo, e36) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Erf_grad.mjs
var g68 = { kernelName: to, inputsToSave: ["x"], gradFunc: (o80, t67) => {
  let [m96] = t67, e36 = y8(u20(g14(p24(m96))), 2 / Math.sqrt(Math.PI));
  return { x: () => y8(o80, e36) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Exp_grad.mjs
var u82 = { kernelName: ro, outputsToSave: [true], gradFunc: (r56, o80) => {
  let [t67] = o80;
  return { x: () => y8(r56, t67) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/ExpandDims_grad.mjs
var a68 = { kernelName: no, inputsToSave: ["input"], gradFunc: (n67, p103) => {
  let [r56] = p103;
  return { input: () => h9(n67, r56.shape) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Expm1_grad.mjs
var a69 = { kernelName: so, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [m96] = o80;
  return { x: () => y8(r56, u20(m96)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Floor_grad.mjs
var t63 = { kernelName: xo, gradFunc: (r56) => ({ x: () => k11(r56) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/FloorDiv_grad.mjs
var N55 = { kernelName: io, inputsToSave: ["a", "b"], gradFunc: (a71, c103) => {
  let [t67, e36] = c103, m96 = u14(t67.shape, e36.shape);
  return { a: () => {
    let r56 = D6(a71, w12(e36, "float32")), o80 = f15(t67.shape, m96);
    return o80.length > 0 ? h9(T10(r56, o80), t67.shape) : r56;
  }, b: () => {
    let r56 = y8(a71, w12(t67, "float32")), o80 = f15(e36.shape, m96);
    o80.length > 0 && (r56 = h9(T10(r56, o80), e36.shape));
    let u86 = p24(e36);
    return g14(D6(r56, w12(u86, "float32")));
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/FusedBatchNorm_grad.mjs
var J14 = { kernelName: lo, inputsToSave: ["x", "mean", "variance", "scale"], gradFunc: (o80, x76, k63) => {
  let { varianceEpsilon: v42 } = k63, [t67, a71, M30, u86] = x76, f85 = u86 ?? m21(1), c103 = f15(a71.shape, t67.shape), p103 = [];
  if (a71.rank === 1) {
    for (let e36 = 0; e36 < t67.shape.length - 1; ++e36) p103.push(t67.shape[e36]);
    p103.push(1);
  }
  let h74 = E16(t67, a71), d55 = y8(o80, f85), n67 = q8(T7(M30, m21(v42))), S45 = y8(y8(y8(n67, n67), n67), m21(-0.5));
  return { x: () => a71.rank === 1 ? h9(y8(y8(o80, g12(h9(n67, [1, 1, 1, a71.shape[0]]), p103)), f85), t67.shape) : h9(y8(y8(o80, n67), f85), t67.shape), mean: () => {
    let e36 = y8(y8(n67, m21(-1)), d55);
    return a71.rank === 1 && (e36 = T10(e36, c103)), h9(e36, a71.shape);
  }, variance: () => {
    let e36 = y8(y8(S45, h74), d55);
    return a71.rank === 1 && (e36 = T10(e36, c103)), h9(e36, a71.shape);
  }, scale: () => {
    let e36 = y8(h74, n67), l80 = y8(o80, e36);
    return a71.rank === 1 && (l80 = T10(l80, c103)), h9(l80, a71.shape);
  }, offset: () => {
    let e36 = o80;
    return a71.rank === 1 && (e36 = T10(e36, c103)), h9(e36, a71.shape);
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/GatherV2_grad.mjs
var K18 = { kernelName: uo, inputsToSave: ["x", "indices"], gradFunc: (t67, n67, s84) => {
  let [e36, o80] = n67, { axis: u86, batchDims: k63 } = s84, l80 = x(u86, e36.shape)[0], d55 = (c103, a71, f85) => () => {
    let i88 = c103.shape, p103 = a71.size, r56 = i88.slice(0, l80), h74 = r56.length, g72 = i88.slice(u86, i88.length).slice(1), B30 = g72.length, z32 = A32(0, h74), G30 = A32(h74 + 1, h74 + 1 + B30), I44 = D38([r56, [p103], g72]), T40 = h9(f85, I44), X20 = h9(a71, [p103]), x76 = D38([[h74], z32, G30]), b58 = A10(T40, x76), m96 = N19(b58, X20, c103.shape[l80]), C28 = d9(x76);
    return m96 = A10(m96, C28), m96;
  };
  if (k63 === 1) {
    let c103 = e36.shape[0], a71 = e36.split(c103, 0);
    return { x: () => g21(a71.map((p103, r56) => d55(p103, o80.slice(r56, 1), t67.slice(r56, 1))())).reshape(e36.shape), indices: () => o80 };
  } else return { x: d55(e36, o80, t67), indices: () => o80 };
} };
function A32(t67, n67) {
  let s84 = [];
  for (let e36 = t67; e36 < n67; ++e36) s84.push(e36);
  return s84;
}
function D38(t67) {
  let n67 = [];
  for (let s84 = 0; s84 < t67.length; ++s84) for (let e36 = 0; e36 < t67[s84].length; ++e36) n67.push(t67[s84][e36]);
  return n67;
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/GreaterEqual_grad.mjs
var u83 = { kernelName: Do, inputsToSave: ["a", "b"], gradFunc: (n67, e36) => {
  let [a71, o80] = e36;
  return { a: () => k11(a71), b: () => k11(o80) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Identity_grad.mjs
var i84 = { kernelName: mo, gradFunc: (t67) => ({ x: () => w12(t67, "float32") }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/IsFinite_grad.mjs
var t64 = { kernelName: Mo, gradFunc: (r56) => ({ x: () => k11(r56) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/IsInf_grad.mjs
var i85 = { kernelName: Ao, gradFunc: (r56) => ({ x: () => k11(r56) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/IsNan_grad.mjs
var i86 = { kernelName: Bo, gradFunc: (r56) => ({ x: () => k11(r56) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/LeakyRelu_grad.mjs
var k57 = { kernelName: No, inputsToSave: ["x"], gradFunc: (r56, o80, e36) => {
  let [t67] = o80, { alpha: m96 } = e36, a71 = G6(t67, 0);
  return { x: () => G5(a71, r56, y8(r56, m96)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Log1p_grad.mjs
var d48 = { kernelName: To, inputsToSave: ["x"], gradFunc: (o80, r56) => {
  let [t67] = r56;
  return { x: () => D6(o80, T7(t67, 1)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Log_grad.mjs
var p101 = { kernelName: Po, inputsToSave: ["x"], gradFunc: (o80, r56) => {
  let [t67] = r56;
  return { x: () => D6(o80, w12(t67, "float32")) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/LogSoftmax_grad.mjs
var k58 = { kernelName: fo, inputsToSave: [], outputsToSave: [true], gradFunc: (o80, t67, r56) => {
  let [m96] = t67, { axis: e36 } = r56;
  return { logits: () => {
    let s84 = u20(m96);
    return E16(o80, y8(T10(o80, e36, true), s84));
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/local_response_normalization_backprop.mjs
function N56(o80, r56, t67, n67 = 5, p103 = 1, a71 = 1, i88 = 0.5) {
  let s84 = { x: o80, y: r56, dy: t67 }, c103 = { depthRadius: n67, bias: p103, alpha: a71, beta: i88 };
  return v3.runKernel(wo, s84, c103);
}
var k59 = u4({ localResponseNormalizationBackprop_: N56 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/LRN_grad.mjs
var d49 = { kernelName: qo, inputsToSave: ["x"], outputsToSave: [true], gradFunc: (o80, a71, r56) => {
  let [t67, e36] = a71, { depthRadius: n67, bias: p103, alpha: s84, beta: i88 } = r56;
  return { x: () => k59(t67, e36, o80, n67, p103, s84, i88) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/min_max_grad_util.mjs
function l73(a71, r56, e36, o80) {
  return r56.rank < e36.rank && (r56 = h9(r56, m20(r56.shape, o80))), a71.rank < e36.rank && (a71 = h9(a71, m20(a71.shape, o80))), { x: () => y8(a71, w12(E13(e36, r56), a71.dtype)) };
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Max_grad.mjs
var f79 = { kernelName: yo, inputsToSave: ["x"], outputsToSave: [true], gradFunc: (n67, r56, a71) => {
  let s84 = a71, { reductionIndices: e36 } = s84, t67 = r56[0], i88 = r56[1], x76 = x(e36, t67.shape), m96 = l73(n67, i88, t67, x76);
  return { x: () => m96.x() };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Maximum_grad.mjs
var g69 = { kernelName: bo, inputsToSave: ["a", "b"], gradFunc: (r56, e36) => {
  let [o80, m96] = e36;
  return { a: () => y8(r56, w12(h18(o80, m96), "float32")), b: () => y8(r56, w12(d11(o80, m96), "float32")) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/max_pool_3d_grad.mjs
function E42(h74, k63, c103, f85, x76, d55, i88) {
  let o80 = S5(h74, "dy", "maxPool3dGrad"), r56 = S5(k63, "input", "maxPool3dGrad"), t67 = S5(c103, "output", "maxPool3dGrad"), e36 = o80, s84 = r56, n67 = t67, l80 = false;
  r56.rank === 4 && (l80 = true, e36 = h9(o80, [1, o80.shape[0], o80.shape[1], o80.shape[2], o80.shape[3]]), s84 = h9(r56, [1, r56.shape[0], r56.shape[1], r56.shape[2], r56.shape[3]]), n67 = h9(t67, [1, t67.shape[0], t67.shape[1], t67.shape[2], t67.shape[3]])), c(e36.rank === 5, () => `Error in maxPool3dGrad: dy must be rank 5 but got rank ${e36.rank}.`), c(s84.rank === 5, () => `Error in maxPool3dGrad: input must be rank 5 but got rank ${s84.rank}.`), c(n67.rank === 5, () => `Error in maxPool3dGrad: output must be rank 5 but got rank ${n67.rank}.`), z5("maxPool3dGrad", d55, i88);
  let G30 = { dy: e36, input: s84, output: n67 }, P36 = { filterSize: f85, strides: x76, pad: d55, dimRoundingMode: i88 }, a71 = v3.runKernel(Ho, G30, P36);
  return l80 ? h9(a71, [a71.shape[1], a71.shape[2], a71.shape[3], a71.shape[4]]) : a71;
}
var M28 = u4({ maxPool3dGrad_: E42 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/MaxPool3D_grad.mjs
var l74 = { kernelName: Oo, inputsToSave: ["x"], outputsToSave: [true], gradFunc: (o80, r56, t67) => {
  let [e36, a71] = r56, { filterSize: n67, strides: d55, pad: i88, dimRoundingMode: m96 } = t67;
  return { x: () => M28(o80, e36, a71, n67, d55, i88, m96) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/ops/max_pool_grad.mjs
function f80(i88, s84, l80, p103, k63, n67, u86) {
  let o80 = S5(i88, "dy", "maxPoolGrad"), r56 = S5(s84, "input", "maxPoolGrad"), d55 = S5(l80, "output", "maxPoolGrad");
  c(r56.rank === o80.rank, () => `Rank of input (${r56.rank}) does not match rank of dy (${o80.rank})`), c(o80.rank === 4, () => `Error in maxPoolGrad: dy must be rank 4 but got rank ${o80.rank}.`), c(r56.rank === 4, () => `Error in maxPoolGrad: input must be rank 4 but got rank ${r56.rank}.`), z5("maxPoolGrad", n67, u86);
  let c103 = { dy: o80, input: r56, output: d55 }, e36 = { filterSize: p103, strides: k63, pad: n67, dimRoundingMode: u86 };
  return v3.runKernel(Uo, c103, e36);
}
var v38 = u4({ maxPoolGrad_: f80 });

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/MaxPool_grad.mjs
var d50 = { kernelName: zo, inputsToSave: ["x"], outputsToSave: [true], gradFunc: (o80, r56, t67) => {
  let [e36, a71] = r56, { filterSize: n67, strides: i88, pad: m96 } = t67;
  return { x: () => v38(o80, e36, a71, n67, i88, m96) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Mean_grad.mjs
var C25 = { kernelName: Ko, inputsToSave: ["x"], gradFunc: (t67, a71, p103) => {
  let [e36] = a71, { axis: n67 } = p103, r56 = x(n67, e36.shape), m96 = l17(e36.shape, r56)[1], c103 = q(m96);
  return { x: () => {
    let s84 = e36.shape.slice();
    r56.forEach((d55) => {
      s84[d55] = 1;
    });
    let i88 = h9(t67, s84);
    return D6(y8(i88, c26(e36.shape, "float32")), c103);
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Min_grad.mjs
var f81 = { kernelName: Xo, inputsToSave: ["x"], outputsToSave: [true], gradFunc: (o80, n67, i88) => {
  let s84 = i88, { axis: a71 } = s84, [r56, e36] = n67, m96 = x(a71, r56.shape), u86 = l73(o80, e36, r56, m96);
  return { x: () => u86.x() };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Minimum_grad.mjs
var g70 = { kernelName: Zo, inputsToSave: ["a", "b"], gradFunc: (r56, a71) => {
  let [o80, m96] = a71;
  return { a: () => y8(r56, w12(b15(o80, m96), "float32")), b: () => y8(r56, w12(G6(o80, m96), "float32")) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/MirrorPad_grad.mjs
var d51 = { kernelName: _o, inputsToSave: ["x"], gradFunc: (r56, o80, n67) => {
  let a71 = o80[0], { paddings: e36 } = n67, i88 = e36.map((t67) => t67[0]);
  return { x: () => E10(r56, i88, a71.shape) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Mod_grad.mjs
var F29 = { kernelName: jo, inputsToSave: ["a", "b"], gradFunc: (t67, i88) => {
  let [e36, o80] = i88, s84 = u14(e36.shape, o80.shape);
  return { a: () => {
    let r56 = f15(e36.shape, s84);
    return r56.length > 0 ? h9(T10(t67, r56), e36.shape) : t67;
  }, b: () => {
    let r56 = y8(t67, g14(x24(D6(e36, o80)))), n67 = f15(o80.shape, s84);
    return n67.length > 0 ? h9(T10(r56, n67), o80.shape) : r56;
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Multiply_grad.mjs
var G26 = { kernelName: Qo, inputsToSave: ["a", "b"], gradFunc: (s84, i88) => {
  let [t67, o80] = i88, a71 = u14(t67.shape, o80.shape);
  return { a: () => {
    let e36 = y8(s84, w12(o80, "float32")), r56 = f15(t67.shape, a71);
    return r56.length > 0 ? h9(T10(e36, r56), t67.shape) : e36;
  }, b: () => {
    let e36 = y8(s84, w12(t67, "float32")), r56 = f15(o80.shape, a71);
    return r56.length > 0 ? h9(T10(e36, r56), o80.shape) : e36;
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Neg_grad.mjs
var m90 = { kernelName: Yo, gradFunc: (r56) => ({ x: () => g14(r56) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/OneHot_grad.mjs
var a70 = { kernelName: nt, inputsToSave: ["indices"], gradFunc: (i88, o80) => {
  let e36 = o80[0];
  return { indices: () => e13(e36.shape, "float32") };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/OnesLike_grad.mjs
var m91 = { kernelName: rt, gradFunc: (e36) => ({ x: () => k11(e36) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Pack_grad.mjs
var d52 = { kernelName: st, saveAllInputs: true, gradFunc: (r56, t67, e36) => {
  let { axis: s84 } = e36;
  return g22(r56, s84).map((n67) => () => n67);
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/PadV2_grad.mjs
var m92 = { kernelName: pt, inputsToSave: ["x"], gradFunc: (n67, o80, r56) => {
  let a71 = o80[0], { paddings: e36 } = r56, t67 = e36.map((p103) => p103[0]);
  return { x: () => E10(n67, t67, a71.shape) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Pow_grad.mjs
var D39 = { kernelName: at, inputsToSave: ["a", "b"], outputsToSave: [true], gradFunc: (m96, f85) => {
  let [d55, l80, h74] = f85, o80 = d55, s84 = l80, i88 = u14(o80.shape, s84.shape);
  return { a: () => {
    let a71 = w12(s84, "float32"), r56 = y8(m96, y8(a71, x22(o80, E16(a71, m21(1))))), t67 = f15(o80.shape, i88);
    return t67.length > 0 && (r56 = T10(r56, t67)), h9(r56, o80.shape);
  }, b: () => {
    let a71 = G6(o80, 0), r56 = G5(a71, x29(o80), k11(o80)), t67 = y8(m96, y8(h74, r56)), n67 = f15(s84.shape, i88);
    return n67.length > 0 && (t67 = T10(t67, n67)), h9(t67, s84.shape);
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Prelu_grad.mjs
var F30 = { kernelName: xt, inputsToSave: ["x", "alpha"], gradFunc: (r56, i88) => {
  let [t67, e36] = i88, m96 = G6(t67, 0);
  return { x: () => G5(m96, r56, y8(r56, e36)), alpha: () => {
    let o80 = G5(m96, k11(r56), y8(r56, t67)), p103 = f15(e36.shape, r56.shape);
    return p103.length > 0 && (o80 = T10(o80, p103)), h9(o80, e36.shape);
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Prod_grad.mjs
function S41(t67, a71, r56) {
  let n67 = t67.shape.slice();
  n67[r56] = 1;
  let o80 = h9(a71, n67), e36 = E12(t67, r56, true, false), s84 = E12(t67, r56, true, true), p103 = y8(e36, s84);
  return y8(o80, p103);
}
function v39(t67, a71, r56) {
  let n67 = t67.shape.length, o80 = n67 - r56.length, e36 = backend_util_exports.getAxesPermutation(r56, n67), s84 = t67;
  e36 != null && (s84 = A10(t67, e36));
  let p103 = s84.shape.slice(), h74 = p103.splice(n67 - r56.length, r56.length).reduce((u86, P36) => u86 * P36, 1);
  p103.push(h74);
  let f85 = s84.reshape(p103), d55 = S41(f85, a71, o80);
  if (d55 = d55.reshape(s84.shape), e36 != null) {
    let u86 = backend_util_exports.getUndoAxesPermutation(e36);
    d55 = A10(d55, u86);
  }
  return d55;
}
var y41 = { kernelName: it, inputsToSave: ["x"], gradFunc: (t67, a71, r56) => {
  let [n67] = a71, { axis: o80 } = r56, e36 = [];
  return o80 == null ? e36 = n67.shape.map((s84, p103) => p103) : typeof o80 == "number" ? e36 = [o80] : e36 = o80, { x: () => v39(n67, t67, e36) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/RealDiv_grad.mjs
var q23 = { kernelName: Q2, inputsToSave: ["a", "b"], gradFunc: (n67, u86) => {
  let [a71, r56] = u86, i88 = u14(a71.shape, r56.shape);
  return { a: () => {
    let t67 = D6(n67, w12(r56, "float32")), e36 = f15(a71.shape, i88);
    return e36.length > 0 ? h9(T10(t67, e36), a71.shape) : t67;
  }, b: () => {
    let t67 = y8(n67, w12(a71, "float32")), e36 = f15(r56.shape, i88);
    e36.length > 0 && (t67 = h9(T10(t67, e36), r56.shape));
    let d55 = p24(r56);
    return g14(D6(t67, w12(d55, "float32")));
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Reciprocal_grad.mjs
var s68 = { kernelName: Dt, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [e36] = o80;
  return { x: () => D6(r56, g14(p24(e36))) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Relu6_grad.mjs
var x73 = { kernelName: Nt, inputsToSave: ["x"], gradFunc: (t67, m96) => {
  let [o80] = m96, e36 = y8(b15(o80, 6), N18(o80));
  return { x: () => y8(t67, w12(e36, "float32")) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Relu_grad.mjs
var l75 = { kernelName: mt, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [t67] = o80;
  return { x: () => y8(r56, w12(N18(t67), "float32")) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Reshape_grad.mjs
var t65 = { kernelName: Rt, inputsToSave: ["x"], gradFunc: (e36, r56) => {
  let [o80] = r56;
  return { x: () => h9(e36, o80.shape) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/ResizeBilinear_grad.mjs
var l76 = { kernelName: At, inputsToSave: ["images"], gradFunc: (e36, i88, r56) => {
  let [n67] = i88, s84 = { dy: e36, images: n67 };
  return { images: () => v3.runKernel(Bt, s84, r56) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/ResizeNearestNeighbor_grad.mjs
var c95 = { kernelName: ht, inputsToSave: ["images"], gradFunc: (e36, r56, s84) => {
  let [i88] = r56, o80 = { dy: e36, images: i88 };
  return { images: () => v3.runKernel(Mt, o80, s84) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Reverse_grad.mjs
var f82 = { kernelName: Ct, gradFunc: (r56, n67, e36) => {
  let { dims: s84 } = e36, o80 = x(s84, r56.shape);
  return { x: () => E21(r56, o80) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Round_grad.mjs
var t66 = { kernelName: vt, gradFunc: (r56) => ({ x: () => k11(r56) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Rsqrt_grad.mjs
var c96 = { kernelName: Ft, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [m96] = o80;
  return { x: () => g14(D6(r56, y8(x22(m96, 1.5), 2))) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Select_grad.mjs
var d53 = { kernelName: kt, inputsToSave: ["condition"], gradFunc: (o80, i88) => {
  let [t67] = i88;
  return { condition: () => w12(k11(t67), "float32"), t: () => y8(o80, w12(t67, o80.dtype)), e: () => y8(o80, w12(s18(t67), o80.dtype)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Selu_grad.mjs
var U21 = { kernelName: Gt, inputsToSave: ["x"], gradFunc: (e36, m96) => {
  let [t67] = m96;
  return { x: () => {
    let a71 = G6(t67, m21(0)), s84 = m21(L6), n67 = m21(o17), c103 = y8(e36, n67), p103 = y8(y8(e36, s84), u20(w12(t67, "float32")));
    return G5(a71, c103, p103);
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Sigmoid_grad.mjs
var f83 = { kernelName: wt, outputsToSave: [true], gradFunc: (m96, t67) => {
  let [o80] = t67;
  return { x: () => y8(m96, y8(o80, E16(m21(1), o80))) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Sign_grad.mjs
var m93 = { kernelName: qt, gradFunc: (r56) => ({ x: () => k11(r56) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Sin_grad.mjs
var c97 = { kernelName: ft, inputsToSave: ["x"], gradFunc: (o80, r56) => {
  let [t67] = r56;
  return { x: () => y8(u13(w12(t67, "float32")), o80) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Sinh_grad.mjs
var c98 = { kernelName: It, inputsToSave: ["x"], gradFunc: (o80, r56) => {
  let [t67] = r56;
  return { x: () => y8(h14(w12(t67, "float32")), o80) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Slice_grad.mjs
var S42 = { kernelName: Et, inputsToSave: ["x"], gradFunc: (n67, s84, t67) => {
  let [o80] = s84, { begin: a71, size: p103 } = t67, c103 = o80.shape, [r56, m96] = q12(o80, a71, p103), i88 = [];
  for (let e36 = 0; e36 < n67.rank; e36++) i88.push([r56[e36], c103[e36] - r56[e36] - m96[e36]]);
  return { x: () => l20(n67, i88) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Softmax_grad.mjs
var l77 = { kernelName: Ot, outputsToSave: [true], gradFunc: (r56, s84, e36) => {
  let [o80] = s84, { dim: i88 } = e36, n67 = true, t67 = y8(r56, o80);
  return { logits: () => E16(t67, y8(T10(t67, [i88], n67), o80)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Softplus_grad.mjs
var f84 = { kernelName: Vt, inputsToSave: ["x"], gradFunc: (o80, r56) => {
  let [t67] = r56;
  return { x: () => y8(o80, d6(t67)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/SpaceToBatchND_grad.mjs
var m94 = { kernelName: zt, gradFunc: (a71, p103, o80) => {
  let { blockShape: c103, paddings: e36 } = o80;
  return { x: () => N8(a71, c103, e36) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/SplitV_grad.mjs
var m95 = { kernelName: Ut, gradFunc: (r56, e36, o80) => {
  let { axis: t67 } = o80;
  return { x: () => E9(r56, t67) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Sqrt_grad.mjs
var x74 = { kernelName: yt, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [t67] = o80;
  return { x: () => D6(r56, y8(q6(w12(t67, "float32")), 2)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Square_grad.mjs
var i87 = { kernelName: jt, inputsToSave: ["x"], gradFunc: (o80, t67) => {
  let [a71] = t67;
  return { x: () => y8(o80, y8(w12(a71, "float32"), 2)) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/SquaredDifference_grad.mjs
var l78 = { kernelName: _t, inputsToSave: ["a", "b"], gradFunc: (e36, m96) => {
  let [o80, t67] = m96, n67 = m21(2);
  return { a: () => y8(e36, y8(n67, E16(o80, t67))), b: () => y8(e36, y8(n67, E16(t67, o80))) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Step_grad.mjs
var n65 = { kernelName: ue, gradFunc: (r56) => ({ x: () => k11(r56) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Sub_grad.mjs
var A33 = { kernelName: te, inputsToSave: ["a", "b"], gradFunc: (o80, p103) => {
  let [s84, a71] = p103, n67 = u14(s84.shape, a71.shape);
  return { a: () => {
    let e36 = o80, t67 = f15(s84.shape, n67);
    return t67.length > 0 && (e36 = T10(e36, t67)), h9(e36, s84.shape);
  }, b: () => {
    let e36 = o80, t67 = f15(a71.shape, n67);
    return t67.length > 0 && (e36 = T10(e36, t67)), h9(g14(e36), a71.shape);
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Sum_grad.mjs
var D40 = { kernelName: bt, inputsToSave: ["x"], gradFunc: (r56, s84, a71) => {
  let [o80] = s84, e36 = o80.shape.slice(), { axis: t67 } = a71;
  x(t67, o80.shape).forEach((p103) => {
    e36[p103] = 1;
  });
  let m96 = h9(r56, e36), n67 = y8(m96, c26(o80.shape, "float32"));
  return { x: () => n67 };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Tan_grad.mjs
var c99 = { kernelName: ee, inputsToSave: ["x"], gradFunc: (r56, o80) => {
  let [t67] = o80;
  return { x: () => D6(r56, p24(u13(t67))) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Tanh_grad.mjs
var l79 = { kernelName: re, outputsToSave: [true], gradFunc: (r56, o80) => {
  let [t67] = o80;
  return { x: () => y8(E16(m21(1), p24(t67)), r56) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Tile_grad.mjs
var G27 = { kernelName: ne, inputsToSave: ["x"], gradFunc: (p103, f85, h74) => {
  let [e36] = f85, { reps: a71 } = h74;
  return { x: () => {
    let o80 = k11(e36);
    if (e36.rank === 1) for (let r56 = 0; r56 < a71[0]; ++r56) o80 = T7(o80, E10(p103, [r56 * e36.shape[0]], [e36.shape[0]]));
    else if (e36.rank === 2) for (let r56 = 0; r56 < a71[0]; ++r56) for (let s84 = 0; s84 < a71[1]; ++s84) o80 = T7(o80, E10(p103, [r56 * e36.shape[0], s84 * e36.shape[1]], [e36.shape[0], e36.shape[1]]));
    else if (e36.rank === 3) for (let r56 = 0; r56 < a71[0]; ++r56) for (let s84 = 0; s84 < a71[1]; ++s84) for (let t67 = 0; t67 < a71[2]; ++t67) o80 = T7(o80, E10(p103, [r56 * e36.shape[0], s84 * e36.shape[1], t67 * e36.shape[2]], [e36.shape[0], e36.shape[1], e36.shape[2]]));
    else if (e36.rank === 4) for (let r56 = 0; r56 < a71[0]; ++r56) for (let s84 = 0; s84 < a71[1]; ++s84) for (let t67 = 0; t67 < a71[2]; ++t67) for (let n67 = 0; n67 < a71[3]; ++n67) o80 = T7(o80, E10(p103, [r56 * e36.shape[0], s84 * e36.shape[1], t67 * e36.shape[2], n67 * e36.shape[3]], [e36.shape[0], e36.shape[1], e36.shape[2], e36.shape[3]]));
    else throw new Error(`Gradient for tile operation is not implemented for rank-${e36.rank} tensors yet.`);
    return o80;
  } };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Transpose_grad.mjs
var c100 = { kernelName: ce, gradFunc: (o80, i88, t67) => {
  let s84 = t67, { perm: e36 } = s84, n67 = d9(e36);
  return { x: () => A10(o80, n67) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/Unpack_grad.mjs
var k60 = { kernelName: xe, gradFunc: (r56, e36, a71) => {
  let n67 = a71, { axis: t67 } = n67;
  return { value: () => g21(r56, t67) };
} };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/UnsortedSegmentSum_grad.mjs
var w44 = { kernelName: ie, inputsToSave: ["segmentIds"], gradFunc: (t67, o80) => {
  let [m96] = o80;
  return { x: () => k61(t67, m96) };
} };
function k61(t67, o80) {
  let m96 = E18(o80, k11(o80)), e36 = E15(t67, m96), r56 = h18(o80, m21(0, "int32")), s84 = e36.rank - r56.rank;
  for (let n67 = 0; n67 < s84; ++n67) r56 = D7(r56, n67 + 1);
  r56 = g16(r56, c26(e36.shape, "bool"));
  let a71 = k11(e36);
  return G5(r56, e36, a71);
}

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/gradients/ZerosLike_grad.mjs
var n66 = { kernelName: de, gradFunc: (r56) => ({ x: () => k11(r56) }) };

// https://esm.sh/@tensorflow/tfjs-core@4.22.0/denonext/dist/register_all_gradients.mjs
var Yo2 = [c92, A31, h72, b56, c93, i82, m87, q21, q22, R24, u81, l72, p99, m88, i83, s67, h73, o79, n64, k55, m89, d46, v37, g66, g67, x72, c94, d47, k56, D37, q23, p100, g68, u82, a68, a69, N55, t63, J14, K18, u83, i84, t64, i85, i86, k57, d48, p101, k58, d49, f79, f79, g69, l74, d50, C25, f81, g70, d51, F29, G26, m90, a70, m91, d52, m92, m92, D39, F30, y41, s68, x73, l75, t65, l76, c95, f82, t66, c96, d53, U21, f83, m93, c97, c98, S42, l77, f84, m94, m94, m95, m95, x74, l78, i87, n65, A33, D40, c99, l79, G27, c100, k60, w44, n66];
for (let f85 of Yo2) b3(f85);

// https://esm.sh/@tensorflow/tfjs-data@4.22.0/denonext/tfjs-data.mjs
var tfjs_data_exports = {};
__export(tfjs_data_exports, {
  CSVDataset: () => T39,
  Dataset: () => d54,
  FileDataSource: () => F31,
  TextLineDataset: () => R25,
  URLDataSource: () => I43,
  array: () => Ae3,
  csv: () => Ge,
  func: () => Ze2,
  generator: () => je2,
  microphone: () => Ye,
  version_data: () => Xe2,
  webcam: () => Je2,
  zip: () => Te3
});
import { Buffer as __Buffer$3 } from "node:buffer";
import * as __0$3 from "node:fs";
import * as __1$2 from "node:string_decoder";
var require4 = (n67) => {
  const e36 = (m96) => typeof m96.default < "u" ? m96.default : m96, c103 = (m96) => Object.assign({ __esModule: true }, m96);
  switch (n67) {
    case "node:fs":
      return e36(__0$3);
    case "node:string_decoder":
      return e36(__1$2);
    default:
      console.error('module "' + n67 + '" not found');
      return null;
  }
};
var W14 = ((r56) => typeof require4 < "u" ? require4 : typeof Proxy < "u" ? new Proxy(r56, { get: (e36, t67) => (typeof require4 < "u" ? require4 : e36)[t67] }) : r56)(function(r56) {
  if (typeof require4 < "u") return require4.apply(this, arguments);
  throw Error('Dynamic require of "' + r56 + '" is not supported');
});
function le5(r56, e36) {
  return k62(r56, e36);
}
function k62(r56, e36, t67 = /* @__PURE__ */ new Map(), s84 = /* @__PURE__ */ new Set()) {
  if (r56 == null) return null;
  if (typeof Blob == "function" && r56 instanceof Blob) return r56.slice();
  if (s84.has(r56)) throw new Error("Circular references are not supported.");
  if (t67.has(r56)) return t67.get(r56);
  let i88 = e36(r56);
  if (i88.recurse && i88.value !== null) throw new Error("A deep map function may not return both a value and recurse=true.");
  if (i88.recurse) if (y42(r56)) {
    let n67 = Array.isArray(r56) ? [] : {};
    s84.add(r56);
    for (let o80 in r56) {
      let a71 = r56[o80], l80 = k62(a71, e36, t67, s84);
      n67[o80] = l80;
    }
    return s84.delete(r56), r56.__proto__ && (n67.__proto__ = r56.__proto__), n67;
  } else throw new Error(`Can't recurse into non-iterable type: ${r56}`);
  else return t67.set(r56, i88.value), i88.value;
}
function he4(r56, e36 = U22) {
  return ce5(r56, e36);
}
function ce5(r56, e36, t67 = /* @__PURE__ */ new Set()) {
  let s84 = r56[0];
  if (t67.has(s84)) throw new Error("Circular references are not supported.");
  let i88 = e36(r56);
  if (i88.recurse && i88.value !== null) throw new Error("A deep zip function may not return both a value and recurse=true.");
  if (i88.recurse) if (y42(s84)) {
    let n67 = Array.isArray(s84) ? [] : {};
    t67.add(s84);
    for (let o80 in s84) {
      let a71 = r56.map((f85) => f85[o80]), l80 = ce5(a71, e36, t67);
      n67[o80] = l80;
    }
    return t67.delete(s84), n67;
  } else throw new Error(`Can't recurse into non-iterable type: ${s84}`);
  else return i88.value;
}
function U22(r56) {
  return r56 === null ? null : y42(r56[0]) ? { value: null, recurse: true } : { value: r56, recurse: false };
}
async function N57(r56, e36) {
  let t67 = /* @__PURE__ */ new Map();
  k62(r56, e36, t67);
  for (let i88 of Array.from(t67.keys())) {
    let n67 = t67.get(i88);
    if (util_exports.isPromise(n67)) {
      let o80 = await n67;
      t67.set(i88, o80);
    }
  }
  return k62(r56, e36, t67);
}
function y42(r56) {
  let e36 = false;
  if (l().get("IS_BROWSER")) e36 = r56 instanceof TextDecoder;
  else {
    let { StringDecoder: t67 } = W14("node:string_decoder");
    e36 = r56 instanceof t67;
  }
  return r56 != null && !ArrayBuffer.isView(r56) && (Array.isArray(r56) || typeof r56 == "object" && !(r56 instanceof o5) && !(r56 instanceof Promise) && !e36);
}
function fe4(r56) {
  return r56 == null || ze2(r56) || Array.isArray(r56) || typeof r56 == "object" && r56 instanceof o5 || util_exports.isTypedArray(r56);
}
function ze2(r56) {
  return r56 === null || typeof r56 != "object" && typeof r56 != "function";
}
function de4(r56) {
  return le5(r56, Re4);
}
function Re4(r56) {
  return r56 instanceof o5 ? { value: r56.clone(), recurse: false } : y42(r56) ? { value: null, recurse: true } : { value: r56, recurse: false };
}
var x75 = class {
  constructor(e36) {
    if (this.capacity = e36, this.begin = 0, this.end = 0, e36 == null) throw new RangeError("Can't create a ring buffer of unknown capacity.");
    if (e36 < 1) throw new RangeError("Can't create ring buffer of capacity < 1.");
    this.data = new Array(e36), this.doubledCapacity = 2 * e36;
  }
  wrap(e36) {
    for (; e36 < 0; ) e36 += this.doubledCapacity;
    return e36 % this.doubledCapacity;
  }
  get(e36) {
    if (e36 < 0) throw new RangeError("Can't get item at a negative index.");
    return this.data[e36 % this.capacity];
  }
  set(e36, t67) {
    if (e36 < 0) throw new RangeError("Can't set item at a negative index.");
    this.data[e36 % this.capacity] = t67;
  }
  length() {
    let e36 = this.end - this.begin;
    return e36 < 0 && (e36 = this.doubledCapacity + e36), e36;
  }
  isFull() {
    return this.length() === this.capacity;
  }
  isEmpty() {
    return this.length() === 0;
  }
  push(e36) {
    if (this.isFull()) throw new RangeError("Ring buffer is full.");
    this.set(this.end, e36), this.end = this.wrap(this.end + 1);
  }
  pushAll(e36) {
    for (let t67 of e36) this.push(t67);
  }
  pop() {
    if (this.isEmpty()) throw new RangeError("Ring buffer is empty.");
    this.end = this.wrap(this.end - 1);
    let e36 = this.get(this.end);
    return this.set(this.end, void 0), e36;
  }
  unshift(e36) {
    if (this.isFull()) throw new RangeError("Ring buffer is full.");
    this.begin = this.wrap(this.begin - 1), this.set(this.begin, e36);
  }
  shift() {
    if (this.isEmpty()) throw new RangeError("Ring buffer is empty.");
    let e36 = this.get(this.begin);
    return this.set(this.begin, void 0), this.begin = this.wrap(this.begin + 1), e36;
  }
  shuffleExcise(e36) {
    if (this.isEmpty()) throw new RangeError("Ring buffer is empty.");
    let t67 = this.wrap(this.begin + e36), s84 = this.get(t67);
    return this.set(t67, this.pop()), s84;
  }
};
var C26 = class r52 extends x75 {
  constructor() {
    super(r52.INITIAL_CAPACITY);
  }
  isFull() {
    return false;
  }
  push(e36) {
    super.isFull() && this.expand(), super.push(e36);
  }
  unshift(e36) {
    super.isFull() && this.expand(), super.unshift(e36);
  }
  expand() {
    let e36 = this.capacity * 2, t67 = new Array(e36), s84 = this.length();
    for (let i88 = 0; i88 < s84; i88++) t67[i88] = this.get(this.wrap(this.begin + i88));
    this.data = t67, this.capacity = e36, this.doubledCapacity = 2 * this.capacity, this.begin = 0, this.end = s84;
  }
};
C26.INITIAL_CAPACITY = 32;
function re6(r56) {
  return new Q11(r56);
}
function z31(r56) {
  return new V23(r56);
}
function we2(r56, e36) {
  return new O20(r56, e36);
}
function ye2(r56, e36 = p102.FAIL) {
  return new ee6(r56, e36);
}
var u84 = class {
  async toArray() {
    let e36 = [], t67 = await this.next();
    for (; !t67.done; ) e36.push(t67.value), t67 = await this.next();
    return e36;
  }
  async toArrayForTest() {
    let e36 = this.prefetch(100), t67 = [], s84 = await e36.next();
    for (; !s84.done; ) t67.push(s84.value), s84 = await e36.next();
    return t67;
  }
  async resolveFully() {
    let e36 = await this.next();
    for (; !e36.done; ) e36 = await this.next();
  }
  async resolveWhile(e36) {
    let t67 = await this.next(), s84 = e36(t67.value);
    for (; !t67.done && s84; ) t67 = await this.next(), s84 = e36(t67.value);
  }
  handleErrors(e36) {
    return new X19(this, e36);
  }
  filter(e36) {
    return new J15(this, e36);
  }
  map(e36) {
    return new Y12(this, e36);
  }
  mapAsync(e36) {
    return new D41(this, e36);
  }
  serialMapAsync(e36) {
    return new D41(this, e36).serial();
  }
  flatmap(e36) {
    return new K19(this, e36);
  }
  async forEachAsync(e36) {
    return this.map(e36).resolveFully();
  }
  async serialForEach(e36) {
    return this.serialMapAsync(e36).resolveWhile((t67) => t67 === true);
  }
  rowMajorBatch(e36, t67 = true) {
    return new j20(this, e36, t67);
  }
  columnMajorBatch(e36, t67 = true, s84 = U22) {
    return this.rowMajorBatch(e36, t67).map((n67) => he4(n67, s84));
  }
  concatenate(e36, t67) {
    return new O20(re6([this, e36]), t67);
  }
  take(e36) {
    return e36 < 0 || e36 == null ? this : new Z14(this, e36);
  }
  skip(e36) {
    return e36 < 0 || e36 == null ? this : new G28(this, e36);
  }
  prefetch(e36) {
    return new _23(this, e36);
  }
  shuffle(e36, t67) {
    return new te6(this, e36, t67);
  }
  serial() {
    return new q24(this);
  }
};
var Q11 = class extends u84 {
  constructor(e36) {
    super(), this.items = e36, this.trav = 0;
  }
  summary() {
    return `Array of ${this.items.length} items`;
  }
  async next() {
    if (this.trav >= this.items.length) return { value: null, done: true };
    let e36 = this.items[this.trav];
    return this.trav++, { value: de4(e36), done: false };
  }
};
var V23 = class extends u84 {
  constructor(e36) {
    super(), this.nextFn = e36;
  }
  summary() {
    return "Function call";
  }
  async next() {
    try {
      return this.nextFn();
    } catch (e36) {
      throw e36.message = `Error thrown while iterating through a dataset: ${e36.message}`, e36;
    }
  }
};
var q24 = class extends u84 {
  constructor(e36) {
    super(), this.upstream = e36, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Serial`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    return this.upstream.next();
  }
};
var G28 = class extends u84 {
  constructor(e36, t67) {
    super(), this.upstream = e36, this.maxCount = t67, this.count = 0, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Skip`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; this.count++ < this.maxCount; ) {
      let e36 = await this.upstream.next();
      if (e36.done) return e36;
      E4(e36.value);
    }
    return this.upstream.next();
  }
};
var Z14 = class extends u84 {
  constructor(e36, t67) {
    super(), this.upstream = e36, this.maxCount = t67, this.count = 0;
  }
  summary() {
    return `${this.upstream.summary()} -> Take`;
  }
  async next() {
    return this.count++ >= this.maxCount ? { value: null, done: true } : this.upstream.next();
  }
};
var j20 = class extends u84 {
  constructor(e36, t67, s84 = true) {
    super(), this.upstream = e36, this.batchSize = t67, this.enableSmallLastBatch = s84, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> RowMajorBatch`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    let e36 = [];
    for (; e36.length < this.batchSize; ) {
      let t67 = await this.upstream.next();
      if (t67.done) return this.enableSmallLastBatch && e36.length > 0 ? { value: e36, done: false } : { value: null, done: true };
      e36.push(t67.value);
    }
    return { value: e36, done: false };
  }
};
var J15 = class extends u84 {
  constructor(e36, t67) {
    super(), this.upstream = e36, this.predicate = t67, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> Filter`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; ; ) {
      let e36 = await this.upstream.next();
      if (e36.done || this.predicate(e36.value)) return e36;
      E4(e36.value);
    }
  }
};
var Y12 = class extends u84 {
  constructor(e36, t67) {
    super(), this.upstream = e36, this.transform = t67;
  }
  summary() {
    return `${this.upstream.summary()} -> Map`;
  }
  async next() {
    let e36 = await this.upstream.next();
    if (e36.done) return { value: null, done: true };
    let t67 = tensor_util_exports.getTensorsInContainer(e36.value), s84 = this.transform(e36.value), i88 = tensor_util_exports.getTensorsInContainer(s84);
    for (let n67 of t67) tensor_util_exports.isTensorInList(n67, i88) || n67.dispose();
    return { value: s84, done: false };
  }
};
var X19 = class extends u84 {
  constructor(e36, t67) {
    super(), this.upstream = e36, this.handler = t67, this.count = 0, this.lastRead = Promise.resolve({ value: null, done: false });
  }
  summary() {
    return `${this.upstream.summary()} -> handleErrors`;
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; ; ) try {
      return await this.upstream.next();
    } catch (e36) {
      if (!this.handler(e36)) return { value: null, done: true };
    }
  }
};
var D41 = class extends u84 {
  constructor(e36, t67) {
    super(), this.upstream = e36, this.transform = t67;
  }
  summary() {
    return `${this.upstream.summary()} -> AsyncMap`;
  }
  async next() {
    let e36 = await this.upstream.next();
    if (e36.done) return { value: null, done: true };
    let t67 = tensor_util_exports.getTensorsInContainer(e36.value), s84 = await this.transform(e36.value), i88 = tensor_util_exports.getTensorsInContainer(s84);
    for (let n67 of t67) tensor_util_exports.isTensorInList(n67, i88) || n67.dispose();
    return { value: s84, done: false };
  }
};
var g71 = class extends u84 {
  constructor() {
    super(), this.outputQueue = new C26(), this.lastRead = Promise.resolve({ value: null, done: false });
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  async serialNext() {
    for (; this.outputQueue.length() === 0; ) if (!await this.pump()) return { value: null, done: true };
    return { value: this.outputQueue.shift(), done: false };
  }
};
var K19 = class extends g71 {
  constructor(e36, t67) {
    super(), this.upstream = e36, this.transform = t67;
  }
  summary() {
    return `${this.upstream.summary()} -> Flatmap`;
  }
  async pump() {
    let e36 = await this.upstream.next();
    if (e36.done) return false;
    let t67 = tensor_util_exports.getTensorsInContainer(e36.value), s84 = this.transform(e36.value), i88 = tensor_util_exports.getTensorsInContainer(s84);
    this.outputQueue.pushAll(s84);
    for (let n67 of t67) tensor_util_exports.isTensorInList(n67, i88) || n67.dispose();
    return true;
  }
};
var O20 = class extends u84 {
  constructor(e36, t67) {
    super(), this.baseErrorHandler = t67, this.lastRead = null, this.iterator = null, this.moreIterators = e36;
  }
  summary() {
    return "TODO: fill in upstream of chained summaries -> Chained";
  }
  async next() {
    return this.lastRead = this.readFromChain(this.lastRead), this.lastRead;
  }
  async readFromChain(e36) {
    if (await e36, this.iterator == null) {
      let s84 = await this.moreIterators.next();
      if (s84.done) return { value: null, done: true };
      this.iterator = s84.value, this.baseErrorHandler != null && (this.iterator = this.iterator.handleErrors(this.baseErrorHandler));
    }
    let t67 = await this.iterator.next();
    return t67.done ? (this.iterator = null, this.readFromChain(e36)) : t67;
  }
};
var p102;
(function(r56) {
  r56[r56.FAIL = 0] = "FAIL", r56[r56.SHORTEST = 1] = "SHORTEST", r56[r56.LONGEST = 2] = "LONGEST";
})(p102 || (p102 = {}));
var ee6 = class extends u84 {
  constructor(e36, t67 = p102.FAIL) {
    super(), this.iterators = e36, this.mismatchMode = t67, this.count = 0, this.currentPromise = null;
  }
  summary() {
    return "{TODO: fill in upstream of zip summaries} -> Zip";
  }
  async nextState(e36) {
    await e36;
    let t67 = 0, s84 = 0;
    function i88(o80) {
      return o80 instanceof u84 ? { value: o80.next().then((l80) => (t67++, l80.done && s84++, l80.value)), recurse: false } : { value: null, recurse: true };
    }
    let n67 = await N57(this.iterators, i88);
    if (t67 === s84) return { value: null, done: true };
    if (s84 > 0) switch (this.mismatchMode) {
      case p102.FAIL:
        throw new Error(`Zipped streams should have the same length. Mismatched at element ${this.count}.`);
      case p102.SHORTEST:
        return { value: null, done: true };
      case p102.LONGEST:
      default:
    }
    return this.count++, { value: n67, done: false };
  }
  async next() {
    return this.currentPromise = this.nextState(this.currentPromise), this.currentPromise;
  }
};
var _23 = class extends u84 {
  constructor(e36, t67) {
    super(), this.upstream = e36, this.bufferSize = t67, this.buffer = new x75(t67);
  }
  summary() {
    return `${this.upstream.summary()} -> Prefetch`;
  }
  refill() {
    for (; !this.buffer.isFull(); ) {
      let e36 = this.upstream.next();
      this.buffer.push(e36);
    }
  }
  next() {
    return this.refill(), this.buffer.shift();
  }
};
var te6 = class extends _23 {
  constructor(e36, t67, s84) {
    super(e36, t67), this.upstream = e36, this.windowSize = t67, this.upstreamExhausted = false, this.random = qn(s84 || util_exports.now().toString()), this.lastRead = Promise.resolve({ value: null, done: false });
  }
  async next() {
    return this.lastRead = this.lastRead.then(() => this.serialNext()), this.lastRead;
  }
  randomInt(e36) {
    return Math.floor(this.random() * e36);
  }
  chooseIndex() {
    return this.randomInt(this.buffer.length());
  }
  async serialNext() {
    for (this.upstreamExhausted || this.refill(); !this.buffer.isEmpty(); ) {
      let e36 = this.chooseIndex(), t67 = await this.buffer.shuffleExcise(e36);
      if (t67.done) this.upstreamExhausted = true;
      else return this.refill(), t67;
    }
    return { value: null, done: true };
  }
};
var d54 = class {
  constructor() {
    this.size = null;
  }
  batch(e36, t67 = true) {
    let s84 = this;
    util_exports.assert(e36 > 0, () => `batchSize needs to be positive, but it is
      ${e36}`);
    let i88;
    return this.size === 1 / 0 || this.size == null ? i88 = this.size : t67 ? i88 = Math.ceil(this.size / e36) : i88 = Math.floor(this.size / e36), c101(async () => (await s84.iterator()).columnMajorBatch(e36, t67, Se3), i88);
  }
  concatenate(e36) {
    let t67 = this, s84;
    return this.size === 1 / 0 || e36.size === 1 / 0 ? s84 = 1 / 0 : this.size != null && e36.size != null ? s84 = this.size + e36.size : s84 = null, c101(async () => (await t67.iterator()).concatenate(await e36.iterator()), s84);
  }
  filter(e36) {
    let t67 = this, s84;
    return this.size === 1 / 0 ? s84 = 1 / 0 : s84 = null, c101(async () => (await t67.iterator()).filter((i88) => g4(() => e36(i88))), s84);
  }
  async forEachAsync(e36) {
    return (await this.iterator()).forEachAsync(e36);
  }
  map(e36) {
    let t67 = this;
    return c101(async () => (await t67.iterator()).map((s84) => g4(() => e36(s84))), this.size);
  }
  mapAsync(e36) {
    let t67 = this;
    return c101(async () => (await t67.iterator()).mapAsync(e36), this.size);
  }
  prefetch(e36) {
    if (e36 == null) throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");
    let t67 = this;
    return c101(async () => (await t67.iterator()).prefetch(e36), this.size);
  }
  repeat(e36) {
    let t67 = this, s84;
    return this.size != null && e36 > 0 ? s84 = this.size * e36 : e36 === 0 ? s84 = 0 : this.size != null && (e36 === void 0 || e36 < 0) ? s84 = 1 / 0 : s84 = null, c101(async () => {
      let i88 = z31(async () => ({ value: await t67.iterator(), done: false }));
      return we2(i88.take(e36));
    }, s84);
  }
  skip(e36) {
    let t67 = this, s84;
    return this.size != null && e36 >= 0 && this.size >= e36 ? s84 = this.size - e36 : this.size != null && (this.size < e36 || e36 === void 0 || e36 < 0) ? s84 = 0 : s84 = null, c101(async () => (await t67.iterator()).skip(e36), s84);
  }
  shuffle(e36, t67, s84 = true) {
    if (e36 == null || e36 < 0) throw this.size == null ? new RangeError("`Dataset.shuffle()` requires bufferSize to be specified.") : new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);
    let i88 = this, n67 = qn(t67 || util_exports.now().toString());
    return c101(async () => {
      let o80 = n67.int32();
      return s84 && (o80 += n67.int32()), (await i88.iterator()).shuffle(e36, o80.toString());
    }, this.size);
  }
  take(e36) {
    let t67 = this, s84;
    return this.size != null && this.size > e36 ? s84 = e36 : this.size != null && this.size <= e36 ? s84 = this.size : s84 = null, c101(async () => (await t67.iterator()).take(e36), s84);
  }
  async toArray() {
    if (this.size === 1 / 0) throw new Error("Can not convert infinite data stream to array.");
    return (await this.iterator()).toArray();
  }
  async toArrayForTest() {
    if (this.size === 1 / 0) throw new Error("Can not convert infinite data stream to array.");
    return (await this.iterator()).toArrayForTest();
  }
};
d54.MAX_BUFFER_SIZE = 1e4;
function c101(r56, e36 = null) {
  return new class extends d54 {
    constructor() {
      super(...arguments), this.size = e36;
    }
    async iterator() {
      return r56();
    }
  }();
}
function Ae3(r56) {
  return c101(async () => re6(r56), r56.length);
}
function Te3(r56) {
  if (!y42(r56)) throw new Error("The argument to zip() must be an object or array.");
  let e36;
  if (Array.isArray(r56)) for (let t67 = 0; t67 < r56.length; t67++) e36 = e36 == null ? r56[t67].size : Math.min(e36, r56[t67].size);
  else if (r56 instanceof Object) for (let t67 in r56) e36 = e36 == null ? r56[t67].size : Math.min(e36, r56[t67].size);
  return c101(async () => {
    let t67 = await N57(r56, (s84) => {
      if (s84 instanceof d54) return { value: s84.iterator(), recurse: false };
      if (y42(s84)) return { value: null, recurse: true };
      throw new Error("Leaves of the structure passed to zip() must be Datasets, not primitives.");
    });
    return ye2(t67, p102.SHORTEST);
  }, e36);
}
function Se3(r56) {
  if (r56 === null) return null;
  let e36 = r56[0];
  return fe4(e36) ? { value: Fe3(r56), recurse: false } : { value: null, recurse: true };
}
function Fe3(r56) {
  if (r56.length === 0) throw new Error("Can't make a batch of zero elements.");
  return r56[0] instanceof o5 ? g21(r56) : p10(r56);
}
var R25 = class extends d54 {
  constructor(e36) {
    super(), this.input = e36;
  }
  async iterator() {
    return (await this.input.iterator()).decodeUTF8().split(`
`).map((i88) => (i88.endsWith("\r") && (i88 = i88.slice(0, -1)), i88));
  }
};
var L21 = '"';
var A34 = Symbol("out");
var xe5 = Symbol("field");
var $35 = Symbol("quote");
var ie8 = Symbol("quoteafterquote");
var be3 = Symbol("quoteinquote");
var T39 = class extends d54 {
  async columnNames() {
    return this.columnNamesValidated || await this.setColumnNames(), this.configuredColumnsOnly ? Object.keys(this.columnConfigs) : this.fullColumnNames;
  }
  async setColumnNames() {
    let e36 = await this.maybeReadHeaderLine();
    if (!this.fullColumnNames && !e36) throw new Error("Column names must be provided if there is no header line.");
    this.fullColumnNames && e36 && util_exports.assert(e36.length === this.fullColumnNames.length, () => "The length of provided columnNames (" + this.fullColumnNames.length.toString() + ") does not match the length of the header line read from file (" + e36.length.toString() + ")."), this.fullColumnNames || (this.fullColumnNames = e36);
    let t67 = this.fullColumnNames.reduce((i88, n67) => (i88[n67] = i88[n67] + 1 || 1, i88), {}), s84 = Object.keys(t67).filter((i88) => t67[i88] > 1);
    if (util_exports.assert(s84.length === 0, () => "Duplicate column names found: " + s84.toString()), this.columnConfigs) {
      for (let i88 of Object.keys(this.columnConfigs)) if (this.fullColumnNames.indexOf(i88) === -1) throw new Error('The key "' + i88 + '" provided in columnConfigs does not match any of the column names (' + this.fullColumnNames.toString() + ").");
    }
    this.columnNamesValidated = true;
  }
  async maybeReadHeaderLine() {
    if (this.hasHeader) {
      let t67 = await (await this.base.iterator()).next();
      if (t67.done) throw new Error("No data was found for CSV parsing.");
      let s84 = t67.value;
      return this.parseRow(s84, false);
    } else return null;
  }
  constructor(e36, t67) {
    super(), this.input = e36, this.hasHeader = true, this.fullColumnNames = null, this.columnNamesValidated = false, this.columnConfigs = null, this.configuredColumnsOnly = false, this.delimiter = ",", this.delimWhitespace = false, this.base = new R25(e36), t67 || (t67 = {}), this.hasHeader = t67.hasHeader !== false, this.fullColumnNames = t67.columnNames, this.columnConfigs = t67.columnConfigs, this.configuredColumnsOnly = t67.configuredColumnsOnly, t67.delimWhitespace ? (util_exports.assert(t67.delimiter == null, () => "Delimiter should not be provided when delimWhitespace is true."), this.delimWhitespace = true, this.delimiter = " ") : this.delimiter = t67.delimiter ? t67.delimiter : ",";
  }
  async iterator() {
    this.columnNamesValidated || await this.setColumnNames();
    let e36 = await this.base.iterator();
    return this.hasHeader && (e36 = e36.skip(1)), e36.map((t67) => this.makeDataElement(t67));
  }
  makeDataElement(e36) {
    let t67 = this.parseRow(e36), s84 = {}, i88 = {};
    for (let n67 = 0; n67 < this.fullColumnNames.length; n67++) {
      let o80 = this.fullColumnNames[n67], a71 = this.columnConfigs ? this.columnConfigs[o80] : null;
      if (!(this.configuredColumnsOnly && !a71)) {
        let l80 = t67[n67], f85 = null;
        if (l80 === "") if (a71 && a71.default !== void 0) f85 = a71.default;
        else {
          if (a71 && (a71.required || a71.isLabel)) throw new Error(`Required column ${o80} is empty in this line: ${e36}`);
          f85 = void 0;
        }
        else {
          let E44 = Number(l80);
          if (isNaN(E44)) a71 && a71.dtype === "bool" ? f85 = this.getBoolean(l80) : f85 = l80;
          else if (!a71 || !a71.dtype) f85 = E44;
          else switch (a71.dtype) {
            case "float32":
              f85 = E44;
              break;
            case "int32":
              f85 = Math.floor(E44);
              break;
            case "bool":
              f85 = this.getBoolean(l80);
              break;
            default:
              f85 = E44;
          }
        }
        a71 && a71.isLabel ? i88[o80] = f85 : s84[o80] = f85;
      }
    }
    return Object.keys(i88).length === 0 ? s84 : { xs: s84, ys: i88 };
  }
  getBoolean(e36) {
    return e36 === "1" || e36.toLowerCase() === "true" ? 1 : 0;
  }
  parseRow(e36, t67 = true) {
    let s84 = [], i88 = 0, n67 = e36.length, o80 = A34;
    for (let a71 = 0; a71 < n67; a71++) switch (o80) {
      case A34:
        switch (e36.charAt(a71)) {
          case L21:
            i88 = a71 + 1, o80 = $35;
            break;
          case this.delimiter:
            if (i88 = a71 + 1, this.delimiter === " " && this.delimWhitespace) break;
            s84.push(""), o80 = A34;
            break;
          default:
            o80 = xe5, i88 = a71;
            break;
        }
        break;
      case xe5:
        switch (e36.charAt(a71)) {
          case this.delimiter:
            s84.push(e36.substring(i88, a71)), o80 = A34, i88 = a71 + 1;
            break;
          default:
        }
        break;
      case $35:
        switch (e36.charAt(a71)) {
          case L21:
            o80 = ie8;
            break;
          default:
        }
        break;
      case ie8:
        switch (e36.charAt(a71)) {
          case this.delimiter:
            s84.push(e36.substring(i88, a71 - 1)), o80 = A34, i88 = a71 + 1;
            break;
          case L21:
            o80 = $35;
            break;
          default:
            o80 = be3;
            break;
        }
        break;
      case be3:
        switch (e36.charAt(a71)) {
          case L21:
            o80 = $35;
            break;
          default:
        }
        break;
      default:
    }
    if (o80 === ie8 ? s84.push(e36.substring(i88, n67 - 1)) : s84.push(e36.substring(i88)), t67 && s84.length !== this.fullColumnNames.length) throw new Error(`Invalid row in csv file. Should have ${this.fullColumnNames.length} elements in a row, but got ${s84}`);
    return s84;
  }
};
var B28 = class r53 extends u84 {
  constructor(e36) {
    super(), this.microphoneConfig = e36, this.isClosed = false, this.fftSize = e36.fftSize || 1024;
    let t67 = Math.log2(this.fftSize);
    if (this.fftSize < 0 || t67 < 4 || t67 > 14 || !Number.isInteger(t67)) throw new Error(`Invalid fftSize: it must be a power of 2 between 2 to 4 and 2 to 14, but got ${this.fftSize}`);
    if (this.numFrames = e36.numFramesPerSpectrogram || 43, this.sampleRateHz = e36.sampleRateHz, this.columnTruncateLength = e36.columnTruncateLength || this.fftSize, this.audioTrackConstraints = e36.audioTrackConstraints, this.smoothingTimeConstant = e36.smoothingTimeConstant || 0, this.includeSpectrogram = e36.includeSpectrogram !== false, this.includeWaveform = e36.includeWaveform === true, !this.includeSpectrogram && !this.includeWaveform) throw new Error("Both includeSpectrogram and includeWaveform are false. At least one type of data should be returned.");
  }
  summary() {
    return "microphone";
  }
  static async create(e36 = {}) {
    if (!l().get("IS_BROWSER")) throw new Error("microphone API is only supported in browser environment.");
    let t67 = new r53(e36);
    return await t67.start(), t67;
  }
  async start() {
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({ audio: this.audioTrackConstraints == null ? true : this.audioTrackConstraints, video: false });
    } catch (s84) {
      throw new Error(`Error thrown while initializing video stream: ${s84.message}`);
    }
    if (!this.stream) throw new Error("Could not obtain audio from microphone.");
    let e36 = globalThis.AudioContext || globalThis.webkitAudioContext;
    if (this.audioContext = new e36(), !this.sampleRateHz) this.sampleRateHz = this.audioContext.sampleRate;
    else if (this.audioContext.sampleRate !== this.sampleRateHz) throw new Error(`Mismatch in sampling rate: Expected: ${this.sampleRateHz}; Actual: ${this.audioContext.sampleRate}`);
    let t67 = this.audioContext.createMediaStreamSource(this.stream);
    this.analyser = this.audioContext.createAnalyser(), this.analyser.fftSize = this.fftSize * 2, this.analyser.smoothingTimeConstant = this.smoothingTimeConstant, t67.connect(this.analyser), this.freqData = new Float32Array(this.fftSize), this.timeData = new Float32Array(this.fftSize);
  }
  async next() {
    if (this.isClosed) return { value: null, done: true };
    let e36, t67, s84 = await this.getAudioData();
    if (this.includeSpectrogram) {
      let i88 = this.flattenQueue(s84.freqDataQueue);
      e36 = this.getTensorFromAudioDataArray(i88, [this.numFrames, this.columnTruncateLength, 1]);
    }
    if (this.includeWaveform) {
      let i88 = this.flattenQueue(s84.timeDataQueue);
      t67 = this.getTensorFromAudioDataArray(i88, [this.numFrames * this.fftSize, 1]);
    }
    return { value: { spectrogram: e36, waveform: t67 }, done: false };
  }
  async capture() {
    return (await this.next()).value;
  }
  async getAudioData() {
    let e36 = [], t67 = [], s84 = 0;
    return new Promise((i88) => {
      let n67 = setInterval(() => {
        this.includeSpectrogram && (this.analyser.getFloatFrequencyData(this.freqData), this.freqData[0] === -1 / 0 && i88({ freqDataQueue: e36, timeDataQueue: t67 }), e36.push(this.freqData.slice(0, this.columnTruncateLength))), this.includeWaveform && (this.analyser.getFloatTimeDomainData(this.timeData), t67.push(this.timeData.slice())), ++s84 === this.numFrames && (clearInterval(n67), i88({ freqDataQueue: e36, timeDataQueue: t67 }));
      }, this.fftSize / this.sampleRateHz * 1e3);
    });
  }
  stop() {
    this.isClosed || (this.isClosed = true, this.analyser.disconnect(), this.audioContext.close(), this.stream != null && this.stream.getTracks().length > 0 && this.stream.getTracks()[0].stop());
  }
  toArray() {
    throw new Error("Can not convert infinite audio stream to array.");
  }
  getSampleRate() {
    return this.sampleRateHz;
  }
  flattenQueue(e36) {
    let t67 = e36[0].length, s84 = new Float32Array(e36.length * t67);
    return e36.forEach((i88, n67) => s84.set(i88, n67 * t67)), s84;
  }
  getTensorFromAudioDataArray(e36, t67) {
    let s84 = new Float32Array(util_exports.sizeFromShape(t67));
    return s84.set(e36, s84.length - e36.length), p10(s84, t67);
  }
};
var M29 = class r54 extends u84 {
  constructor(e36, t67) {
    if (super(), this.webcamVideoElement = e36, this.webcamConfig = t67, this.isClosed = true, this.resize = false, this.needToResize()) if (this.resize = true, this.cropSize = [this.webcamConfig.resizeHeight, this.webcamConfig.resizeWidth], this.cropBoxInd = m25([0], "int32"), this.webcamConfig.centerCrop) {
      let s84 = this.webcamConfig.resizeWidth * 1 / this.webcamVideoElement.width, i88 = this.webcamConfig.resizeHeight * 1 / this.webcamVideoElement.height, n67 = (1 - s84) / 2, o80 = (1 - i88) / 2, a71 = n67 + s84, l80 = i88 + o80;
      this.cropBox = h22([o80, n67, l80, a71], [1, 4]);
    } else this.cropBox = h22([0, 0, 1, 1], [1, 4]);
  }
  summary() {
    return "webcam";
  }
  static async create(e36, t67 = {}) {
    if (!l().get("IS_BROWSER")) throw new Error("tf.data.webcam is only supported in browser environment.");
    if (!e36) {
      if (e36 = document.createElement("video"), !t67.resizeWidth || !t67.resizeHeight) throw new Error("Please provide webcam video element, or resizeWidth and resizeHeight to create a hidden video element.");
      e36.width = t67.resizeWidth, e36.height = t67.resizeHeight;
    }
    let s84 = new r54(e36, t67);
    return await s84.start(), s84;
  }
  async start() {
    this.webcamConfig.facingMode && util_exports.assert(this.webcamConfig.facingMode === "user" || this.webcamConfig.facingMode === "environment", () => `Invalid webcam facing mode: ${this.webcamConfig.facingMode}. Please provide 'user' or 'environment'`);
    try {
      this.stream = await navigator.mediaDevices.getUserMedia({ video: { deviceId: this.webcamConfig.deviceId, facingMode: this.webcamConfig.facingMode ? this.webcamConfig.facingMode : "user", width: this.webcamVideoElement.width, height: this.webcamVideoElement.height } });
    } catch (e36) {
      throw e36.message = `Error thrown while initializing video stream: ${e36.message}`, e36;
    }
    if (!this.stream) throw new Error("Could not obtain video from webcam.");
    try {
      this.webcamVideoElement.srcObject = this.stream;
    } catch (e36) {
      console.log(e36), this.webcamVideoElement.src = globalThis.URL.createObjectURL(this.stream);
    }
    return this.webcamVideoElement.play(), this.isClosed = false, new Promise((e36) => {
      this.webcamVideoElement.onloadedmetadata = () => {
        e36();
      };
    });
  }
  async next() {
    if (this.isClosed) return { value: null, done: true };
    let e36;
    try {
      e36 = browser_exports.fromPixels(this.webcamVideoElement);
    } catch (t67) {
      throw new Error(`Error thrown converting video to pixels: ${JSON.stringify(t67)}`);
    }
    if (this.resize) try {
      return { value: this.cropAndResizeFrame(e36), done: false };
    } catch (t67) {
      throw new Error(`Error thrown cropping the video: ${t67.message}`);
    } finally {
      e36.dispose();
    }
    else return { value: e36, done: false };
  }
  needToResize() {
    return !!(this.webcamConfig.resizeWidth && this.webcamConfig.resizeHeight && (this.webcamVideoElement.width !== this.webcamConfig.resizeWidth || this.webcamVideoElement.height !== this.webcamConfig.resizeHeight));
  }
  cropAndResizeFrame(e36) {
    return g4(() => {
      let t67 = D7(w12(e36, "float32"), 0), s84;
      s84 = go2.cropAndResize(t67, this.cropBox, this.cropBoxInd, this.cropSize, "bilinear");
      let i88 = s84.shape;
      return h9(s84, i88.slice(1));
    });
  }
  async capture() {
    return (await this.next()).value;
  }
  stop() {
    this.stream.getTracks().forEach((t67) => t67.stop());
    try {
      this.webcamVideoElement.srcObject = null;
    } catch (t67) {
      console.log(t67), this.webcamVideoElement.src = null;
    }
    this.isClosed = true;
  }
  toArray() {
    throw new Error("Can not convert infinite video stream to array.");
  }
};
var b57 = class {
};
var S43 = class extends u84 {
  split(e36) {
    return new ne6(this, e36);
  }
};
var ne6 = class extends S43 {
  constructor(e36, t67) {
    super(), this.upstream = e36, this.impl = new ae6(e36, t67);
  }
  summary() {
    return this.impl.summary();
  }
  async next() {
    return this.impl.next();
  }
};
var ae6 = class extends g71 {
  constructor(e36, t67) {
    super(), this.upstream = e36, this.separator = t67, this.carryover = "";
  }
  summary() {
    return `${this.upstream.summary()} -> Split('${this.separator}')`;
  }
  async pump() {
    let e36 = await this.upstream.next();
    if (e36.done) return this.carryover === "" ? false : (this.outputQueue.push(this.carryover), this.carryover = "", true);
    let t67 = e36.value.split(this.separator);
    t67[0] = this.carryover + t67[0];
    for (let s84 of t67.slice(0, -1)) this.outputQueue.push(s84);
    return this.carryover = t67[t67.length - 1], true;
  }
};
var H16 = class extends u84 {
  decodeUTF8() {
    return new oe7(this);
  }
};
var oe7 = class extends S43 {
  constructor(e36) {
    super(), this.upstream = e36, this.impl = new ue6(e36);
  }
  summary() {
    return this.impl.summary();
  }
  async next() {
    return this.impl.next();
  }
};
var ue6 = class extends g71 {
  constructor(e36) {
    if (super(), this.upstream = e36, l().get("IS_BROWSER")) this.decoder = new TextDecoder("utf-8");
    else {
      let { StringDecoder: t67 } = W14("node:string_decoder");
      this.decoder = new t67("utf8");
    }
  }
  summary() {
    return `${this.upstream.summary()} -> Utf8`;
  }
  async pump() {
    let e36 = await this.upstream.next(), t67;
    if (e36.done) return false;
    t67 = e36.value;
    let s84;
    return l().get("IS_BROWSER") ? s84 = this.decoder.decode(t67, { stream: true }) : s84 = this.decoder.write(__Buffer$3.from(t67.buffer)), this.outputQueue.push(s84), true;
  }
};
var v40 = class extends H16 {
  constructor(e36, t67 = {}) {
    super(), this.file = e36, this.options = t67, util_exports.assert(e36 instanceof Uint8Array || (l().get("IS_BROWSER") ? e36 instanceof File || e36 instanceof Blob : false), () => "FileChunkIterator only supports File, Blob and Uint8Array right now."), this.offset = t67.offset || 0, this.chunkSize = t67.chunkSize || 1024 * 1024;
  }
  summary() {
    return `FileChunks ${this.file}`;
  }
  async next() {
    return this.offset >= (this.file instanceof Uint8Array ? this.file.byteLength : this.file.size) ? { value: null, done: true } : { value: await new Promise((t67, s84) => {
      let i88 = this.offset + this.chunkSize;
      if (this.file instanceof Uint8Array) t67(new Uint8Array(this.file.slice(this.offset, i88)));
      else {
        let n67 = new FileReader();
        n67.onload = (a71) => {
          let l80 = n67.result;
          if (l80 instanceof ArrayBuffer && (l80 = new Uint8Array(l80)), !(l80 instanceof Uint8Array)) return s84(new TypeError("FileReader returned unknown type."));
          t67(l80);
        }, n67.onabort = (a71) => s84(new Error("Aborted")), n67.onerror = (a71) => s84(new Error(a71.type));
        let o80 = this.file.slice(this.offset, i88);
        n67.readAsArrayBuffer(o80);
      }
      this.offset = i88;
    }), done: false };
  }
};
async function Ce2(r56, e36 = {}, t67) {
  let s84, i88;
  typeof r56 == "string" ? s84 = r56 : (s84 = r56.url, i88 = Ve2(r56));
  let n67 = await (t67 || util_exports.fetch)(s84, i88);
  if (n67.ok) {
    let o80 = new Uint8Array(await n67.arrayBuffer());
    return new v40(o80, e36);
  } else throw new Error(n67.statusText);
}
var Ve2 = (r56) => ({ method: r56.method, headers: r56.headers, body: r56.body, mode: r56.mode, credentials: r56.credentials, cache: r56.cache, redirect: r56.redirect, referrer: r56.referrer, integrity: r56.integrity });
function P35(r56) {
  return typeof r56 == "string" && r56.slice(0, 7) === "file://";
}
var F31 = class extends b57 {
  constructor(e36, t67 = {}) {
    super(), this.input = e36, this.options = t67;
  }
  async iterator() {
    if (P35(this.input) && l().get("IS_NODE")) {
      let e36 = W14("node:fs");
      this.input = e36.readFileSync(this.input.slice(7));
    }
    return new v40(this.input, this.options);
  }
};
var I43 = class extends b57 {
  constructor(e36, t67 = {}) {
    super(), this.url = e36, this.fileOptions = t67;
  }
  async iterator() {
    return P35(this.url) ? new F31(this.url, this.fileOptions).iterator() : Ce2(this.url, this.fileOptions);
  }
};
function Ge(r56, e36 = {}) {
  return new T39(new I43(r56), e36);
}
function Ze2(r56) {
  let e36 = z31(r56);
  return c101(async () => e36);
}
function je2(r56) {
  return c101(async () => {
    let e36 = await r56();
    return z31(() => e36.next());
  });
}
async function Je2(r56, e36) {
  return M29.create(r56, e36);
}
async function Ye(r56) {
  return B28.create(r56);
}
var Xe2 = "4.22.0";

// https://esm.sh/@tensorflow/tfjs-layers@4.22.0/denonext/tfjs-layers.mjs
var Pa = Object.defineProperty;
var Pe2 = (s84, t67) => {
  for (var e36 in t67) Pa(s84, e36, { get: t67[e36], enumerable: true });
};
var At3 = class s69 extends Error {
  constructor(t67) {
    super(t67), Object.setPrototypeOf(this, s69.prototype);
  }
};
var ht6 = class s70 extends Error {
  constructor(t67) {
    super(t67), Object.setPrototypeOf(this, s70.prototype);
  }
};
var c102 = class s71 extends Error {
  constructor(t67) {
    super(t67), Object.setPrototypeOf(this, s71.prototype);
  }
};
var S44 = class s72 extends Error {
  constructor(t67) {
    super(t67), Object.setPrototypeOf(this, s72.prototype);
  }
};
var qi = class s73 extends Error {
  constructor(t67) {
    super(t67), Object.setPrototypeOf(this, s73.prototype);
  }
};
var Ni = class {
  constructor(t67) {
    this.maxEntries = t67 || 100, this.cache = /* @__PURE__ */ new Map();
  }
  get(t67) {
    let e36;
    return this.cache.has(t67) && (e36 = this.cache.get(t67), this.cache.delete(t67), this.cache.set(t67, e36)), e36;
  }
  put(t67, e36) {
    if (this.cache.has(t67)) this.cache.delete(t67);
    else if (this.cache.size >= this.maxEntries) {
      let i88 = this.cache.keys().next().value;
      this.cache.delete(i88);
    }
    this.cache.set(t67, e36);
  }
  getMaxEntries() {
    return this.maxEntries;
  }
  setMaxEntries(t67) {
    if (t67 < 0) throw new Error(`The maxEntries of LRU caches must be at least 0, but got ${t67}.`);
    if (this.maxEntries > t67) for (let e36 = 0; e36 < this.maxEntries - t67; e36++) {
      let i88 = this.cache.keys().next().value;
      this.cache.delete(i88);
    }
    this.maxEntries = t67;
  }
};
function zt3(s84, t67) {
  if (Array.isArray(s84)) {
    let e36 = [];
    for (let i88 = 0; i88 < t67; i88++) e36 = e36.concat(s84);
    return e36;
  } else {
    let e36 = new Array(t67);
    return e36.fill(s84), e36;
  }
}
function It2(s84, t67) {
  if (!s84) throw new qi(t67);
}
function fr(s84, t67) {
  let e36 = 0;
  for (let i88 of s84) i88 === t67 && e36++;
  return e36;
}
function st6(s84) {
  return s84.length === 1 ? s84[0] : s84;
}
function $36(s84) {
  return Array.isArray(s84) ? s84 : [s84];
}
function Ct2(s84) {
  let e36 = s84.replace(/(.)([A-Z][a-z0-9]+)/g, "$1_$2").replace(/([a-z])([A-Z])/g, "$1_$2").toLowerCase();
  return e36[0] !== "_" ? e36 : "private" + e36;
}
function qt3(s84) {
  return s84.length <= 1 || s84.indexOf("_") === -1 ? s84 : s84.replace(/[_]+(\w|$)/g, (t67, e36) => e36.toUpperCase());
}
var Nt4 = {};
function Ke(s84) {
  if (s84 == null) return null;
  let t67 = {};
  return t67.className = s84.getClassName(), t67.config = s84.getConfig(), t67;
}
function pr(s84) {
  if (!(s84 == null || typeof s84 != "object")) if (Array.isArray(s84)) s84.forEach((t67) => pr(t67));
  else {
    let t67 = Object.keys(s84);
    for (let e36 of t67) {
      let i88 = s84[e36];
      i88 != null && typeof i88 == "object" && (!Array.isArray(i88) && i88.type === "ndarray" && typeof i88.value == "number" ? s84[e36] = i88.value : pr(i88));
    }
  }
}
function Bt3(s84, t67 = {}, e36 = {}, i88 = "object", n67 = false) {
  if (typeof s84 == "string") {
    let r56 = s84, o80;
    if (r56 in e36) o80 = e36[r56];
    else if (r56 in Nt4) o80 = Nt4[r56];
    else if (o80 = t67[r56], o80 == null) throw new c102(`Unknown ${i88}: ${s84}. This may be due to one of the following reasons:
1. The ${i88} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${i88} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
    return o80;
  } else {
    let r56 = s84;
    if (r56.className == null || r56.config == null) throw new c102(`${i88}: Improper config format: ${JSON.stringify(r56)}.
'className' and 'config' must set.`);
    let o80 = r56.className, a71, l80;
    if (o80 in e36 ? [a71, l80] = e36[o80] : o80 in Nt4 ? [a71, l80] = Nt4.className : o80 in t67 && ([a71, l80] = t67[o80]), a71 == null) throw new c102(`Unknown ${i88}: ${o80}. This may be due to one of the following reasons:
1. The ${i88} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.
2. The custom ${i88} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);
    if (l80 != null) {
      let u86 = {};
      for (let w45 of Object.keys(Nt4)) u86[w45] = Nt4[w45];
      for (let w45 of Object.keys(e36)) u86[w45] = e36[w45];
      let h74 = r56.config;
      h74.customObjects = u86;
      let p103 = Object.assign({}, Nt4);
      for (let w45 of Object.keys(e36)) Nt4[w45] = e36[w45];
      pr(r56.config);
      let f85 = l80(a71, r56.config, e36, n67);
      return Nt4 = Object.assign({}, p103), f85;
    } else {
      let u86 = Object.assign({}, Nt4);
      for (let p103 of Object.keys(e36)) Nt4[p103] = e36[p103];
      let h74 = new a71(r56.config);
      return Nt4 = Object.assign({}, u86), h74;
    }
  }
}
function Ka(s84, t67) {
  return s84 < t67 ? -1 : s84 > t67 ? 1 : 0;
}
function zi(s84, t67) {
  return -1 * Ka(s84, t67);
}
function St3(s84) {
  if (s84 == null) return s84;
  let t67 = [];
  for (let e36 of s84) t67.indexOf(e36) === -1 && t67.push(e36);
  return t67;
}
function Jr(s84) {
  if (s84 == null) throw new c102(`Invalid value in obj: ${JSON.stringify(s84)}`);
  for (let t67 in s84) if (s84.hasOwnProperty(t67)) return false;
  return true;
}
function Wt3(s84, t67, e36) {
  if (e36 != null && s84.indexOf(e36) < 0) throw new c102(`${e36} is not a valid ${t67}.  Valid values are ${s84} or null/undefined.`);
}
function Ji(s84, t67, e36 = 0, i88 = 1 / 0) {
  return It2(e36 >= 0), It2(i88 >= e36), Array.isArray(s84) && s84.length >= e36 && s84.length <= i88 && s84.every((n67) => typeof n67 === t67);
}
function Y13(s84, t67) {
  Array.isArray(s84) ? (util_exports.assert(s84.length > 0, () => `${t67} is unexpectedly an empty array.`), s84.forEach((e36, i88) => Y13(e36, `element ${i88 + 1} of ${t67}`))) : util_exports.assert(Number.isInteger(s84) && s84 > 0, () => `Expected ${t67} to be a positive integer, but got ${Zr(s84)}.`);
}
function Zr(s84) {
  return s84 === null ? "null" : Array.isArray(s84) ? "[" + s84.map((t67) => Zr(t67)).join(",") + "]" : typeof s84 == "string" ? `"${s84}"` : `${s84}`;
}
function Gr(s84, t67, e36) {
  let i88 = e36 != null ? e36() : util_exports.now(), n67;
  return (...o80) => {
    let a71 = e36 != null ? e36() : util_exports.now();
    return a71 - i88 < t67 || (i88 = a71, n67 = s84(...o80)), n67;
  };
}
function Zi(s84) {
  return s84 === "relu" ? "relu" : s84 === "linear" ? "linear" : s84 === "elu" ? "elu" : null;
}
var ja = 0;
function Yi() {
  return ja++;
}
var Gi = {};
function ae7(s84 = "") {
  return s84 in Gi || (Gi[s84] = 0), Gi[s84] += 1, s84 + Gi[s84].toString();
}
var Yr = ["channelsFirst", "channelsLast"];
var Xr = ["nearest", "bilinear"];
var Qr = ["valid", "same", "causal"];
var to2 = ["max", "avg"];
var eo2 = ["sum", "mul", "concat", "ave"];
var je3 = /* @__PURE__ */ new Map();
function J16(s84) {
  Wt3(Yr, "DataFormat", s84);
}
function io2(s84) {
  Wt3(Xr, "InterpolationFormat", s84);
}
function pt2(s84) {
  Wt3(Qr, "PaddingMode", s84);
}
function dr(s84) {
  Wt3(to2, "PoolMode", s84);
}
var Ci = [];
var so2 = "/";
function Ot4(s84, t67) {
  Ci.push(s84);
  try {
    let e36 = t67();
    return Ci.pop(), e36;
  } catch (e36) {
    throw Ci.pop(), e36;
  }
}
function qa() {
  return Ci.length === 0 ? "" : Ci.join(so2) + so2;
}
function Xi(s84) {
  if (!no2(s84)) throw new Error("Not a valid tensor name: '" + s84 + "'");
  return qa() + s84;
}
function Qi(s84) {
  if (!no2(s84)) throw new Error("Not a valid tensor name: '" + s84 + "'");
  je3.has(s84) || je3.set(s84, 0);
  let t67 = je3.get(s84);
  if (je3.set(s84, je3.get(s84) + 1), t67 > 0) {
    let e36 = `${s84}_${t67}`;
    return je3.set(e36, 1), e36;
  } else return s84;
}
var Ha = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);
function no2(s84) {
  return !!s84.match(Ha);
}
function ro3(s84) {
  return s84 === parseInt(s84.toString(), 10);
}
function vt3(s84, t67, e36) {
  t67 == null && (t67 = 0), e36 == null && (e36 = s84.length);
  let i88 = 1;
  for (let n67 = t67; n67 < e36; ++n67) i88 *= s84[n67];
  return i88;
}
function we3(s84) {
  if (s84.length === 0) return Number.NaN;
  let t67 = Number.POSITIVE_INFINITY;
  for (let e36 = 0; e36 < s84.length; e36++) {
    let i88 = s84[e36];
    i88 < t67 && (t67 = i88);
  }
  return t67;
}
function _t4(s84) {
  if (s84.length === 0) return Number.NaN;
  let t67 = Number.NEGATIVE_INFINITY;
  for (let e36 = 0; e36 < s84.length; e36++) {
    let i88 = s84[e36];
    i88 > t67 && (t67 = i88);
  }
  return t67;
}
function ft5(s84, t67) {
  if (t67 < s84) throw new c102(`end (${t67}) < begin (${s84}) is forbidden.`);
  let e36 = [];
  for (let i88 = s84; i88 < t67; ++i88) e36.push(i88);
  return e36;
}
var mr;
function Q12() {
  return mr == null && (mr = v4().epsilon()), mr;
}
function dt4() {
  return "channelsLast";
}
function at6(s84, t67) {
  return w12(s84, t67);
}
function Zt3(s84, t67 = -1) {
  let e36 = s84.shape.slice();
  return t67 < 0 && (t67 = e36.length + t67 + 1), e36.splice(t67, 0, 1), h9(s84, e36);
}
function oo2(s84, t67) {
  return g4(() => {
    if (s84.shape.length !== 2) throw new c102(`repeat() expects a rank-2 tensor, but received a rank-${s84.shape.length} tensor.`);
    let e36 = Zt3(s84, 1);
    return en(e36, [1, t67, 1]);
  });
}
function ao2(s84) {
  let t67 = [vt3(s84.shape)];
  return h9(s84, t67);
}
function lo3(s84) {
  if (s84.rank <= 1) throw new c102(`batchFlatten requires a minimum rank of 2. Got rank: ${s84.rank}.`);
  let t67 = [s84.shape[0], vt3(s84.shape, 1)];
  return h9(s84, t67);
}
function Ht3(s84, t67, e36) {
  return g4(() => {
    switch (s84.rank) {
      case 1:
        return f27(s84, t67, e36);
      case 2:
        return f28(s84, [t67, 0], [e36, s84.shape[1]]);
      case 3:
        return f29(s84, [t67, 0, 0], [e36, s84.shape[1], s84.shape[2]]);
      case 4:
        return f30(s84, [t67, 0, 0, 0], [e36, s84.shape[1], s84.shape[2], s84.shape[3]]);
      case 5:
        return E10(s84, [t67, 0, 0, 0, 0], [e36, s84.shape[1], s84.shape[2], s84.shape[3], s84.shape[4]]);
      case 6:
        return E10(s84, [t67, 0, 0, 0, 0, 0], [e36, s84.shape[1], s84.shape[2], s84.shape[3], s84.shape[4], s84.shape[5]]);
      default:
        throw new c102(`sliceAlongFirstAxis() received an unsupported tensor rank: ${s84.rank}`);
    }
  });
}
function gr(s84, t67, e36) {
  return g4(() => {
    switch (s84.rank) {
      case 1:
        return f27(s84, t67, e36);
      case 2:
        return f28(s84, [0, t67], [s84.shape[0], e36]);
      case 3:
        return f29(s84, [0, 0, t67], [s84.shape[0], s84.shape[1], e36]);
      case 4:
        return f30(s84, [0, 0, 0, t67], [s84.shape[0], s84.shape[1], s84.shape[2], e36]);
      default:
        throw new c102(`sliceAlongLastAxis() received an unsupported tensor rank: ${s84.rank}`);
    }
  });
}
function Si(s84, t67, e36, i88) {
  return g4(() => {
    switch (s84.rank) {
      case 1:
        return f27(s84, t67, e36);
      case 2:
        switch (i88) {
          case 1:
            return Ht3(s84, t67, e36);
          case 2:
            return gr(s84, t67, e36);
          default:
            throw new c102(`The axis is not within the rank of the tensor ${i88}`);
        }
      case 3:
        switch (i88) {
          case 1:
            return Ht3(s84, t67, e36);
          case 2:
            return f29(s84, [0, t67, 0], [s84.shape[0], e36, s84.shape[2]]);
          case 3:
            return gr(s84, t67, e36);
          default:
            throw new c102(`The axis is not within the rank of the tensor ${i88}`);
        }
      case 4:
        switch (i88) {
          case 1:
            return Ht3(s84, t67, e36);
          case 2:
            return f30(s84, [0, t67, 0, 0], [s84.shape[0], e36, s84.shape[2], s84.shape[3]]);
          case 3:
            return f30(s84, [0, 0, t67, 0], [s84.shape[0], s84.shape[1], e36, s84.shape[3]]);
          case 4:
            return gr(s84, t67, e36);
          default:
            throw new c102(`The axis is not within the rank of the tensor ${i88}`);
        }
      default:
        throw new c102(`sliceAlongLastAxis() received an unsupported tensor rank: ${s84.rank}`);
    }
  });
}
function qe(s84, t67 = -1) {
  let e36;
  return t67 < 0 && (e36 = s84[0].rank, e36 !== 0 ? t67 = e36 : t67 = 0), t67 === s84[0].rank && (t67 = -1), E9(s84, t67);
}
function br(s84, t67) {
  switch (s84.rank) {
    case 1:
      return p19([s84, t67]);
    case 2:
      return a9([s84, t67], 0);
    case 3:
      return a10([s84, t67], 0);
    case 4:
      return a11([s84, t67], 0);
    default:
      throw new c102(`concatAlongFirstAxis() received an unsupported tensor rank: ${s84.rank}`);
  }
}
function en(s84, t67) {
  if (Array.isArray(t67) || (t67 = [t67]), s84.rank !== t67.length) throw new c102(`The length of input n (${t67.length}) does not match the number of dimensions in input x (${s84.rank})`);
  return g12(s84, t67);
}
function He2(s84, t67 = 0, e36 = 1, i88, n67) {
  return w17(s84, t67, e36, i88, n67);
}
function Lt3(s84, t67, e36, i88) {
  if (s84.rank < 2 || t67.rank < 2) throw new S44(`dot requires both inputs to be rank >= 2 but got x shape = ${s84.shape} and y shape = ${t67.shape}`);
  if (t67.rank >= 3) {
    let n67 = s84.shape.slice(-1)[0], r56 = t67.shape.slice(-2)[0];
    if (n67 !== r56) throw new S44(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${s84.shape} and  y shape = ${t67.shape}`);
  }
  if (s84.rank === 2 && t67.rank === 2) return fused_ops_exports.matMul({ a: s84, b: t67, transposeA: false, transposeB: false, bias: i88 ? yr(s84.rank, i88, dt4()) : null, activation: e36 });
  {
    let n67 = s84.shape.slice(), r56 = n67.pop();
    s84 = h9(s84, [-1, r56]);
    let o80 = t67.shape.slice(), a71 = o80.pop(), l80 = o80.pop(), u86 = [...o80, a71], h74 = Array.from({ length: t67.rank }, (b58, m96) => m96 === 0 ? t67.rank - 2 : m96 <= t67.rank - 2 ? m96 - 1 : m96);
    t67 = h9(A10(t67, h74), [l80, -1]);
    let p103 = [...n67, ...u86];
    return h9(fused_ops_exports.matMul({ a: s84, b: t67, transposeA: false, transposeB: false, bias: i88 ? yr(s84.rank, i88, dt4()) : null, activation: e36 }), p103);
  }
}
function sn2(s84, t67, e36) {
  return g4(() => (Array.isArray(t67) ? t67 = m25(t67, "int32") : t67 = w12(t67, "int32"), E15(s84, t67, e36)));
}
function xe6(s84) {
  return y8(s84, s84);
}
function yr(s84, t67, e36) {
  let i88 = t67.shape;
  if (t67.rank !== 1 && t67.rank !== s84) throw new c102(`Unexpected bias dimensions: ${t67.rank}; expected it to be 1 or ${s84}`);
  if (s84 === 5) {
    if (e36 === "channelsFirst") return i88.length === 1 ? h9(t67, [1, i88[0], 1, 1, 1]) : h9(t67, [1, i88[3], i88[0], i88[1], i88[2]]);
    if (e36 === "channelsLast") return i88.length === 1 ? h9(t67, [1, 1, 1, 1, i88[0]]) : h9(t67, [1].concat(i88));
  } else if (s84 === 4) {
    if (e36 === "channelsFirst") return i88.length === 1 ? h9(t67, [1, i88[0], 1, 1]) : h9(t67, [1, i88[2], i88[0], i88[1]]);
    if (e36 === "channelsLast") return i88.length === 1 ? h9(t67, [1, 1, 1, i88[0]]) : h9(t67, [1].concat(i88));
  } else if (s84 === 3) {
    if (e36 === "channelsFirst") return i88.length === 1 ? h9(t67, [1, i88[0], 1]) : h9(t67, [1, i88[1], i88[0]]);
    if (e36 === "channelsLast") return i88.length === 1 ? h9(t67, [1, 1, i88[0]]) : h9(t67, [1].concat(i88));
  } else if (s84 < 3) return t67;
  throw new c102(`Unsupported input rank by biasAdd: ${t67.rank}`);
}
function mt5(s84, t67, e36) {
  return g4(() => (e36 == null && (e36 = dt4()), J16(e36), T7(s84, yr(s84.rank, t67, e36))));
}
function uo2(s84, t67 = 1) {
  if (t67 !== 1) throw new S44(`Support for alpha values other than 1 (${t67}) is not implemented yet.`);
  return s12(s84);
}
function co2(s84) {
  return g4(() => D6(s84, T7(b9(s84), 1)));
}
function nn2(s84, t67, e36, i88) {
  return g4(() => _10(s84, t67, e36, i88));
}
function ho2(s84) {
  return g4(() => {
    let t67 = T7(0.5, y8(0.2, s84));
    return x18(t67, 0, 1);
  });
}
function le6(s84, t67, e36 = false) {
  return e36 ? s84() : t67();
}
var po2 = ["fanIn", "fanOut", "fanAvg"];
var fo3 = ["normal", "uniform", "truncatedNormal"];
function tl(s84) {
  Wt3(po2, "FanMode", s84);
}
function el(s84) {
  Wt3(fo3, "Distribution", s84);
}
var gt3 = class extends serialization_exports.Serializable {
  fromConfigUsesCustomObjects() {
    return false;
  }
  getConfig() {
    return {};
  }
};
var Je3 = class extends gt3 {
  apply(t67, e36) {
    return e13(t67, e36);
  }
};
Je3.className = "Zeros";
serialization_exports.registerClass(Je3);
var ue7 = class extends gt3 {
  apply(t67, e36) {
    return c26(t67, e36);
  }
};
ue7.className = "Ones";
serialization_exports.registerClass(ue7);
var Ze3 = class extends gt3 {
  constructor(t67) {
    if (super(), typeof t67 != "object") throw new c102(`Expected argument of type ConstantConfig but got ${t67}`);
    if (t67.value === void 0) throw new c102(`config must have value set but got ${t67}`);
    this.value = t67.value;
  }
  apply(t67, e36) {
    return g4(() => y8(m21(this.value), c26(t67, e36)));
  }
  getConfig() {
    return { value: this.value };
  }
};
Ze3.className = "Constant";
serialization_exports.registerClass(Ze3);
var Ge2 = class extends gt3 {
  constructor(t67) {
    super(), this.DEFAULT_MINVAL = -0.05, this.DEFAULT_MAXVAL = 0.05, this.minval = t67.minval || this.DEFAULT_MINVAL, this.maxval = t67.maxval || this.DEFAULT_MAXVAL, this.seed = t67.seed;
  }
  apply(t67, e36) {
    return U6(t67, this.minval, this.maxval, e36, this.seed);
  }
  getConfig() {
    return { minval: this.minval, maxval: this.maxval, seed: this.seed };
  }
};
Ge2.className = "RandomUniform";
serialization_exports.registerClass(Ge2);
var Ye2 = class extends gt3 {
  constructor(t67) {
    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = 0.05, this.mean = t67.mean || this.DEFAULT_MEAN, this.stddev = t67.stddev || this.DEFAULT_STDDEV, this.seed = t67.seed;
  }
  apply(t67, e36) {
    if (e36 = e36 || "float32", e36 !== "float32" && e36 !== "int32") throw new S44(`randomNormal does not support dType ${e36}.`);
    return He2(t67, this.mean, this.stddev, e36, this.seed);
  }
  getConfig() {
    return { mean: this.mean, stddev: this.stddev, seed: this.seed };
  }
};
Ye2.className = "RandomNormal";
serialization_exports.registerClass(Ye2);
var Xe3 = class extends gt3 {
  constructor(t67) {
    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = 0.05, this.mean = t67.mean || this.DEFAULT_MEAN, this.stddev = t67.stddev || this.DEFAULT_STDDEV, this.seed = t67.seed;
  }
  apply(t67, e36) {
    if (e36 = e36 || "float32", e36 !== "float32" && e36 !== "int32") throw new S44(`truncatedNormal does not support dType ${e36}.`);
    return v18(t67, this.mean, this.stddev, e36, this.seed);
  }
  getConfig() {
    return { mean: this.mean, stddev: this.stddev, seed: this.seed };
  }
};
Xe3.className = "TruncatedNormal";
serialization_exports.registerClass(Xe3);
var Qe = class extends gt3 {
  constructor(t67) {
    super(), this.gain = t67.gain != null ? t67.gain : 1;
  }
  apply(t67, e36) {
    return g4(() => {
      if (t67.length !== 2 || t67[0] !== t67[1]) throw new c102("Identity matrix initializer can only be used for 2D square matrices.");
      return y8(this.gain, $9(t67[0]));
    });
  }
  getConfig() {
    return { gain: this.gain };
  }
};
Qe.className = "Identity";
serialization_exports.registerClass(Qe);
function sl(s84, t67 = "channelsLast") {
  let e36, i88;
  if (J16(t67), s84.length === 2) e36 = s84[0], i88 = s84[1];
  else if ([3, 4, 5].indexOf(s84.length) !== -1) {
    if (t67 === "channelsFirst") {
      let n67 = vt3(s84, 2);
      e36 = s84[1] * n67, i88 = s84[0] * n67;
    } else if (t67 === "channelsLast") {
      let n67 = vt3(s84, 0, s84.length - 2);
      e36 = s84[s84.length - 2] * n67, i88 = s84[s84.length - 1] * n67;
    }
  } else {
    let n67 = vt3(s84);
    e36 = Math.sqrt(n67), i88 = Math.sqrt(n67);
  }
  return [e36, i88];
}
var rt7 = class extends gt3 {
  constructor(t67) {
    if (super(), t67.scale < 0) throw new c102(`scale must be a positive float. Got: ${t67.scale}`);
    this.scale = t67.scale == null ? 1 : t67.scale, this.mode = t67.mode == null ? "fanIn" : t67.mode, tl(this.mode), this.distribution = t67.distribution == null ? "normal" : t67.distribution, el(this.distribution), this.seed = t67.seed;
  }
  apply(t67, e36) {
    let i88 = sl(t67), n67 = i88[0], r56 = i88[1], o80 = this.scale;
    if (this.mode === "fanIn" ? o80 /= Math.max(1, n67) : this.mode === "fanOut" ? o80 /= Math.max(1, r56) : o80 /= Math.max(1, (n67 + r56) / 2), this.distribution === "normal") {
      let a71 = Math.sqrt(o80);
      if (e36 = e36 || "float32", e36 !== "float32" && e36 !== "int32") throw new S44(`${this.getClassName()} does not support dType ${e36}.`);
      return v18(t67, 0, a71, e36, this.seed);
    } else {
      let a71 = Math.sqrt(3 * o80);
      return U6(t67, -a71, a71, e36, this.seed);
    }
  }
  getConfig() {
    return { scale: this.scale, mode: this.mode, distribution: this.distribution, seed: this.seed };
  }
};
rt7.className = "VarianceScaling";
serialization_exports.registerClass(rt7);
var Ae4 = class extends rt7 {
  constructor(t67) {
    super({ scale: 1, mode: "fanAvg", distribution: "uniform", seed: t67 == null ? null : t67.seed });
  }
  getClassName() {
    return rt7.className;
  }
};
Ae4.className = "GlorotUniform";
serialization_exports.registerClass(Ae4);
var Ie2 = class extends rt7 {
  constructor(t67) {
    super({ scale: 1, mode: "fanAvg", distribution: "normal", seed: t67 == null ? null : t67.seed });
  }
  getClassName() {
    return rt7.className;
  }
};
Ie2.className = "GlorotNormal";
serialization_exports.registerClass(Ie2);
var ke2 = class extends rt7 {
  constructor(t67) {
    super({ scale: 2, mode: "fanIn", distribution: "normal", seed: t67 == null ? null : t67.seed });
  }
  getClassName() {
    return rt7.className;
  }
};
ke2.className = "HeNormal";
serialization_exports.registerClass(ke2);
var Ne2 = class extends rt7 {
  constructor(t67) {
    super({ scale: 2, mode: "fanIn", distribution: "uniform", seed: t67 == null ? null : t67.seed });
  }
  getClassName() {
    return rt7.className;
  }
};
Ne2.className = "HeUniform";
serialization_exports.registerClass(Ne2);
var ze3 = class extends rt7 {
  constructor(t67) {
    super({ scale: 1, mode: "fanIn", distribution: "normal", seed: t67 == null ? null : t67.seed });
  }
  getClassName() {
    return rt7.className;
  }
};
ze3.className = "LeCunNormal";
serialization_exports.registerClass(ze3);
var Ce3 = class extends rt7 {
  constructor(t67) {
    super({ scale: 1, mode: "fanIn", distribution: "uniform", seed: t67 == null ? null : t67.seed });
  }
  getClassName() {
    return rt7.className;
  }
};
Ce3.className = "LeCunUniform";
serialization_exports.registerClass(Ce3);
var ts2 = class extends gt3 {
  constructor(t67) {
    super(), this.DEFAULT_GAIN = 1, this.ELEMENTS_WARN_SLOW = 2e3, this.gain = t67.gain == null ? this.DEFAULT_GAIN : t67.gain, this.seed = t67.seed;
  }
  apply(t67, e36) {
    return g4(() => {
      if (t67.length < 2) throw new S44("Shape must be at least 2D.");
      if (e36 !== "int32" && e36 !== "float32" && e36 !== void 0) throw new TypeError(`Unsupported data type ${e36}.`);
      e36 = e36;
      let i88 = util_exports.sizeFromShape(t67.slice(0, -1)), n67 = t67[t67.length - 1], r56 = i88 * n67;
      r56 > this.ELEMENTS_WARN_SLOW && console.warn(`Orthogonal initializer is being called on a matrix with more than ${this.ELEMENTS_WARN_SLOW} (${r56}) elements: Slowness may result.`);
      let o80 = [Math.max(n67, i88), Math.min(n67, i88)], a71 = He2(o80, 0, 1, e36, this.seed), l80 = bo2.qr(a71, false), u86 = l80[0], p103 = l80[1].flatten().stridedSlice([0], [Math.min(n67, i88) * Math.min(n67, i88)], [Math.min(n67, i88) + 1]);
      return u86 = y8(u86, p103.sign()), i88 < n67 && (u86 = u86.transpose()), y8(m21(this.gain), u86.reshape(t67));
    });
  }
  getConfig() {
    return { gain: this.gain, seed: this.seed };
  }
};
ts2.className = "Orthogonal";
serialization_exports.registerClass(ts2);
var mo2 = { constant: "Constant", glorotNormal: "GlorotNormal", glorotUniform: "GlorotUniform", heNormal: "HeNormal", heUniform: "HeUniform", identity: "Identity", leCunNormal: "LeCunNormal", leCunUniform: "LeCunUniform", ones: "Ones", orthogonal: "Orthogonal", randomNormal: "RandomNormal", randomUniform: "RandomUniform", truncatedNormal: "TruncatedNormal", varianceScaling: "VarianceScaling", zeros: "Zeros" };
function go4(s84, t67 = {}) {
  return Bt3(s84, serialization_exports.SerializationMap.getMap().classNameMap, t67, "initializer");
}
function H17(s84) {
  return Ke(s84);
}
function U23(s84) {
  if (typeof s84 == "string") {
    let t67 = s84 in mo2 ? mo2[s84] : s84;
    if (t67 === "GlorotNormal") return new Ie2();
    if (t67 === "GlorotUniform") return new Ae4();
    if (t67 === "HeNormal") return new ke2();
    if (t67 === "HeUniform") return new Ne2();
    if (t67 === "LeCunNormal") return new ze3();
    if (t67 === "LeCunUniform") return new Ce3();
    {
      let e36 = {};
      return e36.className = t67, e36.config = {}, go4(e36);
    }
  } else return s84 instanceof gt3 ? s84 : go4(s84);
}
function on2(s84) {
  return Array.isArray(s84) && Array.isArray(s84[0]);
}
function es2(s84) {
  return s84.length === 0 ? [] : Array.isArray(s84[0]) ? s84 : [s84];
}
function C27(s84) {
  let t67;
  if (Array.isArray(s84)) {
    if (s84.length !== 1) throw new c102(`Expected Tensor length to be 1; got ${s84.length}`);
    t67 = s84[0];
  } else t67 = s84;
  return t67;
}
function E43(s84) {
  if (Array.isArray(s84) && Array.isArray(s84[0])) {
    if (s84.length === 1) return s84 = s84, s84[0];
    throw new c102(`Expected exactly 1 Shape; got ${s84.length}`);
  } else return s84;
}
function ss2(s84) {
  let t67 = 0;
  for (let e36 of s84) e36.shape.length === 0 ? t67 += 1 : t67 += e36.shape.reduce((i88, n67) => i88 * n67);
  return t67;
}
var Io2 = "Variable";
var vi = class {
  constructor(t67, e36 = "float32", i88 = Io2, n67 = true, r56 = null) {
    this.dtype = e36 ?? "float32", this.shape = t67.shape, this.id = Yi(), i88 = i88 ?? Io2, this.originalName = Xi(i88), this.name = Qi(this.originalName), this.trainable_ = n67, this.constraint = r56, this.val = m27(t67, this.trainable_, this.name, this.dtype);
  }
  read() {
    return this.assertNotDisposed(), this.val;
  }
  write(t67) {
    return this.assertNotDisposed(), nl(this.val, t67), this.val.id !== t67.id && (this.val.assign(t67), this.constraint != null && this.val.assign(this.constraint.apply(this.val))), this;
  }
  dispose() {
    this.assertNotDisposed(), this.val.dispose();
  }
  assertNotDisposed() {
    if (this.val.isDisposed) throw new Error(`LayersVariable ${this.name} is already disposed.`);
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(t67) {
    this.trainable_ = t67, this.val.trainable = t67;
  }
};
function nl(s84, t67) {
  if (s84.shape.toString() !== t67.shape.toString()) throw new Error("Shape mismatch: " + JSON.stringify(s84.shape) + " vs. " + JSON.stringify(t67.shape));
}
function Li(s84) {
  return s84.map((t67) => t67.read());
}
function is2(s84) {
  s84.forEach((t67) => {
    t67[0].write(t67[1]);
  });
}
var K20 = class {
  constructor(t67) {
    this.dtype = t67.dtype, this.shape = t67.shape, t67.shape != null ? this.ndim = t67.shape.length : this.ndim = t67.ndim, this.maxNDim = t67.maxNDim, this.minNDim = t67.minNDim, this.axes = t67.axes || {};
  }
};
var ut3 = class {
  constructor(t67, e36, i88, n67, r56, o80, a71) {
    this.dtype = t67, this.shape = e36, this.sourceLayer = i88, this.inputs = n67, this.callArgs = r56, this.outputTensorIndex = a71, this.id = Yi(), o80 != null && (this.originalName = Xi(o80), this.name = Qi(this.originalName)), this.rank = e36.length;
  }
};
var ll = 0;
var Gt3 = class {
  constructor(t67, e36) {
    this.callArgs = e36, this.id = ll++, this.outboundLayer = t67.outboundLayer, this.inboundLayers = t67.inboundLayers, this.nodeIndices = t67.nodeIndices, this.tensorIndices = t67.tensorIndices, this.inputTensors = t67.inputTensors, this.outputTensors = t67.outputTensors, this.inputMasks = t67.inputMasks, this.outputMasks = t67.outputMasks, this.inputShapes = t67.inputShapes, this.outputShapes = t67.outputShapes;
    for (let i88 of t67.inboundLayers) i88?.outboundNodes.push(this);
    t67.outboundLayer.inboundNodes.push(this);
  }
  getConfig() {
    let t67 = [];
    for (let e36 of this.inboundLayers) e36 != null ? t67.push(e36.name) : t67.push(null);
    return { outboundLayer: this.outboundLayer ? this.outboundLayer.name : null, inboundLayers: t67, nodeIndices: this.nodeIndices, tensorIndices: this.tensorIndices };
  }
};
var ul = 0;
var v41 = class extends serialization_exports.Serializable {
  constructor(t67 = {}) {
    super(), this._callHook = null, this._addedWeightNames = [], this._stateful = false, this.id = ul++, this.activityRegularizer = null, this.inputSpec = null, this.supportsMasking = false, this._trainableWeights = [], this._nonTrainableWeights = [], this._losses = [], this._updates = [], this._built = false, this.inboundNodes = [], this.outboundNodes = [];
    let e36 = t67.name;
    if (!e36) {
      let i88 = this.getClassName();
      e36 = Ct2(i88) + "_" + ae7(i88);
    }
    if (this.name = e36, this.trainable_ = t67.trainable == null ? true : t67.trainable, t67.inputShape != null || t67.batchInputShape != null) {
      let i88;
      if (t67.batchInputShape != null) i88 = t67.batchInputShape;
      else if (t67.inputShape != null) {
        let r56 = null;
        t67.batchSize != null && (r56 = t67.batchSize), i88 = [r56].concat(t67.inputShape);
      }
      this.batchInputShape = i88;
      let n67 = t67.dtype;
      n67 == null && (n67 = t67.inputDType), n67 == null && (n67 = "float32"), this.dtype = n67;
    }
    t67.weights != null ? this.initialWeights = t67.weights : this.initialWeights = null, this._refCount = null, this.fastWeightInitDuringBuild = false;
  }
  static nodeKey(t67, e36) {
    return t67.name + "_ib-" + e36.toString();
  }
  getNodeAtIndex(t67, e36) {
    if (this.inboundNodes.length === 0) throw new ht6(`The layer has never been called and thus has no defined ${e36}.`);
    if (this.inboundNodes.length <= t67) throw new c102(`Asked to get ${e36} at node ${t67}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);
    return this.inboundNodes[t67];
  }
  getInputAt(t67) {
    return st6(this.getNodeAtIndex(t67, "input").inputTensors);
  }
  getOutputAt(t67) {
    return st6(this.getNodeAtIndex(t67, "output").outputTensors);
  }
  get input() {
    if (this.inboundNodes.length > 1) throw new At3(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);
    if (this.inboundNodes.length === 0) throw new At3(`Layer ${this.name} is not connected, no input to return.`);
    return st6(this.getNodeAtIndex(0, "input").inputTensors);
  }
  get output() {
    if (this.inboundNodes.length === 0) throw new At3(`Layer ${this.name} has no inbound nodes.`);
    if (this.inboundNodes.length > 1) throw new At3(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);
    return st6(this.getNodeAtIndex(0, "output").outputTensors);
  }
  get losses() {
    return this._losses;
  }
  calculateLosses() {
    return this.losses.map((t67) => t67());
  }
  get updates() {
    return this._updates;
  }
  get built() {
    return this._built;
  }
  set built(t67) {
    this._built = t67;
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(t67) {
    this._trainableWeights.forEach((e36) => e36.trainable = t67), this.trainable_ = t67;
  }
  get trainableWeights() {
    return this.trainable_ ? this._trainableWeights.filter((t67) => t67.trainable) : [];
  }
  set trainableWeights(t67) {
    this._trainableWeights = t67;
  }
  get nonTrainableWeights() {
    return this.trainable ? this._trainableWeights.filter((t67) => !t67.trainable).concat(this._nonTrainableWeights) : this._trainableWeights.concat(this._nonTrainableWeights);
  }
  set nonTrainableWeights(t67) {
    this._nonTrainableWeights = t67;
  }
  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }
  get stateful() {
    return this._stateful;
  }
  resetStates() {
    if (!this.stateful) throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.");
  }
  assertInputCompatibility(t67) {
    let e36 = $36(t67);
    if (this.inputSpec == null || this.inputSpec.length === 0) return;
    let i88 = $36(this.inputSpec);
    if (e36.length !== i88.length) throw new c102(`Layer ${this.name} expects ${i88.length} inputs, but it received ${e36.length} input tensors. Input received: ${t67}`);
    for (let n67 = 0; n67 < e36.length; n67++) {
      let r56 = e36[n67], o80 = i88[n67];
      if (o80 == null) continue;
      let a71 = r56.rank;
      if (o80.ndim != null && a71 !== o80.ndim) throw new c102(`Input ${n67} is incompatible with layer ${this.name}: expected ndim=${o80.ndim}, found ndim=${a71}`);
      if (o80.maxNDim != null && a71 > o80.maxNDim) throw new c102(`Input ${n67} is incompatible with layer ${this.name}: expected max_ndim=${o80.maxNDim}, found ndim=${a71}`);
      if (o80.minNDim != null && a71 < o80.minNDim) throw new c102(`Input ${n67} is incompatible with layer ${this.name}: expected min_ndim=${o80.minNDim}, found ndim=${a71}.`);
      if (o80.dtype != null && r56.dtype !== o80.dtype) throw new c102(`Input ${n67} is incompatible with layer ${this.name} : expected dtype=${o80.dtype}, found dtype=${r56.dtype}.`);
      if (o80.axes) {
        let l80 = r56.shape;
        for (let u86 in o80.axes) {
          let h74 = Number(u86), p103 = o80.axes[u86], f85 = h74 >= 0 ? l80[h74] : l80[l80.length + h74];
          if (p103 != null && [p103, null].indexOf(f85) === -1) throw new c102(`Input ${n67} is incompatible with layer ${this.name}: expected axis ${h74} of input shape to have value ${p103} but got shape ${l80}.`);
        }
      }
      if (o80.shape != null) for (let l80 = 0; l80 < o80.shape.length; ++l80) {
        let u86 = o80.shape[l80], h74 = r56.shape[l80];
        if (u86 != null && h74 != null && u86 !== h74) throw new c102(`Input ${n67} is incompatible with layer ${this.name}: expected shape=${o80.shape}, found shape=${r56.shape}.`);
      }
    }
  }
  call(t67, e36) {
    return t67;
  }
  invokeCallHook(t67, e36) {
    this._callHook != null && this._callHook(t67, e36);
  }
  setCallHook(t67) {
    this._callHook = t67;
  }
  clearCallHook() {
    this._callHook = null;
  }
  apply(t67, e36) {
    e36 = e36 || {}, this.assertNotDisposed();
    let i88 = $36(t67), n67 = pl(t67), r56 = fl(t67);
    if (n67 === r56) throw new c102("Arguments to apply() must be all SymbolicTensors or all Tensors");
    return Ot4(this.name, () => {
      if (!this.built) {
        this.assertInputCompatibility(t67);
        let o80 = [];
        for (let a71 of $36(t67)) o80.push(a71.shape);
        this.build(st6(o80)), this.built = true, this.initialWeights && this.setWeights(this.initialWeights), this._refCount === null && r56 && (this._refCount = 1);
      }
      if (this.assertInputCompatibility(t67), r56) {
        let o80 = this.call(t67, e36);
        this.supportsMasking && this.setMaskMetadata(t67, o80);
        let a71 = $36(o80), l80 = [];
        for (let u86 of a71) i88.indexOf(u86) !== -1 && (u86 = u86.clone()), l80.push(u86);
        if (o80 = st6(l80), this.activityRegularizer != null) throw new S44("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        return o80;
      } else {
        let o80 = cl(t67), a71 = this.computeOutputShape(o80), l80, u86 = hl(t67);
        if (this.warnOnIncompatibleInputShape(Array.isArray(t67) ? o80[0] : o80), a71 != null && a71.length > 0 && Array.isArray(a71[0]) ? l80 = a71.map((h74, p103) => new ut3(u86, h74, this, $36(t67), e36, this.name, p103)) : l80 = new ut3(u86, a71, this, $36(t67), e36, this.name), this.addInboundNode(t67, l80, null, null, o80, a71, e36), this._refCount++, this.activityRegularizer != null) throw new S44("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        return l80;
      }
    });
  }
  warnOnIncompatibleInputShape(t67) {
    if (this.batchInputShape != null) if (t67.length !== this.batchInputShape.length) console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(t67)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);
    else {
      let e36 = false;
      this.batchInputShape.forEach((i88, n67) => {
        i88 != null && t67[n67] != null && t67[n67] !== i88 && (e36 = true);
      }), e36 && console.warn(`The shape of the input tensor (${JSON.stringify(t67)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`);
    }
  }
  get outputShape() {
    if (this.inboundNodes == null || this.inboundNodes.length === 0) throw new At3(`The layer ${this.name} has never been called and thus has no defined output shape.`);
    let t67 = [];
    for (let e36 of this.inboundNodes) {
      let i88 = JSON.stringify(e36.outputShapes);
      t67.indexOf(i88) === -1 && t67.push(i88);
    }
    if (t67.length === 1) {
      let e36 = this.inboundNodes[0].outputShapes;
      return Array.isArray(e36) && Array.isArray(e36[0]) && e36.length === 1 ? e36[0] : e36;
    } else throw new At3(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`);
  }
  countParams() {
    if (!this.built) throw new ht6(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);
    return ss2(this.weights);
  }
  build(t67) {
    this.built = true;
  }
  getWeights(t67 = false) {
    return Li(t67 ? this.trainableWeights : this.weights);
  }
  setWeights(t67) {
    g4(() => {
      let e36 = this.weights;
      if (e36.length !== t67.length) throw new c102(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${t67.length}, but the layer was expecting ${e36.length} weights. Provided weights: ${t67}...`);
      if (e36.length === 0) return;
      let i88 = [], n67 = Li(e36);
      for (let r56 = 0; r56 < n67.length; ++r56) {
        let o80 = n67[r56], a71 = e36[r56], l80 = t67[r56];
        if (!util_exports.arraysEqual(o80.shape, l80.shape)) throw new c102(`Layer weight shape ${o80.shape} not compatible with provided weight shape ${l80.shape}`);
        i88.push([a71, l80]);
      }
      is2(i88);
    });
  }
  addWeight(t67, e36, i88, n67, r56, o80, a71, l80) {
    if (this._addedWeightNames.indexOf(t67) !== -1) throw new c102(`Duplicate weight name ${t67} for layer ${this.name}`);
    this._addedWeightNames.push(t67), i88 == null && (i88 = "float32"), this.fastWeightInitDuringBuild && (n67 = l80 != null ? l80() : U23("zeros"));
    let u86 = n67.apply(e36, i88), h74 = new vi(u86, i88, t67, o80, a71);
    return u86.dispose(), r56 != null && this.addLoss(() => r56.apply(h74.read())), o80 == null && (o80 = true), o80 ? this._trainableWeights.push(h74) : this._nonTrainableWeights.push(h74), h74;
  }
  setFastWeightInitDuringBuild(t67) {
    this.fastWeightInitDuringBuild = t67;
  }
  addLoss(t67) {
    t67 == null || Array.isArray(t67) && t67.length === 0 || (t67 = $36(t67), this._losses !== void 0 && this._losses !== null && this.losses.push(...t67));
  }
  computeOutputShape(t67) {
    return t67;
  }
  computeMask(t67, e36) {
    if (!this.supportsMasking) {
      if (e36 != null) if (Array.isArray(e36)) e36.forEach((i88) => {
        if (i88 != null) throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
      });
      else throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);
      return null;
    }
    return e36;
  }
  setMaskMetadata(t67, e36, i88) {
    if (!this.supportsMasking) return;
    let n67 = this.computeMask(t67, i88), r56 = $36(e36), o80 = $36(n67);
    if (r56.length !== o80.length) throw new Error(`${this.name} outputs ${r56.length} tensors but ${r56.length} masks for those tensors`);
    for (let a71 = 0; a71 < r56.length; a71++) r56[a71].kerasMask = o80[a71];
  }
  addInboundNode(t67, e36, i88, n67, r56, o80, a71 = null) {
    let l80 = $36(t67);
    e36 = $36(e36), i88 = $36(i88), n67 = $36(n67), r56 = es2(r56), o80 = es2(o80);
    let u86 = [], h74 = [], p103 = [];
    for (let f85 of l80) u86.push(f85.sourceLayer), h74.push(f85.nodeIndex), p103.push(f85.tensorIndex);
    new Gt3({ outboundLayer: this, inboundLayers: u86, nodeIndices: h74, tensorIndices: p103, inputTensors: l80, outputTensors: e36, inputMasks: i88, outputMasks: n67, inputShapes: r56, outputShapes: o80 }, a71);
    for (let f85 = 0; f85 < e36.length; f85++) e36[f85].sourceLayer = this, e36[f85].nodeIndex = this.inboundNodes.length - 1, e36[f85].tensorIndex = f85;
  }
  getConfig() {
    let t67 = { name: this.name, trainable: this.trainable };
    return this.batchInputShape != null && (t67.batchInputShape = this.batchInputShape), this.dtype != null && (t67.dtype = this.dtype), t67;
  }
  disposeWeights() {
    return this.weights.forEach((t67) => t67.dispose()), this.weights.length;
  }
  assertNotDisposed() {
    if (this._refCount === 0) throw new Error(`Layer '${this.name}' is already disposed.`);
  }
  dispose() {
    if (!this.built) throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);
    if (this._refCount === null) throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);
    this.assertNotDisposed();
    let t67 = 0;
    return --this._refCount === 0 && (t67 = this.disposeWeights()), { refCountAfterDispose: this._refCount, numDisposedVariables: t67 };
  }
};
function cl(s84) {
  s84 = $36(s84);
  let t67 = [];
  for (let e36 of s84) t67.push(e36.shape);
  return st6(t67);
}
function hl(s84) {
  return "float32";
}
function xr(s84, t67, e36) {
  if ((t67 == null || e36 != null && e36 > 0) && (t67 = s84.sourceLayer, e36 = s84.nodeIndex), t67.inboundNodes.length === 0) return [s84];
  {
    let i88 = t67.inboundNodes[e36];
    if (i88.inboundLayers.length === 0) return i88.inputTensors;
    {
      let n67 = [];
      for (let r56 = 0; r56 < i88.inboundLayers.length; r56++) {
        let o80 = i88.inputTensors[r56], a71 = i88.inboundLayers[r56], l80 = i88.nodeIndices[r56], u86 = xr(o80, a71, l80);
        for (let h74 of u86) n67.indexOf(h74) === -1 && n67.push(h74);
      }
      return n67;
    }
  }
}
function pl(s84) {
  let t67 = true;
  for (let e36 of $36(s84)) if (!(e36 instanceof ut3)) {
    t67 = false;
    break;
  }
  return t67;
}
function fl(s84) {
  let t67 = true;
  for (let e36 of $36(s84)) if (e36 instanceof ut3) {
    t67 = false;
    break;
  }
  return t67;
}
var Mt3 = class extends v41 {
  constructor(t67) {
    if (super({ dtype: t67.dtype, name: t67.name != null ? t67.name : ae7("input").toString() }), t67.batchSize == null && (t67.batchSize = null), t67.sparse == null && (t67.sparse = false), this.trainable = false, this.built = true, this.sparse = t67.sparse, t67.inputShape != null && t67.batchInputShape != null) throw new c102("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");
    let e36 = t67.batchInputShape;
    if (e36 == null) {
      if (t67.inputShape == null) throw new c102("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");
      e36 = [t67.batchSize].concat(t67.inputShape);
    } else if (t67.batchSize != null) throw new c102("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");
    let i88 = t67.dtype || "float32";
    this.batchInputShape = e36, this.dtype = i88, this.inputSpec = [{ shape: e36 }];
    let n67 = new ut3(this.dtype, this.batchInputShape, this, [], {}, this.name);
    n67.nodeIndex = 0, n67.tensorIndex = 0, new Gt3({ outboundLayer: this, inboundLayers: [], nodeIndices: [], tensorIndices: [], inputTensors: [n67], outputTensors: [n67], inputMasks: [null], outputMasks: [null], inputShapes: [e36], outputShapes: [e36] });
  }
  apply(t67, e36) {
    throw new c102(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`);
  }
  dispose() {
    return { refCountAfterDispose: this._refCount, numDisposedVariables: 0 };
  }
  getConfig() {
    return { batchInputShape: this.batchInputShape, dtype: this.dtype, sparse: this.sparse, name: this.name };
  }
};
Mt3.className = "InputLayer";
serialization_exports.registerClass(Mt3);
function an2(s84) {
  if (s84.batchShape == null && s84.shape == null) throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");
  if (s84.batchShape != null && s84.shape != null) throw new c102("Please provide either a `shape` or `batchShape` argument to Input, but not both.");
  let t67 = s84.batchShape;
  s84.shape != null && t67 == null && (t67 = [null].concat(s84.shape));
  let e36 = s84.dtype;
  return e36 == null && (e36 = "float32"), new Mt3({ batchInputShape: t67, name: s84.name, dtype: e36, sparse: s84.sparse }).inboundNodes[0].outputTensors[0];
}
function bl(s84, t67) {
  if (s84.dtype == null || s84.dtype === t67.dtype) return t67;
  try {
    return w12(t67, s84.dtype);
  } catch {
    throw new c102(`The dtype of the feed (${t67.dtype}) can not be cast to the dtype of the key '${s84.name}' (${s84.dtype}).`);
  }
}
var Vt2 = class s74 {
  constructor(t67) {
    if (this.id2Value = {}, this.id2Mask = {}, this.name2Id = {}, t67 instanceof s74) for (let e36 in t67.id2Value) this.id2Value[e36] = t67.id2Value[e36], e36 in t67.id2Mask && (this.id2Mask[e36] = t67.id2Mask[e36]);
    else {
      if (t67 == null) return;
      for (let e36 of t67) this.add(e36.key, e36.value);
    }
  }
  add(t67, e36, i88) {
    if (this.id2Value[t67.id] == null) this.id2Value[t67.id] = bl(t67, e36), this.name2Id[t67.name] = t67.id, i88 != null && (this.id2Mask[t67.id] = i88);
    else throw new c102(`Duplicate key: name=${t67.name}, id=${t67.id}`);
    return this;
  }
  addFeed(t67) {
    this.add(t67.key, t67.value);
  }
  hasKey(t67) {
    return this.id2Value[t67.id] != null;
  }
  names() {
    return Object.keys(this.name2Id);
  }
  getValue(t67) {
    if (t67 instanceof ut3) {
      if (this.id2Value[t67.id] == null) throw new c102(`Nonexistent key: ${t67.name}`);
      return this.id2Value[t67.id];
    } else {
      let e36 = this.name2Id[t67];
      if (e36 == null) throw new c102(`Feed dict has no SymbolicTensor name: ${t67}`);
      return this.id2Value[e36];
    }
  }
  getMask(t67) {
    if (t67 instanceof ut3) {
      if (this.id2Value[t67.id] == null) throw new c102(`Nonexistent key: ${t67.name}`);
      return this.id2Mask[t67.id];
    } else {
      let e36 = this.name2Id[t67];
      if (e36 == null) throw new c102(`Feed dict has no SymbolicTensor name: ${t67}`);
      return this.id2Mask[e36];
    }
  }
  disposeMasks() {
    this.id2Mask != null && E4(this.id2Mask);
  }
};
var ln2 = new Ni();
var un2 = new Ni();
function zo2(s84) {
  ln2?.setMaxEntries(s84), un2?.setMaxEntries(s84);
}
function Se4(s84, t67, e36, i88) {
  let n67 = e36 == null ? false : e36.training, r56 = Array.isArray(s84), o80 = r56 ? s84 : [s84], a71 = o80.map((b58) => b58.name), l80 = [], u86 = t67.names();
  for (let b58 of a71) u86.indexOf(b58) !== -1 ? l80.push(t67.getValue(b58)) : l80.push(null);
  i88 != null && (i88.maxNumTensors = -1 / 0, i88.minNumTensors = 1 / 0);
  let h74 = a71.join(",") + "|" + t67.names().sort().join(","), p103 = ln2.get(h74), f85;
  if (p103 == null) {
    let b58 = wl(o80, t67);
    p103 = b58.sorted, f85 = b58.recipientCounts, ln2.put(h74, p103), un2.put(h74, f85);
  }
  f85 = {}, n67 || Object.assign(f85, un2.get(h74));
  let w45 = new Vt2(t67);
  for (let b58 = 0; b58 < p103.length; ++b58) {
    if (i88 != null) {
      let O21 = B5().numTensors;
      O21 > i88.maxNumTensors && (i88.maxNumTensors = O21), O21 < i88.minNumTensors && (i88.minNumTensors = O21);
    }
    let m96 = p103[b58], g72 = m96.sourceLayer;
    if (g72 instanceof Mt3) continue;
    let x76 = [], d55 = [], k63 = [], A35 = false;
    for (let O21 of m96.inputs) {
      let F32 = w45.getValue(O21), ct4 = w45.getMask(O21);
      x76.push(F32), d55.push(ct4), ct4 != null && (A35 = true), n67 || (f85[O21.name]--, f85[O21.name] === 0 && !t67.hasKey(O21) && a71.indexOf(O21.name) === -1 && !F32.isDisposed && O21.sourceLayer.stateful !== true && k63.push(F32));
    }
    A35 && (e36 = e36 || {}, e36.mask = d55[0]);
    let z32 = $36(g72.apply(x76, e36)), D42 = null;
    g72.supportsMasking && (D42 = g72.computeMask(x76, d55));
    let q25 = Al(m96), R26 = Array.isArray(q25) ? q25 : [q25];
    for (let O21 = 0; O21 < R26.length; ++O21) {
      w45.hasKey(R26[O21]) || w45.add(R26[O21], z32[O21], Array.isArray(D42) ? D42[0] : D42);
      let F32 = a71.indexOf(R26[O21].name);
      F32 !== -1 && (l80[F32] = z32[O21]);
    }
    n67 || E4(k63);
  }
  return w45.disposeMasks(), r56 ? l80 : l80[0];
}
function wl(s84, t67) {
  util_exports.assert(s84 != null && s84.length > 0, () => "Expected at least one fetch, got none");
  let e36 = [], i88 = {};
  if (s84.length === 1) {
    let n67 = ko2(s84[0], t67);
    e36 = n67.sorted, i88 = n67.recipientMap;
  } else {
    let n67 = /* @__PURE__ */ new Set();
    for (let r56 of s84) {
      let { sorted: o80, recipientMap: a71 } = ko2(r56, t67);
      for (let l80 of o80) n67.has(l80.name) || (e36.push(l80), n67.add(l80.name));
      for (let l80 in a71) i88[l80] == null && (i88[l80] = /* @__PURE__ */ new Set()), a71[l80].forEach((u86) => i88[l80].add(u86));
    }
  }
  return { sorted: e36, recipientCounts: xl(i88) };
}
function xl(s84) {
  let t67 = {};
  for (let e36 in s84) t67[e36] = s84[e36].size;
  return t67;
}
function ko2(s84, t67) {
  let e36 = /* @__PURE__ */ new Set(), i88 = [], n67 = {};
  for (let a71 of t67.names()) e36.add(a71);
  let r56 = [], o80 = [];
  for (r56.push(s84); r56.length > 0; ) {
    let a71 = r56[r56.length - 1];
    if (e36.has(a71.name)) {
      r56.pop();
      continue;
    }
    let l80 = o80[o80.length - 1] === r56.length - 1;
    if (a71.inputs.length === 0 || l80) r56.pop(), i88.push(a71), e36.add(a71.name), l80 && o80.pop();
    else {
      o80.push(r56.length - 1);
      for (let u86 of a71.inputs) n67[u86.name] == null && (n67[u86.name] = /* @__PURE__ */ new Set()), n67[u86.name].add(a71.name), !e36.has(u86.name) && r56.push(u86);
    }
  }
  return { sorted: i88, recipientMap: n67 };
}
function Al(s84) {
  let t67;
  if (s84.sourceLayer.inboundNodes.length === 1) t67 = s84.sourceLayer.output;
  else {
    let e36 = null;
    for (let i88 = 0; i88 < s84.sourceLayer.inboundNodes.length; ++i88) for (let n67 of s84.sourceLayer.inboundNodes[i88].outputTensors) if (n67.id === s84.id) {
      e36 = i88;
      break;
    }
    t67 = s84.sourceLayer.getOutputAt(e36);
  }
  return t67;
}
var kl = l();
kl.registerFlag("TOPOLOGICAL_SORT_CACHE_MAX_ENTRIES", () => 100, zo2);
var vo2 = {};
Pe2(vo2, { maxNorm: () => Nl, minMaxNorm: () => Sl, nonNeg: () => Cl, unitNorm: () => zl });
function Ar(s84, t67) {
  return g4(() => q6(T10(y8(s84, s84), t67, true)));
}
var ve2 = class extends serialization_exports.Serializable {
  getConfig() {
    return {};
  }
};
var ns2 = class extends ve2 {
  constructor(t67) {
    super(), this.defaultMaxValue = 2, this.defaultAxis = 0, this.maxValue = t67.maxValue != null ? t67.maxValue : this.defaultMaxValue, this.axis = t67.axis != null ? t67.axis : this.defaultAxis;
  }
  apply(t67) {
    return g4(() => {
      let e36 = Ar(t67, this.axis), i88 = x18(e36, 0, this.maxValue);
      return y8(t67, D6(i88, T7(Q12(), e36)));
    });
  }
  getConfig() {
    return { maxValue: this.maxValue, axis: this.axis };
  }
};
ns2.className = "MaxNorm";
serialization_exports.registerClass(ns2);
var rs2 = class extends ve2 {
  constructor(t67) {
    super(), this.defaultAxis = 0, this.axis = t67.axis != null ? t67.axis : this.defaultAxis;
  }
  apply(t67) {
    return g4(() => D6(t67, T7(Q12(), Ar(t67, this.axis))));
  }
  getConfig() {
    return { axis: this.axis };
  }
};
rs2.className = "UnitNorm";
serialization_exports.registerClass(rs2);
var os = class extends ve2 {
  apply(t67) {
    return s22(t67);
  }
};
os.className = "NonNeg";
serialization_exports.registerClass(os);
var as2 = class extends ve2 {
  constructor(t67) {
    super(), this.defaultMinValue = 0, this.defaultMaxValue = 1, this.defaultRate = 1, this.defaultAxis = 0, this.minValue = t67.minValue != null ? t67.minValue : this.defaultMinValue, this.maxValue = t67.maxValue != null ? t67.maxValue : this.defaultMaxValue, this.rate = t67.rate != null ? t67.rate : this.defaultRate, this.axis = t67.axis != null ? t67.axis : this.defaultAxis;
  }
  apply(t67) {
    return g4(() => {
      let e36 = Ar(t67, this.axis), i88 = T7(y8(this.rate, x18(e36, this.minValue, this.maxValue)), y8(1 - this.rate, e36));
      return y8(t67, D6(i88, T7(Q12(), e36)));
    });
  }
  getConfig() {
    return { minValue: this.minValue, maxValue: this.maxValue, rate: this.rate, axis: this.axis };
  }
};
as2.className = "MinMaxNorm";
serialization_exports.registerClass(as2);
var Co3 = { maxNorm: "MaxNorm", minMaxNorm: "MinMaxNorm", nonNeg: "NonNeg", unitNorm: "UnitNorm" };
function Z15(s84) {
  return Ke(s84);
}
function So2(s84, t67 = {}) {
  return Bt3(s84, serialization_exports.SerializationMap.getMap().classNameMap, t67, "constraint");
}
function G29(s84) {
  if (s84 == null) return null;
  if (typeof s84 == "string") {
    let e36 = { className: s84 in Co3 ? Co3[s84] : s84, config: {} };
    return So2(e36);
  } else return s84 instanceof ve2 ? s84 : So2(s84);
}
function Nl(s84) {
  return new ns2(s84);
}
function zl(s84) {
  return new rs2(s84);
}
function Cl() {
  return new os();
}
function Sl(s84) {
  return new as2(s84);
}
var Lo2 = {};
Pe2(Lo2, { constant: () => Tl, glorotNormal: () => $l, glorotUniform: () => Rl, heNormal: () => Fl, heUniform: () => Bl, identity: () => _l, leCunNormal: () => Wl, leCunUniform: () => Vl, ones: () => Ll, orthogonal: () => Ul, randomNormal: () => Dl, randomUniform: () => El, truncatedNormal: () => Ol, varianceScaling: () => Ml, zeros: () => vl });
function vl() {
  return new Je3();
}
function Ll() {
  return new ue7();
}
function Tl(s84) {
  return new Ze3(s84);
}
function El(s84) {
  return new Ge2(s84);
}
function Dl(s84) {
  return new Ye2(s84);
}
function Ol(s84) {
  return new Xe3(s84);
}
function _l(s84) {
  return new Qe(s84);
}
function Ml(s84) {
  return new rt7(s84);
}
function Rl(s84) {
  return new Ae4(s84);
}
function $l(s84) {
  return new Ie2(s84);
}
function Fl(s84) {
  return new ke2(s84);
}
function Bl(s84) {
  return new Ne2(s84);
}
function Wl(s84) {
  return new ze3(s84);
}
function Vl(s84) {
  return new Ce3(s84);
}
function Ul(s84) {
  return new ts2(s84);
}
var Fa = {};
Pe2(Fa, { Layer: () => v41, RNN: () => kt3, RNNCell: () => Xt3, activation: () => kh, add: () => Dh, alphaDropout: () => mp, average: () => Oh, averagePooling1d: () => Ur, averagePooling2d: () => Pr, averagePooling3d: () => Kr, avgPool1d: () => Uh, avgPool2d: () => Kh, avgPool3d: () => qh, avgPooling1d: () => Ph, avgPooling2d: () => jh, avgPooling3d: () => Hh, batchNormalization: () => Bh, bidirectional: () => ap, categoryEncoding: () => xp, centerCrop: () => bp, concatenate: () => _h, conv1d: () => dh, conv2d: () => mh, conv2dTranspose: () => gh, conv3d: () => yh, conv3dTranspose: () => bh, convLstm2d: () => ip, convLstm2dCell: () => np, cropping2D: () => xh, dense: () => Nh, depthwiseConv2d: () => Ih, dot: () => Fh, dropout: () => zh, elu: () => lh, embedding: () => Eh, flatten: () => Sh, gaussianDropout: () => dp, gaussianNoise: () => fp, globalAveragePooling1d: () => Jh, globalAveragePooling2d: () => Zh, globalMaxPool1d: () => up, globalMaxPool2d: () => cp, globalMaxPooling1d: () => _a, globalMaxPooling2d: () => Ma, gru: () => Yh, gruCell: () => Xh, input: () => Dr, inputLayer: () => ah, layerNormalization: () => Wh, leakyReLU: () => ch, lstm: () => Qh, lstmCell: () => tp, masking: () => gp, maxPool1d: () => hp, maxPool2d: () => pp, maxPooling1d: () => Ra, maxPooling2d: () => $a, maxPooling3d: () => Gh, maximum: () => Mh, minimum: () => Rh, multiply: () => $h, permute: () => Th, prelu: () => hh, randomWidth: () => Ap, reLU: () => uh, repeatVector: () => vh, rescaling: () => yp, reshape: () => Lh, resizing: () => wp, rnn: () => rp, separableConv2d: () => wh, simpleRNN: () => ep, simpleRNNCell: () => sp, softmax: () => ph, spatialDropout1d: () => Ch, stackedRNNCells: () => op, thresholdedReLU: () => fh, timeDistributed: () => lp, upSampling2d: () => Ah, zeroPadding2d: () => Vh });
async function Ut3(s84) {
  if (s84 == null) return;
  let t67 = [], e36 = [], i88 = [];
  for (let n67 in s84) {
    let r56 = s84[n67];
    if (typeof r56 != "number") {
      let o80 = r56;
      t67.push(o80.data()), e36.push(n67), i88.push(o80);
    }
  }
  if (t67.length > 0) {
    let n67 = await Promise.all(t67);
    for (let r56 = 0; r56 < n67.length; ++r56) s84[e36[r56]] = n67[r56][0];
    E4(i88);
  }
}
function hn2(s84) {
  if (s84 != null) for (let t67 in s84) {
    let e36 = s84[t67];
    typeof e36 != "number" && e36.dispose();
  }
}
var Do2;
(function(s84) {
  s84[s84.SILENT = 0] = "SILENT", s84[s84.VERBOSE = 1] = "VERBOSE";
})(Do2 || (Do2 = {}));
var Jl = 125;
var Yt3 = class {
  constructor() {
    this.validationData = null;
  }
  setParams(t67) {
    this.params = t67;
  }
  async onEpochBegin(t67, e36) {
  }
  async onEpochEnd(t67, e36) {
  }
  async onBatchBegin(t67, e36) {
  }
  async onBatchEnd(t67, e36) {
  }
  async onTrainBegin(t67) {
  }
  async onTrainEnd(t67) {
  }
  setModel(t67) {
  }
};
var pn = class {
  constructor(t67, e36 = 10) {
    t67 == null && (t67 = []), this.callbacks = t67, this.queueLength = e36;
  }
  append(t67) {
    this.callbacks.push(t67);
  }
  setParams(t67) {
    for (let e36 of this.callbacks) e36.setParams(t67);
  }
  setModel(t67) {
    for (let e36 of this.callbacks) e36.setModel(t67);
  }
  async onEpochBegin(t67, e36) {
    e36 == null && (e36 = {});
    for (let i88 of this.callbacks) await i88.onEpochBegin(t67, e36);
  }
  async onEpochEnd(t67, e36) {
    e36 == null && (e36 = {});
    for (let i88 of this.callbacks) await i88.onEpochEnd(t67, e36);
  }
  async onBatchBegin(t67, e36) {
    e36 == null && (e36 = {});
    for (let i88 of this.callbacks) await i88.onBatchBegin(t67, e36);
  }
  async onBatchEnd(t67, e36) {
    e36 == null && (e36 = {});
    for (let i88 of this.callbacks) await i88.onBatchEnd(t67, e36);
  }
  async onTrainBegin(t67) {
    t67 == null && (t67 = {});
    for (let e36 of this.callbacks) await e36.onTrainBegin(t67);
  }
  async onTrainEnd(t67) {
    t67 == null && (t67 = {});
    for (let e36 of this.callbacks) await e36.onTrainEnd(t67);
  }
};
var kr = class extends Yt3 {
  constructor() {
    super();
  }
  async onEpochBegin(t67) {
    this.seen = 0, this.totals = {};
  }
  async onBatchEnd(t67, e36) {
    e36 == null && (e36 = {});
    let i88 = e36.size == null ? 0 : e36.size;
    this.seen += i88;
    for (let n67 in e36) {
      let r56 = e36[n67];
      if (typeof r56 == "number") this.totals.hasOwnProperty(n67) || (this.totals[n67] = 0), this.totals[n67] = this.totals[n67] + r56 * i88;
      else {
        let o80;
        n67 in this.totals ? o80 = this.totals[n67] : this.totals[n67] = 0;
        let a71 = g4(() => T7(this.totals[n67], y8(r56, i88)));
        this.totals[n67] = a71, o80?.dispose();
      }
    }
  }
  async onEpochEnd(t67, e36) {
    if (e36 != null) for (let i88 of this.params.metrics) this.totals[i88] != null && (typeof this.totals[i88] == "number" ? e36[i88] = this.totals[i88] / this.seen : g4(() => {
      let n67 = y8(D6(1, this.seen), this.totals[i88]);
      e36[i88] = n67, this.totals[i88].dispose(), N3(e36[i88]);
    }));
  }
};
var fn2 = class extends Yt3 {
  async onTrainBegin(t67) {
    this.epoch = [], this.history = {};
  }
  async onEpochEnd(t67, e36) {
    e36 == null && (e36 = {}), this.epoch.push(t67);
    for (let i88 in e36) this.history[i88] == null && (this.history[i88] = []), this.history[i88].push(e36[i88]);
  }
  async syncData() {
    let t67 = [], e36 = [], i88 = [];
    for (let r56 in this.history) {
      let o80 = this.history[r56];
      for (let a71 = 0; a71 < o80.length; ++a71) if (typeof o80[a71] != "number") {
        let l80 = o80[a71];
        t67.push(l80.data()), e36.push(r56), i88.push(a71);
      }
    }
    let n67 = await Promise.all(t67);
    for (let r56 = 0; r56 < n67.length; ++r56) this.history[e36[r56]][i88[r56]].dispose(), this.history[e36[r56]][i88[r56]] = n67[r56][0];
  }
};
var dn2 = class extends Yt3 {
  constructor(t67, e36) {
    if (super(), this.currentEpoch = 0, this.nowFunc = t67.nowFunc, this.nextFrameFunc = t67.nextFrameFunc || n18, this.yieldEvery = e36 || "auto", this.yieldEvery === "auto" && (this.yieldEvery = Jl), this.yieldEvery === "never" && t67.onYield != null) throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");
    util_exports.isNumber(this.yieldEvery) && (this.maybeWait = Gr(this.maybeWait.bind(this), this.yieldEvery, this.nowFunc)), this.trainBegin = t67.onTrainBegin, this.trainEnd = t67.onTrainEnd, this.epochBegin = t67.onEpochBegin, this.epochEnd = t67.onEpochEnd, this.batchBegin = t67.onBatchBegin, this.batchEnd = t67.onBatchEnd, this.yield = t67.onYield;
  }
  async maybeWait(t67, e36, i88) {
    let n67 = [];
    this.yield != null && (await Ut3(i88), n67.push(this.yield(t67, e36, i88))), n67.push(this.nextFrameFunc()), await Promise.all(n67);
  }
  async onEpochBegin(t67, e36) {
    this.currentEpoch = t67, this.epochBegin != null && (await Ut3(e36), await this.epochBegin(t67, e36));
  }
  async onEpochEnd(t67, e36) {
    let i88 = [];
    this.epochEnd != null && (await Ut3(e36), i88.push(this.epochEnd(t67, e36))), this.yieldEvery === "epoch" && i88.push(this.nextFrameFunc()), await Promise.all(i88);
  }
  async onBatchBegin(t67, e36) {
    this.batchBegin != null && (await Ut3(e36), await this.batchBegin(t67, e36));
  }
  async onBatchEnd(t67, e36) {
    let i88 = [];
    this.batchEnd != null && (await Ut3(e36), i88.push(this.batchEnd(t67, e36))), this.yieldEvery === "batch" ? i88.push(this.nextFrameFunc()) : util_exports.isNumber(this.yieldEvery) && i88.push(this.maybeWait(this.currentEpoch, t67, e36)), await Promise.all(i88);
  }
  async onTrainBegin(t67) {
    this.trainBegin != null && (await Ut3(t67), await this.trainBegin(t67));
  }
  async onTrainEnd(t67) {
    this.trainEnd != null && (await Ut3(t67), await this.trainEnd(t67));
  }
};
function mn(s84, t67) {
  return s84 == null && (s84 = {}), s84 instanceof Yt3 ? [s84] : Array.isArray(s84) && s84[0] instanceof Yt3 ? s84 : $36(s84).map((i88) => new dn2(i88, t67));
}
var us = class s75 {
  constructor() {
  }
  static registerCallbackConstructor(t67, e36) {
    util_exports.assert(t67 >= 0 && Number.isInteger(t67), () => `Verbosity level is expected to be an integer >= 0, but got ${t67}`), s75.checkForDuplicate(e36), s75.constructors[t67] == null && (s75.constructors[t67] = []), s75.constructors[t67].push(e36);
  }
  static checkForDuplicate(t67) {
    for (let e36 in s75.constructors) s75.constructors[+e36].forEach((n67) => {
      if (n67 === t67) throw new c102("Duplicate callback constructor.");
    });
  }
  static clear() {
    s75.constructors = {};
  }
  static createCallbacks(t67) {
    let e36 = [];
    for (let i88 in s75.constructors) {
      let n67 = +i88;
      t67 >= n67 && e36.push(...s75.constructors[n67]);
    }
    return e36.map((i88) => new i88());
  }
};
us.constructors = {};
function gn(s84, t67, e36, i88, n67, r56, o80, a71, l80) {
  let u86 = new fn2(), h74 = [new kr(), ...us.createCallbacks(t67)];
  s84 != null && h74.push(...s84), h74.push(u86);
  let p103 = new pn(h74);
  return p103.setParams({ epochs: e36, initialEpoch: i88, samples: n67, steps: r56, batchSize: o80, verbose: t67, doValidation: a71, metrics: l80 }), { callbackList: p103, history: u86 };
}
function yt5(s84, t67 = {}, e36 = false) {
  return Bt3(s84, serialization_exports.SerializationMap.getMap().classNameMap, t67, "layer", e36);
}
function Ti(s84, t67) {
  return g4(() => {
    s84.dtype !== "float32" && (s84 = w12(s84, "float32"));
    let e36 = T10(xe6(s84), t67, true), i88 = c16(e36.shape, Q12()), n67 = q6(E18(e36, i88));
    return D6(s84, n67);
  });
}
function Pt3(s84, t67) {
  return g4(() => E19(xe6(E16(t67, s84)), -1));
}
function cs2(s84, t67) {
  return g4(() => E19(b9(E16(t67, s84)), -1));
}
function ce6(s84, t67) {
  return g4(() => {
    let e36 = E16(s84, t67), i88 = x18(b9(s84), Q12(), Number.MAX_VALUE), n67 = b9(D6(e36, i88));
    return y8(100, E19(n67, -1));
  });
}
function Yl(s84, t67) {
  return g4(() => {
    let e36 = x18(t67, Q12(), Number.MAX_VALUE), i88 = x29(T7(1, e36)), n67 = x18(s84, Q12(), Number.MAX_VALUE), r56 = x29(T7(1, n67));
    return E19(xe6(E16(i88, r56)), -1);
  });
}
function Xl(s84, t67) {
  return g4(() => {
    let e36 = E18(0, E16(1, y8(s84, t67)));
    return E19(xe6(e36), -1);
  });
}
function Ql(s84, t67) {
  return g4(() => {
    let e36 = E18(0, E16(1, y8(s84, t67)));
    return E19(e36, -1);
  });
}
function tu(s84, t67) {
  return g4(() => {
    let e36 = T10(y8(s84, t67), -1), i88 = d10(y8(E16(1, s84), t67), -1);
    return E18(0, T7(1, E16(i88, e36)));
  });
}
function eu(s84, t67) {
  return g4(() => {
    let e36 = Math.log(2), i88 = E16(t67, s84), n67 = E16(T7(i88, l18(y8(-2, i88))), e36);
    return E19(n67, -1);
  });
}
function Le2(s84, t67, e36 = false) {
  return g4(() => {
    if (e36) t67 = g20(t67);
    else {
      let i88 = T10(t67, t67.shape.length - 1, true);
      t67 = D6(t67, i88);
    }
    return t67 = x18(t67, Q12(), 1 - Q12()), g14(T10(y8(w12(s84, "float32"), x29(t67)), t67.shape.length - 1));
  });
}
function hs3(s84, t67, e36 = false) {
  return g4(() => {
    let i88 = w12(x24(ao2(s84)), "int32");
    t67 = x18(t67, Q12(), 1 - Q12());
    let n67 = t67.shape, r56 = h9(w15(i88, n67[n67.length - 1]), n67);
    return Le2(r56, t67, e36);
  });
}
function su(s84, t67) {
  if (!util_exports.arraysEqual(s84.shape, t67.shape)) throw new c102(`logits and labels must have the same shape, but got shapes ${JSON.stringify(s84.shape)} and ${JSON.stringify(t67.shape)}`);
  return g4(() => {
    let e36 = s22(t67), i88 = g14(b9(t67));
    return T7(E16(e36, y8(t67, s84)), g13(u20(i88)));
  });
}
function ps(s84, t67) {
  return g4(() => {
    let e36;
    return e36 = x18(t67, Q12(), 1 - Q12()), e36 = x29(D6(e36, E16(1, e36))), E19(su(s84, e36), -1);
  });
}
function iu(s84, t67) {
  return g4(() => {
    let e36 = x18(s84, Q12(), 1), i88 = x18(t67, Q12(), 1);
    return T10(y8(s84, x29(D6(e36, i88))), -1);
  });
}
function nu(s84, t67) {
  return g4(() => {
    let e36 = x29(T7(Q12(), t67));
    return E19(E16(t67, y8(s84, e36)), -1);
  });
}
function Di(s84, t67) {
  return g4(() => {
    let e36 = Ti(s84, -1), i88 = Ti(t67, -1), n67 = y8(e36, i88);
    return g14(T10(n67, -1));
  });
}
var Ei = { meanSquaredError: Pt3, meanAbsoluteError: cs2, meanAbsolutePercentageError: ce6, meanSquaredLogarithmicError: Yl, squaredHinge: Xl, hinge: Ql, categoricalHinge: tu, logcosh: eu, categoricalCrossentropy: Le2, sparseCategoricalCrossentropy: hs3, binaryCrossentropy: ps, kullbackLeiblerDivergence: iu, poisson: nu, cosineProximity: Di };
function yn(s84) {
  if (typeof s84 == "string") {
    if (s84 in Ei) return Ei[s84];
    let t67 = `Unknown loss ${s84}`;
    throw s84.toLowerCase().includes("softmaxcrossentropy") && (t67 = `Unknown loss ${s84}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`), new c102(t67);
  } else return s84;
}
function Oi(s84, t67) {
  return g4(() => {
    let e36 = y8(0.5, k15(t67)), i88 = at6(G6(t67, e36), s84.dtype);
    return E19(E13(s84, i88), -1);
  });
}
function _i(s84, t67) {
  return g4(() => at6(E13(u9(s84, -1), u9(t67, -1)), "float32"));
}
function _o2(s84, t67) {
  return g4(() => w12(T10(g16(E13(s84, 1), E13(t67, 1))), "float32"));
}
function ru(s84, t67) {
  return g4(() => w12(T10(g16(E13(s84, 1), E13(t67, 0))), "float32"));
}
function ou(s84, t67) {
  return g4(() => w12(T10(g16(E13(s84, 0), E13(t67, 1))), "float32"));
}
function Nr(s84, t67) {
  return g4(() => {
    let e36 = _o2(s84, t67), i88 = ou(s84, t67), n67 = T7(e36, i88);
    return w12(G5(G6(n67, 0), D6(e36, n67), 0), "float32");
  });
}
function Mo2(s84, t67) {
  return g4(() => {
    let e36 = _o2(s84, t67), i88 = ru(s84, t67), n67 = T7(e36, i88);
    return w12(G5(G6(n67, 0), D6(e36, n67), 0), "float32");
  });
}
function wn(s84, t67) {
  return ps(s84, t67);
}
function xn2(s84, t67) {
  return s84.rank === t67.rank && (s84 = a23(s84, [s84.rank - 1])), t67 = u9(t67, -1), t67.dtype !== s84.dtype && (t67 = w12(t67, s84.dtype)), w12(E13(s84, t67), "float32");
}
function Ro2(s84, t67) {
  return g4(() => {
    let e36 = s84.sub(t67).square().sum(), i88 = s84.sub(s84.mean()).square().sum();
    return m21(1).sub(e36.div(i88));
  });
}
var au = Pt3;
var lu = Pt3;
var uu = cs2;
var cu = cs2;
var hu = ce6;
var pu = ce6;
var Mi = Le2;
var fu = Di;
var zr = hs3;
var bn = { binaryAccuracy: Oi, categoricalAccuracy: _i, precision: Nr, categoricalCrossentropy: Mi, sparseCategoricalCrossentropy: zr, mse: au, MSE: lu, mae: uu, MAE: cu, mape: hu, MAPE: pu, cosine: fu };
function $o2(s84) {
  if (typeof s84 == "string" && s84 in bn) return bn[s84];
  if (typeof s84 != "string" && s84 != null) return s84;
  throw new c102(`Unknown metric ${s84}`);
}
function Ri(s84) {
  if (It2(s84 !== null, `Unknown LossOrMetricFn ${s84}`), typeof s84 == "string") return s84;
  {
    let t67;
    for (let e36 of Object.keys(Ei)) if (Ei[e36] === s84) {
      t67 = e36;
      break;
    }
    if (t67 !== void 0) return t67;
    for (let e36 of Object.keys(bn)) if (bn[e36] === s84) {
      t67 = e36;
      break;
    }
    return t67 !== void 0 ? t67 : s84.name;
  }
}
function Bo2(s84) {
  let t67 = { Adagrad: () => o13.adagrad(0.01), Adadelta: () => o13.adadelta(1, 0.95, Q12()), Adam: () => o13.adam(1e-3, 0.9, 0.999, Q12()), Adamax: () => o13.adamax(2e-3, 0.9, 0.999, Q12(), 0), RMSProp: () => o13.rmsprop(1e-3, 0.9, 0, Q12()), SGD: () => o13.sgd(0.01) };
  if (t67.adagrad = t67.Adagrad, t67.adadelta = t67.Adadelta, t67.adam = t67.Adam, t67.adamax = t67.Adamax, t67.rmsprop = t67.RMSProp, t67.sgd = t67.SGD, s84 in t67) return t67[s84]();
  throw new c102(`Unknown Optimizer ${s84}`);
}
function Sr(s84, t67, e36 = false) {
  if (s84 == null || typeof s84 != "object" || Object.getPrototypeOf(s84) !== Object.prototype || !Cr(s84)) throw new Error("User-defined metadata is expected to be a JSON object, but is not.");
  if (e36) {
    let i88 = JSON.stringify(s84);
    i88.length > 1048576 && console.warn(`User-defined metadata of model "${t67}" is too large in size (length=${i88.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= 1048576.`);
  }
}
function Cr(s84) {
  if (s84 === null) return true;
  if (typeof s84 == "object") if (Object.getPrototypeOf(s84) === Object.prototype) {
    let t67 = Object.keys(s84);
    for (let e36 of t67) if (typeof e36 != "string" || !Cr(s84[e36])) return false;
    return true;
  } else if (Array.isArray(s84)) {
    for (let t67 of s84) if (!Cr(t67)) return false;
    return true;
  } else return false;
  else {
    let t67 = typeof s84;
    return t67 === "string" || t67 === "number" || t67 === "boolean";
  }
}
function Wo2(s84, t67, e36, i88 = console.log) {
  let n67 = gu(s84), r56 = ["Layer (type)", "Input Shape", "Output shape", "Param #"];
  n67 ? (t67 = t67 || 90, e36 = e36 || [0.32, 0.61, 0.89, 1]) : (t67 = t67 || 115, e36 = e36 || [0.24, 0.48, 0.7, 0.8, 1]), e36[e36.length - 1] <= 1 && (e36 = e36.map((h74) => Math.floor(t67 * h74)));
  let o80;
  if (!n67) {
    r56.push("Receives inputs"), o80 = [];
    for (let h74 in s84.nodesByDepth) o80.push(...s84.nodesByDepth[h74]);
  }
  i88("_".repeat(t67)), An2(r56, e36, i88), i88("=".repeat(t67));
  let a71 = s84.layers;
  for (let h74 = 0; h74 < a71.length; ++h74) n67 ? yu(a71[h74], e36, i88) : bu(a71[h74], e36, o80, i88), i88((h74 === a71.length - 1 ? "=" : "_").repeat(t67));
  s84.checkTrainableWeightsConsistency();
  let l80 = mu(s84), u86 = ss2(s84.nonTrainableWeights);
  i88(`Total params: ${l80 + u86}`), i88(`Trainable params: ${l80}`), i88(`Non-trainable params: ${u86}`), i88("_".repeat(t67));
}
function mu(s84) {
  let t67;
  return s84.collectedTrainableWeights != null ? t67 = ss2(s84.collectedTrainableWeights) : t67 = ss2(s84.trainableWeights), t67;
}
function gu(s84) {
  let t67 = true, e36 = [], i88 = [];
  for (let n67 in s84.nodesByDepth) e36.push(s84.nodesByDepth[n67]);
  for (let n67 of e36) {
    if (n67.length > 1 || n67.length === 1 && n67[0].inboundLayers.length > 1) {
      t67 = false;
      break;
    }
    i88.push(...n67);
  }
  if (t67) for (let n67 of s84.layers) {
    let r56 = false;
    for (let o80 of n67.inboundNodes) if (i88.indexOf(o80) !== -1) if (r56) {
      t67 = false;
      break;
    } else r56 = true;
    if (!t67) break;
  }
  return t67;
}
function An2(s84, t67, e36 = console.log) {
  let i88 = "";
  for (let n67 = 0; n67 < s84.length; ++n67) n67 > 0 && (i88 = i88.slice(0, i88.length - 1) + " "), i88 += s84[n67], i88 = i88.slice(0, t67[n67]), i88 += " ".repeat(t67[n67] - i88.length);
  e36(i88);
}
function yu(s84, t67, e36) {
  let i88, n67;
  try {
    n67 = s84.inboundNodes.map((l80) => JSON.stringify(l80.inputShapes)).join(",");
  } catch {
    n67 = "multiple";
  }
  try {
    i88 = JSON.stringify(s84.outputShape);
  } catch {
    i88 = "multiple";
  }
  let r56 = s84.name, o80 = s84.getClassName(), a71 = [`${r56} (${o80})`, n67, i88, s84.countParams().toString()];
  An2(a71, t67, e36);
}
function bu(s84, t67, e36, i88) {
  let n67, r56;
  try {
    r56 = s84.inboundNodes.map((p103) => JSON.stringify(p103.inputShapes)).join(",");
  } catch {
    r56 = "multiple";
  }
  try {
    n67 = JSON.stringify(s84.outputShape);
  } catch {
    n67 = "multiple";
  }
  let o80 = [];
  for (let p103 of s84.inboundNodes) if (!(e36 != null && e36.length > 0 && e36.indexOf(p103) === -1)) for (let f85 = 0; f85 < p103.inboundLayers.length; ++f85) {
    let w45 = p103.inboundLayers[f85].name, b58 = p103.nodeIndices[f85], m96 = p103.tensorIndices[f85];
    o80.push(`${w45}[${b58}][${m96}]`);
  }
  let a71 = s84.name, l80 = s84.getClassName(), u86 = o80.length === 0 ? "" : o80[0], h74 = [`${a71} (${l80})`, r56, n67, s84.countParams().toString(), u86];
  An2(h74, t67, i88);
  for (let p103 = 1; p103 < o80.length; ++p103) An2(["", "", "", "", o80[p103]], t67, i88);
}
function Vo2(s84, t67, e36) {
  return (s84 === "inboundNodes" || s84 === "outputLayers" || s84 === "inputLayers") && t67 === 0 && typeof e36 == "string";
}
function Te4(s84, t67) {
  if (s84 === null) return null;
  if (typeof s84 == "string") return qt3(s84);
  if (typeof s84 == "number" || typeof s84 == "boolean") return s84;
  if (s84 instanceof Array) {
    let e36 = [], i88 = s84.length;
    for (let n67 = 0; n67 < i88; ++n67) {
      let r56 = s84[n67];
      Vo2(t67, n67, r56) ? e36.push(r56) : e36.push(Te4(r56, t67));
    }
    return e36;
  } else {
    let e36 = {};
    for (let i88 of Object.keys(s84)) {
      let n67 = s84[i88];
      if (i88 === "name" && typeof n67 == "string") e36[i88] = n67;
      else {
        let r56 = qt3(i88);
        e36[r56] = Te4(n67, r56);
      }
    }
    return e36;
  }
}
function In(s84, t67) {
  if (s84 == null) return null;
  if (typeof s84 == "string") return Ct2(s84);
  if (typeof s84 == "number" || typeof s84 == "boolean") return s84;
  if (s84 instanceof Array) {
    let e36 = [], i88 = s84.length;
    for (let n67 = 0; n67 < i88; ++n67) {
      let r56 = s84[n67];
      Vo2(t67, n67, r56) ? e36.push(r56) : e36.push(In(r56, t67));
    }
    return e36;
  } else {
    let e36 = {};
    for (let i88 of Object.keys(s84)) {
      let n67 = s84[i88], r56 = Ct2(i88);
      (i88 === "name" || i88 === "className") && typeof n67 == "string" ? e36[r56] = n67 : e36[r56] = In(n67, i88);
    }
    return e36;
  }
}
var $i = "4.22.0";
var wu = (s84) => {
  let t67 = Object.keys(s84);
  if (t67.length === 0) return false;
  let e36 = t67[0].split("/");
  return !isNaN(parseInt(e36[e36.length - 1], 10));
};
var Nn = class s76 extends v41 {
  constructor(t67) {
    if (super({}), this.containerNodes = /* @__PURE__ */ new Set(), this.name = t67.name, this.name == null) {
      let d55 = this.getClassName().toLowerCase();
      this.name = ae7(d55);
    }
    if (this.supportsMasking = false, this.trainable_ = true, Array.isArray(t67.inputs) ? this.inputs = t67.inputs.slice() : this.inputs = [t67.inputs], Array.isArray(t67.outputs) ? this.outputs = t67.outputs.slice() : this.outputs = [t67.outputs], St3(this.inputs).length !== this.inputs.length) throw new c102(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((d55) => d55.name)}`);
    St3(this.outputs).length !== this.outputs.length && console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((d55) => d55.name)}`), this.inputLayers = [], this.inputLayersNodeIndices = [], this.inputLayersTensorIndices = [], this.outputLayers = [], this.outputLayersNodeIndices = [], this.outputLayersTensorIndices = [], this.layers = [], this.internalContainerRefs = [];
    for (let d55 of this.outputs) {
      let k63 = d55.sourceLayer, A35 = d55.nodeIndex, z32 = d55.tensorIndex;
      this.outputLayers.push(k63), this.outputLayersNodeIndices.push(A35), this.outputLayersTensorIndices.push(z32);
    }
    for (let d55 of this.inputs) {
      let k63 = d55.sourceLayer, A35 = d55.nodeIndex, z32 = d55.tensorIndex;
      It2(A35 === 0, "input layer has >1 nodes"), It2(z32 === 0, "input layer has >1 tensors"), this.inputLayers.push(k63), this.inputLayersNodeIndices.push(A35), this.inputLayersTensorIndices.push(z32);
    }
    this.inputNames = [], this.outputNames = [], this.feedInputShapes = [], this.feedInputNames = [], this.feedOutputNames = [];
    for (let d55 = 0; d55 < this.inputLayers.length; d55++) {
      let k63 = this.inputLayers[d55];
      if (!(k63 instanceof Mt3)) throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t67.inputs}. Input ${d55} (0-based) originates from layer type ${k63.getClassName()}.`);
      this.inputNames.push(k63.name), this.feedInputShapes.push(k63.batchInputShape), this.feedInputNames.push(k63.name);
    }
    for (let d55 of this.outputLayers) this.outputNames.push(d55.name);
    this.internalInputShapes = this.inputs.map((d55) => d55.shape), this.internalOutputShapes = this.outputs.map((d55) => d55.shape);
    let e36 = {}, i88 = {}, n67 = {}, r56 = {}, o80 = {}, a71 = [], l80 = (d55, k63, A35, z32, D42, q25) => {
      (z32 == null || D42 == null || q25 == null) && (z32 = d55.sourceLayer, D42 = d55.nodeIndex, q25 = d55.tensorIndex);
      let R26 = z32.inboundNodes[D42];
      if (A35.indexOf(R26) !== -1) throw new ht6(`The tensor ${d55.name} at layer "${z32.name}" is part of a cycle.`);
      if (k63.indexOf(R26) !== -1) return;
      this.containerNodes.add(s76.nodeKey(z32, D42)), z32.id in o80 || (o80[z32.id] = Object.keys(o80).length), A35.indexOf(R26) === -1 && A35.push(R26);
      let O21 = R26.inboundLayers.length;
      for (let F32 = 0; F32 < O21; F32++) {
        let ct4 = R26.inputTensors[F32], ne7 = R26.inboundLayers[F32], Ai = R26.nodeIndices[F32], Ii = R26.tensorIndices[F32];
        l80(ct4, k63, A35, ne7, Ai, Ii);
      }
      for (k63.push(R26); A35.indexOf(R26) >= 0; ) A35.splice(A35.indexOf(R26), 1);
      a71.push(R26);
    }, u86 = [], h74 = [];
    for (let d55 of this.outputs) l80(d55, u86, h74);
    let p103 = a71.slice().reverse();
    for (let d55 of p103) {
      i88[d55.id] = d55, d55.id in e36 || (e36[d55.id] = 0);
      let k63 = e36[d55.id], A35 = n67[d55.outboundLayer.id] == null ? 0 : n67[d55.outboundLayer.id];
      k63 = Math.max(k63, A35), n67[d55.outboundLayer.id] = k63, r56[d55.outboundLayer.id] = d55.outboundLayer, e36[d55.id] = k63;
      for (let z32 = 0; z32 < d55.inboundLayers.length; z32++) {
        let D42 = d55.inboundLayers[z32], q25 = d55.nodeIndices[z32], R26 = D42.inboundNodes[q25], O21 = e36[R26.id] == null ? 0 : e36[R26.id];
        e36[R26.id] = Math.max(k63 + 1, O21), i88[R26.id] = R26;
      }
    }
    let f85 = {};
    for (let d55 in e36) {
      let k63 = e36[d55];
      k63 in f85 || (f85[k63] = []), f85[k63].push(i88[d55]);
    }
    let w45 = {};
    for (let d55 in n67) {
      let k63 = n67[d55];
      k63 in w45 || (w45[k63] = []), w45[k63].push(r56[d55]);
    }
    let b58 = Object.keys(w45).map((d55) => parseInt(d55, 10)).sort(zi);
    this.layers = [];
    for (let d55 of b58) {
      let k63 = w45[d55];
      k63.sort((A35, z32) => {
        let D42 = o80[A35.id], q25 = o80[z32.id];
        return D42 < q25 ? -1 : D42 > q25 ? 1 : 0;
      });
      for (let A35 of k63) A35 instanceof s76 && this.internalContainerRefs.push(A35), this.layers.push(A35);
    }
    this.layersByDepth = w45, b58 = Object.keys(f85).map((d55) => parseInt(d55, 10)).sort(zi);
    let m96 = this.inputs.slice(), g72 = [];
    for (let d55 of b58) for (let k63 of f85[d55]) {
      let A35 = k63.outboundLayer;
      if (A35 != null) {
        for (let z32 of k63.inputTensors) if (m96.indexOf(z32) === -1) throw new ht6(`Graph disconnected: cannot obtain value for tensor ${z32} at layer "${A35.name}". The following previous layers were accessed without issue: ${g72}`);
        for (let z32 of k63.outputTensors) m96.push(z32);
        g72.push(A35.name);
      }
    }
    this.nodesByDepth = f85;
    let x76 = this.layers.map((d55) => d55.name);
    for (let d55 of x76) {
      let k63 = x76.filter((A35) => A35 === d55).length;
      if (k63 !== 1) throw new ht6(`The name "${d55}" is used ${k63} times in the model. All layer names should be unique. Layer names: ` + JSON.stringify(x76));
    }
    this.outboundNodes = [], this.inboundNodes = [], new Gt3({ outboundLayer: this, inboundLayers: [], nodeIndices: [], tensorIndices: [], inputTensors: this.inputs, outputTensors: this.outputs, inputMasks: this.inputs.map((d55) => null), outputMasks: this.outputs.map((d55) => null), inputShapes: this.inputs.map((d55) => d55.shape), outputShapes: this.outputs.map((d55) => d55.shape) }), this.built = true, this._refCount = 1;
  }
  assertNotDisposed() {
    if (this._refCount === 0) throw new Error(`Container '${this.name}' is already disposed.`);
  }
  dispose() {
    this.assertNotDisposed();
    let t67 = { refCountAfterDispose: null, numDisposedVariables: 0 };
    if (--this._refCount === 0) {
      for (let e36 of this.layers) t67.numDisposedVariables += e36.dispose().numDisposedVariables;
      for (let e36 of this.internalContainerRefs) t67.numDisposedVariables += e36.dispose().numDisposedVariables;
    }
    return t67.refCountAfterDispose = this._refCount, t67;
  }
  get trainable() {
    return this.trainable_;
  }
  set trainable(t67) {
    this.layers.forEach((e36) => {
      e36._trainableWeights.forEach((i88) => i88.trainable = t67);
    }), this.trainable_ = t67;
  }
  get trainableWeights() {
    if (this._trainableWeights.length > 0) throw new c102("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");
    if (!this.trainable) return [];
    let t67 = [];
    for (let e36 of this.layers) t67 = t67.concat(e36.trainableWeights);
    return t67;
  }
  get nonTrainableWeights() {
    let t67 = [];
    for (let e36 of this.layers) t67.push(...e36.nonTrainableWeights);
    if (!this.trainable) {
      let e36 = [];
      for (let i88 of this.layers) e36.push(...i88.trainableWeights);
      return e36.concat(t67);
    }
    return t67;
  }
  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }
  loadWeights(t67, e36 = true) {
    let i88 = {}, n67 = 0, r56 = wu(t67);
    r56 && this.parseWeights(t67);
    for (let a71 of this.layers) for (let [l80, u86] of a71.weights.entries()) {
      let h74 = r56 ? `${u86.name.split("/").slice(0, -1).join("/") + "/"}${l80}` : u86.originalName;
      if (i88[h74] != null) throw new c102(`Duplicate weight name: ${h74}`);
      i88[h74] = u86, n67++;
    }
    let o80 = [];
    for (let a71 in t67) {
      let l80 = a71;
      if (i88[a71] == null) {
        let u86 = a71.split("/");
        l80 = u86.slice(0, -2).concat([u86[u86.length - 1]]).join("/");
      }
      if (i88[l80] != null) o80.push([i88[l80], t67[a71]]);
      else if (e36) throw new c102(`Provided weight data has no target variable: ${a71}`);
      delete i88[l80];
    }
    if (e36) {
      let a71 = [];
      for (let l80 in i88) a71.push(l80);
      if (a71.length > 0) throw new c102(`${a71.length} of ${n67} weights are not set: ${a71}`);
    }
    is2(o80);
  }
  parseWeights(t67) {
    for (let e36 in Object.keys(t67)) {
      let i88 = e36.split("/"), n67 = ["vars", "layer_checkpoint_dependencies"], r56 = i88.map((o80) => o80.startsWith("_") ? o80.slice(1) : o80).filter((o80) => !n67.includes(o80)).join("/");
      r56 !== e36 && (t67[r56] = t67[e36], delete t67[e36]);
    }
  }
  updatedConfig() {
    let t67 = this.getConfig(), e36 = {};
    return e36.className = this.getClassName(), e36.config = t67, e36.kerasVersion = `tfjs-layers ${$i}`, e36.backend = "TensorFlow.js", e36;
  }
  toJSON(t67, e36 = true) {
    let i88 = In(this.updatedConfig());
    return e36 ? JSON.stringify(i88) : i88;
  }
  call(t67, e36) {
    return g4(() => {
      t67 = $36(t67);
      let i88 = new Vt2();
      for (let n67 = 0; n67 < this.inputs.length; ++n67) i88.add(this.inputs[n67], t67[n67]);
      return Se4(this.outputs, i88, e36);
    });
  }
  computeMask(t67, e36) {
    return g4(() => {
      t67 = $36(t67);
      let i88;
      return e36 == null ? i88 = zt3(null, t67.length) : i88 = $36(e36), this.runInternalGraph(t67, i88)[1];
    });
  }
  computeOutputShape(t67) {
    let e36 = es2(t67);
    if (e36.length !== this.inputLayers.length) throw new c102(`Invalid inputShape argument ${t67}: model has ${this.inputLayers.length} tensor inputs.`);
    let i88 = {};
    for (let a71 = 0; a71 < e36.length; a71++) {
      let l80 = this.inputLayers[a71], u86 = e36[a71], h74 = l80.name + "_0_0";
      i88[h74] = u86;
    }
    let n67 = Object.keys(this.nodesByDepth).map((a71) => parseInt(a71, 10)).sort(zi);
    if (n67.length > 1) for (let a71 of n67) {
      let l80 = this.nodesByDepth[a71];
      for (let u86 of l80) {
        let h74 = u86.outboundLayer;
        if (this.inputLayers.map((m96) => m96.id).indexOf(h74.id) !== -1) continue;
        let p103 = [];
        for (let m96 = 0; m96 < u86.inboundLayers.length; m96++) {
          let g72 = u86.inboundLayers[m96], x76 = u86.nodeIndices[m96], d55 = u86.tensorIndices[m96], k63 = `${g72.name}_${x76}_${d55}`, A35 = i88[k63];
          p103.push(A35);
        }
        let f85 = h74.computeOutputShape(st6(p103)), w45 = es2(f85), b58 = h74.inboundNodes.indexOf(u86);
        for (let m96 = 0; m96 < w45.length; m96++) {
          let g72 = `${h74.name}_${b58}_${m96}`;
          i88[g72] = w45[m96];
        }
      }
    }
    let r56 = [], o80 = [];
    for (let a71 = 0; a71 < this.outputLayers.length; a71++) {
      let l80 = this.outputLayers[a71], u86 = this.outputLayersNodeIndices[a71], h74 = this.outputLayersTensorIndices[a71], p103 = `${l80.name}_${u86}_${h74}`;
      o80.push(p103);
    }
    for (let a71 = 0; a71 < o80.length; a71++) {
      let l80 = o80[a71];
      It2(l80 in i88), r56.push(i88[l80]);
    }
    return st6(r56);
  }
  runInternalGraph(t67, e36) {
    e36 == null && (e36 = zt3(null, t67.length));
    let i88 = {};
    for (let l80 = 0; l80 < this.inputs.length; ++l80) {
      let u86 = this.inputs[l80], h74 = t67[l80], p103 = e36[l80];
      i88[u86.id] = [h74, p103];
    }
    let n67 = Object.keys(this.nodesByDepth).map((l80) => parseInt(l80, 10)).sort(zi);
    for (let l80 of n67) {
      let u86 = this.nodesByDepth[l80];
      for (let h74 of u86) {
        let p103 = h74.outboundLayer, f85 = h74.inputTensors, w45 = h74.outputTensors, b58 = new Array();
        for (let m96 of f85) m96.id in i88 && b58.push(i88[m96.id]);
        if (b58.length === f85.length) {
          let m96 = {}, g72, x76, d55, k63;
          if (h74.callArgs != null && (m96 = h74.callArgs), b58.length === 1) {
            let [A35, z32] = b58[0];
            m96.mask == null && (m96.mask = z32), d55 = $36(p103.call(A35, m96)), k63 = $36(p103.computeMask(A35, z32)), g72 = [A35], x76 = [z32];
          } else g72 = b58.map((A35) => A35[0]), x76 = b58.map((A35) => A35[1]), m96.mask == null && (m96.mask = x76), d55 = $36(p103.call(g72, m96)), k63 = $36(p103.computeMask(g72, x76));
          if (p103.activityRegularizer) throw new S44("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");
          for (let A35 = 0; A35 < w45.length; ++A35) {
            let z32 = w45[A35], D42 = d55[A35], q25 = k63[A35];
            i88[z32.id] = [D42, q25];
          }
        }
      }
    }
    let r56 = [], o80 = [], a71 = [];
    for (let l80 of this.outputs) {
      It2(l80.id in i88, `Could not compute output ${l80.name} : ${l80.id}`);
      let [u86, h74] = i88[l80.id];
      a71.push(u86.shape), r56.push(u86), o80.push(h74);
    }
    return [r56, o80, a71];
  }
  buildNodeConversionMap(t67) {
    let e36 = {}, i88;
    for (let n67 of this.layers) {
      i88 = n67 instanceof s76 ? 1 : 0;
      for (let r56 = 0; r56 < n67.inboundNodes.length; r56++) {
        let o80 = s76.nodeKey(n67, r56);
        this.containerNodes.has(o80) && (e36[o80] = i88, i88 += 1);
      }
    }
    return e36;
  }
  getLayer(t67, e36) {
    if (e36 != null) return this.findLayer(e36);
    if (t67 == null) throw new c102("Provide either a layer name or layer index");
    if (typeof t67 == "number") return this.findLayer(t67);
    for (let i88 of this.layers) if (i88.name === t67) return i88;
    throw new c102(`No such layer: ${t67}`);
  }
  findLayer(t67) {
    if (this.layers.length <= t67) throw new c102(`Was asked to retrieve layer at index ${t67}, but model only has ${this.layers.length} layer(s).`);
    return this.layers[t67];
  }
  calculateLosses() {
    return g4(() => {
      let t67 = [];
      for (let e36 of this.layers) for (let i88 = 0; i88 < e36.inboundNodes.length; ++i88) {
        let n67 = s76.nodeKey(e36, i88);
        this.containerNodes.has(n67) && t67.push(...e36.calculateLosses());
      }
      return t67;
    });
  }
  getConfig() {
    let t67 = { name: this.name }, e36 = this.buildNodeConversionMap(this.layers), i88 = [];
    for (let o80 of this.layers) {
      let a71 = o80.getClassName(), l80 = o80.getConfig(), u86 = [];
      for (let p103 = 0; p103 < o80.inboundNodes.length; p103++) {
        let f85 = o80.inboundNodes[p103], w45 = s76.nodeKey(o80, p103), b58 = {};
        if (this.containerNodes.has(w45)) {
          if (f85.callArgs) try {
            JSON.stringify(f85.callArgs), b58 = f85.callArgs;
          } catch {
            console.warn(`Layer ${o80.name} was passed non-serializable keyword arguments: ${f85.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`), b58 = {};
          }
          if (f85.inboundLayers.length > 0) {
            let m96 = [];
            for (let g72 = 0; g72 < f85.inboundLayers.length; g72++) {
              let x76 = f85.inboundLayers[g72], d55 = f85.nodeIndices[g72], k63 = f85.tensorIndices[g72], A35 = s76.nodeKey(x76, d55), z32 = e36[A35];
              z32 == null && (z32 = 0), m96.push([x76.name, z32, k63, b58]);
            }
            u86.push(m96);
          }
        }
      }
      let h74 = {};
      h74.name = o80.name, h74.className = a71, h74.config = l80, h74.inboundNodes = u86, i88.push(h74);
    }
    t67.layers = i88;
    let n67 = [];
    for (let o80 = 0; o80 < this.inputLayers.length; o80++) {
      let a71 = this.inputLayers[o80], l80 = this.inputLayersNodeIndices[o80], u86 = s76.nodeKey(a71, l80);
      if (!this.containerNodes.has(u86)) continue;
      let h74 = e36[u86];
      h74 == null && (h74 = 0);
      let p103 = this.inputLayersTensorIndices[o80];
      n67.push([a71.name, h74, p103]);
    }
    t67.inputLayers = n67;
    let r56 = [];
    for (let o80 = 0; o80 < this.outputLayers.length; o80++) {
      let a71 = this.outputLayers[o80], l80 = this.outputLayersNodeIndices[o80], u86 = s76.nodeKey(a71, l80);
      if (!this.containerNodes.has(u86)) continue;
      let h74 = e36[u86];
      h74 == null && (h74 = 0);
      let p103 = this.outputLayersTensorIndices[o80];
      r56.push([a71.name, h74, p103]);
    }
    return t67.outputLayers = r56, t67;
  }
  static fromConfig(t67, e36, i88 = {}, n67 = false) {
    let r56 = {}, o80 = {};
    function a71(g72, x76) {
      g72.name in o80 ? o80[g72.name].push(x76) : o80[g72.name] = [x76];
    }
    function l80(g72, x76) {
      let d55 = [], k63;
      for (let A35 of x76) {
        let z32 = A35[0], D42 = A35[1], q25 = A35[2];
        if (k63 = A35[3] == null ? {} : A35[3], !(z32 in r56)) {
          a71(g72, x76);
          return;
        }
        let R26 = r56[z32];
        if (R26.inboundNodes.length <= D42) {
          a71(g72, x76);
          return;
        }
        let O21 = R26.inboundNodes[D42];
        d55.push(O21.outputTensors[q25]);
      }
      d55.length > 0 && g72.apply(st6(d55), k63);
    }
    function u86(g72) {
      let x76 = g72.name, d55 = yt5(g72, e36.customObjects != null ? e36.customObjects : {});
      d55.setFastWeightInitDuringBuild(n67), r56[x76] = d55, g72.inboundNodes.forEach((A35) => {
        if (!(A35 instanceof Array)) throw new c102(`Corrupted configuration, expected array for nodeData: ${A35}`);
        a71(d55, A35);
      });
    }
    let h74 = e36.name, p103 = e36.layers;
    for (let g72 of p103) u86(g72);
    for (; !Jr(o80); ) for (let g72 of p103) {
      let x76 = r56[g72.name];
      if (x76.name in o80) {
        let d55 = o80[x76.name];
        delete o80[x76.name];
        for (let k63 of d55) l80(x76, k63);
      }
    }
    let f85 = [], w45 = [], b58 = e36.inputLayers;
    for (let g72 of b58) {
      let x76 = g72[0], d55 = g72[1], k63 = g72[2];
      It2(x76 in r56);
      let z32 = r56[x76].inboundNodes[d55].outputTensors;
      f85.push(z32[k63]);
    }
    let m96 = e36.outputLayers;
    for (let g72 of m96) {
      let x76 = g72[0], d55 = g72[1], k63 = g72[2];
      It2(x76 in r56);
      let z32 = r56[x76].inboundNodes[d55].outputTensors;
      w45.push(z32[k63]);
    }
    return new t67({ inputs: f85, outputs: w45, name: h74 });
  }
  get stateful() {
    if (this._stateful) throw new c102("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");
    for (let t67 of this.layers) if (t67.stateful) return true;
    return false;
  }
  resetStates() {
    g4(() => {
      this.layers.forEach((t67) => {
        t67.stateful && t67.resetStates();
      });
    });
  }
};
function Su(s84, t67, e36) {
  let i88 = t67.length;
  if (s84 == null || Array.isArray(s84) && s84.length === 0) return t67.map((n67) => null);
  if (i88 === 1) return Array.isArray(s84) && s84.length === 1 ? s84 : typeof s84 == "object" && t67[0] in s84 ? [s84[t67[0]]] : [s84];
  if (Array.isArray(s84)) {
    if (s84.length !== i88) throw new Error(`Provided ${e36} is an array of ${s84.length} element(s), but the model has ${i88} outputs. Make sure a set of weights is provided for each model output.`);
    return s84;
  } else if (typeof s84 == "object" && Object.keys(s84).length > 0 && typeof s84[Object.keys(s84)[0]] == "object") {
    let n67 = [];
    return t67.forEach((r56) => {
      r56 in s84 ? n67.push(s84[r56]) : n67.push(null);
    }), n67;
  } else throw new Error(`The model has multiple (${i88}) outputs, so ${e36} must be either an array with ${i88} elements or an object with ${t67} keys. Provided ${e36} not understood: ${JSON.stringify(s84)}`);
}
function zn2(s84, t67) {
  return Su(s84, t67, "classWeight");
}
async function Cn2(s84, t67, e36, i88) {
  if (t67 != null || i88 != null) throw new Error("Support sampleWeight is not implemented yet");
  if (e36 != null) {
    let n67 = g4(() => {
      if (s84.shape.length === 1) return x11(s84);
      if (s84.shape.length === 2) {
        if (s84.shape[1] > 1) return u9(s84, 1);
        if (s84.shape[1] === 1) return h9(s84, [s84.shape[0]]);
        throw new Error(`Encountered unexpected last-dimension size (${s84.shape[1]}) during handling of class weights. The size is expected to be >= 1.`);
      } else throw new Error(`Unexpected rank of target (y) tensor (${s84.rank}) during handling of class weights. The rank is expected to be 1 or 2.`);
    }), r56 = Array.from(await n67.data());
    E4(n67);
    let o80 = [];
    return r56.forEach((a71) => {
      if (e36[a71] == null) throw new Error(`classWeight must contain all classes in the training data. The class ${a71} exists in the data but not in classWeight`);
      o80.push(e36[a71]);
    }), m25(o80, "float32");
  } else return null;
}
function Uo2(s84, t67) {
  return y8(s84, t67);
}
var Lu = 32;
function jo2(s84, t67) {
  let e36, i88, n67 = t67;
  e36 = n67.xs, i88 = n67.ys, util_exports.assert(e36 != null && i88 != null, () => `A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${t67}`);
  let r56 = Po2("input", s84.inputNames, e36), o80 = Po2("output", s84.outputNames, i88), a71 = r56[0].shape[0];
  util_exports.assert(r56.length === s84.inputs.length, () => `LayersModel has ${s84.inputs.length} inputs, but the dataset provides ${r56.length} inputs.  (Expected input keys: ${JSON.stringify(s84.inputNames)})`), util_exports.assert(o80.length === s84.outputs.length, () => `LayersModel has ${s84.outputs.length} outputs, but the dataset provides ${o80.length} outputs.  (Expected output keys: ${JSON.stringify(s84.outputNames)})`);
  for (let l80 = 0; l80 < r56.length; l80++) util_exports.assert(r56[l80].shape[0] === a71, () => `Batch size mismatch: input ${s84.inputNames[l80]} has ${r56[l80].shape[0]}; expected  ${a71} based on input ${s84.inputNames[0]}.`);
  for (let l80 = 0; l80 < o80.length; l80++) util_exports.assert(o80[l80].shape[0] === a71, () => `Batch size mismatch: output ${s84.outputNames[l80]} has ${o80[l80].shape[0]}; expected  ${a71} based on input ${s84.inputNames[0]}.`);
  return { xs: r56, ys: o80 };
}
function Po2(s84, t67, e36) {
  if (e36 instanceof o5) return [e36];
  if (Array.isArray(e36)) return util_exports.assert(e36.length === t67.length, () => `Received an array of ${e36.length} Tensors, but expected ${t67.length} to match the ${s84} keys ${t67}.`), e36;
  {
    let i88 = [];
    for (let n67 of t67) {
      if (e36[n67] == null) throw new c102(`The feature data generated by the dataset lacks the required ${s84} key '${n67}'.`);
      i88.push(e36[n67]);
    }
    return i88;
  }
}
function Tu(s84) {
  if (s84.length === 3) throw new S44("Validation with sample weights is not implemented yet.");
  return { xs: s84[0], ys: s84[1] };
}
async function qo2(s84, t67, e36) {
  let i88 = e36.batchesPerEpoch != null;
  if (util_exports.assert(s84.optimizer != null, () => "You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."), util_exports.assert(e36 != null, () => "For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."), util_exports.assert(e36.epochs != null && e36.epochs > 0 && Number.isInteger(e36.epochs), () => `For fitDataset(), config.epochs is expected to be a positive integer, but got ${e36.epochs}`), util_exports.assert(!i88 || e36.batchesPerEpoch > 0 && Number.isInteger(e36.batchesPerEpoch), () => `For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${e36.batchesPerEpoch}`), util_exports.assert(e36.validationSplit == null, () => "`validationSplit` is not supported by `fitDataset()`. Use validationData instead."), s84.isTraining) throw new Error("Cannot start training because another fit() call is ongoing.");
  s84.isTraining = true;
  try {
    let n67 = e36.validationData != null, r56, o80;
    if (n67) if (Ko2(e36.validationData)) util_exports.assert(e36.validationBatches == null || e36.validationBatches > 0 && Number.isInteger(e36.validationBatches), () => `For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${e36.validationBatches}`);
    else {
      let g72 = Tu(e36.validationData);
      r56 = g72.xs, o80 = g72.ys;
    }
    let a71 = s84.makeTrainFunction(), l80 = s84.getDedupedMetricsNames(), u86;
    n67 ? u86 = l80.slice().concat(l80.map((g72) => "val_" + g72)) : u86 = l80.slice();
    let h74 = mn(e36.callbacks, e36.yieldEvery), p103 = e36.verbose == null ? 1 : e36.verbose, { callbackList: f85, history: w45 } = gn(h74, p103, e36.epochs, null, null, Eu(t67, e36), null, n67, u86);
    f85.setModel(s84), s84.history = w45, await f85.onTrainBegin(), s84.stopTraining_ = false;
    let b58 = e36.initialEpoch == null ? 0 : e36.initialEpoch, m96 = await t67.iterator();
    for (; b58 < e36.epochs; ) {
      let g72 = {};
      await f85.onEpochBegin(b58);
      let x76 = 0, d55 = 0;
      for (i88 || (m96 = await t67.iterator()); !i88 || x76 < e36.batchesPerEpoch; ) {
        let k63 = await m96.next();
        if (i88 && k63.done) {
          console.warn(`You provided \`batchesPerEpoch\` as ${e36.batchesPerEpoch}, but your dataset iterator ran out of data after ${x76} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, ${e36.batchesPerEpoch * e36.epochs} batches). You may need to use the repeat() function when building your dataset.`);
          break;
        }
        if (k63.value != null) {
          let { xs: A35, ys: z32 } = jo2(s84, k63.value), D42 = {};
          D42.batch = d55, D42.size = A35[0].shape[0], await f85.onBatchBegin(d55, D42);
          let q25 = [];
          if (e36.classWeight != null) {
            let F32 = zn2(e36.classWeight, s84.outputNames);
            for (let ct4 = 0; ct4 < F32.length; ++ct4) q25.push(await Cn2(z32[ct4], null, F32[ct4]));
          }
          let R26 = A35.concat(z32).concat(q25), O21 = a71(R26);
          E4(R26);
          for (let F32 = 0; F32 < l80.length; ++F32) {
            let ct4 = l80[F32], ne7 = O21[F32];
            D42[ct4] = ne7, N3(ne7);
          }
          await f85.onBatchEnd(d55, D42), hn2(D42), d55++, x76++;
        }
        if (i88 ? x76 >= e36.batchesPerEpoch : k63.done) {
          if (n67) {
            let A35;
            Ko2(e36.validationData) ? A35 = $36(await s84.evaluateDataset(e36.validationData, { batches: e36.validationBatches })) : A35 = $36(s84.evaluate(r56, o80, { batchSize: e36.validationBatchSize == null ? Lu : e36.validationBatchSize, verbose: 0 }));
            for (let z32 = 0; z32 < s84.metricsNames.length; ++z32) g72[`val_${s84.metricsNames[z32]}`] = A35[z32];
          }
          break;
        }
        if (s84.stopTraining_) break;
      }
      if (await f85.onEpochEnd(b58, g72), b58++, s84.stopTraining_) break;
    }
    return await f85.onTrainEnd(), await s84.history.syncData(), s84.history;
  } finally {
    s84.isTraining = false;
  }
}
function Eu(s84, t67) {
  let e36 = null;
  return t67.batchesPerEpoch != null ? e36 = t67.batchesPerEpoch : Number.isFinite(s84.size) && (e36 = s84.size), e36;
}
function Ko2(s84) {
  return typeof s84.iterator == "function";
}
function Du(s84) {
  return typeof s84.next == "function";
}
async function Ho2(s84, t67, e36) {
  e36 = e36 || {};
  let i88 = e36.batches != null, n67 = s84.testFunction, r56 = [];
  if (e36.verbose > 0) throw new S44("Verbose mode is not implemented yet.");
  util_exports.assert(!i88 || e36.batches > 0 && Number.isInteger(e36.batches), () => `Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(e36.batches)}`);
  let o80 = Du(t67) ? t67 : await t67.iterator(), a71 = 0, l80 = 0;
  for (; !i88 || l80 < e36.batches; ) {
    let u86 = await o80.next();
    if (r56 = g4(() => {
      if (u86.value) {
        let { xs: h74, ys: p103 } = jo2(s84, u86.value), f85 = h74.concat(p103), w45 = g4(() => n67(f85));
        if (E4(f85), l80 === 0) for (let m96 = 0; m96 < w45.length; ++m96) r56.push(m21(0));
        let b58 = f85[0].shape[0];
        for (let m96 = 0; m96 < w45.length; ++m96) {
          let g72 = w45[m96], x76 = r56[m96];
          r56[m96] = g4(() => T7(r56[m96], y8(b58, g72))), l80 > 0 && E4(x76);
        }
        E4(w45), a71 += b58, ++l80;
      }
      return r56;
    }), u86.done) {
      i88 && console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${e36.batches} batches). You may need to use the repeat() function when building your dataset.`);
      break;
    }
  }
  for (let u86 = 0; u86 < r56.length; ++u86) {
    let h74 = r56[u86];
    r56[u86] = D6(r56[u86], a71), E4(h74);
  }
  return st6(r56);
}
function Sn2(s84) {
  util_exports.assert(s84 > 0 && Number.isInteger(s84), () => `batchSize is required to be a positive integer, but got ${s84}`);
}
function ms(s84, t67, e36) {
  return s84 == null ? [null] : Array.isArray(s84) ? s84.map((i88) => Ht3(i88, t67, e36 - t67)) : Ht3(s84, t67, e36 - t67);
}
function vn(s84, t67) {
  return g4(() => s84 == null ? null : Array.isArray(s84) ? s84.map((e36) => vn(e36, t67)) : sn2(s84, t67.dtype === "int32" ? t67 : w12(t67, "int32")));
}
function Ln(s84, t67) {
  let e36 = [], i88 = 0, n67 = null;
  for (; i88 < s84; ) n67 = i88 + t67, n67 >= s84 && (n67 = s84), e36.push([i88, n67]), i88 = n67;
  return e36;
}
function Lr(s84) {
  let t67 = [];
  s84 instanceof o5 && (s84 = [s84]);
  for (let e36 = 0; e36 < s84.length; ++e36) {
    let i88 = s84[e36];
    if (i88.rank === 1) t67.push(Zt3(i88, 1));
    else {
      if (i88.rank === 0) throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");
      t67.push(i88);
    }
  }
  return t67;
}
function Et3(s84, t67) {
  if (s84 == null) return;
  let e36 = [];
  if (t67 instanceof o5) e36.push(t67.id);
  else if (Array.isArray(t67)) t67.forEach((n67) => e36.push(n67.id));
  else if (t67 != null) for (let n67 in t67) {
    let r56 = t67[n67];
    e36.push(r56.id);
  }
  let i88 = [];
  if (s84 instanceof o5) e36.indexOf(s84.id) === -1 && i88.push(s84);
  else if (Array.isArray(s84)) s84.forEach((n67) => {
    e36.indexOf(n67.id) === -1 && i88.push(n67);
  });
  else if (s84 != null) for (let n67 in s84) {
    let r56 = s84[n67];
    e36.indexOf(r56.id) === -1 && i88.push(r56);
  }
  i88.forEach((n67) => {
    n67.isDisposed || n67.dispose();
  });
}
function Mu(s84) {
  return s84 instanceof o5;
}
function Tr(s84) {
  return Array.isArray(s84);
}
function Zo2(s84) {
  return !Mu(s84) && !Tr(s84);
}
function Go2(s84, t67, e36, i88 = true, n67 = "") {
  if (t67 == null || t67.length === 0) {
    if (s84 != null) {
      let o80 = false;
      if (Tr(s84) && s84.length > 0) o80 = true;
      else if (Zo2(s84)) {
        for (let a71 in s84) if (s84.hasOwnProperty(a71)) {
          o80 = true;
          break;
        }
      } else o80 = true;
      if (o80) throw new c102(`Error when checking model ${n67} expected no data, but got ${s84}`);
    }
    return [];
  }
  if (s84 == null) return t67.map((o80) => null);
  let r56;
  if (Zo2(s84)) {
    s84 = s84, r56 = [];
    for (let o80 of t67) {
      if (s84[o80] == null) throw new c102(`No data provided for "${o80}". Need data for each key in: ${t67}`);
      r56.push(s84[o80]);
    }
  } else if (Tr(s84)) {
    if (s84 = s84, s84.length !== t67.length) throw new c102(`Error when checking model ${n67}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${t67.length} Tensor(s), but instead got the following list of Tensor(s): ${s84}`);
    r56 = s84;
  } else {
    if (s84 = s84, t67.length > 1) throw new c102(`The model ${n67} expects ${t67.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${s84.shape}`);
    r56 = [s84];
  }
  if (r56 = Lr(r56), e36 != null) for (let o80 = 0; o80 < t67.length; ++o80) {
    if (e36[o80] == null) continue;
    let a71 = r56[o80];
    if (a71.shape.length !== e36[o80].length) throw new c102(`Error when checking ${n67}: expected ${t67[o80]} to have ${e36[o80].length} dimension(s). but got array with shape ${a71.shape}`);
    for (let l80 = 0; l80 < e36[o80].length; ++l80) {
      if (l80 === 0 && !i88) continue;
      let u86 = a71.shape[l80], h74 = e36[o80][l80];
      if (h74 != null && h74 >= 0 && u86 !== h74) throw new c102(`${n67} expected a batch of elements where each example has shape [${e36[o80].slice(1, e36[o80].length)}] (i.e.,tensor shape [*,${e36[o80].slice(1, e36[o80].length)}]) but the ${n67} received an input with ${a71.shape[0]} examples, each with shape [${a71.shape.slice(1, a71.shape.length)}] (tensor shape [${a71.shape}])`);
    }
  }
  return r56;
}
function Ru(s84, t67, e36) {
  let i88 = St3(s84.map((r56) => r56.shape[0]));
  i88.sort();
  let n67 = St3(t67.map((r56) => r56.shape[0]));
  if (n67.sort(), i88.length > 1) throw new c102(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(s84.map((r56) => r56.shape))}`);
  if (n67.length > 1) throw new c102(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(t67.map((r56) => r56.shape))}`);
  if (i88.length > 0 && n67.length > 0 && !util_exports.arraysEqual(i88, n67)) throw new c102(`Input Tensors should have the same number of samples as target Tensors. Found ${i88[0]} input sample(s) and ${n67[0]} target sample(s).`);
}
function $u(s84, t67, e36) {
  let i88 = [Pt3, ps, Le2];
  for (let n67 = 0; n67 < s84.length; ++n67) {
    let r56 = s84[n67], o80 = t67[n67], a71 = e36[n67];
    if (o80 != null) {
      if (o80 === Le2 && r56.shape[r56.shape.length - 1] === 1) throw new c102(`You are passing a target array of shape ${r56.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);
      if (i88.indexOf(o80) !== -1) {
        let l80 = r56.shape.slice(1), u86 = a71.slice(1);
        for (let h74 = 0; h74 < l80.length; ++h74) {
          let p103 = l80[h74], f85 = u86[h74];
          if (f85 != null && p103 !== f85) throw new c102(`A target Tensor with shape ${r56.shape} was passed for an output of shape ${a71}, while using a loss function that expects targets to have the same shape as the output.`);
        }
      }
    }
  }
}
function Yo3(s84, t67, e36, i88 = true, n67 = "") {
  let r56;
  if (Array.isArray(s84)) {
    if (s84.length !== t67.length) throw new c102(`Error when checking model ${n67}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${t67.length} Tensor(s), but instead got ${s84.length} Tensors(s).`);
    r56 = s84;
  } else {
    if (t67.length > 1) throw new c102(`The model expects ${t67.length} ${n67} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(s84.shape)}.`);
    r56 = [s84];
  }
  if (e36 != null) for (let o80 = 0; o80 < t67.length; ++o80) {
    if (e36[o80] == null) continue;
    let a71 = r56[o80];
    if (a71.shape.length !== e36[o80].length) throw new c102(`Error when checking ${n67}: expected ${t67[o80]} to have ${e36[o80].length} dimension(s), but got array with shape ${JSON.stringify(a71.shape)}`);
    for (let l80 = 0; l80 < e36[o80].length; ++l80) {
      if (l80 === 0 && !i88) continue;
      let u86 = a71.shape[l80], h74 = e36[o80][l80];
      if (h74 != null && h74 !== u86) throw new c102(`Error when checking ${n67}: expected ${t67[o80]} to have shape ${JSON.stringify(e36[o80])} but got array with shape ${JSON.stringify(a71.shape)}.`);
    }
  }
}
function Fu(s84, t67) {
  if (s84 == null || Array.isArray(s84) && s84.length === 0) return t67.map((i88) => []);
  let e36;
  if (typeof s84 == "string" || typeof s84 == "function") e36 = [s84];
  else if (Array.isArray(s84) || typeof s84 == "object") e36 = s84;
  else throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${s84}`);
  if (Array.isArray(e36)) return t67.map((i88) => e36);
  {
    let i88 = [];
    for (let n67 of t67) {
      let r56 = e36.hasOwnProperty(n67) ? e36[n67] : [];
      Array.isArray(r56) || (r56 = [r56]), i88.push(r56);
    }
    return i88;
  }
}
var Bu = "layers-model";
var xt2 = class extends Nn {
  constructor(t67) {
    super(t67), this.isTraining = false;
  }
  summary(t67, e36, i88 = console.log) {
    if (!this.built) throw new c102("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");
    Wo2(this, t67, e36, i88);
  }
  compile(t67) {
    if (t67.loss == null && (t67.loss = []), this.loss = t67.loss, typeof t67.optimizer == "string") this.optimizer_ = Bo2(t67.optimizer), this.isOptimizerOwned = true;
    else {
      if (!(t67.optimizer instanceof n15)) throw new c102("User-defined optimizer must be an instance of tf.Optimizer.");
      this.optimizer_ = t67.optimizer, this.isOptimizerOwned = false;
    }
    let e36 = [];
    if (!Array.isArray(t67.loss) && typeof t67.loss != "string" && typeof t67.loss != "function") {
      t67.loss = t67.loss;
      for (let o80 in t67.loss) if (this.outputNames.indexOf(o80) === -1) throw new c102(`Unknown entry in loss dictionary: "${o80}". Only expected the following keys: ${this.outputNames}`);
      for (let o80 of this.outputNames) t67.loss[o80] == null && console.warn(`Output "${o80}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${o80} during training`), e36.push(yn(t67.loss[o80]));
    } else if (Array.isArray(t67.loss)) {
      if (t67.loss.length !== this.outputs.length) throw new c102(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${t67.loss}.`);
      e36 = t67.loss.map((a71) => yn(a71));
    } else {
      let o80 = yn(t67.loss);
      this.outputs.forEach((a71) => {
        e36.push(o80);
      });
    }
    this.lossFunctions = e36, this.feedOutputNames = [], this.feedOutputShapes = [], this.feedLossFns = [];
    for (let o80 = 0; o80 < this.outputs.length; ++o80) {
      let a71 = this.internalOutputShapes[o80], l80 = this.outputNames[o80];
      this.feedOutputNames.push(l80), this.feedOutputShapes.push(a71), this.feedLossFns.push(this.lossFunctions[o80]);
    }
    let i88 = [];
    this.metrics = t67.metrics, this.metricsNames = ["loss"], this.metricsTensors = [], Ot4("loss", () => {
      for (let o80 = 0; o80 < this.outputs.length; ++o80) {
        if (i88.indexOf(o80) !== -1) continue;
        let a71 = this.lossFunctions[o80];
        this.outputs.length > 1 && (this.metricsTensors.push([a71, o80]), this.metricsNames.push(this.outputNames[o80] + "_loss"));
      }
    });
    let n67 = Fu(t67.metrics, this.outputNames), r56 = (o80, a71, l80) => {
      this.outputNames.length > 1 && (a71 = this.outputNames[o80] + "_" + a71), this.metricsNames.push(a71), this.metricsTensors.push([l80, o80]);
    };
    Ot4("metric", () => {
      for (let o80 = 0; o80 < this.outputs.length; ++o80) {
        if (i88.indexOf(o80) !== -1) continue;
        let a71 = n67[o80];
        ((u86) => {
          let h74 = "", p103, f85, w45;
          for (let b58 of u86) {
            if (typeof b58 == "string" && ["accuracy", "acc", "crossentropy", "ce"].indexOf(b58) !== -1) {
              let g72 = this.internalOutputShapes[o80];
              g72[g72.length - 1] === 1 || this.lossFunctions[o80] === ps ? ["accuracy", "acc"].indexOf(b58) !== -1 ? f85 = Oi : ["crossentropy", "ce"].indexOf(b58) !== -1 && (f85 = wn) : this.lossFunctions[o80] === hs3 ? ["accuracy", "acc"].indexOf(b58) !== -1 ? f85 = xn2 : ["crossentropy", "ce"].indexOf(b58) !== -1 && (f85 = zr) : ["accuracy", "acc"].indexOf(b58) !== -1 ? f85 = _i : ["crossentropy", "ce"].indexOf(b58) !== -1 && (f85 = Mi);
              let x76;
              ["accuracy", "acc"].indexOf(b58) !== -1 ? x76 = "acc" : ["crossentropy", "ce"].indexOf(b58) !== -1 && (x76 = "ce"), w45 = f85, p103 = h74 + x76;
            } else w45 = $o2(b58), p103 = h74 + Ri(b58);
            let m96;
            Ot4(p103, () => {
              m96 = w45;
            }), r56(o80, p103, m96);
          }
        })(a71);
      }
    }), this.collectedTrainableWeights = this.trainableWeights;
  }
  checkTrainableWeightsConsistency() {
    this.collectedTrainableWeights != null && this.trainableWeights.length !== this.collectedTrainableWeights.length && console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?");
  }
  evaluate(t67, e36, i88 = {}) {
    let n67 = i88.batchSize == null ? 32 : i88.batchSize;
    Sn2(n67);
    let o80 = this.standardizeUserDataXY(t67, e36, true, n67);
    try {
      let a71 = o80[0].concat(o80[1]);
      this.makeTestFunction();
      let l80 = this.testFunction, u86 = this.testLoop(l80, a71, n67, i88.verbose, i88.steps);
      return st6(u86);
    } finally {
      Et3(o80[0], t67), Et3(o80[1], e36);
    }
  }
  async evaluateDataset(t67, e36) {
    return this.makeTestFunction(), Ho2(this, t67, e36);
  }
  checkNumSamples(t67, e36, i88, n67 = "steps") {
    let r56;
    if (i88 != null) {
      if (r56 = null, e36 != null) throw new c102(`If ${n67} is set, batchSize must be null or undefined.Got batchSize = ${e36}`);
    } else if (t67 != null) Array.isArray(t67) ? r56 = t67[0].shape[0] : r56 = t67.shape[0];
    else throw new c102(`Either the input data should have a defined shape, or ${n67} shoud be specified.`);
    return r56;
  }
  execute(t67, e36) {
    if (Array.isArray(e36) && e36.length === 0) throw new c102("`outputs` is an empty Array, which is not allowed.");
    let i88 = Array.isArray(e36), n67 = i88 ? e36 : [e36], r56 = this.retrieveSymbolicTensors(n67), o80 = new Vt2();
    if (t67 instanceof o5 && (t67 = [t67]), Array.isArray(t67)) {
      if (t67.length !== this.inputs.length) throw new c102(`The number of inputs provided (${t67.length}) does not match the number of inputs of this model (${this.inputs.length}).`);
      for (let l80 = 0; l80 < this.inputs.length; ++l80) o80.add(this.inputs[l80], t67[l80]);
    } else for (let l80 of this.inputs) {
      let u86 = t67[l80.name];
      if (u86 == null) throw new c102(`No value is provided for the model's input ${l80.name}`);
      o80.add(l80, u86);
    }
    let a71 = Se4(r56, o80);
    return i88 ? a71 : a71[0];
  }
  retrieveSymbolicTensors(t67) {
    let e36 = zt3(null, t67.length), i88 = t67.length;
    for (let n67 of this.layers) {
      let r56 = Array.isArray(n67.output) ? n67.output : [n67.output], o80 = r56.map((a71) => a71.name);
      for (let a71 = 0; a71 < t67.length; ++a71) {
        let l80 = o80.indexOf(t67[a71]);
        if (l80 !== -1 && (e36[a71] = r56[l80], i88--), i88 === 0) break;
      }
      if (i88 === 0) break;
    }
    if (i88 > 0) {
      let n67 = [];
      throw e36.forEach((r56, o80) => {
        r56 == null && n67.push(t67[o80]);
      }), new c102(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(n67)}`);
    }
    return e36;
  }
  predictLoop(t67, e36 = 32, i88 = false) {
    return g4(() => {
      let n67 = this.checkNumSamples(t67);
      if (i88) throw new S44("Verbose predictLoop() is not implemented yet.");
      let r56 = Ln(n67, e36), o80 = this.outputs.map((a71) => []);
      for (let a71 = 0; a71 < r56.length; ++a71) g4(() => {
        let u86 = r56[a71][0], h74 = r56[a71][1], p103 = ms(t67, u86, h74), f85 = [];
        if (Array.isArray(p103)) for (let b58 = 0; b58 < p103.length; ++b58) f85.push({ key: this.inputs[b58], value: p103[b58] });
        else f85.push({ key: this.inputs[0], value: p103 });
        let w45 = new Vt2(f85);
        return Se4(this.outputs, w45);
      }).forEach((u86, h74) => o80[h74].push(u86));
      return st6(o80.map((a71) => E9(a71, 0)));
    });
  }
  predict(t67, e36 = {}) {
    let i88 = Lr(t67);
    Yo3(i88, this.inputNames, this.feedInputShapes, false);
    try {
      let n67 = e36.batchSize == null ? 32 : e36.batchSize;
      return Sn2(n67), this.predictLoop(i88, n67);
    } finally {
      Et3(i88, t67);
    }
  }
  predictOnBatch(t67) {
    Yo3(t67, this.inputNames, this.feedInputShapes, true);
    let e36 = (Array.isArray(t67) ? t67[0] : t67).shape[0];
    return this.predictLoop(t67, e36);
  }
  standardizeUserDataXY(t67, e36, i88 = true, n67) {
    if (this.optimizer_ == null) throw new ht6("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");
    let r56 = [];
    for (let o80 = 0; o80 < this.feedOutputShapes.length; ++o80) {
      let a71 = this.feedOutputShapes[o80];
      this.feedLossFns[o80] === hs3 ? r56.push(a71.slice(0, a71.length - 1).concat([1])) : r56.push(a71);
    }
    if (t67 = Go2(t67, this.feedInputNames, this.feedInputShapes, false, "input"), e36 = Go2(e36, this.feedOutputNames, r56, false, "target"), Ru(t67, e36, null), $u(e36, this.feedLossFns, this.feedOutputShapes), this.stateful && n67 != null && n67 > 0 && t67[0].shape[0] % n67 !== 0) throw new c102(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${n67}. Found: ${t67[0].shape[0]} sample(s).`);
    return [t67, e36];
  }
  async standardizeUserData(t67, e36, i88, n67, r56 = true, o80) {
    let [a71, l80] = this.standardizeUserDataXY(t67, e36, r56, o80);
    if (i88 != null) throw new Error("sample weight is not supported yet.");
    let u86 = null;
    if (n67 != null) {
      let h74 = zn2(n67, this.outputNames);
      u86 = [];
      for (let p103 = 0; p103 < h74.length; ++p103) u86.push(await Cn2(l80[p103], null, h74[p103]));
    }
    return [a71, l80, u86];
  }
  testLoop(t67, e36, i88, n67 = 0, r56) {
    return g4(() => {
      let o80 = this.checkNumSamples(e36, i88, r56, "steps"), a71 = [];
      if (n67 > 0) throw new S44("Verbose mode is not implemented yet.");
      if (r56 != null) throw new S44("steps mode in testLoop() is not implemented yet");
      {
        let l80 = Ln(o80, i88), u86 = m25(ft5(0, o80));
        for (let h74 = 0; h74 < l80.length; ++h74) {
          let p103 = l80[h74][0], f85 = l80[h74][1], w45 = Ht3(u86, p103, f85 - p103), b58 = vn(e36, w45), m96 = t67(b58);
          if (h74 === 0) for (let g72 = 0; g72 < m96.length; ++g72) a71.push(m21(0));
          for (let g72 = 0; g72 < m96.length; ++g72) {
            let x76 = m96[g72];
            a71[g72] = T7(a71[g72], y8(f85 - p103, x76));
          }
        }
        for (let h74 = 0; h74 < a71.length; ++h74) a71[h74] = D6(a71[h74], o80);
      }
      return a71;
    });
  }
  getDedupedMetricsNames() {
    let t67 = this.metricsNames, e36 = [];
    for (let i88 = 0; i88 < t67.length; ++i88) {
      let n67 = t67[i88], r56 = n67;
      if (fr(t67, n67) > 1) {
        let o80 = fr(t67.slice(0, i88), n67);
        r56 += `_${o80}`;
      }
      e36.push(r56);
    }
    return e36;
  }
  makeTrainFunction() {
    return (t67) => {
      let e36 = [], i88 = t67.slice(0, this.inputs.length), n67 = t67.slice(this.inputs.length, this.inputs.length + this.outputs.length), r56 = t67.slice(this.inputs.length + this.outputs.length, this.inputs.length + this.outputs.length * 2), o80 = [], a71 = () => {
        let p103 = [];
        for (let m96 = 0; m96 < this.inputs.length; ++m96) p103.push({ key: this.inputs[m96], value: i88[m96] });
        let f85 = new Vt2(p103), w45 = Se4(this.outputs, f85, { training: true }), b58;
        for (let m96 = 0; m96 < this.lossFunctions.length; ++m96) {
          let g72 = this.lossFunctions[m96], x76 = g72(n67[m96], w45[m96]);
          r56[m96] != null && (x76 = Uo2(x76, r56[m96]));
          let d55 = E19(x76);
          e36.push(d55), m96 === 0 ? b58 = x76 : b58 = T7(b58, x76);
        }
        for (let m96 = 0; m96 < this.metricsTensors.length; ++m96) {
          let g72;
          if (this.outputs.length > 1 && m96 < this.outputs.length) g72 = e36[m96];
          else {
            let x76 = this.metricsTensors[m96][0], d55 = this.metricsTensors[m96][1];
            g72 = E19(x76(n67[d55], w45[d55]));
          }
          N3(g72), o80.push(g72);
        }
        return b58 = E19(b58), this.calculateLosses().forEach((m96) => {
          b58 = T7(b58, m96);
        }), b58;
      }, l80 = this.collectedTrainableWeights.map((p103) => p103.read());
      return [this.optimizer_.minimize(a71, true, l80)].concat(o80);
    };
  }
  makeTestFunction() {
    this.testFunction = (t67) => g4(() => {
      let e36 = [], i88, n67 = t67.slice(0, this.inputs.length), r56 = t67.slice(this.inputs.length, this.inputs.length + this.outputs.length), o80 = [];
      for (let u86 = 0; u86 < this.inputs.length; ++u86) o80.push({ key: this.inputs[u86], value: n67[u86] });
      let a71 = new Vt2(o80), l80 = Se4(this.outputs, a71);
      for (let u86 = 0; u86 < this.lossFunctions.length; ++u86) {
        let h74 = this.lossFunctions[u86], p103 = E19(h74(r56[u86], l80[u86]));
        u86 === 0 ? i88 = p103 : i88 = T7(i88, p103), e36.push(i88);
      }
      for (let u86 = 0; u86 < this.metricsTensors.length; ++u86) {
        let h74 = this.metricsTensors[u86][0], p103 = this.metricsTensors[u86][1], f85 = E19(h74(r56[p103], l80[p103]));
        e36.push(f85);
      }
      return e36;
    });
  }
  async fit(t67, e36, i88 = {}) {
    if (this.isTraining) throw new Error("Cannot start training because another fit() call is ongoing.");
    this.isTraining = true;
    let n67, r56, o80, a71, l80, u86, h74, p103, f85;
    try {
      let w45 = i88.batchSize == null ? 32 : i88.batchSize;
      Sn2(w45);
      let m96 = await this.standardizeUserData(t67, e36, i88.sampleWeight, i88.classWeight, false, w45);
      n67 = m96[0], r56 = m96[1], f85 = m96[2];
      let g72 = false, x76;
      if (i88.validationData != null && i88.validationData.length > 0) {
        if (g72 = true, i88.validationData.length === 2) l80 = i88.validationData[0], u86 = i88.validationData[1];
        else throw i88.validationData.length === 3 ? new S44("validationData including sample weights is not supported yet.") : new c102(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${i88.validationData} is invalid.`);
        let F32 = await this.standardizeUserData(l80, u86, null, null, true, w45);
        h74 = F32[0], p103 = F32[1], x76 = h74.concat(p103);
      } else if (i88.validationSplit != null && i88.validationSplit > 0 && i88.validationSplit < 1) {
        g72 = true;
        let O21 = Math.floor(n67[0].shape[0] * (1 - i88.validationSplit)), F32 = n67[0].shape[0];
        h74 = ms(n67, O21, F32), o80 = n67, n67 = ms(n67, 0, O21), p103 = ms(r56, O21, F32), a71 = r56, r56 = ms(r56, 0, O21), x76 = h74.concat(p103);
      } else i88.validationSteps != null && (g72 = true);
      let d55 = n67.concat(r56).concat(f85);
      this.checkTrainableWeightsConsistency();
      let k63 = this.makeTrainFunction(), A35 = this.getDedupedMetricsNames(), z32, D42;
      g72 ? (this.makeTestFunction(), z32 = this.testFunction, D42 = A35.slice().concat(A35.map((O21) => "val_" + O21))) : (z32 = null, x76 = [], D42 = A35.slice());
      let q25 = mn(i88.callbacks, i88.yieldEvery);
      return await this.fitLoop(k63, d55, A35, w45, i88.epochs, i88.verbose, q25, z32, x76, i88.shuffle, D42, i88.initialEpoch, null, null);
    } finally {
      this.isTraining = false, Et3(n67, t67), Et3(r56, e36), Et3(o80, t67), Et3(a71, e36), Et3(h74, l80), Et3(p103, u86), f85 != null && E4(f85);
    }
  }
  async fitLoop(t67, e36, i88, n67, r56, o80, a71, l80, u86, h74, p103, f85, w45, b58) {
    n67 == null && (n67 = 32), r56 == null && (r56 = 1), h74 == null && (h74 = true), f85 == null && (f85 = 0);
    let m96 = false;
    if (l80 != null && u86 != null && (m96 = true), b58 != null && (m96 = true, w45 == null)) throw new c102("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");
    let g72 = this.checkNumSamples(e36, n67, w45, "steps_per_epoch"), x76;
    g72 != null && (x76 = ft5(0, g72)), o80 == null && (o80 = 1);
    let { callbackList: d55, history: k63 } = gn(a71, o80, r56, f85, g72, w45, n67, m96, p103);
    d55.setModel(this), this.history = k63, await d55.onTrainBegin(), this.stopTraining_ = false;
    for (let A35 = f85; A35 < r56; ++A35) {
      await d55.onEpochBegin(A35);
      let z32 = {};
      if (w45 != null) throw new S44("stepsPerEpoch mode is not implemented yet.");
      {
        if (h74 === "batch") throw new S44("batch shuffling is not implemneted yet");
        h74 && util_exports.shuffle(x76);
        let D42 = m25(x76), q25 = Ln(g72, n67);
        for (let R26 = 0; R26 < q25.length; ++R26) {
          let O21 = {};
          if (await d55.onBatchBegin(R26, O21), g4(() => {
            let F32 = q25[R26][0], ct4 = q25[R26][1], ne7 = Ht3(D42, F32, ct4 - F32);
            O21.batch = R26, O21.size = ct4 - F32;
            let Ai = vn(e36, ne7), Ii = t67(Ai);
            for (let re7 = 0; re7 < i88.length; ++re7) {
              let oe8 = i88[re7], Ue = Ii[re7];
              O21[oe8] = Ue, N3(Ue);
            }
            if (R26 === q25.length - 1 && m96) {
              let re7 = this.testLoop(l80, u86, n67);
              for (let oe8 = 0; oe8 < i88.length; ++oe8) {
                let Ue = i88[oe8], ki = re7[oe8];
                N3(ki), z32["val_" + Ue] = ki;
              }
            }
          }), await d55.onBatchEnd(R26, O21), hn2(O21), this.stopTraining_) break;
        }
        D42.dispose();
      }
      if (await d55.onEpochEnd(A35, z32), this.stopTraining_) break;
    }
    return await d55.onTrainEnd(), await this.history.syncData(), this.history;
  }
  async fitDataset(t67, e36) {
    return qo2(this, t67, e36);
  }
  async trainOnBatch(t67, e36) {
    let i88 = await this.standardizeUserData(t67, e36), n67 = i88[0], r56 = i88[1], a71 = this.makeTrainFunction()(n67.concat(r56)), l80 = [];
    for (let u86 of a71) {
      let h74 = await u86.data();
      l80.push(h74[0]);
    }
    return E4(a71), Et3(i88[0], t67), Et3(i88[1], e36), st6(l80);
  }
  getNamedWeights(t67) {
    let e36 = [], i88 = t67 != null && t67.trainableOnly, n67 = i88 ? this.trainableWeights : this.weights, r56 = this.getWeights(i88);
    for (let o80 = 0; o80 < n67.length; ++o80) i88 && !n67[o80].trainable || e36.push({ name: n67[o80].originalName, tensor: r56[o80] });
    return e36;
  }
  set stopTraining(t67) {
    this.stopTraining_ = t67;
  }
  get stopTraining() {
    return this.stopTraining_;
  }
  get optimizer() {
    return this.optimizer_;
  }
  set optimizer(t67) {
    this.optimizer_ !== t67 && (this.optimizer_ = t67, this.isOptimizerOwned = false);
  }
  dispose() {
    let t67 = super.dispose();
    if (t67.refCountAfterDispose === 0 && this.optimizer != null && this.isOptimizerOwned) {
      let e36 = B5().numTensors;
      this.optimizer_.dispose(), t67.numDisposedVariables += e36 - B5().numTensors;
    }
    return t67;
  }
  getLossIdentifiers() {
    let t67;
    if (typeof this.loss == "string") t67 = Ct2(this.loss);
    else if (Array.isArray(this.loss)) {
      for (let e36 of this.loss) if (typeof e36 != "string") throw new Error("Serialization of non-string loss is not supported.");
      t67 = this.loss.map((e36) => Ct2(e36));
    } else {
      let e36 = Object.keys(this.loss);
      t67 = {};
      let i88 = this.loss;
      for (let n67 of e36) if (typeof i88[n67] == "string") t67[n67] = Ct2(i88[n67]);
      else throw new Error("Serialization of non-string loss is not supported.");
    }
    return t67;
  }
  getMetricIdentifiers() {
    if (typeof this.metrics == "string" || typeof this.metrics == "function") return [Ct2(Ri(this.metrics))];
    if (Array.isArray(this.metrics)) return this.metrics.map((t67) => Ct2(Ri(t67)));
    {
      let t67 = {};
      for (let e36 in this.metrics) t67[e36] = Ct2(Ri(this.metrics[e36]));
      return t67;
    }
  }
  getTrainingConfig() {
    return { loss: this.getLossIdentifiers(), metrics: this.getMetricIdentifiers(), optimizer_config: { class_name: this.optimizer.getClassName(), config: this.optimizer.getConfig() } };
  }
  loadTrainingConfig(t67) {
    if (t67.weighted_metrics != null) throw new Error("Loading weight_metrics is not supported yet.");
    if (t67.loss_weights != null) throw new Error("Loading loss_weights is not supported yet.");
    if (t67.sample_weight_mode != null) throw new Error("Loading sample_weight_mode is not supported yet.");
    let e36 = Te4(t67.optimizer_config), i88 = yt5(e36), n67;
    if (typeof t67.loss == "string") n67 = qt3(t67.loss);
    else if (Array.isArray(t67.loss)) n67 = t67.loss.map((o80) => qt3(o80));
    else if (t67.loss != null) {
      n67 = {};
      for (let o80 in t67.loss) n67[o80] = qt3(t67.loss[o80]);
    }
    let r56;
    if (Array.isArray(t67.metrics)) r56 = t67.metrics.map((o80) => qt3(o80));
    else if (t67.metrics != null) {
      r56 = {};
      for (let o80 in t67.metrics) r56[o80] = qt3(t67.metrics[o80]);
    }
    this.compile({ loss: n67, metrics: r56, optimizer: i88 });
  }
  async save(t67, e36) {
    if (typeof t67 == "string") {
      let u86 = io_exports.getSaveHandlers(t67);
      if (u86.length === 0) throw new c102(`Cannot find any save handlers for URL '${t67}'`);
      if (u86.length > 1) throw new c102(`Found more than one (${u86.length}) save handlers for URL '${t67}'`);
      t67 = u86[0];
    }
    if (t67.save == null) throw new c102("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
    let i88 = await io_exports.encodeWeights(this.getNamedWeights(e36)), a71 = { modelTopology: this.toJSON(null, false), format: Bu, generatedBy: `TensorFlow.js tfjs-layers v${$i}`, convertedBy: null };
    if ((e36 == null ? false : e36.includeOptimizer) && this.optimizer != null) {
      a71.trainingConfig = this.getTrainingConfig();
      let u86 = "optimizer", { data: h74, specs: p103 } = await io_exports.encodeWeights(await this.optimizer.getWeights(), u86);
      i88.specs.push(...p103), i88.data = io_exports.concatenateArrayBuffers([i88.data, h74]);
    }
    return this.userDefinedMetadata != null && (Sr(this.userDefinedMetadata, this.name, true), a71.userDefinedMetadata = this.userDefinedMetadata), a71.weightData = i88.data, a71.weightSpecs = i88.specs, t67.save(a71);
  }
  setUserDefinedMetadata(t67) {
    Sr(t67, this.name), this.userDefinedMetadata = t67;
  }
  getUserDefinedMetadata() {
    return this.userDefinedMetadata;
  }
};
xt2.className = "Model";
serialization_exports.registerClass(xt2);
var En = class extends xt2 {
};
En.className = "Functional";
serialization_exports.registerClass(En);
async function ea(s84, t67) {
  "modelTopology" in s84 || (s84 = { modelTopology: s84 }), s84 = s84;
  let e36 = s84.modelTopology;
  e36.model_config != null && (e36 = e36.model_config);
  let i88 = Te4(e36), n67 = yt5(i88, t67);
  if (s84.weightsManifest != null) {
    let r56 = await io_exports.loadWeights(s84.weightsManifest, s84.pathPrefix, n67.weights.map((a71) => a71.originalName)), o80 = {};
    for (let a71 of n67.weights) o80[a71.originalName] = r56[a71.originalName];
    n67.loadWeights(o80), E4(r56);
  }
  return n67;
}
async function sa(s84, t67) {
  if (t67 == null && (t67 = {}), typeof s84 == "string") {
    let e36 = io_exports.getLoadHandlers(s84, t67);
    if (e36.length === 0) e36.push(io_exports.browserHTTPRequest(s84, t67));
    else if (e36.length > 1) throw new c102(`Found more than one (${e36.length}) load handlers for URL '${s84}'`);
    s84 = e36[0];
  }
  return Uu(s84, void 0, t67);
}
async function Uu(s84, t67, e36) {
  if (e36 == null && (e36 = {}), s84.load == null) throw new c102("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
  let i88 = await s84.load(), n67 = i88.modelTopology;
  n67.model_config != null && (n67 = n67.model_config);
  let r56 = e36.strict == null ? true : e36.strict, o80 = i88.weightData != null && i88.weightSpecs != null && r56, a71 = yt5(Te4(n67), t67, o80), l80 = i88.trainingConfig;
  if (l80 != null && a71.loadTrainingConfig(l80), i88.userDefinedMetadata != null && a71.setUserDefinedMetadata(i88.userDefinedMetadata), i88.weightData != null) {
    if (i88.weightSpecs == null) throw new c102("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");
    let { modelWeights: u86, optimizerWeights: h74 } = Pu(i88.weightData, i88.weightSpecs);
    a71.loadWeights(u86, r56), a71.optimizer != null && h74.length > 0 && await a71.optimizer.setWeights(h74), E4(u86), E4(h74.map((p103) => p103.tensor));
  }
  return a71;
}
function Pu(s84, t67) {
  let e36 = io_exports.decodeWeights(s84, t67), i88 = {}, n67 = [];
  return t67.forEach((r56) => {
    r56.group === "optimizer" ? n67.push({ name: r56.name, tensor: e36[r56.name] }) : i88[r56.name] = e36[r56.name];
  }), { modelWeights: i88, optimizerWeights: n67 };
}
var Ee3 = class s77 extends xt2 {
  constructor(t67) {
    if (super({ inputs: [], outputs: [] }), t67 = t67 || {}, this.trainable = true, this.built = false, this.name = t67.name != null ? t67.name : ae7("sequential_"), t67.layers != null) for (let e36 of t67.layers) this.add(e36);
  }
  checkShape(t67) {
    if (t67.inboundNodes[0].outputTensors[0].shape.some((i88) => i88 < 0)) throw new c102(`Negative dimension size caused by adding layer ${t67.name} with input shape [${t67.inboundNodes[0].inputTensors[0].shape}]`);
  }
  add(t67) {
    let e36 = t67 instanceof s77 || t67 instanceof xt2, i88;
    if (e36) {
      if (i88 = t67, i88.outputs.length !== 1) throw new c102("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      if (i88.inputs.length !== 1) throw new c102("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.");
    }
    if (this.outputs.length === 0) {
      if (t67.inboundNodes.length === 0) {
        if (t67.batchInputShape == null) throw new c102("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");
        let n67 = an2({ batchShape: t67.batchInputShape, dtype: t67.dtype, name: t67.name + "_input" });
        t67.apply(n67);
      }
      if (e36) this.outputs = i88.outputs, this.inputs = i88.inputs;
      else {
        if (t67.inboundNodes.length !== 1) throw new c102(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${t67.name} which has ${t67.inboundNodes.length} pre-existing inbound connections.`);
        if (t67.inboundNodes[0].outputTensors.length !== 1) throw new c102("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
        this.checkShape(t67), this.outputs = [t67.inboundNodes[0].outputTensors[0]], this.inputs = xr(this.outputs[0]);
      }
      this.inboundNodes = [], new Gt3({ outboundLayer: this, inboundLayers: [], nodeIndices: [], tensorIndices: [], inputTensors: this.inputs, outputTensors: this.outputs, inputMasks: zt3(null, this.inputs.length), outputMasks: [null], inputShapes: this.inputs.map((n67) => n67.shape), outputShapes: this.outputs[0].shape });
    } else {
      let n67 = t67.apply(this.outputs[0]);
      if (Array.isArray(n67)) throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      this.checkShape(t67), this.outputs = [n67], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }
    this.layers.push(t67), this.built = false;
  }
  pop() {
    if (this.layers.length === 0) throw new TypeError("There are no layers in the model.");
    if (this.layers.pop(), this.layers.length === 0) this.outputs = [], this.inboundNodes = [], this.outboundNodes = [];
    else {
      let t67 = this.layers.length - 1;
      this.layers[t67].outboundNodes = [], this.outputs = [this.layers[t67].output], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }
  }
  call(t67, e36) {
    return this.model == null && this.build(), this.model.call(t67, e36);
  }
  build(t67) {
    if (E43(t67), this.inputs.length === 0 || this.outputs.length === 0) throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");
    this.model = new xt2({ inputs: this.inputs, outputs: this.outputs[0], name: this.name + "_model" }), this.model.trainable = this.trainable, this.supportsMasking = this.model.supportsMasking, this.inputLayers = this.model.inputLayers, this.inputLayersNodeIndices = this.model.inputLayersNodeIndices, this.inputLayersTensorIndices = this.model.inputLayersTensorIndices, this.outputLayers = this.model.outputLayers, this.outputLayersNodeIndices = this.model.outputLayersNodeIndices, this.outputLayersTensorIndices = this.model.outputLayersTensorIndices, this.nodesByDepth = this.model.nodesByDepth, this.containerNodes = this.model.containerNodes, this.outputNames = this.model.outputNames, this.inputNames = this.model.inputNames, this.built = true;
  }
  countParams() {
    return this.built || this.build(), super.countParams();
  }
  summary(t67, e36, i88 = console.log) {
    this.built || this.build(), super.summary(t67, e36, i88);
  }
  setWeights(t67) {
    this.model == null && this.build(), this.model.setWeights(t67);
  }
  evaluate(t67, e36, i88 = {}) {
    if (!this.built) throw new ht6("The model needs to be compiled before being used.");
    return this.model.evaluate(t67, e36, i88);
  }
  async evaluateDataset(t67, e36) {
    if (!this.built) throw new ht6("The model needs to be compiled before being used.");
    return this.model.evaluateDataset(t67, e36);
  }
  predict(t67, e36 = {}) {
    return this.model == null && this.build(), this.model.predict(t67, e36);
  }
  predictOnBatch(t67) {
    return this.model == null && this.build(), this.model.predictOnBatch(t67);
  }
  compile(t67) {
    this.build(), this.model.compile(t67), this.optimizer_ = this.model.optimizer, this.isOptimizerOwned = this.model.isOptimizerOwned, this.loss = this.model.loss, this.metrics = this.model.metrics, this.metricsTensors = this.model.metricsTensors, this.metricsNames = this.model.metricsNames;
  }
  get optimizer() {
    return this.model == null ? void 0 : this.model.optimizer;
  }
  set optimizer(t67) {
    this.model.optimizer = t67;
  }
  async fit(t67, e36, i88 = {}) {
    if (!this.built) throw new ht6("The model needs to be compiled before being used.");
    return this.model.fit(t67, e36, i88);
  }
  async fitDataset(t67, e36) {
    if (!this.built) throw new ht6("The model needs to be compiled before being used.");
    return this.model.fitDataset(t67, e36);
  }
  async trainOnBatch(t67, e36) {
    return this.model.trainOnBatch(t67, e36);
  }
  static fromConfig(t67, e36, i88 = {}, n67 = false) {
    let r56, o80 = {};
    if (e36 instanceof Array) {
      if (e36[0].className == null || e36[0].className === "Merge") throw new c102("Legacy serialization format not supported yet.");
      r56 = e36;
    } else util_exports.assert(e36.layers != null, () => "When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."), r56 = e36.layers, delete e36.layers, o80 = e36;
    let a71 = new t67(o80);
    if (!(a71 instanceof s77)) throw new S44(`Sequential.fromConfig called on non-Sequential input: ${a71}`);
    for (let l80 of r56) {
      let h74 = yt5(l80, void 0, n67);
      n67 && h74.setFastWeightInitDuringBuild(true), a71.add(h74);
    }
    return a71;
  }
  set stopTraining(t67) {
    if (this.model == null) throw new c102("Cannot set the stopTraining property of a sequential model before it is compiled.");
    this.model.stopTraining = t67;
  }
  get stopTraining() {
    if (this.model == null) throw new c102("Cannot get the stopTraining property of a sequential model before it is compiled.");
    return this.model.stopTraining;
  }
  getConfig() {
    let t67 = [];
    for (let e36 of this.layers) {
      let i88 = {};
      i88.className = e36.getClassName(), i88.config = e36.getConfig(), t67.push(i88);
    }
    return { name: this.name, layers: t67 };
  }
};
Ee3.className = "Sequential";
serialization_exports.registerClass(Ee3);
function Ku(s84) {
  return new xt2(s84);
}
function ju(s84) {
  return new Ee3(s84);
}
function Dr(s84) {
  return an2(s84);
}
function qu(s84, t67) {
  us.registerCallbackConstructor(s84, t67);
}
var nt4 = class extends serialization_exports.Serializable {
  getConfig() {
    return {};
  }
};
var On = class extends nt4 {
  apply(t67, e36 = 1) {
    return uo2(t67, e36);
  }
};
On.className = "elu";
serialization_exports.registerClass(On);
var _n = class extends nt4 {
  apply(t67) {
    return l23(t67);
  }
};
_n.className = "selu";
serialization_exports.registerClass(_n);
var Mn = class extends nt4 {
  apply(t67) {
    return s22(t67);
  }
};
Mn.className = "relu";
serialization_exports.registerClass(Mn);
var Rn = class extends nt4 {
  apply(t67) {
    return g4(() => G8(6, s22(t67)));
  }
};
Rn.className = "relu6";
serialization_exports.registerClass(Rn);
var $n = class extends nt4 {
  apply(t67) {
    return t67;
  }
};
$n.className = "linear";
serialization_exports.registerClass($n);
var Fn = class extends nt4 {
  apply(t67) {
    return d6(t67);
  }
};
Fn.className = "sigmoid";
serialization_exports.registerClass(Fn);
var Bn = class extends nt4 {
  apply(t67) {
    return ho2(t67);
  }
};
Bn.className = "hardSigmoid";
serialization_exports.registerClass(Bn);
var Wn = class extends nt4 {
  apply(t67) {
    return l18(t67);
  }
};
Wn.className = "softplus";
serialization_exports.registerClass(Wn);
var Vn = class extends nt4 {
  apply(t67) {
    return co2(t67);
  }
};
Vn.className = "softsign";
serialization_exports.registerClass(Vn);
var Un = class extends nt4 {
  apply(t67) {
    return x16(t67);
  }
};
Un.className = "tanh";
serialization_exports.registerClass(Un);
var gs2 = class extends nt4 {
  apply(t67, e36 = -1) {
    return g20(t67, e36);
  }
};
gs2.className = "softmax";
serialization_exports.registerClass(gs2);
var Pn = class extends nt4 {
  apply(t67, e36 = -1) {
    return A8(t67, e36);
  }
};
Pn.className = "logSoftmax";
serialization_exports.registerClass(Pn);
var Kn = class extends nt4 {
  apply(t67) {
    return g4(() => g4(() => {
      let e36 = Math.sqrt(2), i88 = y8(0.5, T7(1, x20(D6(t67, e36))));
      return y8(t67, i88);
    }));
  }
};
Kn.className = "gelu";
serialization_exports.registerClass(Kn);
var jn = class extends nt4 {
  apply(t67) {
    return g4(() => y8(0.5, y8(t67, T7(1, x16(y8(q6(D6(2, Math.PI)), T7(t67, y8(0.044715, x22(t67, 3)))))))));
  }
};
jn.className = "gelu_new";
serialization_exports.registerClass(jn);
var qn2 = class extends nt4 {
  apply(t67) {
    return g4(() => y8(t67, x16(l18(t67))));
  }
};
qn2.className = "mish";
serialization_exports.registerClass(qn2);
var Hn = class extends nt4 {
  apply(t67, e36 = 1) {
    return g4(() => y8(d6(y8(t67, e36)), t67));
  }
};
Hn.className = "swish";
serialization_exports.registerClass(Hn);
function Rt3(s84) {
  return s84.getClassName();
}
function Or(s84, t67 = {}) {
  return Bt3(s84, serialization_exports.SerializationMap.getMap().classNameMap, t67, "activation");
}
function $t3(s84) {
  if (s84 == null) {
    let t67 = {};
    return t67.className = "linear", t67.config = {}, Or(t67);
  }
  if (typeof s84 == "string") {
    let t67 = {};
    return t67.className = s84, t67.config = {}, Or(t67);
  } else return s84 instanceof nt4 ? s84 : Or(s84);
}
function Mr(s84) {
  if (s84 != null && typeof s84 != "object") throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${s84}`);
}
var Jn = class extends serialization_exports.Serializable {
};
var pe3 = class extends Jn {
  constructor(t67) {
    super(), Mr(t67), this.l1 = t67 == null || t67.l1 == null ? 0.01 : t67.l1, this.l2 = t67 == null || t67.l2 == null ? 0.01 : t67.l2, this.hasL1 = this.l1 !== 0, this.hasL2 = this.l2 !== 0;
  }
  apply(t67) {
    return g4(() => {
      let e36 = e13([1]);
      return this.hasL1 && (e36 = T7(e36, T10(y8(this.l1, b9(t67))))), this.hasL2 && (e36 = T7(e36, T10(y8(this.l2, xe6(t67))))), h9(e36, []);
    });
  }
  getConfig() {
    return { l1: this.l1, l2: this.l2 };
  }
  static fromConfig(t67, e36) {
    return new t67({ l1: e36.l1, l2: e36.l2 });
  }
};
pe3.className = "L1L2";
serialization_exports.registerClass(pe3);
function aa(s84) {
  return Mr(s84), new pe3({ l1: s84 != null ? s84.l1 : null, l2: 0 });
}
function la(s84) {
  return Mr(s84), new pe3({ l2: s84 != null ? s84.l2 : null, l1: 0 });
}
var ra = { l1l2: "L1L2" };
function B29(s84) {
  return Ke(s84);
}
function oa(s84, t67 = {}) {
  return Bt3(s84, serialization_exports.SerializationMap.getMap().classNameMap, t67, "regularizer");
}
function j21(s84) {
  if (s84 == null) return null;
  if (typeof s84 == "string") {
    let e36 = { className: s84 in ra ? ra[s84] : s84, config: {} };
    return oa(e36);
  } else return s84 instanceof Jn ? s84 : oa(s84);
}
var ys2 = class extends v41 {
  constructor(t67) {
    super(t67 ?? {}), this.supportsMasking = true, t67 != null && (this.maxValue = t67.maxValue);
  }
  call(t67, e36) {
    t67 = C27(t67);
    let i88 = s22(t67);
    return this.maxValue != null && (i88 = x18(i88, 0, this.maxValue)), i88;
  }
  computeOutputShape(t67) {
    return t67;
  }
  getConfig() {
    let t67 = { maxValue: this.maxValue }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
ys2.className = "ReLU";
serialization_exports.registerClass(ys2);
var bs = class extends v41 {
  constructor(t67) {
    super(t67 ?? {}), this.DEFAULT_ALPHA = 0.3, t67 == null && (t67 = {}), this.alpha = t67.alpha == null ? this.DEFAULT_ALPHA : t67.alpha;
  }
  call(t67, e36) {
    let i88 = C27(t67);
    return x27(i88, this.alpha);
  }
  computeOutputShape(t67) {
    return t67;
  }
  getConfig() {
    let t67 = { alpha: this.alpha }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
bs.className = "LeakyReLU";
serialization_exports.registerClass(bs);
var ws = class extends v41 {
  constructor(t67) {
    if (super(t67 ?? {}), this.DEFAULT_ALPHA_INITIALIZER = "zeros", t67 == null && (t67 = {}), this.supportsMasking = true, this.alphaInitializer = U23(t67.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER), this.alphaRegularizer = j21(t67.alphaRegularizer), this.alphaConstraint = G29(t67.alphaConstraint), t67.sharedAxes == null) this.sharedAxes = null;
    else if (Array.isArray(t67.sharedAxes)) this.sharedAxes = t67.sharedAxes;
    else if (typeof t67.sharedAxes == "number") this.sharedAxes = [t67.sharedAxes];
    else throw new c102(`Expected sharedAxes to be a number or an array of numbers, but got ${t67.sharedAxes}`);
  }
  build(t67) {
    t67 = E43(t67);
    let e36 = t67.slice(1);
    if (this.sharedAxes != null) for (let n67 of this.sharedAxes) e36[n67 - 1] = 1;
    this.alpha = this.addWeight("alpha", e36, "float32", this.alphaInitializer, this.alphaRegularizer, true, this.alphaConstraint);
    let i88 = {};
    if (this.sharedAxes != null) for (let n67 = 1; n67 < t67.length; ++n67) i88[n67] = t67[n67];
    this.inputSpec = [new K20({ ndim: t67.length, axes: i88 })], this.built = true;
  }
  call(t67, e36) {
    return t67 = C27(t67), x32(t67, this.alpha.read());
  }
  getConfig() {
    let t67 = { alphaInitializer: H17(this.alphaInitializer), alphaRegularizer: B29(this.alphaRegularizer), alphaConstraint: Z15(this.alphaConstraint), sharedAxes: this.sharedAxes }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
ws.className = "PReLU";
serialization_exports.registerClass(ws);
var xs = class extends v41 {
  constructor(t67) {
    if (super(t67 ?? {}), this.DEFAULT_ALPHA = 1, t67 == null && (t67 = {}), t67.alpha != null && t67.alpha !== this.DEFAULT_ALPHA) throw new S44(`Non-default alpha value (${t67.alpha}) is not supported by the ELU layer yet.`);
    this.alpha = t67.alpha == null ? this.DEFAULT_ALPHA : t67.alpha;
  }
  call(t67, e36) {
    let i88 = C27(t67);
    return s12(i88);
  }
  computeOutputShape(t67) {
    return t67;
  }
  getConfig() {
    let t67 = { alpha: this.alpha }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
xs.className = "ELU";
serialization_exports.registerClass(xs);
var As = class extends v41 {
  constructor(t67) {
    super(t67 ?? {}), this.DEFAULT_THETA = 1, t67 == null && (t67 = {}), this.theta = t67.theta == null ? this.DEFAULT_THETA : t67.theta;
  }
  call(t67, e36) {
    let i88 = C27(t67);
    return y8(i88, w12(G6(i88, this.theta), "float32"));
  }
  computeOutputShape(t67) {
    return t67;
  }
  getConfig() {
    let t67 = { theta: this.theta }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
As.className = "ThresholdedReLU";
serialization_exports.registerClass(As);
var Is = class extends v41 {
  constructor(t67) {
    super(t67 ?? {}), this.DEFAULT_AXIS = 1, t67 == null && (t67 = {}), this.softmax = new gs2().apply, this.axis = t67.axis == null ? this.DEFAULT_AXIS : t67.axis;
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = C27(t67), n67 = e36.mask;
      if (n67 != null) {
        let r56 = y8(E16(c26(i88.shape), w12(n67, i88.dtype)), m21(-1e9));
        i88 = T7(i88, r56);
      }
      return this.axis instanceof Array ? this.axis.length > 1 ? u20(E16(i88, z9(i88, this.axis, true))) : this.softmax(i88, this.axis[0]) : this.softmax(i88, this.axis);
    });
  }
  computeOutputShape(t67) {
    return t67;
  }
  getConfig() {
    let t67 = { axis: this.axis }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Is.className = "Softmax";
serialization_exports.registerClass(Is);
function fe5(s84, t67, e36) {
  if (typeof s84 == "number") return zt3(s84, t67);
  if (s84.length !== t67) throw new c102(`The ${e36} argument must be an integer or tuple of ${t67} integers. Received: ${s84.length} elements.`);
  for (let i88 = 0; i88 < t67; ++i88) {
    let n67 = s84[i88];
    if (!ro3(n67)) throw new c102(`The ${e36} argument must be an integer or tuple of ${t67} integers. Received: ${JSON.stringify(s84)} including a non-integer number ${n67}`);
  }
  return s84;
}
function wt4(s84, t67, e36, i88, n67 = 1) {
  if (s84 == null) return s84;
  let r56 = t67 + (t67 - 1) * (n67 - 1), o80;
  return e36 === "same" ? o80 = s84 : o80 = s84 - r56 + 1, Math.floor((o80 + i88 - 1) / i88);
}
function Ft5(s84, t67, e36, i88) {
  if (s84 == null) return null;
  if (i88 === "valid") s84 = s84 * t67 + _t4([e36 - t67, 0]);
  else if (i88 === "same") s84 = s84 * t67;
  else throw new c102(`Unsupport padding mode: ${i88}.`);
  return s84;
}
function Vi(s84, t67) {
  return g4(() => (J16(t67), t67 === "channelsFirst" ? A10(s84, [0, 2, 3, 1]) : s84));
}
function Rr(s84, t67) {
  return g4(() => (J16(t67), t67 === "channelsFirst" ? A10(s84, [0, 2, 3, 4, 1]) : s84));
}
function uc(s84, t67, e36, i88 = 1, n67 = "valid", r56, o80 = 1) {
  return g4(() => {
    if (r56 == null && (r56 = dt4()), J16(r56), s84.shape.length !== 3) throw new c102(`The input of a conv1dWithBias operation should be 3, but is ${s84.shape.length} instead.`);
    if (t67.shape.length !== 3) throw new c102(`The kernel for a conv1dWithBias operation should be 3, but is ${t67.shape.length} instead`);
    if (e36 != null && e36.shape.length !== 1) throw new c102(`The bias for a conv1dWithBias operation should be 1, but is ${e36.shape.length} instead`);
    if (r56 === "channelsFirst" && (s84 = A10(s84, [0, 2, 1])), n67 === "causal") throw new S44("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    let a71 = W5(s84, t67, i88, n67 === "same" ? "same" : "valid", "NWC", o80);
    return e36 != null && (a71 = mt5(a71, e36)), a71;
  });
}
function pa(s84, t67, e36, i88 = [1, 1], n67 = "valid", r56, o80, a71 = null) {
  return g4(() => {
    if (r56 == null && (r56 = dt4()), J16(r56), s84.rank !== 3 && s84.rank !== 4) throw new c102(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${s84.rank}.`);
    if (t67.rank !== 3 && t67.rank !== 4) throw new c102(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${s84.rank}.`);
    let l80 = Vi(s84, r56);
    if (n67 === "causal") throw new S44("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    return l80 = fused_ops_exports.conv2d({ x: l80, filter: t67, strides: i88, pad: n67 === "same" ? "same" : "valid", dilations: o80, dataFormat: "NHWC", bias: e36, activation: a71 }), r56 === "channelsFirst" && (l80 = A10(l80, [0, 3, 1, 2])), l80;
  });
}
function cc(s84, t67, e36, i88 = [1, 1, 1], n67 = "valid", r56, o80) {
  return g4(() => {
    if (r56 == null && (r56 = dt4()), J16(r56), s84.rank !== 4 && s84.rank !== 5) throw new c102(`conv3dWithBias expects input to be of rank 4 or 5, but received ${s84.rank}.`);
    if (t67.rank !== 4 && t67.rank !== 5) throw new c102(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${s84.rank}.`);
    let a71 = Rr(s84, r56);
    if (n67 === "causal") throw new S44("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");
    return a71 = T9(a71, t67, i88, n67 === "same" ? "same" : "valid", "NDHWC", o80), e36 != null && (a71 = mt5(a71, e36)), r56 === "channelsFirst" && (a71 = A10(a71, [0, 4, 1, 2, 3])), a71;
  });
}
var Wi = class s78 extends v41 {
  constructor(t67, e36) {
    if (super(e36), this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_BIAS_INITIALIZER = "zeros", s78.verifyArgs(e36), this.rank = t67, Y13(this.rank, "rank"), this.rank !== 1 && this.rank !== 2 && this.rank !== 3) throw new S44(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);
    if (this.kernelSize = fe5(e36.kernelSize, t67, "kernelSize"), this.strides = fe5(e36.strides == null ? 1 : e36.strides, t67, "strides"), this.padding = e36.padding == null ? "valid" : e36.padding, pt2(this.padding), this.dataFormat = e36.dataFormat == null ? "channelsLast" : e36.dataFormat, J16(this.dataFormat), this.activation = $t3(e36.activation), this.useBias = e36.useBias == null ? true : e36.useBias, this.biasInitializer = U23(e36.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.biasConstraint = G29(e36.biasConstraint), this.biasRegularizer = j21(e36.biasRegularizer), this.activityRegularizer = j21(e36.activityRegularizer), this.dilationRate = fe5(e36.dilationRate == null ? 1 : e36.dilationRate, t67, "dilationRate"), this.rank === 1 && Array.isArray(this.dilationRate) && this.dilationRate.length !== 1) throw new c102(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);
    if (this.rank === 2) {
      if (typeof this.dilationRate == "number") this.dilationRate = [this.dilationRate, this.dilationRate];
      else if (this.dilationRate.length !== 2) throw new c102(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`);
    } else if (this.rank === 3) {
      if (typeof this.dilationRate == "number") this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];
      else if (this.dilationRate.length !== 3) throw new c102(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`);
    }
  }
  static verifyArgs(t67) {
    if (It2("kernelSize" in t67, "required key 'kernelSize' not in config"), typeof t67.kernelSize != "number" && !Ji(t67.kernelSize, "number", 1, 3)) throw new c102(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(t67.kernelSize)}.`);
  }
  getConfig() {
    let t67 = { kernelSize: this.kernelSize, strides: this.strides, padding: this.padding, dataFormat: this.dataFormat, dilationRate: this.dilationRate, activation: Rt3(this.activation), useBias: this.useBias, biasInitializer: H17(this.biasInitializer), biasRegularizer: B29(this.biasRegularizer), activityRegularizer: B29(this.activityRegularizer), biasConstraint: Z15(this.biasConstraint) }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
var Ns = class s79 extends Wi {
  constructor(t67, e36) {
    super(t67, e36), this.kernel = null, s79.verifyArgs(e36), this.filters = e36.filters, Y13(this.filters, "filters"), this.kernelInitializer = U23(e36.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.kernelConstraint = G29(e36.kernelConstraint), this.kernelRegularizer = j21(e36.kernelRegularizer);
  }
  build(t67) {
    t67 = E43(t67);
    let e36 = this.dataFormat === "channelsFirst" ? 1 : t67.length - 1;
    if (t67[e36] == null) throw new c102(`The channel dimension of the input should be defined. Found ${t67[e36]}`);
    let i88 = t67[e36], n67 = this.kernelSize.concat([i88, this.filters]);
    this.kernel = this.addWeight("kernel", n67, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint)), this.inputSpec = [{ ndim: this.rank + 2, axes: { [e36]: i88 } }], this.built = true;
  }
  call(t67, e36) {
    return g4(() => {
      t67 = C27(t67);
      let i88, n67 = this.bias == null ? null : this.bias.read(), r56 = Zi(this.activation.getClassName());
      if (r56 != null && this.rank === 2) i88 = pa(t67, this.kernel.read(), n67, this.strides, this.padding, this.dataFormat, this.dilationRate, r56);
      else {
        if (this.rank === 1) i88 = uc(t67, this.kernel.read(), n67, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);
        else if (this.rank === 2) i88 = pa(t67, this.kernel.read(), n67, this.strides, this.padding, this.dataFormat, this.dilationRate);
        else if (this.rank === 3) i88 = cc(t67, this.kernel.read(), n67, this.strides, this.padding, this.dataFormat, this.dilationRate);
        else throw new S44("convolutions greater than 3D are not implemented yet.");
        this.activation != null && (i88 = this.activation.apply(i88));
      }
      return i88;
    });
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = [], i88 = this.dataFormat === "channelsLast" ? t67.slice(1, t67.length - 1) : t67.slice(2);
    for (let r56 = 0; r56 < i88.length; ++r56) {
      let o80 = wt4(i88[r56], this.kernelSize[r56], this.padding, this.strides[r56], typeof this.dilationRate == "number" ? this.dilationRate : this.dilationRate[r56]);
      e36.push(o80);
    }
    let n67 = [t67[0]];
    return this.dataFormat === "channelsLast" ? (n67 = n67.concat(e36), n67.push(this.filters)) : (n67.push(this.filters), n67 = n67.concat(e36)), n67;
  }
  getConfig() {
    let t67 = { filters: this.filters, kernelInitializer: H17(this.kernelInitializer), kernelRegularizer: B29(this.kernelRegularizer), kernelConstraint: Z15(this.kernelConstraint) }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
  static verifyArgs(t67) {
    if (!("filters" in t67) || typeof t67.filters != "number" || t67.filters < 1) throw new c102(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(t67.filters)}`);
  }
};
var De2 = class s80 extends Ns {
  constructor(t67) {
    super(2, t67), s80.verifyArgs(t67);
  }
  getConfig() {
    let t67 = super.getConfig();
    return delete t67.rank, t67;
  }
  static verifyArgs(t67) {
    if (typeof t67.kernelSize != "number" && !Ji(t67.kernelSize, "number", 1, 2)) throw new c102(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(t67.kernelSize)}.`);
  }
};
De2.className = "Conv2D";
serialization_exports.registerClass(De2);
var Oe2 = class s81 extends Ns {
  constructor(t67) {
    super(3, t67), s81.verifyArgs(t67);
  }
  getConfig() {
    let t67 = super.getConfig();
    return delete t67.rank, t67;
  }
  static verifyArgs(t67) {
    if (typeof t67.kernelSize != "number" && !(Array.isArray(t67.kernelSize) && (t67.kernelSize.length === 1 || t67.kernelSize.length === 3))) throw new c102(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(t67.kernelSize)}.`);
  }
};
Oe2.className = "Conv3D";
serialization_exports.registerClass(Oe2);
var zs = class extends De2 {
  constructor(t67) {
    if (super(t67), this.inputSpec = [new K20({ ndim: 4 })], this.padding !== "same" && this.padding !== "valid") throw new c102(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
  }
  build(t67) {
    if (t67 = E43(t67), t67.length !== 4) throw new c102("Input should have rank 4; Received input shape: " + JSON.stringify(t67));
    let e36 = this.dataFormat === "channelsFirst" ? 1 : t67.length - 1;
    if (t67[e36] == null) throw new c102("The channel dimension of the inputs should be defined. Found `None`.");
    let i88 = t67[e36], n67 = this.kernelSize.concat([this.filters, i88]);
    this.kernel = this.addWeight("kernel", n67, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint)), this.inputSpec = [new K20({ ndim: 4, axes: { [e36]: i88 } })], this.built = true;
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = C27(t67);
      if (i88.shape.length !== 4) throw new c102(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${i88.shape.length}`);
      let n67 = i88.shape, r56 = n67[0], o80, a71;
      this.dataFormat === "channelsFirst" ? (o80 = 2, a71 = 3) : (o80 = 1, a71 = 2);
      let l80 = n67[o80], u86 = n67[a71], h74 = this.kernelSize[0], p103 = this.kernelSize[1], f85 = this.strides[0], w45 = this.strides[1], b58 = Ft5(l80, f85, h74, this.padding), m96 = Ft5(u86, w45, p103, this.padding), g72 = [r56, b58, m96, this.filters];
      this.dataFormat !== "channelsLast" && (i88 = A10(i88, [0, 2, 3, 1]));
      let x76 = u12(i88, this.kernel.read(), g72, this.strides, this.padding);
      return this.dataFormat !== "channelsLast" && (x76 = A10(x76, [0, 3, 1, 2])), this.bias != null && (x76 = mt5(x76, this.bias.read(), this.dataFormat)), this.activation != null && (x76 = this.activation.apply(x76)), x76;
    });
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = t67.slice(), i88, n67, r56;
    this.dataFormat === "channelsFirst" ? (i88 = 1, n67 = 2, r56 = 3) : (i88 = 3, n67 = 1, r56 = 2);
    let o80 = this.kernelSize[0], a71 = this.kernelSize[1], l80 = this.strides[0], u86 = this.strides[1];
    return e36[i88] = this.filters, e36[n67] = Ft5(e36[n67], l80, o80, this.padding), e36[r56] = Ft5(e36[r56], u86, a71, this.padding), e36;
  }
  getConfig() {
    let t67 = super.getConfig();
    return delete t67.dilationRate, t67;
  }
};
zs.className = "Conv2DTranspose";
serialization_exports.registerClass(zs);
var Cs = class extends Oe2 {
  constructor(t67) {
    if (super(t67), this.inputSpec = [new K20({ ndim: 5 })], this.padding !== "same" && this.padding !== "valid") throw new c102(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`);
  }
  build(t67) {
    if (t67 = E43(t67), t67.length !== 5) throw new c102("Input should have rank 5; Received input shape: " + JSON.stringify(t67));
    let e36 = this.dataFormat === "channelsFirst" ? 1 : t67.length - 1;
    if (t67[e36] == null) throw new c102("The channel dimension of the inputs should be defined. Found `None`.");
    let i88 = t67[e36], n67 = this.kernelSize.concat([this.filters, i88]);
    this.kernel = this.addWeight("kernel", n67, "float32", this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, true, this.biasConstraint)), this.inputSpec = [new K20({ ndim: 5, axes: { [e36]: i88 } })], this.built = true;
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = C27(t67);
      if (i88.shape.length !== 5) throw new c102(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${i88.shape.length}`);
      let n67 = i88.shape, r56 = n67[0], o80, a71, l80;
      this.dataFormat === "channelsFirst" ? (l80 = 2, o80 = 3, a71 = 4) : (l80 = 1, o80 = 2, a71 = 3);
      let u86 = n67[l80], h74 = n67[o80], p103 = n67[a71], f85 = this.kernelSize[0], w45 = this.kernelSize[1], b58 = this.kernelSize[2], m96 = this.strides[0], g72 = this.strides[1], x76 = this.strides[2], d55 = Ft5(u86, m96, f85, this.padding), k63 = Ft5(h74, g72, w45, this.padding), A35 = Ft5(p103, x76, b58, this.padding), z32 = [r56, d55, k63, A35, this.filters];
      this.dataFormat !== "channelsLast" && (i88 = A10(i88, [0, 2, 3, 4, 1]));
      let D42 = d7(i88, this.kernel.read(), z32, this.strides, this.padding);
      return this.dataFormat !== "channelsLast" && (D42 = A10(D42, [0, 4, 1, 2, 3])), this.bias !== null && (D42 = mt5(D42, this.bias.read(), this.dataFormat)), this.activation !== null && (D42 = this.activation.apply(D42)), D42;
    });
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = t67.slice(), i88, n67, r56, o80;
    this.dataFormat === "channelsFirst" ? (i88 = 1, n67 = 2, r56 = 3, o80 = 4) : (i88 = 4, n67 = 1, r56 = 2, o80 = 3);
    let a71 = this.kernelSize[0], l80 = this.kernelSize[1], u86 = this.kernelSize[2], h74 = this.strides[0], p103 = this.strides[1], f85 = this.strides[2];
    return e36[i88] = this.filters, e36[n67] = Ft5(e36[n67], h74, a71, this.padding), e36[r56] = Ft5(e36[r56], p103, l80, this.padding), e36[o80] = Ft5(e36[o80], f85, u86, this.padding), e36;
  }
  getConfig() {
    let t67 = super.getConfig();
    return delete t67.dilationRate, t67;
  }
};
Cs.className = "Conv3DTranspose";
serialization_exports.registerClass(Cs);
var Zn = class extends Ns {
  constructor(t67, e36) {
    if (super(t67, e36), this.DEFAULT_DEPTHWISE_INITIALIZER = "glorotUniform", this.DEFAULT_POINTWISE_INITIALIZER = "glorotUniform", this.depthwiseKernel = null, this.pointwiseKernel = null, e36.filters == null) throw new c102("The `filters` configuration field is required by SeparableConv, but is unspecified.");
    if (e36.kernelInitializer != null || e36.kernelRegularizer != null || e36.kernelConstraint != null) throw new c102("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");
    if (e36.padding != null && e36.padding !== "same" && e36.padding !== "valid") throw new c102(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(e36.padding)}`);
    this.depthMultiplier = e36.depthMultiplier == null ? 1 : e36.depthMultiplier, this.depthwiseInitializer = U23(e36.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER), this.depthwiseRegularizer = j21(e36.depthwiseRegularizer), this.depthwiseConstraint = G29(e36.depthwiseConstraint), this.pointwiseInitializer = U23(e36.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER), this.pointwiseRegularizer = j21(e36.pointwiseRegularizer), this.pointwiseConstraint = G29(e36.pointwiseConstraint);
  }
  build(t67) {
    if (t67 = E43(t67), t67.length < this.rank + 2) throw new c102(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank + 2}, but received input shape: ${JSON.stringify(t67)}`);
    let e36 = this.dataFormat === "channelsFirst" ? 1 : t67.length - 1;
    if (t67[e36] == null || t67[e36] < 0) throw new c102(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(t67[e36])}`);
    let i88 = t67[e36], n67 = this.kernelSize.concat([i88, this.depthMultiplier]), r56 = [];
    for (let a71 = 0; a71 < this.rank; ++a71) r56.push(1);
    r56.push(i88 * this.depthMultiplier, this.filters);
    let o80 = true;
    this.depthwiseKernel = this.addWeight("depthwise_kernel", n67, "float32", this.depthwiseInitializer, this.depthwiseRegularizer, o80, this.depthwiseConstraint), this.pointwiseKernel = this.addWeight("pointwise_kernel", r56, "float32", this.pointwiseInitializer, this.pointwiseRegularizer, o80, this.pointwiseConstraint), this.useBias ? this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, o80, this.biasConstraint) : this.bias = null, this.inputSpec = [new K20({ ndim: this.rank + 2, axes: { [e36]: i88 } })], this.built = true;
  }
  call(t67, e36) {
    return g4(() => {
      t67 = C27(t67);
      let i88;
      if (this.rank === 1) throw new S44("1D separable convolution is not implemented yet.");
      return this.rank === 2 && (this.dataFormat === "channelsFirst" && (t67 = A10(t67, [0, 2, 3, 1])), i88 = T16(t67, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, "NHWC")), this.useBias && (i88 = mt5(i88, this.bias.read(), this.dataFormat)), this.activation != null && (i88 = this.activation.apply(i88)), this.dataFormat === "channelsFirst" && (i88 = A10(i88, [0, 3, 1, 2])), i88;
    });
  }
  getConfig() {
    let t67 = super.getConfig();
    return delete t67.rank, delete t67.kernelInitializer, delete t67.kernelRegularizer, delete t67.kernelConstraint, t67.depthwiseInitializer = H17(this.depthwiseInitializer), t67.pointwiseInitializer = H17(this.pointwiseInitializer), t67.depthwiseRegularizer = B29(this.depthwiseRegularizer), t67.pointwiseRegularizer = B29(this.pointwiseRegularizer), t67.depthwiseConstraint = Z15(this.depthwiseConstraint), t67.pointwiseConstraint = Z15(this.pointwiseConstraint), t67;
  }
};
Zn.className = "SeparableConv";
var Ss = class extends Zn {
  constructor(t67) {
    super(2, t67);
  }
};
Ss.className = "SeparableConv2D";
serialization_exports.registerClass(Ss);
var vs = class s82 extends Ns {
  constructor(t67) {
    super(1, t67), s82.verifyArgs(t67), this.inputSpec = [{ ndim: 3 }];
  }
  getConfig() {
    let t67 = super.getConfig();
    return delete t67.rank, delete t67.dataFormat, t67;
  }
  static verifyArgs(t67) {
    if (typeof t67.kernelSize != "number" && !Ji(t67.kernelSize, "number", 1, 1)) throw new c102(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(t67.kernelSize)}.`);
  }
};
vs.className = "Conv1D";
serialization_exports.registerClass(vs);
var Ls = class extends v41 {
  constructor(t67) {
    super(t67), typeof t67.cropping == "number" ? this.cropping = [[t67.cropping, t67.cropping], [t67.cropping, t67.cropping]] : typeof t67.cropping[0] == "number" ? this.cropping = [[t67.cropping[0], t67.cropping[0]], [t67.cropping[1], t67.cropping[1]]] : this.cropping = t67.cropping, this.dataFormat = t67.dataFormat === void 0 ? "channelsLast" : t67.dataFormat, this.inputSpec = [{ ndim: 4 }];
  }
  computeOutputShape(t67) {
    return this.dataFormat === "channelsFirst" ? [t67[0], t67[1], t67[2] - this.cropping[0][0] - this.cropping[0][1], t67[3] - this.cropping[1][0] - this.cropping[1][1]] : [t67[0], t67[1] - this.cropping[0][0] - this.cropping[0][1], t67[2] - this.cropping[1][0] - this.cropping[1][1], t67[3]];
  }
  call(t67, e36) {
    return g4(() => {
      if (t67 = C27(t67), this.dataFormat === "channelsLast") {
        let i88 = Si(t67, this.cropping[0][0], t67.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);
        return Si(i88, this.cropping[1][0], t67.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);
      } else {
        let i88 = Si(t67, this.cropping[0][0], t67.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);
        return Si(i88, this.cropping[1][0], t67.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);
      }
    });
  }
  getConfig() {
    let t67 = { cropping: this.cropping, dataFormat: this.dataFormat }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Ls.className = "Cropping2D";
serialization_exports.registerClass(Ls);
var Ts = class extends v41 {
  constructor(t67) {
    super(t67), this.DEFAULT_SIZE = [2, 2], this.inputSpec = [{ ndim: 4 }], this.size = t67.size == null ? this.DEFAULT_SIZE : t67.size, this.dataFormat = t67.dataFormat == null ? "channelsLast" : t67.dataFormat, J16(this.dataFormat), this.interpolation = t67.interpolation == null ? "nearest" : t67.interpolation, io2(this.interpolation);
  }
  computeOutputShape(t67) {
    if (this.dataFormat === "channelsFirst") {
      let e36 = t67[2] == null ? null : this.size[0] * t67[2], i88 = t67[3] == null ? null : this.size[1] * t67[3];
      return [t67[0], t67[1], e36, i88];
    } else {
      let e36 = t67[1] == null ? null : this.size[0] * t67[1], i88 = t67[2] == null ? null : this.size[1] * t67[2];
      return [t67[0], e36, i88, t67[3]];
    }
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = C27(t67), n67 = i88.shape;
      if (this.dataFormat === "channelsFirst") {
        i88 = A10(i88, [0, 2, 3, 1]);
        let r56 = this.size[0] * n67[2], o80 = this.size[1] * n67[3], a71 = this.interpolation === "nearest" ? go2.resizeNearestNeighbor(i88, [r56, o80]) : go2.resizeBilinear(i88, [r56, o80]);
        return A10(a71, [0, 3, 1, 2]);
      } else {
        let r56 = this.size[0] * n67[1], o80 = this.size[1] * n67[2];
        return this.interpolation === "nearest" ? go2.resizeNearestNeighbor(i88, [r56, o80]) : go2.resizeBilinear(i88, [r56, o80]);
      }
    });
  }
  getConfig() {
    let t67 = { size: this.size, dataFormat: this.dataFormat, interpolation: this.interpolation }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Ts.className = "UpSampling2D";
serialization_exports.registerClass(Ts);
function pc(s84, t67, e36 = [1, 1], i88 = "valid", n67, r56) {
  return g4(() => {
    n67 == null && (n67 = dt4()), J16(n67);
    let o80 = Vi(s84, n67);
    if (s84.rank !== 4) throw new c102(`Input for depthwiseConv2d is required to be 4-D, but is instead ${s84.rank}-D`);
    if (t67.rank !== 4) throw new c102(`depthwiseKernel is required to be 4-D, but is instead ${t67.rank}-D`);
    return o80 = g11(o80, t67, e36, i88 === "same" ? "same" : "valid", "NHWC", r56), n67 === "channelsFirst" && (o80 = A10(o80, [0, 3, 1, 2])), o80;
  });
}
var Es = class extends Wi {
  constructor(t67) {
    super(2, t67), this.depthwiseKernel = null, this.depthMultiplier = t67.depthMultiplier == null ? 1 : t67.depthMultiplier, this.depthwiseInitializer = U23(t67.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.depthwiseConstraint = G29(t67.depthwiseConstraint), this.depthwiseRegularizer = j21(t67.depthwiseRegularizer);
  }
  build(t67) {
    if (t67 = E43(t67), t67.length < 4) throw new c102(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(t67)}.`);
    let e36 = this.dataFormat === "channelsFirst" ? 1 : 3;
    if (t67[e36] == null || t67[e36] < 0) throw new c102(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${t67[e36]}).`);
    let i88 = t67[e36], n67 = [this.kernelSize[0], this.kernelSize[1], i88, this.depthMultiplier];
    this.depthwiseKernel = this.addWeight("depthwise_kernel", n67, null, this.depthwiseInitializer, this.depthwiseRegularizer, true, this.depthwiseConstraint), this.useBias ? this.bias = this.addWeight("bias", [i88 * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint) : this.bias = null, this.built = true;
  }
  call(t67, e36) {
    return g4(() => {
      t67 = C27(t67);
      let i88 = pc(t67, this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);
      return this.useBias && (i88 = mt5(i88, this.bias.read(), this.dataFormat)), this.activation != null && (i88 = this.activation.apply(i88)), i88;
    });
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = this.dataFormat === "channelsFirst" ? t67[2] : t67[1], i88 = this.dataFormat === "channelsFirst" ? t67[3] : t67[2], n67 = this.dataFormat === "channelsFirst" ? t67[1] * this.depthMultiplier : t67[3] * this.depthMultiplier, r56 = wt4(e36, this.kernelSize[0], this.padding, this.strides[0]), o80 = wt4(i88, this.kernelSize[1], this.padding, this.strides[1]);
    return this.dataFormat === "channelsFirst" ? [t67[0], n67, r56, o80] : [t67[0], r56, o80, n67];
  }
  getConfig() {
    let t67 = super.getConfig();
    return t67.depthMultiplier = this.depthMultiplier, t67.depthwiseInitializer = H17(this.depthwiseInitializer), t67.depthwiseRegularizer = B29(this.depthwiseRegularizer), t67.depthwiseConstraint = Z15(this.depthwiseRegularizer), t67;
  }
};
Es.className = "DepthwiseConv2D";
serialization_exports.registerClass(Es);
function $r(s84, t67, e36, i88) {
  if (Array.isArray(s84)) {
    if (t67 != null || e36 != null) throw new c102("When inputs is an array, neither initialState or constants should be provided");
    i88 != null && (e36 = s84.slice(s84.length - i88, s84.length), s84 = s84.slice(0, s84.length - i88)), s84.length > 1 && (t67 = s84.slice(1, s84.length)), s84 = s84[0];
  }
  function n67(r56) {
    return r56 == null || Array.isArray(r56) ? r56 : [r56];
  }
  return t67 = n67(t67), e36 = n67(e36), { inputs: s84, initialState: t67, constants: e36 };
}
function Fr(s84, t67, e36, i88 = false, n67, r56, o80 = false, a71 = false) {
  return g4(() => {
    let l80 = t67.shape.length;
    if (l80 < 3) throw new c102(`Input should be at least 3D, but is ${l80}D.`);
    let u86 = [1, 0].concat(ft5(2, l80));
    if (t67 = A10(t67, u86), r56 != null) throw new S44("The rnn() functoin of the deeplearn.js backend does not support constants yet.");
    o80 && console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."), n67 != null && (n67 = w12(w12(n67, "bool"), "float32"), n67.rank === l80 - 1 && (n67 = D7(n67, -1)), n67 = A10(n67, u86)), i88 && (t67 = E21(t67, 0), n67 != null && (n67 = E21(n67, 0)));
    let h74 = [], p103, f85 = e36, w45 = t67.shape[0], b58 = g22(t67), m96;
    n67 != null && (m96 = g22(n67));
    for (let x76 = 0; x76 < w45; ++x76) {
      let d55 = b58[x76], k63 = g4(() => s84(d55, f85));
      if (n67 == null) p103 = k63[0], f85 = k63[1];
      else {
        let A35 = g4(() => {
          let z32 = m96[x76], D42 = E16(k15(z32), z32), q25 = T7(y8(k63[0], z32), y8(f85[0], D42)), R26 = f85.map((O21, F32) => T7(y8(k63[1][F32], z32), y8(O21, D42)));
          return { output: q25, newStates: R26 };
        });
        p103 = A35.output, f85 = A35.newStates;
      }
      a71 && h74.push(p103);
    }
    let g72;
    return a71 && (g72 = g21(h74, 1)), [p103, g72, f85];
  });
}
var kt3 = class s83 extends v41 {
  constructor(t67) {
    super(t67);
    let e36;
    if (t67.cell == null) throw new c102("cell property is missing for the constructor of RNN.");
    if (Array.isArray(t67.cell) ? e36 = new Re5({ cells: t67.cell }) : e36 = t67.cell, e36.stateSize == null) throw new c102("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");
    this.cell = e36, this.returnSequences = t67.returnSequences == null ? false : t67.returnSequences, this.returnState = t67.returnState == null ? false : t67.returnState, this.goBackwards = t67.goBackwards == null ? false : t67.goBackwards, this._stateful = t67.stateful == null ? false : t67.stateful, this.unroll = t67.unroll == null ? false : t67.unroll, this.supportsMasking = true, this.inputSpec = [new K20({ ndim: 3 })], this.stateSpec = null, this.states_ = null, this.numConstants = null, this.keptStates = [];
  }
  getStates() {
    if (this.states_ == null) {
      let t67 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      return ft5(0, t67).map((e36) => null);
    } else return this.states_;
  }
  setStates(t67) {
    this.states_ = t67;
  }
  computeOutputShape(t67) {
    on2(t67) && (t67 = t67[0]), t67 = t67;
    let e36 = this.cell.stateSize;
    Array.isArray(e36) || (e36 = [e36]);
    let i88 = e36[0], n67;
    if (this.returnSequences ? n67 = [t67[0], t67[1], i88] : n67 = [t67[0], i88], this.returnState) {
      let r56 = [];
      for (let o80 of e36) r56.push([t67[0], o80]);
      return [n67].concat(r56);
    } else return n67;
  }
  computeMask(t67, e36) {
    return g4(() => {
      Array.isArray(e36) && (e36 = e36[0]);
      let i88 = this.returnSequences ? e36 : null;
      if (this.returnState) {
        let n67 = this.states.map((r56) => null);
        return [i88].concat(n67);
      } else return i88;
    });
  }
  get states() {
    if (this.states_ == null) {
      let t67 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1, e36 = [];
      for (let i88 = 0; i88 < t67; ++i88) e36.push(null);
      return e36;
    } else return this.states_;
  }
  set states(t67) {
    this.states_ = t67;
  }
  build(t67) {
    if (this.numConstants != null) throw new S44("Constants support is not implemented in RNN yet.");
    on2(t67) && (t67 = t67[0]), t67 = t67;
    let i88 = this.stateful ? t67[0] : null, n67 = t67.slice(2);
    this.inputSpec[0] = new K20({ shape: [i88, null, ...n67] });
    let r56 = [t67[0]].concat(t67.slice(2));
    this.cell.build(r56);
    let o80;
    if (Array.isArray(this.cell.stateSize) ? o80 = this.cell.stateSize : o80 = [this.cell.stateSize], this.stateSpec != null) {
      if (!util_exports.arraysEqual(this.stateSpec.map((a71) => a71.shape[a71.shape.length - 1]), o80)) throw new c102(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`);
    } else this.stateSpec = o80.map((a71) => new K20({ shape: [null, a71] }));
    this.stateful && this.resetStates();
  }
  resetStates(t67, e36 = false) {
    g4(() => {
      if (!this.stateful) throw new At3("Cannot call resetStates() on an RNN Layer that is not stateful.");
      let i88 = this.inputSpec[0].shape[0];
      if (i88 == null) throw new c102("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      if (this.states_ == null) Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map((n67) => e13([i88, n67])) : this.states_ = [e13([i88, this.cell.stateSize])];
      else if (t67 == null) E4(this.states_), this.keptStates != null && (E4(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map((n67) => e13([i88, n67])) : this.states_[0] = e13([i88, this.cell.stateSize]);
      else {
        if (Array.isArray(t67) || (t67 = [t67]), t67.length !== this.states_.length) throw new c102(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t67.length} state value(s). Input received: ${t67}`);
        e36 === true ? this.keptStates.push(this.states_.slice()) : E4(this.states_);
        for (let n67 = 0; n67 < this.states_.length; ++n67) {
          let r56 = t67[n67], o80 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[n67] : this.cell.stateSize, a71 = [i88, o80];
          if (!util_exports.arraysEqual(r56.shape, a71)) throw new c102(`State ${n67} is incompatible with layer ${this.name}: expected shape=${a71}, received shape=${r56.shape}`);
          this.states_[n67] = r56;
        }
      }
      this.states_ = this.states_.map((n67) => N3(n67.clone()));
    });
  }
  apply(t67, e36) {
    let i88 = e36 == null ? null : e36.initialState, n67 = e36 == null ? null : e36.constants;
    e36 == null && (e36 = {});
    let r56 = $r(t67, i88, n67, this.numConstants);
    t67 = r56.inputs, i88 = r56.initialState, n67 = r56.constants;
    let o80 = [], a71 = [];
    if (i88 != null) {
      e36.initialState = i88, o80 = o80.concat(i88), this.stateSpec = [];
      for (let u86 of i88) this.stateSpec.push(new K20({ shape: u86.shape }));
      a71 = a71.concat(this.stateSpec);
    }
    if (n67 != null && (e36.constants = n67, o80 = o80.concat(n67), this.numConstants = n67.length), o80[0] instanceof ut3) {
      let u86 = [t67].concat(o80), h74 = this.inputSpec.concat(a71), p103 = this.inputSpec;
      this.inputSpec = h74;
      let f85 = super.apply(u86, e36);
      return this.inputSpec = p103, f85;
    } else return super.apply(t67, e36);
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = e36 == null ? null : e36.mask, n67 = e36 == null ? null : e36.training, r56 = e36 == null ? null : e36.initialState;
      t67 = C27(t67), r56 == null && (this.stateful ? r56 = this.states_ : r56 = this.getInitialState(t67));
      let o80 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      if (r56.length !== o80) throw new c102(`RNN Layer has ${o80} state(s) but was passed ${r56.length} initial state(s).`);
      this.unroll && console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");
      let a71 = { training: n67 }, u86 = Fr((b58, m96) => {
        let g72 = this.cell.call([b58].concat(m96), a71);
        return [g72[0], g72.slice(1)];
      }, t67, r56, this.goBackwards, i88, null, this.unroll, this.returnSequences), h74 = u86[0], p103 = u86[1], f85 = u86[2];
      this.stateful && this.resetStates(f85, n67);
      let w45 = this.returnSequences ? p103 : h74;
      return this.returnState ? [w45].concat(f85) : w45;
    });
  }
  getInitialState(t67) {
    return g4(() => {
      let e36 = e13(t67.shape);
      return e36 = T10(e36, [1, 2]), e36 = Zt3(e36), Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map((i88) => i88 > 1 ? en(e36, [1, i88]) : e36) : this.cell.stateSize > 1 ? [en(e36, [1, this.cell.stateSize])] : [e36];
    });
  }
  get trainableWeights() {
    return this.trainable ? this.cell.trainableWeights : [];
  }
  get nonTrainableWeights() {
    return this.trainable ? this.cell.nonTrainableWeights : this.cell.weights;
  }
  setFastWeightInitDuringBuild(t67) {
    super.setFastWeightInitDuringBuild(t67), this.cell != null && this.cell.setFastWeightInitDuringBuild(t67);
  }
  getConfig() {
    let t67 = super.getConfig(), e36 = { returnSequences: this.returnSequences, returnState: this.returnState, goBackwards: this.goBackwards, stateful: this.stateful, unroll: this.unroll };
    this.numConstants != null && (e36.numConstants = this.numConstants);
    let i88 = this.cell.getConfig();
    return this.getClassName() === s83.className && (e36.cell = { className: this.cell.getClassName(), config: i88 }), Object.assign(Object.assign(Object.assign({}, i88), t67), e36);
  }
  static fromConfig(t67, e36, i88 = {}) {
    let n67 = e36.cell, r56 = yt5(n67, i88);
    return new t67(Object.assign(e36, { cell: r56 }));
  }
};
kt3.className = "RNN";
serialization_exports.registerClass(kt3);
var Xt3 = class extends v41 {
};
var _e3 = class extends Xt3 {
  constructor(t67) {
    super(t67), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", this.units = t67.units, Y13(this.units, "units"), this.activation = $t3(t67.activation == null ? this.DEFAULT_ACTIVATION : t67.activation), this.useBias = t67.useBias == null ? true : t67.useBias, this.kernelInitializer = U23(t67.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = U23(t67.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = U23(t67.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = j21(t67.kernelRegularizer), this.recurrentRegularizer = j21(t67.recurrentRegularizer), this.biasRegularizer = j21(t67.biasRegularizer), this.kernelConstraint = G29(t67.kernelConstraint), this.recurrentConstraint = G29(t67.recurrentConstraint), this.biasConstraint = G29(t67.biasConstraint), this.dropout = we3([1, _t4([0, t67.dropout == null ? 0 : t67.dropout])]), this.recurrentDropout = we3([1, _t4([0, t67.recurrentDropout == null ? 0 : t67.recurrentDropout])]), this.dropoutFunc = t67.dropoutFunc, this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;
  }
  build(t67) {
    t67 = E43(t67), this.kernel = this.addWeight("kernel", [t67[t67.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint), this.useBias ? this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint) : this.bias = null, this.built = true;
  }
  call(t67, e36) {
    return g4(() => {
      if (t67 = t67, t67.length !== 2) throw new c102(`SimpleRNNCell expects 2 input Tensors, got ${t67.length}.`);
      let i88 = t67[1];
      t67 = t67[0];
      let n67 = e36.training == null ? false : e36.training;
      0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = te7({ ones: () => k15(t67), rate: this.dropout, training: n67, dropoutFunc: this.dropoutFunc })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = te7({ ones: () => k15(i88), rate: this.recurrentDropout, training: n67, dropoutFunc: this.dropoutFunc }));
      let r56, o80 = this.dropoutMask, a71 = this.recurrentDropoutMask;
      o80 != null ? r56 = Lt3(y8(t67, o80), this.kernel.read()) : r56 = Lt3(t67, this.kernel.read()), this.bias != null && (r56 = mt5(r56, this.bias.read())), a71 != null && (i88 = y8(i88, a71));
      let l80 = T7(r56, Lt3(i88, this.recurrentKernel.read()));
      return this.activation != null && (l80 = this.activation.apply(l80)), [l80, l80];
    });
  }
  getConfig() {
    let t67 = super.getConfig(), e36 = { units: this.units, activation: Rt3(this.activation), useBias: this.useBias, kernelInitializer: H17(this.kernelInitializer), recurrentInitializer: H17(this.recurrentInitializer), biasInitializer: H17(this.biasInitializer), kernelRegularizer: B29(this.kernelRegularizer), recurrentRegularizer: B29(this.recurrentRegularizer), biasRegularizer: B29(this.biasRegularizer), activityRegularizer: B29(this.activityRegularizer), kernelConstraint: Z15(this.kernelConstraint), recurrentConstraint: Z15(this.recurrentConstraint), biasConstraint: Z15(this.biasConstraint), dropout: this.dropout, recurrentDropout: this.recurrentDropout };
    return Object.assign(Object.assign({}, t67), e36);
  }
};
_e3.className = "SimpleRNNCell";
serialization_exports.registerClass(_e3);
var Ds = class extends kt3 {
  constructor(t67) {
    t67.cell = new _e3(t67), super(t67);
  }
  call(t67, e36) {
    return g4(() => {
      this.cell.dropoutMask != null && (E4(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (E4(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null);
      let i88 = e36 == null ? null : e36.mask, n67 = e36 == null ? null : e36.training, r56 = e36 == null ? null : e36.initialState;
      return super.call(t67, { mask: i88, training: n67, initialState: r56 });
    });
  }
  static fromConfig(t67, e36) {
    return new t67(e36);
  }
};
Ds.className = "SimpleRNN";
serialization_exports.registerClass(Ds);
var Me2 = class extends Xt3 {
  constructor(t67) {
    if (super(t67), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", t67.resetAfter) throw new c102("GRUCell does not support reset_after parameter set to true.");
    this.units = t67.units, Y13(this.units, "units"), this.activation = $t3(t67.activation === void 0 ? this.DEFAULT_ACTIVATION : t67.activation), this.recurrentActivation = $t3(t67.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : t67.recurrentActivation), this.useBias = t67.useBias == null ? true : t67.useBias, this.kernelInitializer = U23(t67.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = U23(t67.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = U23(t67.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = j21(t67.kernelRegularizer), this.recurrentRegularizer = j21(t67.recurrentRegularizer), this.biasRegularizer = j21(t67.biasRegularizer), this.kernelConstraint = G29(t67.kernelConstraint), this.recurrentConstraint = G29(t67.recurrentConstraint), this.biasConstraint = G29(t67.biasConstraint), this.dropout = we3([1, _t4([0, t67.dropout == null ? 0 : t67.dropout])]), this.recurrentDropout = we3([1, _t4([0, t67.recurrentDropout == null ? 0 : t67.recurrentDropout])]), this.dropoutFunc = t67.dropoutFunc, this.implementation = t67.implementation, this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;
  }
  build(t67) {
    t67 = E43(t67);
    let e36 = t67[t67.length - 1];
    this.kernel = this.addWeight("kernel", [e36, this.units * 3], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 3], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint), this.useBias ? this.bias = this.addWeight("bias", [this.units * 3], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint) : this.bias = null, this.built = true;
  }
  call(t67, e36) {
    return g4(() => {
      if (t67 = t67, t67.length !== 2) throw new c102(`GRUCell expects 2 input Tensors (inputs, h, c), got ${t67.length}.`);
      let i88 = e36.training == null ? false : e36.training, n67 = t67[1];
      t67 = t67[0], 0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = te7({ ones: () => k15(t67), rate: this.dropout, training: i88, count: 3, dropoutFunc: this.dropoutFunc })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = te7({ ones: () => k15(n67), rate: this.recurrentDropout, training: i88, count: 3, dropoutFunc: this.dropoutFunc }));
      let r56 = this.dropoutMask, o80 = this.recurrentDropoutMask, a71, l80, u86;
      0 < this.dropout && this.dropout < 1 && (t67 = y8(t67, r56[0]));
      let h74 = Lt3(t67, this.kernel.read());
      this.useBias && (h74 = mt5(h74, this.bias.read())), 0 < this.recurrentDropout && this.recurrentDropout < 1 && (n67 = y8(n67, o80[0]));
      let p103 = this.recurrentKernel.read(), [f85, w45] = N17(p103, [2 * this.units, this.units], p103.rank - 1), b58 = Lt3(n67, f85), [m96, g72, x76] = N17(h74, 3, h74.rank - 1), [d55, k63] = N17(b58, 2, b58.rank - 1);
      a71 = this.recurrentActivation.apply(T7(m96, d55)), l80 = this.recurrentActivation.apply(T7(g72, k63));
      let A35 = Lt3(y8(l80, n67), w45);
      u86 = this.activation.apply(T7(x76, A35));
      let z32 = T7(y8(a71, n67), y8(T7(1, g14(a71)), u86));
      return [z32, z32];
    });
  }
  getConfig() {
    let t67 = super.getConfig(), e36 = { units: this.units, activation: Rt3(this.activation), recurrentActivation: Rt3(this.recurrentActivation), useBias: this.useBias, kernelInitializer: H17(this.kernelInitializer), recurrentInitializer: H17(this.recurrentInitializer), biasInitializer: H17(this.biasInitializer), kernelRegularizer: B29(this.kernelRegularizer), recurrentRegularizer: B29(this.recurrentRegularizer), biasRegularizer: B29(this.biasRegularizer), activityRegularizer: B29(this.activityRegularizer), kernelConstraint: Z15(this.kernelConstraint), recurrentConstraint: Z15(this.recurrentConstraint), biasConstraint: Z15(this.biasConstraint), dropout: this.dropout, recurrentDropout: this.recurrentDropout, implementation: this.implementation, resetAfter: false };
    return Object.assign(Object.assign({}, t67), e36);
  }
};
Me2.className = "GRUCell";
serialization_exports.registerClass(Me2);
var Os = class extends kt3 {
  constructor(t67) {
    t67.implementation === 0 && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."), t67.cell = new Me2(t67), super(t67);
  }
  call(t67, e36) {
    return g4(() => {
      this.cell.dropoutMask != null && (E4(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (E4(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null);
      let i88 = e36 == null ? null : e36.mask, n67 = e36 == null ? null : e36.training, r56 = e36 == null ? null : e36.initialState;
      return super.call(t67, { mask: i88, training: n67, initialState: r56 });
    });
  }
  static fromConfig(t67, e36) {
    return e36.implmentation === 0 && (e36.implementation = 1), new t67(e36);
  }
};
Os.className = "GRU";
serialization_exports.registerClass(Os);
var Qt3 = class extends Xt3 {
  constructor(t67) {
    super(t67), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", this.units = t67.units, Y13(this.units, "units"), this.activation = $t3(t67.activation === void 0 ? this.DEFAULT_ACTIVATION : t67.activation), this.recurrentActivation = $t3(t67.recurrentActivation === void 0 ? this.DEFAULT_RECURRENT_ACTIVATION : t67.recurrentActivation), this.useBias = t67.useBias == null ? true : t67.useBias, this.kernelInitializer = U23(t67.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = U23(t67.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = U23(t67.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.unitForgetBias = t67.unitForgetBias, this.kernelRegularizer = j21(t67.kernelRegularizer), this.recurrentRegularizer = j21(t67.recurrentRegularizer), this.biasRegularizer = j21(t67.biasRegularizer), this.kernelConstraint = G29(t67.kernelConstraint), this.recurrentConstraint = G29(t67.recurrentConstraint), this.biasConstraint = G29(t67.biasConstraint), this.dropout = we3([1, _t4([0, t67.dropout == null ? 0 : t67.dropout])]), this.recurrentDropout = we3([1, _t4([0, t67.recurrentDropout == null ? 0 : t67.recurrentDropout])]), this.dropoutFunc = t67.dropoutFunc, this.implementation = t67.implementation, this.stateSize = [this.units, this.units], this.dropoutMask = null, this.recurrentDropoutMask = null;
  }
  build(t67) {
    var e36;
    t67 = E43(t67);
    let i88 = t67[t67.length - 1];
    this.kernel = this.addWeight("kernel", [i88, this.units * 4], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units * 4], null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);
    let n67;
    if (this.useBias) {
      if (this.unitForgetBias) {
        let r56 = this.biasInitializer, o80 = this.units;
        n67 = new (e36 = class extends gt3 {
          apply(l80, u86) {
            let h74 = r56.apply([o80]), p103 = new ue7().apply([o80]), f85 = r56.apply([o80 * 2]);
            return br(br(h74, p103), f85);
          }
        }, e36.className = "CustomInit", e36)();
      } else n67 = this.biasInitializer;
      this.bias = this.addWeight("bias", [this.units * 4], null, n67, this.biasRegularizer, true, this.biasConstraint);
    } else this.bias = null;
    this.built = true;
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = e36.training == null ? false : e36.training;
      if (t67 = t67, t67.length !== 3) throw new c102(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${t67.length}.`);
      let n67 = t67[1], r56 = t67[2];
      t67 = t67[0], 0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = te7({ ones: () => k15(t67), rate: this.dropout, training: i88, count: 4, dropoutFunc: this.dropoutFunc })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = te7({ ones: () => k15(n67), rate: this.recurrentDropout, training: i88, count: 4, dropoutFunc: this.dropoutFunc }));
      let o80 = this.dropoutMask, a71 = this.recurrentDropoutMask, l80, u86, h74, p103;
      0 < this.dropout && this.dropout < 1 && (t67 = y8(t67, o80[0]));
      let f85 = Lt3(t67, this.kernel.read());
      0 < this.recurrentDropout && this.recurrentDropout < 1 && (n67 = y8(n67, a71[0])), f85 = T7(f85, Lt3(n67, this.recurrentKernel.read())), this.useBias && (f85 = mt5(f85, this.bias.read()));
      let [w45, b58, m96, g72] = N17(f85, 4, f85.rank - 1);
      l80 = this.recurrentActivation.apply(w45), u86 = this.recurrentActivation.apply(b58), h74 = T7(y8(u86, r56), y8(l80, this.activation.apply(m96))), p103 = this.recurrentActivation.apply(g72);
      let x76 = y8(p103, this.activation.apply(h74));
      return [x76, x76, h74];
    });
  }
  getConfig() {
    let t67 = super.getConfig(), e36 = { units: this.units, activation: Rt3(this.activation), recurrentActivation: Rt3(this.recurrentActivation), useBias: this.useBias, kernelInitializer: H17(this.kernelInitializer), recurrentInitializer: H17(this.recurrentInitializer), biasInitializer: H17(this.biasInitializer), unitForgetBias: this.unitForgetBias, kernelRegularizer: B29(this.kernelRegularizer), recurrentRegularizer: B29(this.recurrentRegularizer), biasRegularizer: B29(this.biasRegularizer), activityRegularizer: B29(this.activityRegularizer), kernelConstraint: Z15(this.kernelConstraint), recurrentConstraint: Z15(this.recurrentConstraint), biasConstraint: Z15(this.biasConstraint), dropout: this.dropout, recurrentDropout: this.recurrentDropout, implementation: this.implementation };
    return Object.assign(Object.assign({}, t67), e36);
  }
};
Qt3.className = "LSTMCell";
serialization_exports.registerClass(Qt3);
var _s = class extends kt3 {
  constructor(t67) {
    t67.implementation === 0 && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."), t67.cell = new Qt3(t67), super(t67);
  }
  call(t67, e36) {
    return g4(() => {
      this.cell.dropoutMask != null && (E4(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (E4(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null);
      let i88 = e36 == null ? null : e36.mask, n67 = e36 == null ? null : e36.training, r56 = e36 == null ? null : e36.initialState;
      return super.call(t67, { mask: i88, training: n67, initialState: r56 });
    });
  }
  static fromConfig(t67, e36) {
    return e36.implmentation === 0 && (e36.implementation = 1), new t67(e36);
  }
};
_s.className = "LSTM";
serialization_exports.registerClass(_s);
var Re5 = class extends Xt3 {
  constructor(t67) {
    super(t67), this.cells = t67.cells;
  }
  get stateSize() {
    let t67 = [];
    for (let e36 of this.cells.slice().reverse()) Array.isArray(e36.stateSize) ? t67.push(...e36.stateSize) : t67.push(e36.stateSize);
    return t67;
  }
  call(t67, e36) {
    return g4(() => {
      t67 = t67;
      let i88 = t67.slice(1), n67 = [];
      for (let a71 of this.cells.slice().reverse()) Array.isArray(a71.stateSize) ? n67.push(i88.splice(0, a71.stateSize.length)) : n67.push(i88.splice(0, 1));
      n67.reverse();
      let r56 = [], o80;
      for (let a71 = 0; a71 < this.cells.length; ++a71) {
        let l80 = this.cells[a71];
        i88 = n67[a71], a71 === 0 ? o80 = [t67[0]].concat(i88) : o80 = [o80[0]].concat(i88), o80 = l80.call(o80, e36), r56.push(o80.slice(1));
      }
      i88 = [];
      for (let a71 of r56.slice().reverse()) i88.push(...a71);
      return [o80[0]].concat(i88);
    });
  }
  build(t67) {
    on2(t67) && (t67 = t67[0]), t67 = t67;
    let e36;
    this.cells.forEach((i88, n67) => {
      Ot4(`RNNCell_${n67}`, () => {
        i88.build(t67), Array.isArray(i88.stateSize) ? e36 = i88.stateSize[0] : e36 = i88.stateSize, t67 = [t67[0], e36];
      });
    }), this.built = true;
  }
  getConfig() {
    let t67 = super.getConfig(), e36 = (r56) => ({ className: r56.getClassName(), config: r56.getConfig() }), n67 = { cells: this.cells.map(e36) };
    return Object.assign(Object.assign({}, t67), n67);
  }
  static fromConfig(t67, e36, i88 = {}) {
    let n67 = [];
    for (let r56 of e36.cells) n67.push(yt5(r56, i88));
    return new t67({ cells: n67 });
  }
  get trainableWeights() {
    if (!this.trainable) return [];
    let t67 = [];
    for (let e36 of this.cells) t67.push(...e36.trainableWeights);
    return t67;
  }
  get nonTrainableWeights() {
    let t67 = [];
    for (let e36 of this.cells) t67.push(...e36.nonTrainableWeights);
    if (!this.trainable) {
      let e36 = [];
      for (let i88 of this.cells) e36.push(...i88.trainableWeights);
      return e36.concat(t67);
    }
    return t67;
  }
  getWeights() {
    let t67 = [];
    for (let e36 of this.cells) t67.push(...e36.weights);
    return Li(t67);
  }
  setWeights(t67) {
    let e36 = [];
    for (let i88 of this.cells) {
      let n67 = i88.weights.length, r56 = t67.splice(n67);
      for (let o80 = 0; o80 < i88.weights.length; ++o80) e36.push([i88.weights[o80], r56[o80]]);
    }
    is2(e36);
  }
};
Re5.className = "StackedRNNCells";
serialization_exports.registerClass(Re5);
function te7(s84) {
  let { ones: t67, rate: e36, training: i88 = false, count: n67 = 1, dropoutFunc: r56 } = s84, o80 = () => r56 != null ? r56(t67(), e36) : nn2(t67(), e36), a71 = () => le6(o80, t67, i88);
  return !n67 || n67 <= 1 ? N3(a71().clone()) : Array(n67).fill(void 0).map(a71).map((u86) => N3(u86.clone()));
}
var fc = function(s84, t67) {
  var e36 = {};
  for (var i88 in s84) Object.prototype.hasOwnProperty.call(s84, i88) && t67.indexOf(i88) < 0 && (e36[i88] = s84[i88]);
  if (s84 != null && typeof Object.getOwnPropertySymbols == "function") for (var n67 = 0, i88 = Object.getOwnPropertySymbols(s84); n67 < i88.length; n67++) t67.indexOf(i88[n67]) < 0 && Object.prototype.propertyIsEnumerable.call(s84, i88[n67]) && (e36[i88[n67]] = s84[i88[n67]]);
  return e36;
};
var Yn = class extends kt3 {
  constructor(t67) {
    if (t67.unroll) throw new S44("Unrolling is not possible with convolutional RNNs.");
    if (Array.isArray(t67.cell)) throw new S44("It is not possible at the moment to stack convolutional cells.");
    super(t67), this.inputSpec = [new K20({ ndim: 5 })];
  }
  call(t67, e36) {
    return g4(() => {
      if (this.cell.dropoutMask != null && (E4(this.cell.dropoutMask), this.cell.dropoutMask = null), this.cell.recurrentDropoutMask != null && (E4(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), e36 && e36.constants) throw new c102("ConvRNN2D cell does not support constants");
      let i88 = e36 == null ? null : e36.mask, n67 = e36 == null ? null : e36.training, r56 = e36 == null ? null : e36.initialState;
      return super.call(t67, { mask: i88, training: n67, initialState: r56 });
    });
  }
  computeOutputShape(t67) {
    let e36 = this.computeSingleOutputShape(t67);
    return this.returnSequences || (e36 = [e36[0], ...e36.slice(2)]), this.returnState && (e36 = [e36, ...Array(2).fill([t67[0], ...e36.slice(-3)])]), e36;
  }
  getInitialState(t67) {
    return g4(() => {
      let { stateSize: e36 } = this.cell, i88 = t67.shape, n67 = this.computeSingleOutputShape(i88), r56 = [n67[0], ...n67.slice(2)], o80 = e13(r56);
      return Array.isArray(e36) ? Array(e36.length).fill(o80) : [o80];
    });
  }
  resetStates(t67, e36 = false) {
    g4(() => {
      if (!this.stateful) throw new At3("Cannot call resetStates() on an RNN Layer that is not stateful.");
      let i88 = this.inputSpec[0].shape, n67 = this.computeSingleOutputShape(i88), r56 = [n67[0], ...n67.slice(2)];
      if (i88[0] == null) throw new c102("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      if (this.getStates() == null) Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(() => e13(r56)) : this.states_ = [e13(r56)];
      else if (t67 == null) E4(this.states_), this.keptStates != null && (E4(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(() => e13(r56)) : this.states_[0] = e13(r56);
      else {
        if (Array.isArray(t67) || (t67 = [t67]), t67.length !== this.states_.length) throw new c102(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${t67.length} state value(s). Input received: ${t67}`);
        e36 ? this.keptStates.push(this.states_.slice()) : E4(this.states_);
        for (let a71 = 0; a71 < this.states_.length; ++a71) {
          let l80 = t67[a71], u86 = r56;
          if (!util_exports.arraysEqual(l80.shape, u86)) throw new c102(`State ${a71} is incompatible with layer ${this.name}: expected shape=${u86}, received shape=${l80.shape}`);
          this.states_[a71] = l80;
        }
      }
      this.states_ = this.states_.map((a71) => N3(a71.clone()));
    });
  }
  computeSingleOutputShape(t67) {
    let { dataFormat: e36, filters: i88, kernelSize: n67, padding: r56, strides: o80, dilationRate: a71 } = this.cell, l80 = e36 === "channelsFirst", u86 = t67[l80 ? 3 : 2], h74 = t67[l80 ? 4 : 3], p103 = wt4(u86, n67[0], r56, o80[0], a71[0]), f85 = wt4(h74, n67[1], r56, o80[1], a71[1]);
    return [...t67.slice(0, 2), ...l80 ? [i88, p103, f85] : [p103, f85, i88]];
  }
};
Yn.className = "ConvRNN2D";
var $e2 = class extends Qt3 {
  constructor(t67) {
    let { filters: e36, kernelSize: i88, strides: n67, padding: r56, dataFormat: o80, dilationRate: a71 } = t67;
    super(Object.assign(Object.assign({}, t67), { units: e36 })), this.filters = e36, Y13(this.filters, "filters"), this.kernelSize = fe5(i88, 2, "kernelSize"), this.kernelSize.forEach((l80) => Y13(l80, "kernelSize")), this.strides = fe5(n67 || 1, 2, "strides"), this.strides.forEach((l80) => Y13(l80, "strides")), this.padding = r56 || "valid", pt2(this.padding), this.dataFormat = o80 || "channelsLast", J16(this.dataFormat), this.dilationRate = fe5(a71 || 1, 2, "dilationRate"), this.dilationRate.forEach((l80) => Y13(l80, "dilationRate"));
  }
  build(t67) {
    var e36;
    t67 = E43(t67);
    let i88 = this.dataFormat === "channelsFirst" ? 1 : t67.length - 1;
    if (t67[i88] == null) throw new c102(`The channel dimension of the input should be defined. Found ${t67[i88]}`);
    let n67 = t67[i88], r56 = 4, o80 = this.kernelSize.concat([n67, this.filters * r56]);
    this.kernel = this.addWeight("kernel", o80, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);
    let a71 = this.kernelSize.concat([this.filters, this.filters * r56]);
    if (this.recurrentKernel = this.addWeight("recurrent_kernel", a71, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint), this.useBias) {
      let l80;
      if (this.unitForgetBias) {
        let u86 = this.biasInitializer, h74 = this.filters;
        l80 = new (e36 = class extends gt3 {
          apply(f85, w45) {
            let b58 = u86.apply([h74]), m96 = c26([h74]), g72 = u86.apply([h74 * 2]);
            return qe([b58, m96, g72]);
          }
        }, e36.className = "CustomInit", e36)();
      } else l80 = this.biasInitializer;
      this.bias = this.addWeight("bias", [this.filters * r56], null, l80, this.biasRegularizer, true, this.biasConstraint);
    }
    this.built = true;
  }
  call(t67, e36) {
    return g4(() => {
      if (t67.length !== 3) throw new c102(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${t67.length}.`);
      let i88 = e36.training || false, n67 = t67[0], r56 = t67[1], o80 = t67[2], a71 = 4;
      0 < this.dropout && this.dropout < 1 && this.dropoutMask == null && (this.dropoutMask = te7({ ones: () => k15(n67), rate: this.dropout, training: i88, count: a71, dropoutFunc: this.dropoutFunc }));
      let l80 = this.dropoutMask, u86 = (qr2, hr, Hr) => !hr || !hr[Hr] ? qr2 : y8(hr[Hr], qr2), h74 = u86(n67, l80, 0), p103 = u86(n67, l80, 1), f85 = u86(n67, l80, 2), w45 = u86(n67, l80, 3);
      0 < this.recurrentDropout && this.recurrentDropout < 1 && this.recurrentDropoutMask == null && (this.recurrentDropoutMask = te7({ ones: () => k15(r56), rate: this.recurrentDropout, training: i88, count: a71, dropoutFunc: this.dropoutFunc }));
      let b58 = this.recurrentDropoutMask, m96 = u86(r56, b58, 0), g72 = u86(r56, b58, 1), x76 = u86(r56, b58, 2), d55 = u86(r56, b58, 3), k63 = 3, [A35, z32, D42, q25] = N17(this.kernel.read(), a71, k63), [R26, O21, F32, ct4] = this.useBias ? N17(this.bias.read(), a71) : [null, null, null, null];
      h74 = this.inputConv(h74, A35, R26, this.padding), p103 = this.inputConv(p103, z32, O21, this.padding), f85 = this.inputConv(f85, D42, F32, this.padding), w45 = this.inputConv(w45, q25, ct4, this.padding);
      let [ne7, Ai, Ii, re7] = N17(this.recurrentKernel.read(), a71, k63);
      m96 = this.recurrentConv(m96, ne7), g72 = this.recurrentConv(g72, Ai), x76 = this.recurrentConv(x76, Ii), d55 = this.recurrentConv(d55, re7);
      let oe8 = this.recurrentActivation.apply(T7(h74, m96)), Ue = this.recurrentActivation.apply(T7(p103, g72)), ki = T7(y8(Ue, o80), y8(oe8, this.activation.apply(T7(f85, x76)))), jr = y8(this.recurrentActivation.apply(T7(w45, d55)), this.activation.apply(ki));
      return [jr, jr, ki];
    });
  }
  getConfig() {
    let t67 = super.getConfig(), { units: e36 } = t67, i88 = fc(t67, ["units"]), n67 = { filters: this.filters, kernelSize: this.kernelSize, padding: this.padding, dataFormat: this.dataFormat, dilationRate: this.dilationRate, strides: this.strides };
    return Object.assign(Object.assign({}, i88), n67);
  }
  inputConv(t67, e36, i88, n67) {
    let r56 = C5(t67, e36, this.strides, n67 || "valid", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC", this.dilationRate);
    return i88 ? mt5(r56, i88, this.dataFormat) : r56;
  }
  recurrentConv(t67, e36) {
    return C5(t67, e36, 1, "same", this.dataFormat === "channelsFirst" ? "NCHW" : "NHWC");
  }
};
$e2.className = "ConvLSTM2DCell";
serialization_exports.registerClass($e2);
var Ms = class extends Yn {
  constructor(t67) {
    let e36 = new $e2(t67);
    super(Object.assign(Object.assign({}, t67), { cell: e36 }));
  }
  static fromConfig(t67, e36) {
    return new t67(e36);
  }
};
Ms.className = "ConvLSTM2D";
serialization_exports.registerClass(Ms);
var Fe4 = class extends v41 {
  constructor(t67) {
    super(t67), this.rate = Math.max(Math.min(t67.rate, 1), 0), this.noiseShape = t67.noiseShape, this.seed = t67.seed, this.supportsMasking = true;
  }
  getNoiseShape(t67) {
    if (this.noiseShape == null) return this.noiseShape;
    let e36 = t67.shape, i88 = [];
    for (let n67 = 0; n67 < this.noiseShape.length; ++n67) i88.push(this.noiseShape[n67] == null ? e36[n67] : this.noiseShape[n67]);
    return i88;
  }
  call(t67, e36) {
    return g4(() => {
      this.invokeCallHook(t67, e36);
      let i88 = C27(t67);
      if (0 < this.rate && this.rate < 1) {
        let n67 = e36.training == null ? false : e36.training, r56 = this.getNoiseShape(i88);
        return le6(() => nn2(i88, this.rate, r56, this.seed), () => i88, n67);
      }
      return t67;
    });
  }
  getConfig() {
    let t67 = { rate: this.rate, noiseShape: this.noiseShape, seed: this.seed }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
  dispose() {
    return super.dispose();
  }
};
Fe4.className = "Dropout";
serialization_exports.registerClass(Fe4);
var Rs = class extends Fe4 {
  constructor(t67) {
    super(t67), this.inputSpec = [{ ndim: 3 }];
  }
  getNoiseShape(t67) {
    let e36 = t67.shape;
    return [e36[0], 1, e36[2]];
  }
};
Rs.className = "SpatialDropout1D";
serialization_exports.registerClass(Rs);
var $s = class extends v41 {
  constructor(t67) {
    if (super(t67), this.activation = null, this.useBias = true, this.kernel = null, this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_BIAS_INITIALIZER = "zeros", t67.batchInputShape == null && t67.inputShape == null && t67.inputDim != null) {
      let e36 = null;
      t67.batchSize != null && (e36 = t67.batchSize), this.batchInputShape = [e36, t67.inputDim];
    }
    this.units = t67.units, Y13(this.units, "units"), this.activation = $t3(t67.activation), t67.useBias != null && (this.useBias = t67.useBias), this.kernelInitializer = U23(t67.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.biasInitializer = U23(t67.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelConstraint = G29(t67.kernelConstraint), this.biasConstraint = G29(t67.biasConstraint), this.kernelRegularizer = j21(t67.kernelRegularizer), this.biasRegularizer = j21(t67.biasRegularizer), this.activityRegularizer = j21(t67.activityRegularizer), this.supportsMasking = true, this.inputSpec = [{ minNDim: 2 }];
  }
  build(t67) {
    t67 = E43(t67);
    let e36 = t67[t67.length - 1];
    this.kernel == null && (this.kernel = this.addWeight("kernel", [e36, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint))), this.inputSpec = [{ minNDim: 2, axes: { [-1]: e36 } }], this.built = true;
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = t67.slice();
    return e36[e36.length - 1] = this.units, e36;
  }
  call(t67, e36) {
    return g4(() => {
      this.invokeCallHook(t67, e36);
      let i88 = C27(t67), n67 = Zi(this.activation.getClassName()), r56;
      return n67 != null ? r56 = Lt3(i88, this.kernel.read(), n67, this.bias ? this.bias.read() : null) : (r56 = Lt3(i88, this.kernel.read()), this.bias != null && (r56 = mt5(r56, this.bias.read())), this.activation != null && (r56 = this.activation.apply(r56))), r56;
    });
  }
  getConfig() {
    let t67 = { units: this.units, activation: Rt3(this.activation), useBias: this.useBias, kernelInitializer: H17(this.kernelInitializer), biasInitializer: H17(this.biasInitializer), kernelRegularizer: B29(this.kernelRegularizer), biasRegularizer: B29(this.biasRegularizer), activityRegularizer: B29(this.activityRegularizer), kernelConstraint: Z15(this.kernelConstraint), biasConstraint: Z15(this.biasConstraint) }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
$s.className = "Dense";
serialization_exports.registerClass($s);
var Fs = class extends v41 {
  constructor(t67) {
    t67 = t67 || {}, super(t67), this.inputSpec = [{ minNDim: 3 }], this.dataFormat = t67.dataFormat;
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    for (let e36 of t67.slice(1)) if (e36 == null) throw new c102(`The shape of the input to "Flatten" is not fully defined (got ${t67.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);
    return [t67[0], vt3(t67, 1)];
  }
  call(t67, e36) {
    return g4(() => {
      this.invokeCallHook(t67, e36);
      let i88 = C27(t67);
      if (this.dataFormat === "channelsFirst" && i88.rank > 1) {
        let n67 = [0];
        for (let r56 = 2; r56 < i88.rank; ++r56) n67.push(r56);
        n67.push(1), i88 = A10(i88, n67);
      }
      return lo3(i88);
    });
  }
  getConfig() {
    let t67 = {};
    this.dataFormat != null && (t67.dataFormat = this.dataFormat);
    let e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Fs.className = "Flatten";
serialization_exports.registerClass(Fs);
var Bs = class extends v41 {
  constructor(t67) {
    super(t67), this.supportsMasking = true, this.activation = $t3(t67.activation);
  }
  call(t67, e36) {
    return g4(() => {
      this.invokeCallHook(t67, e36);
      let i88 = C27(t67);
      return this.activation.apply(i88);
    });
  }
  getConfig() {
    let t67 = { activation: Rt3(this.activation) }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Bs.className = "Activation";
serialization_exports.registerClass(Bs);
var Ws = class extends v41 {
  constructor(t67) {
    super(t67), this.n = t67.n, this.inputSpec = [{ ndim: 2 }];
  }
  computeOutputShape(t67) {
    return [t67[0], this.n, t67[1]];
  }
  call(t67, e36) {
    return g4(() => (t67 = C27(t67), oo2(t67, this.n)));
  }
  getConfig() {
    let t67 = { n: this.n }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Ws.className = "RepeatVector";
serialization_exports.registerClass(Ws);
var Vs = class extends v41 {
  constructor(t67) {
    super(t67), this.targetShape = t67.targetShape;
    for (let e36 = 0; e36 < this.targetShape.length; ++e36) this.isUnknown(this.targetShape[e36]) && (this.targetShape[e36] = null);
  }
  isUnknown(t67) {
    return t67 < 0 || t67 == null;
  }
  fixUnknownDimension(t67, e36) {
    let i88 = "Total size of new array must be unchanged.", n67 = e36.slice(), r56 = 1, o80 = null;
    for (let l80 = 0; l80 < n67.length; ++l80) {
      let u86 = n67[l80];
      if (this.isUnknown(u86)) if (o80 === null) o80 = l80;
      else throw new c102("Can only specifiy one unknown dimension.");
      else r56 *= u86;
    }
    let a71 = vt3(t67);
    if (o80 !== null) {
      if (r56 === 0 || a71 % r56 !== 0) throw new c102(i88);
      n67[o80] = a71 / r56;
    } else if (a71 !== r56) throw new c102(i88);
    return n67;
  }
  computeOutputShape(t67) {
    let e36 = false;
    for (let i88 = 0; i88 < t67.length; ++i88) if (this.isUnknown(t67[i88])) {
      e36 = true;
      break;
    }
    return e36 ? t67.slice(0, 1).concat(this.targetShape) : t67.slice(0, 1).concat(this.fixUnknownDimension(t67.slice(1), this.targetShape));
  }
  call(t67, e36) {
    return g4(() => {
      this.invokeCallHook(t67, e36);
      let i88 = C27(t67), n67 = i88.shape, r56 = n67.slice(0, 1).concat(this.fixUnknownDimension(n67.slice(1), this.targetShape));
      return h9(i88, r56);
    });
  }
  getConfig() {
    let t67 = { targetShape: this.targetShape }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Vs.className = "Reshape";
serialization_exports.registerClass(Vs);
var Us = class extends v41 {
  constructor(t67) {
    if (super(t67), t67.dims == null) throw new Error("Required configuration field `dims` is missing during Permute constructor call.");
    if (!Array.isArray(t67.dims)) throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${t67.dims} instead.`);
    let e36 = ft5(1, t67.dims.length + 1);
    if (!util_exports.arraysEqual(t67.dims.slice().sort(), e36)) throw new Error("Invalid permutation `dims`: " + JSON.stringify(t67.dims) + " `dims` must contain consecutive integers starting from 1.");
    this.dims = t67.dims, this.dimsIncludingBatch = [0].concat(this.dims), this.inputSpec = [new K20({ ndim: this.dims.length + 1 })];
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = t67.slice();
    return this.dims.forEach((i88, n67) => {
      e36[n67 + 1] = t67[i88];
    }), e36;
  }
  call(t67, e36) {
    return A10(C27(t67), this.dimsIncludingBatch);
  }
  getConfig() {
    let t67 = { dims: this.dims }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Us.className = "Permute";
serialization_exports.registerClass(Us);
var Ps = class extends v41 {
  constructor(t67) {
    super(t67 ?? {}), this.supportsMasking = true, t67 != null ? this.maskValue = t67.maskValue == null ? 0 : t67.maskValue : this.maskValue = 0;
  }
  computeOutputShape(t67) {
    return t67;
  }
  getConfig() {
    let t67 = super.getConfig(), e36 = { maskValue: this.maskValue };
    return Object.assign(e36, t67), e36;
  }
  computeMask(t67, e36) {
    let i88 = C27(t67);
    return y9(b18(i88, this.maskValue), -1);
  }
  call(t67, e36) {
    return g4(() => {
      this.invokeCallHook(t67, e36);
      let i88 = C27(t67), o80 = y9(b18(i88, this.maskValue), -1, true);
      return y8(i88, w12(o80, i88.dtype));
    });
  }
};
Ps.className = "Masking";
serialization_exports.registerClass(Ps);
var Ks = class extends v41 {
  constructor(t67) {
    if (super(t67), this.embeddings = null, this.DEFAULT_EMBEDDINGS_INITIALIZER = "randomUniform", t67.batchInputShape == null && t67.inputShape == null) {
      let e36 = null;
      t67.batchSize != null && (e36 = t67.batchSize), t67.inputLength == null ? this.batchInputShape = [e36, null] : this.batchInputShape = [e36].concat($36(t67.inputLength));
    }
    this.inputDim = t67.inputDim, Y13(this.inputDim, "inputDim"), this.outputDim = t67.outputDim, Y13(this.outputDim, "outputDim"), this.embeddingsInitializer = U23(t67.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER), this.embeddingsRegularizer = j21(t67.embeddingsRegularizer), this.activityRegularizer = j21(t67.activityRegularizer), this.embeddingsConstraint = G29(t67.embeddingsConstraint), this.maskZero = t67.maskZero, this.supportsMasking = t67.maskZero, this.inputLength = t67.inputLength;
  }
  build(t67) {
    this.embeddings = this.addWeight("embeddings", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, true, this.embeddingsConstraint), this.built = true;
  }
  warnOnIncompatibleInputShape(t67) {
  }
  computeMask(t67, e36) {
    return g4(() => this.maskZero ? (t67 = C27(t67), b18(t67, k11(t67))) : null);
  }
  computeOutputShape(t67) {
    if (t67 = E43(t67), this.inputLength == null) return [...t67, this.outputDim];
    let e36 = $36(this.inputLength);
    if (e36.length !== t67.length - 1) throw new c102(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t67}`);
    {
      let i88 = 0;
      for (let n67 = 0; n67 < e36.length; ++n67) {
        let r56 = e36[n67], o80 = t67[n67 + 1];
        if (r56 != null && o80 != null && r56 !== o80) throw new c102(`"inputLength" is ${this.inputLength}, but received input shape has shape ${t67}`);
        r56 == null && (e36[i88] = o80), i88++;
      }
    }
    return [t67[0], ...e36, this.outputDim];
  }
  call(t67, e36) {
    return g4(() => {
      this.invokeCallHook(t67, e36);
      let i88 = C27(t67);
      i88.dtype !== "int32" && (i88 = at6(i88, "int32"));
      let n67 = sn2(this.embeddings.read(), h9(i88, [i88.size]));
      return h9(n67, E43(this.computeOutputShape(i88.shape)));
    });
  }
  getConfig() {
    let t67 = { inputDim: this.inputDim, outputDim: this.outputDim, embeddingsInitializer: H17(this.embeddingsInitializer), embeddingsRegularizer: B29(this.embeddingsRegularizer), activityRegularizer: B29(this.activityRegularizer), embeddingsConstraint: Z15(this.embeddingsConstraint), maskZero: this.maskZero, inputLength: this.inputLength }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Ks.className = "Embedding";
serialization_exports.registerClass(Ks);
var se5 = class extends v41 {
  constructor(t67) {
    super(t67 || {}), this.supportsMasking = true;
  }
  mergeFunction(t67) {
    throw new S44();
  }
  computeElementwiseOpOutputShape(t67, e36) {
    if (t67 == null || e36 == null) return null;
    if (t67.length < e36.length) return this.computeElementwiseOpOutputShape(e36, t67);
    if (e36.length === 0) return t67;
    let i88 = t67.slice(0, t67.length - e36.length);
    for (let n67 = 0; n67 < e36.length; ++n67) {
      let r56 = t67[t67.length - e36.length + n67], o80 = e36[n67];
      if (r56 == null || o80 == null || r56 < 0 || o80 < 0) i88.push(null);
      else if (r56 === 1) i88.push(o80);
      else if (o80 === 1) i88.push(r56);
      else {
        if (r56 !== o80) throw new c102("Operands could not be broadcast together with shapes " + JSON.stringify(t67) + " " + JSON.stringify(e36));
        i88.push(r56);
      }
    }
    return i88;
  }
  build(t67) {
    if (Array.isArray(t67) && !Array.isArray(t67[0]) && (t67 = [E43(t67)]), t67 = t67, t67.length < 2) throw new c102(`A merge layer should be called on an Array of at least 2 inputs. Got ${t67.length} input(s).`);
    let e36 = [];
    for (let r56 of t67) r56 != null && r56[0] !== null && e36.push(r56[0]);
    if (e36 = St3(e36), e36.length > 1) throw new c102(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(t67)}.`);
    let i88 = t67[0] == null ? null : t67[0].slice(1);
    for (let r56 = 1; r56 < t67.length; ++r56) {
      let o80 = t67[r56] == null ? null : t67[r56].slice(1);
      i88 = this.computeElementwiseOpOutputShape(i88, o80);
    }
    let n67 = t67.map((r56) => r56.length);
    t67.indexOf(null) === -1 && St3(n67).length === 1 ? this.reshapeRequired = false : this.reshapeRequired = true;
  }
  call(t67, e36) {
    return g4(() => {
      if (t67 = t67, this.reshapeRequired) {
        let i88 = [], n67 = t67.map((r56) => r56.rank);
        if (n67.indexOf(null) === -1) {
          let r56 = _t4(n67);
          for (let o80 of t67) {
            let a71 = o80.rank;
            for (let l80 = 0; l80 < r56 - a71; ++l80) o80 = Zt3(o80, 1);
            i88.push(o80);
          }
          return this.mergeFunction(i88);
        } else {
          let r56 = false;
          for (let l80 of t67) {
            let u86 = l80.rank;
            if (u86 == null) {
              let h74 = l80.shape, p103 = h74[0], f85 = h74.slice(1).concat([p103]), w45 = h9(l80, [p103].concat(vt3(h74.slice(1))));
              w45 = A10(w45, [1, 0]), w45 = h9(w45, f85), i88.push(w45), r56 = true;
            } else if (u86 > 1) {
              let h74 = ft5(1, u86).concat([0]);
              i88.push(A10(l80, h74)), r56 = true;
            } else i88.push(l80);
          }
          let o80 = this.mergeFunction(i88), a71 = o80.rank;
          if (r56) {
            if (a71 == null) {
              let l80 = o80.shape, u86 = l80.length, h74 = l80[u86 - 1], p103 = [h74].concat(l80.slice(0, l80.length - 1));
              o80 = h9(A10(h9(o80, [-1, h74]), [1, 0]), p103);
            } else if (a71 > 1) {
              let l80 = [a71 - 1].concat(ft5(0, a71 - 1));
              o80 = A10(o80, l80);
            }
          }
          return o80;
        }
      } else return this.mergeFunction(t67);
    });
  }
  computeOutputShape(t67) {
    t67 = t67;
    let e36;
    t67[0] == null ? e36 = null : e36 = t67[0].slice(1);
    for (let n67 = 1; n67 < t67.length; ++n67) {
      let r56 = t67[n67] == null ? null : t67[n67].slice(1);
      e36 = this.computeElementwiseOpOutputShape(e36, r56);
    }
    let i88 = [];
    for (let n67 of t67) n67 != null && n67[0] !== null && i88.push(n67[0]);
    return i88 = St3(i88), i88.length === 1 ? e36 = i88.concat(e36) : e36 = [null].concat(e36), e36;
  }
  computeMask(t67, e36) {
    return g4(() => {
      if (e36 == null) return null;
      if (!Array.isArray(e36)) throw new c102("`mask` should be an Array");
      if (!Array.isArray(t67)) throw new c102("`inputs` should be an Array");
      if (e36.length !== t67.length) throw new c102(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${t67.length} vs ${e36.length})`);
      if (e36.every((n67) => n67 == null)) return null;
      e36 = e36.map((n67) => n67 == null ? n67 : D7(n67, 0));
      let i88 = e36[0];
      for (let n67 = 1; n67 < e36.length - 1; ++n67) i88 = g16(i88, e36[n67]);
      return i88;
    });
  }
};
var js = class extends se5 {
  constructor(t67) {
    super(t67);
  }
  mergeFunction(t67) {
    return g4(() => {
      let e36 = t67[0].clone();
      for (let i88 = 1; i88 < t67.length; ++i88) e36 = T7(e36, t67[i88]);
      return e36;
    });
  }
};
js.className = "Add";
serialization_exports.registerClass(js);
var qs = class extends se5 {
  constructor(t67) {
    super(t67);
  }
  mergeFunction(t67) {
    return g4(() => {
      let e36 = t67[0].clone();
      for (let i88 = 1; i88 < t67.length; ++i88) e36 = y8(e36, t67[i88]);
      return e36;
    });
  }
};
qs.className = "Multiply";
serialization_exports.registerClass(qs);
var Hs = class extends se5 {
  constructor(t67) {
    super(t67);
  }
  mergeFunction(t67) {
    return g4(() => {
      let e36 = t67[0].clone();
      for (let i88 = 1; i88 < t67.length; ++i88) e36 = T7(e36, t67[i88]);
      return y8(1 / t67.length, e36);
    });
  }
};
Hs.className = "Average";
serialization_exports.registerClass(Hs);
var Js = class extends se5 {
  constructor(t67) {
    super(t67);
  }
  mergeFunction(t67) {
    return g4(() => {
      let e36 = t67[0];
      for (let i88 = 1; i88 < t67.length; ++i88) e36 = E18(e36, t67[i88]);
      return e36;
    });
  }
};
Js.className = "Maximum";
serialization_exports.registerClass(Js);
var Zs = class extends se5 {
  constructor(t67) {
    super(t67);
  }
  mergeFunction(t67) {
    return g4(() => {
      let e36 = t67[0];
      for (let i88 = 1; i88 < t67.length; ++i88) e36 = G8(e36, t67[i88]);
      return e36;
    });
  }
};
Zs.className = "Minimum";
serialization_exports.registerClass(Zs);
var Gs = class extends se5 {
  constructor(t67) {
    super(t67), this.DEFAULT_AXIS = -1, t67 == null && (t67 = {}), this.axis = t67.axis == null ? this.DEFAULT_AXIS : t67.axis, this.supportsMasking = true, this.reshapeRequired = false;
  }
  build(t67) {
    if (!(Array.isArray(t67) && Array.isArray(t67[0])) || t67.length === 1) throw new c102("A `Concatenate` layer should be called on a list of at least 2 inputs");
    t67 = t67;
    let e36 = true;
    for (let n67 of t67) if (n67 != null) {
      e36 = false;
      break;
    }
    if (e36) return;
    let i88 = [];
    for (let n67 = 0; n67 < t67.length; ++n67) {
      let r56 = t67[n67].slice();
      r56.splice(this.axis, 1);
      let o80 = false;
      for (let a71 of i88) if (util_exports.arraysEqual(a71, r56)) {
        o80 = true;
        break;
      }
      o80 || i88.push(r56);
    }
    if (i88.length > 1) throw new c102("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: " + JSON.stringify(t67));
  }
  mergeFunction(t67) {
    return g4(() => qe(t67, this.axis));
  }
  computeOutputShape(t67) {
    if (!(Array.isArray(t67) && Array.isArray(t67[0]))) throw new c102("A `Concatenate` layer should be called on a list of inputs.");
    let e36 = t67, i88 = e36[0].slice(), n67 = this.axis < 0 ? i88.length + this.axis : this.axis;
    for (let r56 of e36.slice(1)) {
      if (i88[n67] == null || r56[n67] == null) {
        i88[n67] = null;
        break;
      }
      i88[n67] += r56[n67];
    }
    return i88;
  }
  computeMask(t67, e36) {
    if (e36 == null) return null;
    if (!Array.isArray(e36)) throw new c102("`mask` should be an array for Concatenate");
    if (!Array.isArray(t67)) throw new c102("`inputs` should be an array for Concatenate");
    if (e36.length !== t67.length) throw new c102(`Mismatch in the length of mask (${e36.length}) and the legnth of inputs (${t67.length})`);
    return g4(() => {
      let i88 = true;
      if (e36.forEach((o80) => {
        if (o80 != null) {
          i88 = false;
          return;
        }
      }), i88) return null;
      let n67 = [];
      for (let o80 = 0; o80 < t67.length; ++o80) e36[o80] == null ? n67.push(w12(k15(t67[o80]), "bool")) : e36[o80].rank < t67[o80].rank ? n67.push(D7(e36[o80], -1)) : n67.push(e36[o80]);
      let r56 = E9(n67, this.axis);
      return E7(r56, -1, false);
    });
  }
  getConfig() {
    let t67 = { axis: this.axis }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Gs.className = "Concatenate";
serialization_exports.registerClass(Gs);
function Ui(s84, t67) {
  for (; s84 < 0; ) s84 += t67;
  return s84;
}
function kc(s84, t67, e36) {
  if (s84.shape.length > 3 || t67.shape.length > 3) throw new S44("batchDot is not implemented for tensors of 4D or higher rank yet");
  if (util_exports.assert(s84.shape.length >= 2, () => `batchDot requires the rank of x to be >= 2, but got ${s84.shape.length}`), util_exports.assert(s84.shape.length >= 2, () => `batchDot requires the rank of y to be >= 2, but got ${t67.shape.length}`), typeof e36 == "number" && (e36 = [e36, e36]), s84.dtype === "complex64" || t67.dtype === "complex64") throw new S44("batchDot is not implemented for complex64-type Tensors yet.");
  let i88 = s84.shape.length, n67 = t67.shape.length;
  e36 == null && (e36 = [i88 - 1, n67 - 2]);
  let r56 = e36;
  return g4(() => {
    let o80;
    if (i88 > n67) {
      o80 = i88 - n67;
      let l80 = [];
      for (let u86 = 0; u86 < o80; ++u86) l80.push(1);
      t67 = h9(t67, t67.shape.concat(l80));
    } else if (n67 > i88) {
      o80 = n67 - i88;
      let l80 = [];
      for (let u86 = 0; u86 < o80; ++u86) l80.push(1);
      s84 = h9(s84, s84.shape.concat(l80));
    } else o80 = 0;
    let a71;
    if (s84.shape.length === 2 && t67.shape.length === 2) r56[0] === r56[1] ? a71 = T10(y8(s84, t67), r56[0]) : a71 = T10(y8(A10(s84, [1, 0]), t67), r56[1]);
    else {
      let l80 = r56[0] !== s84.shape.length - 1, u86 = r56[1] === t67.shape.length - 1;
      a71 = N6(s84, t67, l80, u86);
    }
    if (o80 > 0) {
      let l80;
      i88 > n67 ? l80 = i88 + n67 - 3 : l80 = i88 - 1;
      let u86 = [];
      for (let h74 = l80; h74 < l80 + o80; ++h74) u86.push(h74);
      a71 = a23(a71, u86);
    }
    return a71.shape.length === 1 && (a71 = D7(a71, 1)), a71;
  });
}
var Ys = class extends se5 {
  constructor(t67) {
    super(t67), this.axes = t67.axes, this.normalize = t67.normalize == null ? false : t67.normalize, this.supportsMasking = true, this.reshapeRequired = false;
  }
  build(t67) {
    util_exports.assert(Array.isArray(t67) && t67.length === 2 && Array.isArray(t67[0]) && Array.isArray(t67[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    let e36 = t67[0], i88 = t67[1];
    if (e36.length > 3 || i88.length > 3) throw new S44("Dot layer does not support tensors of 4D or higher rank yet.");
    let n67 = this.interpretAxes(e36, i88);
    if (e36[n67[0]] !== i88[n67[1]]) throw new c102(`Dimension incompatibility: ${e36[n67[0]]} !== ${i88[n67[1]]}`);
  }
  mergeFunction(t67) {
    if (t67.length !== 2) throw new c102(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${t67.length} input(s).`);
    let e36 = t67[0], i88 = t67[1], n67;
    return Array.isArray(this.axes) ? n67 = this.axes.map((r56, o80) => Ui(r56, t67[o80].shape.length)) : n67 = [Ui(this.axes, e36.shape.length), Ui(this.axes, i88.shape.length)], this.normalize && (e36 = Ti(e36, n67[0]), i88 = Ti(i88, n67[1])), kc(e36, i88, n67);
  }
  interpretAxes(t67, e36) {
    let i88;
    return Array.isArray(this.axes) ? i88 = this.axes : i88 = [Ui(this.axes, t67.length), Ui(this.axes, e36.length)], i88;
  }
  computeOutputShape(t67) {
    util_exports.assert(Array.isArray(t67) && t67.length === 2 && Array.isArray(t67[0]) && Array.isArray(t67[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    let e36 = t67[0].slice(), i88 = t67[1].slice();
    if (e36.length > 3 || i88.length > 3) throw new S44("Dot layer does not support tensors of 4D or higher rank yet.");
    let n67 = this.interpretAxes(e36, i88);
    e36.splice(n67[0], 1), i88.splice(n67[1], 1), i88.splice(0, 1);
    let r56 = e36.concat(i88);
    return r56.length === 1 && r56.push(1), r56;
  }
  computeMask(t67, e36) {
    return null;
  }
  getConfig() {
    let t67 = { axes: this.axes, normalize: this.normalize }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
Ys.className = "Dot";
serialization_exports.registerClass(Ys);
var Xs = class extends v41 {
  constructor(t67) {
    super(t67), this.supportsMasking = true, this.stddev = t67.stddev;
  }
  computeOutputShape(t67) {
    return t67;
  }
  getConfig() {
    let t67 = super.getConfig(), e36 = { stddev: this.stddev };
    return Object.assign(e36, t67), e36;
  }
  call(t67, e36) {
    return g4(() => {
      this.invokeCallHook(t67, e36);
      let i88 = C27(t67);
      return le6(() => T7(He2(i88.shape, 0, this.stddev), i88), () => i88, e36.training || false);
    });
  }
};
Xs.className = "GaussianNoise";
serialization_exports.registerClass(Xs);
var Qs = class extends v41 {
  constructor(t67) {
    super(t67), this.supportsMasking = true, this.rate = t67.rate;
  }
  computeOutputShape(t67) {
    return t67;
  }
  getConfig() {
    let t67 = super.getConfig(), e36 = { rate: this.rate };
    return Object.assign(e36, t67), e36;
  }
  call(t67, e36) {
    return g4(() => {
      this.invokeCallHook(t67, e36);
      let i88 = C27(t67);
      return this.rate > 0 && this.rate < 1 ? le6(() => {
        let r56 = Math.sqrt(this.rate / (1 - this.rate));
        return y8(i88, He2(i88.shape, 1, r56));
      }, () => i88, e36.training || false) : i88;
    });
  }
};
Qs.className = "GaussianDropout";
serialization_exports.registerClass(Qs);
var ti = class extends v41 {
  constructor(t67) {
    super(t67), this.supportsMasking = true, this.rate = t67.rate, this.noiseShape = t67.noiseShape;
  }
  _getNoiseShape(t67) {
    return this.noiseShape || C27(t67).shape;
  }
  computeOutputShape(t67) {
    return t67;
  }
  getConfig() {
    let t67 = super.getConfig(), e36 = { rate: this.rate };
    return Object.assign(e36, t67), e36;
  }
  call(t67, e36) {
    return g4(() => {
      if (this.rate < 1 && this.rate > 0) {
        let i88 = this._getNoiseShape(t67);
        return le6(() => {
          let r56 = C27(t67), l80 = -1.6732632423543772 * 1.0507009873554805, u86 = h18(U6(i88), this.rate);
          u86 = at6(u86, "float32");
          let h74 = ((1 - this.rate) * (1 + this.rate * l80 ** 2)) ** -0.5, p103 = -h74 * l80 * this.rate, f85 = T7(y8(r56, u86), y8(T7(u86, -1), l80));
          return T7(y8(f85, h74), p103);
        }, () => C27(t67), e36.training || false);
      }
      return t67;
    });
  }
};
ti.className = "AlphaDropout";
serialization_exports.registerClass(ti);
function Pi(s84, t67, e36, i88, n67, r56 = 1e-3) {
  let o80;
  if (s84.rank === 2) o80 = g7(s84, t67, e36, i88, n67, r56);
  else if (s84.rank === 3) o80 = g8(s84, t67, e36, i88, n67, r56);
  else if (s84.rank === 4) o80 = g9(s84, t67, e36, i88, n67, r56);
  else throw new S44(`batchNormalization is not implemented for array of rank ${s84.rank} yet`);
  return o80;
}
function Sc(s84, t67, e36, i88, n67 = 1e-3) {
  return g4(() => {
    let r56 = g17(s84, i88), o80 = r56.mean, a71 = r56.variance;
    return [Pi(s84, o80, a71, e36, t67, n67), o80, a71];
  });
}
function vc(s84, t67, e36, i88, n67 = 1e-3) {
  return g4(() => {
    let r56 = g17(s84, i88), o80 = r56.mean, a71 = r56.variance, l80 = [];
    for (let b58 of ft5(0, s84.rank)) i88.indexOf(b58) !== -1 ? l80.push(1) : l80.push(s84.shape[b58]);
    let u86 = h9(o80, l80), h74 = h9(a71, l80), p103 = t67 == null ? null : h9(t67, l80), f85 = e36 == null ? null : h9(e36, l80);
    return [Pi(s84, u86, h74, f85, p103, n67), o80, a71];
  });
}
function Lc(s84, t67, e36, i88, n67 = 1e-3) {
  return util_exports.arraysEqual(i88.slice().sort(), ft5(0, s84.rank - 1)) ? Sc(s84, t67, e36, i88, n67) : vc(s84, t67, e36, i88, n67);
}
var ei = class extends v41 {
  constructor(t67) {
    t67 == null && (t67 = {}), super(t67), this.supportsMasking = true, this.axis = t67.axis == null ? -1 : t67.axis, this.momentum = t67.momentum == null ? 0.99 : t67.momentum, this.epsilon = t67.epsilon == null ? 1e-3 : t67.epsilon, this.center = t67.center == null ? true : t67.center, this.scale = t67.scale == null ? true : t67.scale, this.betaInitializer = U23(t67.betaInitializer || "zeros"), this.gammaInitializer = U23(t67.gammaInitializer || "ones"), this.movingMeanInitializer = U23(t67.movingMeanInitializer || "zeros"), this.movingVarianceInitializer = U23(t67.movingVarianceInitializer || "ones"), this.betaConstraint = G29(t67.betaConstraint), this.gammaConstraint = G29(t67.gammaConstraint), this.betaRegularizer = j21(t67.betaRegularizer), this.gammaRegularizer = j21(t67.gammaRegularizer);
  }
  build(t67) {
    t67 = E43(t67);
    let e36 = this.axis >= 0 ? this.axis : this.axis + t67.length, i88 = t67[e36];
    if (i88 == null) throw new c102(`Axis ${e36} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(t67)}.`);
    this.inputSpec = [new K20({ ndim: t67.length, axes: { [e36]: i88 } })];
    let n67 = [i88];
    this.scale && (this.gamma = this.addWeight("gamma", n67, null, this.gammaInitializer, this.gammaRegularizer, true, this.gammaConstraint)), this.center && (this.beta = this.addWeight("beta", n67, null, this.betaInitializer, this.betaRegularizer, true, this.betaConstraint)), this.movingMean = this.addWeight("moving_mean", n67, null, this.movingMeanInitializer, null, false), this.movingVariance = this.addWeight("moving_variance", n67, null, this.movingVarianceInitializer, null, false), this.built = true;
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = e36.training == null ? false : e36.training, n67 = C27(t67), r56 = n67.shape, o80 = r56.length, a71 = ft5(0, o80), l80 = this.axis >= 0 ? this.axis : this.axis + o80;
      a71.splice(l80, 1);
      let u86 = zt3(1, o80);
      u86[l80] = r56[l80];
      let h74 = a71.slice();
      h74.sort();
      let p103 = !util_exports.arraysEqual(h74, ft5(0, o80).slice(0, o80 - 1)), f85 = () => {
        if (p103) {
          let d55 = h9(this.movingMean.read(), u86), k63 = h9(this.movingVariance.read(), u86), A35 = this.center ? h9(this.beta.read(), u86) : null, z32 = this.scale ? h9(this.gamma.read(), u86) : null;
          return Pi(n67, d55, k63, A35, z32, this.epsilon);
        } else return Pi(n67, this.movingMean.read(), this.movingVariance.read(), this.beta == null ? null : this.beta.read(), this.gamma == null ? null : this.gamma.read(), this.epsilon);
      };
      if (!i88) return f85();
      let [w45, b58, m96] = Lc(n67, this.gamma.read(), this.beta.read(), a71, this.epsilon), g72 = (d55, k63, A35) => {
        g4(() => {
          let z32 = 1 - A35, D42 = d55.read(), q25 = y8(E16(D42, k63), z32);
          d55.write(E16(D42, q25));
        });
      };
      return (() => {
        g72(this.movingMean, b58, this.momentum), g72(this.movingVariance, m96, this.momentum);
      })(), w45;
    });
  }
  getConfig() {
    let t67 = { axis: this.axis, momentum: this.momentum, epsilon: this.epsilon, center: this.center, scale: this.scale, betaInitializer: H17(this.betaInitializer), gammaInitializer: H17(this.gammaInitializer), movingMeanInitializer: H17(this.movingMeanInitializer), movingVarianceInitializer: H17(this.movingVarianceInitializer), betaRegularizer: B29(this.betaRegularizer), gammaRegularizer: B29(this.gammaRegularizer), betaConstraint: Z15(this.betaConstraint), gammaConstraint: Z15(this.gammaConstraint) }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
ei.className = "BatchNormalization";
serialization_exports.registerClass(ei);
var si = class extends v41 {
  constructor(t67) {
    if (t67 == null && (t67 = {}), super(t67), this.axis = t67.axis == null ? -1 : t67.axis, typeof this.axis == "number") {
      if (!Number.isInteger(this.axis)) throw new Error(`Expected axis to be an integer, but received ${this.axis}`);
    } else if (Array.isArray(this.axis)) {
      for (let e36 of this.axis) if (!Number.isInteger(e36)) throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`);
    } else throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);
    this.epsilon = t67.epsilon == null ? 1e-3 : t67.epsilon, this.center = t67.center == null ? true : t67.center, this.scale = t67.scale == null ? true : t67.scale, this.betaInitializer = U23(t67.betaInitializer || "zeros"), this.gammaInitializer = U23(t67.gammaInitializer || "ones"), this.betaRegularizer = j21(t67.betaRegularizer), this.gammaRegularizer = j21(t67.gammaRegularizer), this.supportsMasking = true;
  }
  build(t67) {
    t67 = E43(t67);
    let e36 = t67.length;
    typeof this.axis == "number" && (this.axis = [this.axis]);
    for (let r56 = 0; r56 < this.axis.length; ++r56) this.axis[r56] < 0 && (this.axis[r56] += e36);
    for (let r56 of this.axis) if (r56 < 0 || r56 >= e36) throw new Error(`Invalid axis: ${r56}`);
    if (this.axis.length !== St3(this.axis).length) throw new Error(`Found duplicate axes in: ${this.axis}`);
    let i88 = this.axis.map((r56) => t67[r56]), n67 = true;
    this.scale ? this.gamma = this.addWeight("gamma", i88, "float32", this.gammaInitializer, this.gammaRegularizer, n67) : this.gamma = null, this.center ? this.beta = this.addWeight("beta", i88, "float32", this.betaInitializer, this.betaRegularizer, n67) : this.beta = null, this.built = true;
  }
  call(t67, e36) {
    let i88 = C27(t67), n67 = i88.shape, r56 = n67.length;
    return g4(() => {
      let { mean: a71, variance: l80 } = g17(i88, this.axis, true), u86 = zt3(1, r56);
      for (let m96 of this.axis) u86[m96] = n67[m96];
      let h74 = (m96) => m96 != null && m96.shape.length !== r56 ? h9(m96, u86) : m96, p103 = this.scale ? h74(this.gamma.read()) : null, f85 = this.center ? h74(this.beta.read()) : null, w45 = [], b58 = [];
      for (let m96 = 0; m96 < r56; ++m96) this.axis.indexOf(m96) !== -1 ? (w45.push(n67[m96]), b58.push(1)) : (w45.push(1), b58.push(n67[m96]));
      return a71 = g12(a71, w45), l80 = g12(l80, w45), p103 != null && (p103 = g12(p103, b58)), f85 != null && (f85 = g12(f85, b58)), Pi(i88, a71, l80, f85, p103, this.epsilon);
    });
  }
  getConfig() {
    let t67 = { axis: this.axis, epsilon: this.epsilon, center: this.center, scale: this.scale, betaInitializer: H17(this.betaInitializer), gammaInitializer: H17(this.gammaInitializer), betaRegularizer: B29(this.betaRegularizer), gammaRegularizer: B29(this.gammaRegularizer) }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
si.className = "LayerNormalization";
serialization_exports.registerClass(si);
function Ec(s84, t67, e36) {
  return g4(() => {
    if (s84.rank !== 4) throw new c102(`temporalPadding expects input tensor to be 4-D, but received a ${s84.rank}-D tensor.`);
    if (t67 == null && (t67 = [[1, 1], [1, 1]]), t67.length !== 2 || t67[0].length !== 2 || t67[1].length !== 2) throw new c102("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");
    if (e36 == null && (e36 = dt4()), e36 !== "channelsLast" && e36 !== "channelsFirst") throw new c102(`Unknown data format: ${e36}. Supported data formats are 'channelsLast' and 'channelsFirst.`);
    let i88;
    return e36 === "channelsFirst" ? i88 = [[0, 0], [0, 0], t67[0], t67[1]] : i88 = [[0, 0], t67[0], t67[1], [0, 0]], l20(s84, i88);
  });
}
var ii = class extends v41 {
  constructor(t67) {
    if (t67 == null && (t67 = {}), super(t67), this.dataFormat = t67.dataFormat == null ? dt4() : t67.dataFormat, t67.padding == null) this.padding = [[1, 1], [1, 1]];
    else if (typeof t67.padding == "number") this.padding = [[t67.padding, t67.padding], [t67.padding, t67.padding]];
    else {
      if (t67.padding = t67.padding, t67.padding.length !== 2) throw new c102(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${t67.padding.length} array.`);
      let e36, i88;
      if (typeof t67.padding[0] == "number") e36 = [t67.padding[0], t67.padding[0]], i88 = [t67.padding[1], t67.padding[1]];
      else {
        if (t67.padding = t67.padding, t67.padding[0].length !== 2) throw new c102(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${t67.padding[0].length} array.`);
        if (e36 = t67.padding[0], t67.padding[1].length !== 2) throw new c102(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${t67.padding[1].length} array.`);
        i88 = t67.padding[1];
      }
      this.padding = [e36, i88];
    }
    this.inputSpec = [new K20({ ndim: 4 })];
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36, i88;
    return this.dataFormat === "channelsFirst" ? (t67[2] != null && t67[2] >= 0 ? e36 = t67[2] + this.padding[0][0] + this.padding[0][1] : e36 = null, t67[3] != null && t67[3] >= 0 ? i88 = t67[3] + this.padding[1][0] + this.padding[1][1] : i88 = null, [t67[0], t67[1], e36, i88]) : (t67[1] != null && t67[1] >= 0 ? e36 = t67[1] + this.padding[0][0] + this.padding[0][1] : e36 = null, t67[2] != null && t67[2] >= 0 ? i88 = t67[2] + this.padding[1][0] + this.padding[1][1] : i88 = null, [t67[0], e36, i88, t67[3]]);
  }
  call(t67, e36) {
    return g4(() => Ec(C27(t67), this.padding, this.dataFormat));
  }
  getConfig() {
    let t67 = { padding: this.padding, dataFormat: this.dataFormat }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
ii.className = "ZeroPadding2D";
serialization_exports.registerClass(ii);
function or(s84, t67, e36, i88, n67, r56) {
  return g4(() => {
    J16(n67), dr(r56), pt2(i88), e36 == null && (e36 = [1, 1]), i88 == null && (i88 = "valid"), n67 == null && (n67 = dt4()), r56 == null && (r56 = "max"), s84 = Vi(s84, n67);
    let o80, a71 = i88 === "same" ? "same" : "valid";
    return r56 === "max" ? o80 = O6(s84, t67, e36, a71) : o80 = T8(s84, t67, e36, a71), n67 === "channelsFirst" && (o80 = A10(o80, [0, 3, 1, 2])), o80;
  });
}
function Na(s84, t67, e36, i88, n67, r56) {
  return g4(() => {
    J16(n67), dr(r56), pt2(i88), e36 == null && (e36 = [1, 1, 1]), i88 == null && (i88 = "valid"), n67 == null && (n67 = dt4()), r56 == null && (r56 = "max"), s84 = Rr(s84, n67);
    let o80, a71 = i88 === "same" ? "same" : "valid";
    return r56 === "max" ? o80 = W6(s84, t67, e36, a71) : o80 = H5(s84, t67, e36, a71), n67 === "channelsFirst" && (o80 = A10(o80, [0, 4, 1, 2, 3])), o80;
  });
}
var er2 = class extends v41 {
  constructor(t67) {
    if (t67.poolSize == null && (t67.poolSize = 2), super(t67), typeof t67.poolSize == "number") this.poolSize = [t67.poolSize];
    else if (Array.isArray(t67.poolSize) && t67.poolSize.length === 1 && typeof t67.poolSize[0] == "number") this.poolSize = t67.poolSize;
    else throw new c102(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t67.poolSize)}`);
    if (Y13(this.poolSize, "poolSize"), t67.strides == null) this.strides = this.poolSize;
    else if (typeof t67.strides == "number") this.strides = [t67.strides];
    else if (Array.isArray(t67.strides) && t67.strides.length === 1 && typeof t67.strides[0] == "number") this.strides = t67.strides;
    else throw new c102(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(t67.strides)}`);
    Y13(this.strides, "strides"), this.padding = t67.padding == null ? "valid" : t67.padding, pt2(this.padding), this.inputSpec = [new K20({ ndim: 3 })];
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = wt4(t67[1], this.poolSize[0], this.padding, this.strides[0]);
    return [t67[0], e36, t67[2]];
  }
  call(t67, e36) {
    return g4(() => {
      this.invokeCallHook(t67, e36), t67 = Zt3(C27(t67), 2);
      let i88 = this.poolingFunction(C27(t67), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, "channelsLast");
      return a23(i88, [2]);
    });
  }
  getConfig() {
    let t67 = { poolSize: this.poolSize, padding: this.padding, strides: this.strides }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
var ni = class extends er2 {
  constructor(t67) {
    super(t67);
  }
  poolingFunction(t67, e36, i88, n67, r56) {
    return J16(r56), pt2(n67), or(t67, e36, i88, n67, r56, "max");
  }
};
ni.className = "MaxPooling1D";
serialization_exports.registerClass(ni);
var ri = class extends er2 {
  constructor(t67) {
    super(t67);
  }
  poolingFunction(t67, e36, i88, n67, r56) {
    return J16(r56), pt2(n67), or(t67, e36, i88, n67, r56, "avg");
  }
};
ri.className = "AveragePooling1D";
serialization_exports.registerClass(ri);
var sr = class extends v41 {
  constructor(t67) {
    if (t67.poolSize == null && (t67.poolSize = [2, 2]), super(t67), this.poolSize = Array.isArray(t67.poolSize) ? t67.poolSize : [t67.poolSize, t67.poolSize], t67.strides == null) this.strides = this.poolSize;
    else if (Array.isArray(t67.strides)) {
      if (t67.strides.length !== 2) throw new c102(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${t67.strides.length}.`);
      this.strides = t67.strides;
    } else this.strides = [t67.strides, t67.strides];
    Y13(this.poolSize, "poolSize"), Y13(this.strides, "strides"), this.padding = t67.padding == null ? "valid" : t67.padding, this.dataFormat = t67.dataFormat == null ? "channelsLast" : t67.dataFormat, J16(this.dataFormat), pt2(this.padding), this.inputSpec = [new K20({ ndim: 4 })];
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = this.dataFormat === "channelsFirst" ? t67[2] : t67[1], i88 = this.dataFormat === "channelsFirst" ? t67[3] : t67[2];
    return e36 = wt4(e36, this.poolSize[0], this.padding, this.strides[0]), i88 = wt4(i88, this.poolSize[1], this.padding, this.strides[1]), this.dataFormat === "channelsFirst" ? [t67[0], t67[1], e36, i88] : [t67[0], e36, i88, t67[3]];
  }
  call(t67, e36) {
    return g4(() => (this.invokeCallHook(t67, e36), this.poolingFunction(C27(t67), this.poolSize, this.strides, this.padding, this.dataFormat)));
  }
  getConfig() {
    let t67 = { poolSize: this.poolSize, padding: this.padding, strides: this.strides, dataFormat: this.dataFormat }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
var oi = class extends sr {
  constructor(t67) {
    super(t67);
  }
  poolingFunction(t67, e36, i88, n67, r56) {
    return J16(r56), pt2(n67), or(t67, e36, i88, n67, r56, "max");
  }
};
oi.className = "MaxPooling2D";
serialization_exports.registerClass(oi);
var ai2 = class extends sr {
  constructor(t67) {
    super(t67);
  }
  poolingFunction(t67, e36, i88, n67, r56) {
    return J16(r56), pt2(n67), or(t67, e36, i88, n67, r56, "avg");
  }
};
ai2.className = "AveragePooling2D";
serialization_exports.registerClass(ai2);
var ir = class extends v41 {
  constructor(t67) {
    if (t67.poolSize == null && (t67.poolSize = [2, 2, 2]), super(t67), this.poolSize = Array.isArray(t67.poolSize) ? t67.poolSize : [t67.poolSize, t67.poolSize, t67.poolSize], t67.strides == null) this.strides = this.poolSize;
    else if (Array.isArray(t67.strides)) {
      if (t67.strides.length !== 3) throw new c102(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${t67.strides.length}.`);
      this.strides = t67.strides;
    } else this.strides = [t67.strides, t67.strides, t67.strides];
    Y13(this.poolSize, "poolSize"), Y13(this.strides, "strides"), this.padding = t67.padding == null ? "valid" : t67.padding, this.dataFormat = t67.dataFormat == null ? "channelsLast" : t67.dataFormat, J16(this.dataFormat), pt2(this.padding), this.inputSpec = [new K20({ ndim: 5 })];
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = this.dataFormat === "channelsFirst" ? t67[2] : t67[1], i88 = this.dataFormat === "channelsFirst" ? t67[3] : t67[2], n67 = this.dataFormat === "channelsFirst" ? t67[4] : t67[3];
    return e36 = wt4(e36, this.poolSize[0], this.padding, this.strides[0]), i88 = wt4(i88, this.poolSize[1], this.padding, this.strides[1]), n67 = wt4(n67, this.poolSize[2], this.padding, this.strides[2]), this.dataFormat === "channelsFirst" ? [t67[0], t67[1], e36, i88, n67] : [t67[0], e36, i88, n67, t67[4]];
  }
  call(t67, e36) {
    return g4(() => (this.invokeCallHook(t67, e36), this.poolingFunction(C27(t67), this.poolSize, this.strides, this.padding, this.dataFormat)));
  }
  getConfig() {
    let t67 = { poolSize: this.poolSize, padding: this.padding, strides: this.strides, dataFormat: this.dataFormat }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
var li2 = class extends ir {
  constructor(t67) {
    super(t67);
  }
  poolingFunction(t67, e36, i88, n67, r56) {
    return J16(r56), pt2(n67), Na(t67, e36, i88, n67, r56, "max");
  }
};
li2.className = "MaxPooling3D";
serialization_exports.registerClass(li2);
var ui = class extends ir {
  constructor(t67) {
    super(t67);
  }
  poolingFunction(t67, e36, i88, n67, r56) {
    return J16(r56), pt2(n67), Na(t67, e36, i88, n67, r56, "avg");
  }
};
ui.className = "AveragePooling3D";
serialization_exports.registerClass(ui);
var nr2 = class extends v41 {
  constructor(t67) {
    super(t67), this.inputSpec = [new K20({ ndim: 3 })];
  }
  computeOutputShape(t67) {
    return [t67[0], t67[2]];
  }
  call(t67, e36) {
    throw new S44();
  }
};
var ci = class extends nr2 {
  constructor(t67) {
    super(t67 || {});
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = C27(t67);
      return E19(i88, 1);
    });
  }
};
ci.className = "GlobalAveragePooling1D";
serialization_exports.registerClass(ci);
var hi = class extends nr2 {
  constructor(t67) {
    super(t67 || {});
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = C27(t67);
      return d10(i88, 1);
    });
  }
};
hi.className = "GlobalMaxPooling1D";
serialization_exports.registerClass(hi);
var rr2 = class extends v41 {
  constructor(t67) {
    super(t67), this.dataFormat = t67.dataFormat == null ? "channelsLast" : t67.dataFormat, J16(this.dataFormat), this.inputSpec = [new K20({ ndim: 4 })];
  }
  computeOutputShape(t67) {
    return t67 = t67, this.dataFormat === "channelsLast" ? [t67[0], t67[3]] : [t67[0], t67[1]];
  }
  call(t67, e36) {
    throw new S44();
  }
  getConfig() {
    let t67 = { dataFormat: this.dataFormat }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
var pi = class extends rr2 {
  call(t67, e36) {
    return g4(() => {
      let i88 = C27(t67);
      return this.dataFormat === "channelsLast" ? E19(i88, [1, 2]) : E19(i88, [2, 3]);
    });
  }
};
pi.className = "GlobalAveragePooling2D";
serialization_exports.registerClass(pi);
var fi = class extends rr2 {
  call(t67, e36) {
    return g4(() => {
      let i88 = C27(t67);
      return this.dataFormat === "channelsLast" ? d10(i88, [1, 2]) : d10(i88, [2, 3]);
    });
  }
};
fi.className = "GlobalMaxPooling2D";
serialization_exports.registerClass(fi);
var ar = class extends v41 {
  constructor(t67) {
    super(t67), this.layer = t67.layer;
  }
  build(t67) {
    this.built = true;
  }
  get trainable() {
    return this.layer != null ? this.layer.trainable : false;
  }
  set trainable(t67) {
    this.layer != null && (this.layer.trainable = t67);
  }
  get trainableWeights() {
    return this.layer.trainableWeights;
  }
  get nonTrainableWeights() {
    return this.layer.nonTrainableWeights;
  }
  get updates() {
    return this.layer._updates;
  }
  get losses() {
    return this.layer.losses;
  }
  getWeights() {
    return this.layer.getWeights();
  }
  setWeights(t67) {
    this.layer.setWeights(t67);
  }
  getConfig() {
    let t67 = { layer: { className: this.layer.getClassName(), config: this.layer.getConfig() } }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
  setFastWeightInitDuringBuild(t67) {
    super.setFastWeightInitDuringBuild(t67), this.layer != null && this.layer.setFastWeightInitDuringBuild(t67);
  }
  static fromConfig(t67, e36, i88 = {}) {
    let n67 = e36.layer, r56 = yt5(n67, i88);
    delete e36.layer;
    let o80 = { layer: r56 };
    return Object.assign(o80, e36), new t67(o80);
  }
};
var di = class extends ar {
  constructor(t67) {
    super(t67), this.supportsMasking = true;
  }
  build(t67) {
    if (t67 = E43(t67), t67.length < 3) throw new c102(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(t67)}`);
    this.inputSpec = [{ shape: t67 }];
    let e36 = [t67[0]].concat(t67.slice(2));
    this.layer.built || (this.layer.build(e36), this.layer.built = true), super.build(t67);
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = [t67[0]].concat(t67.slice(2)), i88 = this.layer.computeOutputShape(e36), n67 = t67[1];
    return [i88[0], n67].concat(i88.slice(1));
  }
  call(t67, e36) {
    return g4(() => (t67 = C27(t67), Fr((o80, a71) => [C27(this.layer.call(o80, e36)), []], t67, [], false, null, null, false, true)[1]));
  }
};
di.className = "TimeDistributed";
serialization_exports.registerClass(di);
function Dc(s84) {
  Wt3(eo2, "BidirectionalMergeMode", s84);
}
var Oc = "concat";
var mi = class extends ar {
  constructor(t67) {
    super(t67);
    let e36 = t67.layer.getConfig(), i88 = {};
    i88.className = t67.layer.getClassName(), i88.config = e36, this.forwardLayer = yt5(i88), e36.goBackwards = e36.goBackwards !== true;
    let n67 = {};
    if (n67.className = t67.layer.getClassName(), n67.config = e36, this.backwardLayer = yt5(n67), this.forwardLayer.name = "forward_" + this.forwardLayer.name, this.backwardLayer.name = "backward_" + this.backwardLayer.name, this.mergeMode = t67.mergeMode === void 0 ? Oc : t67.mergeMode, Dc(this.mergeMode), t67.weights) throw new S44("weights support is not implemented for Bidirectional layer yet.");
    this._stateful = t67.layer.stateful, this.returnSequences = t67.layer.returnSequences, this.returnState = t67.layer.returnState, this.supportsMasking = true, this._trainable = true, this.inputSpec = t67.layer.inputSpec, this.numConstants = null;
  }
  get trainable() {
    return this._trainable;
  }
  set trainable(t67) {
    this._trainable = t67, this.forwardLayer != null && (this.forwardLayer.trainable = t67), this.backwardLayer != null && (this.backwardLayer.trainable = t67);
  }
  getWeights() {
    return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights());
  }
  setWeights(t67) {
    let e36 = t67.length, i88 = Math.floor(e36 / 2);
    this.forwardLayer.setWeights(t67.slice(0, i88)), this.backwardLayer.setWeights(t67.slice(i88));
  }
  computeOutputShape(t67) {
    let e36 = this.forwardLayer.computeOutputShape(t67);
    Array.isArray(e36) && Array.isArray(e36[0]) || (e36 = [e36]), e36 = e36;
    let i88, n67, r56;
    return this.returnState && (r56 = e36.slice(1)), i88 = e36[0], i88 = i88, this.mergeMode === "concat" ? (i88[i88.length - 1] *= 2, n67 = [i88]) : this.mergeMode == null ? n67 = [i88, i88.slice()] : n67 = [i88], this.returnState ? this.mergeMode == null ? n67.concat(r56).concat(r56.slice()) : [i88].concat(r56).concat(r56.slice()) : st6(n67);
  }
  apply(t67, e36) {
    let i88 = e36 == null ? null : e36.initialState, n67 = e36 == null ? null : e36.constants;
    e36 == null && (e36 = {});
    let r56 = $r(t67, i88, n67, this.numConstants);
    if (t67 = r56.inputs, i88 = r56.initialState, n67 = r56.constants, Array.isArray(t67) && (i88 = t67.slice(1), t67 = t67[0]), (i88 == null || i88.length === 0) && n67 == null) return super.apply(t67, e36);
    let o80 = [], a71 = [];
    if (i88 != null) {
      let u86 = i88.length;
      if (u86 % 2 > 0) throw new c102("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");
      e36.initialState = i88, o80.push(...i88);
      let h74 = i88.map((p103) => new K20({ shape: p103.shape }));
      this.forwardLayer.stateSpec = h74.slice(0, u86 / 2), this.backwardLayer.stateSpec = h74.slice(u86 / 2), a71.push(...h74);
    }
    if (n67 != null) throw new S44("Support for constants in Bidirectional layers is not implemented yet.");
    let l80 = o80[0] instanceof ut3;
    for (let u86 of o80) if (u86 instanceof ut3 !== l80) throw new c102("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");
    if (l80) {
      let u86 = [t67].concat(o80), h74 = this.inputSpec.concat(a71), p103 = this.inputSpec;
      this.inputSpec = h74;
      let f85 = super.apply(u86, e36);
      return this.inputSpec = p103, f85;
    } else return super.apply(t67, e36);
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = e36.initialState, n67, r56;
      if (i88 == null) n67 = this.forwardLayer.call(t67, e36), r56 = this.backwardLayer.call(t67, e36);
      else {
        let l80 = i88.slice(0, i88.length / 2), u86 = i88.slice(i88.length / 2);
        n67 = this.forwardLayer.call(t67, Object.assign(e36, { initialState: l80 })), r56 = this.backwardLayer.call(t67, Object.assign(e36, { initialState: u86 }));
      }
      let o80;
      this.returnState && (Array.isArray(n67) && (o80 = n67.slice(1).concat(r56.slice(1))), n67 = n67[0], r56 = r56[0]), this.returnSequences && (r56 = E21(r56, 1));
      let a71;
      return this.mergeMode === "concat" ? a71 = qe([n67, r56]) : this.mergeMode === "sum" ? a71 = T7(n67, r56) : this.mergeMode === "ave" ? a71 = y8(0.5, T7(n67, r56)) : this.mergeMode === "mul" ? a71 = y8(n67, r56) : this.mergeMode == null && (a71 = [n67, r56]), this.returnState ? this.mergeMode == null ? a71.concat(o80) : [a71].concat(o80) : a71;
    });
  }
  resetStates(t67) {
    this.forwardLayer.resetStates(), this.backwardLayer.resetStates();
  }
  build(t67) {
    Ot4(this.forwardLayer.name, () => {
      this.forwardLayer.build(t67);
    }), Ot4(this.backwardLayer.name, () => {
      this.backwardLayer.build(t67);
    }), this.built = true;
  }
  computeMask(t67, e36) {
    Array.isArray(e36) && (e36 = e36[0]);
    let i88;
    if (this.returnSequences ? this.mergeMode == null ? i88 = [e36, e36] : i88 = e36 : this.mergeMode == null ? i88 = [null, null] : i88 = null, this.returnState) {
      let r56 = this.forwardLayer.states.map((o80) => null);
      return Array.isArray(i88) ? i88.concat(r56).concat(r56) : [i88].concat(r56).concat(r56);
    } else return i88;
  }
  get trainableWeights() {
    return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights);
  }
  get nonTrainableWeights() {
    return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights);
  }
  setFastWeightInitDuringBuild(t67) {
    super.setFastWeightInitDuringBuild(t67), this.forwardLayer != null && this.forwardLayer.setFastWeightInitDuringBuild(t67), this.backwardLayer != null && this.backwardLayer.setFastWeightInitDuringBuild(t67);
  }
  getConfig() {
    let t67 = { mergeMode: this.mergeMode }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
  static fromConfig(t67, e36) {
    let i88 = yt5(e36.layer);
    if (delete e36.layer, e36.numConstants != null) throw new S44("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");
    let n67 = e36;
    return n67.layer = i88, new t67(n67);
  }
};
mi.className = "Bidirectional";
serialization_exports.registerClass(mi);
var gi = class extends v41 {
  constructor(t67) {
    super(t67), this.scale = t67.scale, t67.offset ? this.offset = t67.offset : this.offset = 0;
  }
  getConfig() {
    let t67 = { scale: this.scale, offset: this.offset }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
  call(t67, e36) {
    return g4(() => (t67 = C27(t67), t67.dtype !== "float32" && (t67 = at6(t67, "float32")), T7(y8(t67, this.scale), this.offset)));
  }
};
gi.className = "Rescaling";
serialization_exports.registerClass(gi);
var { resizeBilinear: Kc, cropAndResize: jc } = go2;
var yi = class extends v41 {
  constructor(t67) {
    super(t67), this.height = t67.height, this.width = t67.width;
  }
  centerCrop(t67, e36, i88, n67, r56, o80, a71, l80) {
    return g4(() => {
      let u86, h74 = false, p103 = e36 / o80, f85 = i88 / a71, w45 = (n67 + e36) / o80, b58 = (r56 + i88) / a71, m96 = [p103, f85, w45, b58], g72 = [];
      t67.rank === 3 ? (h74 = true, u86 = g21([t67])) : u86 = t67;
      for (let z32 = 0; z32 < u86.shape[0]; z32++) g72.push(m96);
      let x76 = p10(g72, [g72.length, 4]), d55 = p35(0, g72.length, 1, "int32"), A35 = jc(u86, x76, d55, [n67, r56], "nearest");
      return h74 ? at6(C27(g22(A35)), l80) : at6(A35, l80);
    });
  }
  upsize(t67, e36, i88, n67) {
    return g4(() => {
      let r56 = Kc(t67, [e36, i88]);
      return at6(r56, n67);
    });
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = C27(t67), n67 = i88.dtype, r56 = i88.shape, o80 = r56[r56.length - 3], a71 = r56[r56.length - 2], l80 = 0;
      o80 !== this.height && (l80 = Math.floor((o80 - this.height) / 2));
      let u86 = 0;
      return a71 !== this.width && (u86 = Math.floor((a71 - this.width) / 2), u86 === 0 && (u86 = 1)), l80 >= 0 && u86 >= 0 ? this.centerCrop(i88, l80, u86, this.height, this.width, o80, a71, n67) : this.upsize(t67, this.height, this.width, n67);
    });
  }
  getConfig() {
    let t67 = { height: this.height, width: this.width }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = t67.length - 3, i88 = t67.length - 2;
    return t67[e36] = this.height, t67[i88] = this.width, t67;
  }
};
yi.className = "CenterCrop";
serialization_exports.registerClass(yi);
function La(s84, t67, e36, i88) {
  let n67 = C27(s84);
  if (n67.dtype !== "int32" && (n67 = at6(n67, "int32")), t67 === "int") return n67;
  let r56 = n67.shape;
  if (n67.rank === 0 && (n67 = D7(n67, -1)), t67 === "oneHot" && n67.shape[n67.shape.length - 1] !== 1 && (n67 = D7(n67, -1)), n67.rank > 2) throw new c102(`When outputMode is not int, maximum output rank is 2 Received outputMode ${t67} and input shape ${r56} which would result in output rank ${n67.rank}.`);
  let o80 = ["multiHot", "oneHot"].includes(t67), a71 = n67, l80;
  if (typeof i88 < "u" && t67 === "count" ? l80 = f14(a71, i88, e36, o80) : l80 = f14(a71, [], e36, o80), t67 !== "tfIdf") return l80;
  if (i88) return y8(l80, i88);
  throw new c102("When outputMode is 'tfIdf', weights must be provided.");
}
var bi = class extends v41 {
  constructor(t67) {
    super(t67), this.numTokens = t67.numTokens, t67.outputMode ? this.outputMode = t67.outputMode : this.outputMode = "multiHot";
  }
  getConfig() {
    let t67 = { numTokens: this.numTokens, outputMode: this.outputMode }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
  computeOutputShape(t67) {
    return t67 = E43(t67), t67 == null ? [this.numTokens] : this.outputMode === "oneHot" && t67[t67.length - 1] !== 1 ? (t67.push(this.numTokens), t67) : (t67[t67.length - 1] = this.numTokens, t67);
  }
  call(t67, e36) {
    return g4(() => {
      t67 = C27(t67), t67.dtype !== "int32" && (t67 = at6(t67, "int32"));
      let i88;
      if (typeof e36.countWeights < "u") {
        if (this.outputMode !== "count") throw new c102(`countWeights is not used when outputMode !== count.
              Received countWeights=${e36.countWeights}`);
        i88 = C27(e36.countWeights);
      }
      let n67 = d10(t67), r56 = E14(t67), o80 = G6(this.numTokens, n67).bufferSync().get(0), a71 = h18(r56, 0).bufferSync().get(0);
      if (!(o80 && a71)) throw new c102(`Input values must be between 0 < values <= numTokens with numTokens=${this.numTokens}`);
      return La(t67, this.outputMode, this.numTokens, i88);
    });
  }
};
bi.className = "CategoryEncoding";
serialization_exports.registerClass(bi);
var sh = ["bilinear", "nearest"];
var Ea = new Set(sh);
var wi = class extends v41 {
  constructor(t67) {
    if (super(t67), this.height = t67.height, this.width = t67.width, t67.interpolation) if (Ea.has(t67.interpolation)) this.interpolation = t67.interpolation;
    else throw new c102(`Invalid interpolation parameter: ${t67.interpolation} is not implemented`);
    else this.interpolation = "bilinear";
    this.cropToAspectRatio = !!t67.cropToAspectRatio;
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = t67[2];
    return [this.height, this.width, e36];
  }
  getConfig() {
    let t67 = { height: this.height, width: this.width, interpolation: this.interpolation, cropToAspectRatio: this.cropToAspectRatio }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = [this.height, this.width];
      if (this.interpolation === "bilinear") return go2.resizeBilinear(t67, i88, !this.cropToAspectRatio);
      if (this.interpolation === "nearest") return go2.resizeNearestNeighbor(t67, i88, !this.cropToAspectRatio);
      throw new Error(`Interpolation is ${this.interpolation} but only ${[...Ea]} are supported`);
    });
  }
};
wi.className = "Resizing";
serialization_exports.registerClass(wi);
var Ki = class {
  constructor(t67) {
    this.seed = t67;
  }
  next() {
    if (this.seed !== void 0) return this.seed++;
  }
};
Ki.className = "RandomSeed";
var ji = class extends v41 {
  constructor(t67) {
    super(t67), this.randomGenerator = new Ki(t67.seed);
  }
  getConfig() {
    let t67 = { seed: this.randomGenerator.seed }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
};
ji.className = "BaseRandomLayer";
var oh = ["bilinear", "nearest"];
var Oa = new Set(oh);
var xi = class extends ji {
  constructor(t67) {
    super(t67);
    let { factor: e36, interpolation: i88 = "bilinear" } = t67;
    if (this.factor = e36, Array.isArray(this.factor) && this.factor.length === 2) this.widthLower = this.factor[0], this.widthUpper = this.factor[1];
    else if (!Array.isArray(this.factor) && this.factor > 0) this.widthLower = -this.factor, this.widthUpper = this.factor;
    else throw new c102(`Invalid factor: ${this.factor}. Must be positive number or tuple of 2 numbers`);
    if (this.widthLower < -1 || this.widthUpper < -1) throw new c102(`factor must have values larger than -1. Got: ${this.factor}`);
    if (this.widthUpper < this.widthLower) throw new c102(`factor cannot have upper bound less than lower bound.
        Got upper bound: ${this.widthUpper}.
        Got lower bound: ${this.widthLower}
      `);
    if (i88) if (Oa.has(i88)) this.interpolation = i88;
    else throw new c102(`Invalid interpolation parameter: ${i88} is not implemented`);
  }
  getConfig() {
    let t67 = { factor: this.factor, interpolation: this.interpolation }, e36 = super.getConfig();
    return Object.assign(t67, e36), t67;
  }
  computeOutputShape(t67) {
    t67 = E43(t67);
    let e36 = t67[2];
    return [this.imgHeight, -1, e36];
  }
  call(t67, e36) {
    return g4(() => {
      let i88 = C27(t67);
      this.imgHeight = i88.shape[i88.shape.length - 3];
      let n67 = i88.shape[i88.shape.length - 2];
      this.widthFactor = U6([1], 1 + this.widthLower, 1 + this.widthUpper, "float32", this.randomGenerator.next());
      let r56 = this.widthFactor.dataSync()[0] * n67;
      r56 = Math.round(r56);
      let o80 = [this.imgHeight, r56];
      switch (this.interpolation) {
        case "bilinear":
          return go2.resizeBilinear(t67, o80);
        case "nearest":
          return go2.resizeNearestNeighbor(t67, o80);
        default:
          throw new Error(`Interpolation is ${this.interpolation}
          but only ${[...Oa]} are supported`);
      }
    });
  }
};
xi.className = "RandomWidth";
serialization_exports.registerClass(xi);
function ah(s84) {
  return new Mt3(s84);
}
function lh(s84) {
  return new xs(s84);
}
function uh(s84) {
  return new ys2(s84);
}
function ch(s84) {
  return new bs(s84);
}
function hh(s84) {
  return new ws(s84);
}
function ph(s84) {
  return new Is(s84);
}
function fh(s84) {
  return new As(s84);
}
function dh(s84) {
  return new vs(s84);
}
function mh(s84) {
  return new De2(s84);
}
function gh(s84) {
  return new zs(s84);
}
function yh(s84) {
  return new Oe2(s84);
}
function bh(s84) {
  return new Cs(s84);
}
function wh(s84) {
  return new Ss(s84);
}
function xh(s84) {
  return new Ls(s84);
}
function Ah(s84) {
  return new Ts(s84);
}
function Ih(s84) {
  return new Es(s84);
}
function kh(s84) {
  return new Bs(s84);
}
function Nh(s84) {
  return new $s(s84);
}
function zh(s84) {
  return new Fe4(s84);
}
function Ch(s84) {
  return new Rs(s84);
}
function Sh(s84) {
  return new Fs(s84);
}
function vh(s84) {
  return new Ws(s84);
}
function Lh(s84) {
  return new Vs(s84);
}
function Th(s84) {
  return new Us(s84);
}
function Eh(s84) {
  return new Ks(s84);
}
function Dh(s84) {
  return new js(s84);
}
function Oh(s84) {
  return new Hs(s84);
}
function _h(s84) {
  return new Gs(s84);
}
function Mh(s84) {
  return new Js(s84);
}
function Rh(s84) {
  return new Zs(s84);
}
function $h(s84) {
  return new qs(s84);
}
function Fh(s84) {
  return new Ys(s84);
}
function Bh(s84) {
  return new ei(s84);
}
function Wh(s84) {
  return new si(s84);
}
function Vh(s84) {
  return new ii(s84);
}
function Ur(s84) {
  return new ri(s84);
}
function Uh(s84) {
  return Ur(s84);
}
function Ph(s84) {
  return Ur(s84);
}
function Pr(s84) {
  return new ai2(s84);
}
function Kh(s84) {
  return Pr(s84);
}
function jh(s84) {
  return Pr(s84);
}
function Kr(s84) {
  return new ui(s84);
}
function qh(s84) {
  return Kr(s84);
}
function Hh(s84) {
  return Kr(s84);
}
function Jh(s84) {
  return new ci(s84);
}
function Zh(s84) {
  return new pi(s84);
}
function _a(s84) {
  return new hi(s84);
}
function Ma(s84) {
  return new fi(s84);
}
function Ra(s84) {
  return new ni(s84);
}
function $a(s84) {
  return new oi(s84);
}
function Gh(s84) {
  return new li2(s84);
}
function Yh(s84) {
  return new Os(s84);
}
function Xh(s84) {
  return new Me2(s84);
}
function Qh(s84) {
  return new _s(s84);
}
function tp(s84) {
  return new Qt3(s84);
}
function ep(s84) {
  return new Ds(s84);
}
function sp(s84) {
  return new _e3(s84);
}
function ip(s84) {
  return new Ms(s84);
}
function np(s84) {
  return new $e2(s84);
}
function rp(s84) {
  return new kt3(s84);
}
function op(s84) {
  return new Re5(s84);
}
function ap(s84) {
  return new mi(s84);
}
function lp(s84) {
  return new di(s84);
}
var up = _a;
var cp = Ma;
var hp = Ra;
var pp = $a;
function fp(s84) {
  return new Xs(s84);
}
function dp(s84) {
  return new Qs(s84);
}
function mp(s84) {
  return new ti(s84);
}
function gp(s84) {
  return new Ps(s84);
}
function yp(s84) {
  return new gi(s84);
}
function bp(s84) {
  return new yi(s84);
}
function wp(s84) {
  return new wi(s84);
}
function xp(s84) {
  return new bi(s84);
}
function Ap(s84) {
  return new xi(s84);
}
var Ba = {};
Pe2(Ba, { MAPE: () => Dp, MSE: () => Mp, binaryAccuracy: () => Ip, binaryCrossentropy: () => kp, categoricalAccuracy: () => zp, categoricalCrossentropy: () => Cp, cosineProximity: () => Lp, mape: () => Op, meanAbsoluteError: () => Tp, meanAbsolutePercentageError: () => Ep, meanSquaredError: () => _p, mse: () => Rp, precision: () => Sp, r2Score: () => $p, recall: () => vp, sparseCategoricalAccuracy: () => Np });
function Ip(s84, t67) {
  return Oi(s84, t67);
}
function kp(s84, t67) {
  return wn(s84, t67);
}
function Np(s84, t67) {
  return xn2(s84, t67);
}
function zp(s84, t67) {
  return _i(s84, t67);
}
function Cp(s84, t67) {
  return Mi(s84, t67);
}
function Sp(s84, t67) {
  return Nr(s84, t67);
}
function vp(s84, t67) {
  return Mo2(s84, t67);
}
function Lp(s84, t67) {
  return Di(s84, t67);
}
function Tp(s84, t67) {
  return cs2(s84, t67);
}
function Ep(s84, t67) {
  return ce6(s84, t67);
}
function Dp(s84, t67) {
  return ce6(s84, t67);
}
function Op(s84, t67) {
  return ce6(s84, t67);
}
function _p(s84, t67) {
  return Pt3(s84, t67);
}
function Mp(s84, t67) {
  return Pt3(s84, t67);
}
function Rp(s84, t67) {
  return Pt3(s84, t67);
}
function $p(s84, t67) {
  return Ro2(s84, t67);
}
var Wa = {};
Pe2(Wa, { modelFromJSON: () => ea });
var Va = {};
Pe2(Va, { l1: () => Bp, l1l2: () => Fp, l2: () => Wp });
function Fp(s84) {
  return new pe3(s84);
}
function Bp(s84) {
  return aa(s84);
}
function Wp(s84) {
  return la(s84);
}
var ur = class extends Yt3 {
  constructor() {
    super(...arguments), this.model = null;
  }
  setModel(t67) {
    if (!(t67 instanceof xt2)) throw new Error("model must be a LayersModel, not some other Container");
    this.model = t67;
  }
};
function lr(s84, t67) {
  return s84 < t67;
}
function Ua(s84, t67) {
  return s84 > t67;
}
var cr = class extends ur {
  constructor(t67) {
    if (super(), t67 == null && (t67 = {}), t67.restoreBestWeights) throw new S44("restoreBestWeights = True is not implemented in EarlyStopping yet.");
    this.monitor = t67.monitor || "val_loss", this.minDelta = Math.abs(t67.minDelta || 0), this.patience = t67.patience || 0, this.verbose = t67.verbose || 0, this.mode = t67.mode || "auto", this.baseline = t67.baseline, ["auto", "min", "max"].indexOf(this.mode) === -1 && (console.warn(`EarlyStopping mode '${this.mode}' is invalid. Falling back to mode 'auto'.`), this.mode = "auto"), this.mode === "min" ? this.monitorFunc = lr : this.mode === "max" ? this.monitorFunc = Ua : this.monitor.indexOf("acc") !== -1 ? this.monitorFunc = Ua : this.monitorFunc = lr, this.monitorFunc === lr && (this.minDelta *= -1);
  }
  async onTrainBegin(t67) {
    this.wait = 0, this.stoppedEpoch = 0, this.baseline != null ? this.best = this.baseline : this.best = this.monitorFunc === lr ? 1 / 0 : -1 / 0;
  }
  async onEpochEnd(t67, e36) {
    await Ut3(e36);
    let i88 = this.getMonitorValue(e36);
    i88 != null && (this.monitorFunc(i88 - this.minDelta, this.best) ? (this.best = i88, this.wait = 0) : (this.wait++, this.wait >= this.patience && (this.stoppedEpoch = t67, this.model.stopTraining = true)));
  }
  async onTrainEnd(t67) {
    this.stoppedEpoch > 0 && this.verbose && console.log(`Epoch ${this.stoppedEpoch}: early stopping.`);
  }
  getMonitorValue(t67) {
    t67 == null && (t67 = {});
    let e36 = t67[this.monitor];
    return e36 == null && console.warn(`Metric for EarlyStopping ${this.monitor} is not available. Available metrics are: ${Object.keys(t67)}`), e36;
  }
};
function Vp(s84) {
  return new cr(s84);
}
var Up = { earlyStopping: Vp };

// https://esm.sh/@tensorflow/tfjs@4.22.0/denonext/tfjs.mjs
var r55 = "4.22.0";
var u85 = { "tfjs-core": o12, "tfjs-backend-cpu": o27, "tfjs-backend-webgl": o45, "tfjs-data": Xe2, "tfjs-layers": $i, "tfjs-converter": gs, tfjs: r55 };
export {
  o3 as Abs,
  t as Acos,
  e2 as Acosh,
  v23 as AdadeltaOptimizer,
  m35 as AdagradOptimizer,
  y16 as AdamOptimizer,
  w21 as AdamaxOptimizer,
  r as Add,
  n4 as AddN,
  s3 as All,
  p2 as Any,
  c3 as ArgMax,
  a4 as ArgMin,
  x2 as Asin,
  i as Asinh,
  l2 as Atan,
  u as Atan2,
  d2 as Atanh,
  S2 as AvgPool,
  D2 as AvgPool3D,
  m as AvgPool3DGrad,
  g2 as AvgPoolGrad,
  R2 as BatchMatMul,
  h3 as BatchToSpaceND,
  M2 as Bincount,
  A2 as BitwiseAnd,
  N2 as BroadcastArgs,
  B2 as BroadcastTo,
  ur as Callback,
  pn as CallbackList,
  C2 as Cast,
  v2 as Ceil,
  F2 as ClipByValue,
  P2 as Complex,
  T2 as ComplexAbs,
  L2 as Concat,
  k2 as Conv2D,
  G2 as Conv2DBackpropFilter,
  E2 as Conv2DBackpropInput,
  f3 as Conv3D,
  I2 as Conv3DBackpropFilterV2,
  q2 as Conv3DBackpropInputV2,
  w2 as Cos,
  V2 as Cosh,
  z2 as CropAndResize,
  y3 as Cumprod,
  b2 as Cumsum,
  dn2 as CustomCallback,
  n as DataStorage,
  U2 as DenseBincount,
  O2 as DepthToSpace,
  H2 as DepthwiseConv2dNative,
  W2 as DepthwiseConv2dNativeBackpropFilter,
  K2 as DepthwiseConv2dNativeBackpropInput,
  X2 as Diag,
  Z2 as Dilation2D,
  j2 as Dilation2DBackpropFilter,
  _2 as Dilation2DBackpropInput,
  J2 as Draw,
  a2 as ENV,
  cr as EarlyStopping,
  Y2 as Einsum,
  $2 as Elu,
  oo as EluGrad,
  n2 as Environment,
  eo as Equal,
  to as Erf,
  ro as Exp,
  no as ExpandDims,
  so as Expm1,
  po as FFT,
  co as Fill,
  ao as FlipLeftRight,
  xo as Floor,
  io as FloorDiv,
  Se as FromPixels,
  lo as FusedBatchNorm,
  me as FusedConv2D,
  Re as FusedDepthwiseConv2D,
  f64 as GPGPUContext,
  So as GatherNd,
  uo as GatherV2,
  B27 as GraphModel,
  go as Greater,
  Do as GreaterEqual,
  fn2 as History,
  Ro as IFFT,
  mo as Identity,
  ho as Imag,
  K20 as InputSpec,
  Mo as IsFinite,
  Ao as IsInf,
  Bo as IsNan,
  o as KernelBackend,
  qo as LRN,
  wo as LRNGrad,
  vi as LayerVariable,
  xt2 as LayersModel,
  No as LeakyRelu,
  Co as Less,
  vo as LessEqual,
  Fo as LinSpace,
  Po as Log,
  To as Log1p,
  fo as LogSoftmax,
  Lo as LogicalAnd,
  ko as LogicalNot,
  Go as LogicalOr,
  Eo as LogicalXor,
  Io as LowerBound,
  o21 as MathBackendCPU,
  N41 as MathBackendWebGL,
  Vo as MatrixBandPart,
  yo as Max,
  zo as MaxPool,
  Oo as MaxPool3D,
  Ho as MaxPool3DGrad,
  Uo as MaxPoolGrad,
  Wo as MaxPoolWithArgmax,
  bo as Maximum,
  Ko as Mean,
  Xo as Min,
  Zo as Minimum,
  _o as MirrorPad,
  jo as Mod,
  h30 as MomentumOptimizer,
  Jo as Multinomial,
  Qo as Multiply,
  Yo as Neg,
  ot as NonMaxSuppressionV3,
  tt as NonMaxSuppressionV4,
  et as NonMaxSuppressionV5,
  $o as NotEqual,
  p9 as OP_SCOPE_SUFFIX,
  nt as OneHot,
  rt as OnesLike,
  n15 as Optimizer,
  i22 as OptimizerConstructors,
  st as Pack,
  pt as PadV2,
  ct as Pool,
  at as Pow,
  xt as Prelu,
  it as Prod,
  A11 as RMSPropOptimizer,
  kt3 as RNN,
  lt as RaggedGather,
  dt as RaggedRange,
  ut as RaggedTensorToTensor,
  St as Range,
  i4 as Rank,
  gt as Real,
  Q2 as RealDiv,
  Dt as Reciprocal,
  E24 as Reduction,
  mt as Relu,
  Nt as Relu6,
  Rt as Reshape,
  At as ResizeBilinear,
  Bt as ResizeBilinearGrad,
  ht as ResizeNearestNeighbor,
  Mt as ResizeNearestNeighborGrad,
  Ct as Reverse,
  ge as RotateWithOffset,
  vt as Round,
  Ft as Rsqrt,
  n16 as SGDOptimizer,
  Pt as ScatterNd,
  Lt as SearchSorted,
  kt as Select,
  Gt as Selu,
  Ee3 as Sequential,
  wt as Sigmoid,
  qt as Sign,
  ft as Sin,
  It as Sinh,
  Et as Slice,
  Ot as Softmax,
  Vt as Softplus,
  zt as SpaceToBatchND,
  Ht as SparseFillEmptyRows,
  Wt as SparseReshape,
  Kt as SparseSegmentMean,
  Xt as SparseSegmentSum,
  Zt as SparseToDense,
  Ut as SplitV,
  yt as Sqrt,
  jt as Square,
  _t as SquaredDifference,
  Jt as StaticRegexReplace,
  ue as Step,
  Qt as StridedSlice,
  Yt as StringNGrams,
  $t as StringSplit,
  oe as StringToHashBucketFast,
  te as Sub,
  bt as Sum,
  ut3 as SymbolicTensor,
  ee as Tan,
  re as Tanh,
  o5 as Tensor,
  p8 as TensorBuffer,
  Tt as TensorScatterUpdate,
  ne as Tile,
  se as TopK,
  pe as Transform,
  ce as Transpose,
  ae as Unique,
  xe as Unpack,
  ie as UnsortedSegmentSum,
  le as UpperBound,
  d3 as Variable,
  de as ZerosLike,
  De as _FusedMatMul,
  b9 as abs,
  u8 as acos,
  h7 as acosh,
  T7 as add,
  c11 as addN,
  E7 as all,
  y9 as any,
  u9 as argMax,
  u10 as argMin,
  u11 as asin,
  h8 as asinh,
  x12 as atan,
  E8 as atan2,
  x13 as atanh,
  T8 as avgPool,
  H5 as avgPool3d,
  v4 as backend,
  backend_util_exports as backend_util,
  N7 as basicLSTMCell,
  F5 as batchNorm,
  g7 as batchNorm2d,
  g8 as batchNorm3d,
  g9 as batchNorm4d,
  N8 as batchToSpaceND,
  $7 as bincount,
  A6 as bitwiseAnd,
  q9 as booleanMaskAsync,
  f12 as broadcastArgs,
  v10 as broadcastTo,
  broadcast_util_exports as broadcast_util,
  browser_exports as browser,
  i7 as buffer,
  Up as callbacks,
  w12 as cast,
  x17 as ceil,
  x18 as clipByValue,
  x11 as clone,
  x8 as complex,
  E9 as concat,
  p19 as concat1d,
  a9 as concat2d,
  a10 as concat3d,
  a11 as concat4d,
  vo2 as constraints,
  W5 as conv1d,
  C5 as conv2d,
  u12 as conv2dTranspose,
  T9 as conv3d,
  d7 as conv3dTranspose,
  K3 as copyRegisteredKernels,
  u13 as cos,
  h14 as cosh,
  M6 as cosineWindow,
  E12 as cumprod,
  N9 as cumsum,
  $10 as customGrad,
  tfjs_data_exports as data,
  f14 as denseBincount,
  c9 as deprecationWarn,
  l15 as depthToSpace,
  g11 as depthwiseConv2d,
  Dt2 as deregisterOp,
  device_util_exports as device_util,
  a12 as diag,
  C6 as dilation2d,
  m9 as disableDeprecationWarnings,
  E4 as dispose,
  l10 as disposeVariables,
  D6 as div,
  z6 as divNoNan,
  z7 as dot,
  _10 as dropout,
  N10 as einsum,
  s12 as elu,
  x9 as enableDebugMode,
  f5 as enableProdMode,
  f35 as enclosingPowerOfTwo,
  k7 as engine,
  u17 as ensureShape,
  l as env,
  E13 as equal,
  x20 as erf,
  u19 as euclideanNorm,
  u20 as exp,
  D7 as expandDims,
  u21 as expm1,
  $9 as eye,
  l24 as fft,
  c16 as fill,
  P3 as findBackend,
  W3 as findBackendFactory,
  x24 as floor,
  b8 as floorDiv,
  p68 as forceHalfFloat,
  fused_ops_exports as fused,
  E15 as gather,
  h25 as gatherND,
  gather_nd_util_exports as gather_util,
  A5 as getBackend,
  x3 as getGradient,
  w3 as getKernel,
  k3 as getKernelsForBackend,
  gpgpu_util_exports as gpgpu_util,
  v12 as grad,
  A7 as grads,
  G6 as greater,
  h18 as greaterEqual,
  l25 as ifft,
  a16 as imag,
  go2 as image,
  w18 as inTopKAsync,
  Lo2 as initializers,
  Dr as input,
  io_exports as io,
  G10 as irfft,
  u23 as isFinite,
  x25 as isInf,
  x26 as isNaN,
  N3 as keep,
  kernel_impls_exports as kernel_impls,
  Fa as layers,
  x27 as leakyRelu,
  d11 as less,
  b15 as lessEqual,
  bo2 as linalg,
  f18 as linspace,
  ds as loadGraphModel,
  hs2 as loadGraphModelSync,
  sa as loadLayersModel,
  T11 as localResponseNormalization,
  x29 as log,
  g13 as log1p,
  G7 as logSigmoid,
  A8 as logSoftmax,
  z9 as logSumExp,
  g16 as logicalAnd,
  s18 as logicalNot,
  u25 as logicalOr,
  b16 as logicalXor,
  Eo2 as losses,
  n11 as lowerBound,
  N6 as matMul,
  math_exports as math,
  d10 as max,
  O6 as maxPool,
  W6 as maxPool3d,
  P6 as maxPoolWithArgmax,
  E18 as maximum,
  E19 as mean,
  B5 as memory,
  $11 as meshgrid,
  Ba as metrics,
  E14 as min,
  G8 as minimum,
  k14 as mirrorPad,
  T13 as mod,
  Ku as model,
  Wa as models,
  g17 as moments,
  _9 as movingAverage,
  y8 as mul,
  w14 as multiRNNCell,
  D8 as multinomial,
  g14 as neg,
  n18 as nextFrame,
  z8 as norm,
  b18 as notEqual,
  w15 as oneHot,
  c26 as ones,
  k15 as onesLike,
  u4 as op,
  P7 as outerProduct,
  l20 as pad,
  i16 as pad1d,
  a17 as pad2d,
  u28 as pad3d,
  u29 as pad4d,
  z10 as pool,
  x22 as pow,
  x32 as prelu,
  t3 as print,
  N13 as prod,
  b7 as profile,
  $14 as raggedGather,
  N14 as raggedRange,
  E20 as raggedTensorToTensor,
  A9 as rand,
  p33 as randomGamma,
  w17 as randomNormal,
  f25 as randomStandardNormal,
  U6 as randomUniform,
  d14 as randomUniformInt,
  p35 as range,
  w8 as ready,
  s21 as real,
  x33 as reciprocal,
  R3 as registerBackend,
  qu as registerCallbackConstructor,
  b3 as registerGradient,
  p3 as registerKernel,
  Lt2 as registerOp,
  Va as regularizers,
  s22 as relu,
  s23 as relu6,
  I6 as removeBackend,
  h9 as reshape,
  E21 as reverse,
  u33 as reverse1d,
  v15 as reverse2d,
  v16 as reverse3d,
  v17 as reverse4d,
  K8 as rfft,
  x34 as round,
  q8 as rsqrt,
  m21 as scalar,
  I13 as scatterND,
  scatter_nd_util_exports as scatter_util,
  T12 as searchSorted,
  l23 as selu,
  T16 as separableConv2d,
  ju as sequential,
  serialization_exports as serialization,
  y6 as setBackend,
  F3 as setPlatform,
  d27 as setWebGLContext,
  b19 as setdiff1dAsync,
  shared_exports as shared,
  d6 as sigmoid,
  g19 as sign,
  $23 as signal,
  u34 as sin,
  h21 as sinh,
  E10 as slice,
  f27 as slice1d,
  f28 as slice2d,
  f29 as slice3d,
  f30 as slice4d,
  slice_util_exports as slice_util,
  g20 as softmax,
  l18 as softplus,
  x31 as spaceToBatchND,
  Co2 as sparse,
  g24 as sparseToDense,
  j9 as spectral,
  N17 as split,
  q6 as sqrt,
  p24 as square,
  T17 as squaredDifference,
  a23 as squeeze,
  g21 as stack,
  N18 as step,
  a24 as stridedSlice,
  Oo2 as string,
  E16 as sub,
  T10 as sum,
  l6 as sumOutType,
  x35 as tan,
  x16 as tanh,
  p10 as tensor,
  m25 as tensor1d,
  h22 as tensor2d,
  s28 as tensor3d,
  u36 as tensor4d,
  h23 as tensor5d,
  a25 as tensor6d,
  $18 as tensorScatterUpdate,
  tensor_util_exports as tensor_util,
  test_util_exports as test_util,
  g4 as tidy,
  g12 as tile,
  D4 as time,
  x36 as topk,
  o13 as train,
  A10 as transpose,
  v18 as truncatedNormal,
  v19 as unique,
  m2 as unregisterGradient,
  $3 as unregisterKernel,
  N19 as unsortedSegmentSum,
  g22 as unstack,
  c5 as upcastType,
  n12 as upperBound,
  util_exports as util,
  x30 as valueAndGrad,
  k12 as valueAndGrads,
  m27 as variable,
  N12 as variableGrads,
  u85 as version,
  gs as version_converter,
  o12 as version_core,
  o27 as version_cpu,
  $i as version_layers,
  o45 as version_webgl,
  s47 as webgl,
  webgl_util_exports as webgl_util,
  G5 as where,
  p41 as whereAsync,
  e13 as zeros,
  k11 as zerosLike
};
/*! Bundled license information:

@tensorflow/tfjs-core/dist/backends/backend.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/util_base.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/environment.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/global_util.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/log.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/kernel_registry.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/platforms/is_typed_array_browser.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/hash_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/profiler.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/tape.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/tensor_format.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/tensor.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/types.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/tensor_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/engine.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/device_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/flags.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/tensor_util_env.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/operation.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/complex.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tensor_ops_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tensor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/types.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/globals.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/io_utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/router_registry.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/indexed_db.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/local_storage.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/model_management.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/platforms/platform_browser.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/platforms/platform_node.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/buffer.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/cast.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/clone.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/print.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/base_side_effects.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/add.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/floorDiv.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/div.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/mul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/abs.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/acos.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/acosh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/add_n.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/all.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/any.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/arg_max.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/arg_min.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/asin.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/asinh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/atan.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/atan2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/atanh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/conv_util.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/reshape.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/avg_pool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/avg_pool_3d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/concat.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/mat_mul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sigmoid.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/slice.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tanh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/basic_lstm_cell.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/batch_to_space_nd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/batchnorm.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/bincount.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/bitwise_and.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/broadcast_args.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/broadcast_to.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/ceil.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/fill.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/clip_by_value.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/conv2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/conv2d_backprop_input.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/conv3d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/conv3d_backprop_input.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/cos.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/cosh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/cumprod.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/cumsum.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/dense_bincount.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/depth_to_space.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/depthwise_conv2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/diag.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/dilation2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/broadcast_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/where.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/zeros_like.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/div_no_nan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/dot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/einsum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/elu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/ensure_shape.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/erf.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/axis_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/max.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/min.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/pow.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/scalar.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sqrt.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/square.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sum.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/norm.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/euclidean_norm.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/exp.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/expand_dims.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/expm1.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tile.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/eye.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/floor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/gather.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/greater.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/greater_equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/imag.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/is_finite.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/is_inf.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/is_nan.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/leaky_relu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/less.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/less_equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/linspace.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/local_response_normalization.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/log.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/log1p.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/neg.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/softplus.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/log_sigmoid.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sub.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/log_softmax.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/log_sum_exp.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/logical_and.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/logical_not.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/logical_or.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/logical_xor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/search_sorted.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/lower_bound.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/max_pool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/max_pool_3d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/max_pool_with_argmax.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/maximum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/mean.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/zeros.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/ones.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/meshgrid.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/minimum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/mirror_pad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/mod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/moments.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/multinomial.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/not_equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/one_hot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/ones_like.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/pad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/space_to_batch_nd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/pool.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/prelu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/prod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/ragged_gather.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/ragged_range.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/ragged_tensor_to_tensor.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/rand.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/test_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/rand_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/random_gamma.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/random_normal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/random_standard_normal.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/random_uniform.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/random_uniform_int.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/range.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/real.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/reciprocal.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/relu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/relu6.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/reverse.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/reverse_1d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/reverse_2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/reverse_3d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/reverse_4d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/round.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/rsqrt.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/selu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/setdiff1d_async.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sign.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sin.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sinh.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/slice1d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/slice2d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/slice3d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/slice4d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/softmax.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/spectral/fft.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/spectral/ifft.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/spectral/irfft.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/split.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/spectral/rfft.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/squared_difference.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/squeeze.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/stack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/step.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/strided_slice.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tan.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tensor1d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tensor2d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tensor3d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tensor4d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tensor5d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tensor6d.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/tensor_scatter_update.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/topk.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/truncated_normal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/unique.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/unsorted_segment_sum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/unstack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/upper_bound.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/variable.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/backends/where_impl.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/where_async.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/boolean_mask.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/transpose.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/moving_average.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/scatter_nd.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sparse_to_dense.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/gather_nd.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/dropout_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/dropout.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/signal_ops_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/in_top_k.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/conv2d_backprop_filter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/fused_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/fused/conv2d.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_filter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/depthwise_conv2d_native_backprop_input.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/fused/depthwise_conv2d.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/fused/mat_mul.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/fused_ops.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/signal/hamming_window.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/signal/hann_window.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/signal/frame.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/signal/stft.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/crop_and_resize.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/flip_left_right.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/grayscale_to_rgb.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/rgb_to_grayscale.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/rotate_with_offset.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/nonmax_util.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/backends/non_max_suppression_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/backends/non_max_suppression_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_async.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_with_score_async.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/non_max_suppression_padded_async.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/resize_bilinear.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/resize_nearest_neighbor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/threshold.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * https://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/image/transform.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/linalg/band_part.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/linalg/gram_schmidt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/linalg/qr.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/loss_ops_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/losses/absolute_difference.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/losses/huber_loss.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/losses/log_loss.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/losses/mean_squared_error.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/losses/sigmoid_cross_entropy.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/losses/softmax_cross_entropy.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_mean.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_sum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/string/string_n_grams.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/string/string_split.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/string/string_to_hash_bucket_fast.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/string/static_regex_replace.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/ops.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/serialization.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/optimizers/optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/optimizers/adadelta_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/optimizers/adagrad_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/optimizers/adam_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/optimizers/adamax_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/optimizers/momentum_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/optimizers/rmsprop_optimizer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/optimizers/register_optimizers.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/browser_files.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/progress.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/weights_loader.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/http.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/passthrough.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/io/io.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/confusion_matrix.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/math.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/browser.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/slice_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/version.js:
  (** @license See the LICENSE file. *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/optimizers/optimizer_constructors.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/train.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/browser_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/concat_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/fused_types.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/ragged_to_dense_util.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/reduce_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/rotate_util.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/array_ops_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/selu_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/erf_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/backends/complex_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/backends/einsum_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sparse/sparse_fill_empty_rows_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sparse/sparse_reshape_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/sparse/sparse_segment_reduction_util.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/segment_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/backends/backend_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/backends/kernel_impls.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/base.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/index.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/cpu_util.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/backend_cpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Abs.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/utils/binary_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Complex.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/utils/zeros_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Identity.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Real.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Cast.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/utils/binary_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Add.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/BitwiseAnd.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/utils/unary_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/utils/unary_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Ceil.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Concat_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Exp.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Expm1.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Floor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/FloorDiv.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd_Impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Greater.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/GreaterEqual.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Less.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/LessEqual.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Log.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Max_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Maximum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Minimum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Multiply.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Neg.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/NotEqual.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Transpose.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Prod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Range_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Rsqrt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Scatter_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Sigmoid.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Slice.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentReduction_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Sqrt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SquaredDifference.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/StaticRegexReplace.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast_impl.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Sub.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Tile_impl.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/TopK_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Unique_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/shared.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/version.js:
  (** @license See the LICENSE file. *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/base.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Elu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/LeakyRelu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Prelu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Relu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Relu6.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/utils/fused_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Reshape.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/BatchMatMul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/_FusedMatMul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Acos.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Acosh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/AddN.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/All.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Any.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ArgMin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Asin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Asinh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Atan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Atan2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Atanh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/utils/pool_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPool3DGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/AvgPoolGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/BatchNorm.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/BatchToSpaceND.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Bincount.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/BroadcastArgs.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ClipByValue.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ComplexAbs.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Imag.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Concat.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropFilter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv2DBackpropInput.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropFilterV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Conv3DBackpropInputV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Cos.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Cosh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/CropAndResize.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Cumprod.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Cumsum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/DenseBincount.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/DepthToSpace.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNative.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/DepthwiseConv2dNativeBackpropInput.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Diag.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropFilter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropInput.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Draw.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Sum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Einsum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/EluGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Erf.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ExpandDims.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/RealDiv.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/utils/fft_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/FFT.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Fill.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/FlipLeftRight.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/FusedConv2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/FusedDepthwiseConv2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/GatherNd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/GatherV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/IFFT.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/IsFinite.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/IsInf.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/IsNaN.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/LinSpace.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Log1p.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalAnd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalNot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/LogicalOr.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/LRN.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/LRNGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Max.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPool3DGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/MaxPoolWithArgmax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Mean.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Min.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/MirrorPad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Mod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Softmax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Multinomial.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV3.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV4.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/NonMaxSuppressionV5.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/OneHot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ZerosLike.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/OnesLike.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Pack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/PadV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Pow.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedGather.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedRange.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/RaggedTensorToTensor.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Range.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Reciprocal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinear.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeBilinearGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighbor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ResizeNearestNeighborGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Reverse.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/RotateWithOffset.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Round.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/ScatterNd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SearchSorted.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Select.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Selu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Sign.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Sin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Sinh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Softplus.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SpaceToBatchND.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseFillEmptyRows.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseReshape.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentMean.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseSegmentSum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SparseToDense.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/SplitV.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Square.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Step.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/StridedSlice.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/StringNGrams.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/StringSplit.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/StringToHashBucketFast.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Tan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Tanh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/TensorScatterUpdate.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Tile.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/TopK.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Transform.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Unique.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/Unpack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/kernels/UnsortedSegmentSum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/register_all_kernels.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-cpu/dist/index.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/canvas_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/tex_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/webgl_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/flags_webgl.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/glsl_version.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/shader_compiler_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/shader_compiler.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/gpgpu_math.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/decode_matrix_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/decode_matrix_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/encode_float_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/encode_float_packed_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/encode_matrix_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/encode_matrix_packed_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/gpgpu_util.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/gpgpu_context.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernel_utils/shared.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/packing_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/pack_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/reshape_packed_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/texture_manager.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/unaryop_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/unaryop_packed_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/unpack_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/backend_webgl.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/version.js:
  (** @license See the LICENSE file. *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/webgl.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/base.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/binaryop_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/binaryop_packed_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Identity.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Complex.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/LeakyRelu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Prelu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernel_utils/kernel_funcs_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/mulmat_packed_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/binaryop_complex_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Multiply.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernel_utils/reshape.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Reshape.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/mean_gpu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/reduce_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernel_utils/reduce.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/transpose_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/transpose_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Transpose_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Sum_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Sum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Transpose.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/BatchMatMul_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/_FusedMatMul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Abs.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Acos.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Acosh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Add.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/addn_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/addn_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/AddN.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/All.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Any.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/argminmax_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/argminmax_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernel_utils/arg_min_max.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ArgMax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ArgMin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Asin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Asinh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Atan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Atan2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Atanh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/pool_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool3D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/avg_pool_backprop_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPool3DGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/AvgPoolGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/BatchMatMul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/batchnorm_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/batchnorm_packed_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/BatchNorm.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/slice_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/slice_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Slice.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/BatchToSpaceND.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Bincount.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/BitwiseAnd.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/BroadcastArgs.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/NotEqual.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Real.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernel_utils/int.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Cast.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Ceil.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/clip_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/clip_packed_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ClipByValue.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/complex_abs_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ComplexAbs.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/concat_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/concat_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Imag.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Concat_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Concat.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/conv_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/conv_packed_gpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/im2col_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2D_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/conv_backprop_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2DBackpropFilter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/conv_backprop_packed_gpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Conv2DBackpropInput.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3DBackpropFilterV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Conv3DBackpropInputV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Cos.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Cosh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/crop_and_resize_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/CropAndResize.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Cum_impl.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Cumprod.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Cumsum.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/DenseBincount.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/depth_to_space_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/DepthToSpace.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/conv_gpu_depthwise.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/conv_packed_gpu_depthwise.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNative.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/conv_backprop_gpu_depthwise.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNativeBackpropFilter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/DepthwiseConv2dNativeBackpropInput.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/diag_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Diag.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/dilation_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Dilation2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Einsum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Elu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/EluGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Erf.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Exp.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ExpandDims.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Expm1.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/fft_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/FFT_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/FFT.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/fill_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Fill.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/flip_left_right_gpu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/FlipLeftRight.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Floor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/FloorDiv.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels_utils/from_pixels_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels_utils/from_pixels_packed_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/FromPixels.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/FusedConv2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/FusedDepthwiseConv2D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/GatherNd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/gather_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/GatherV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Greater.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/GreaterEqual.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/IFFT.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/IsFinite.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/IsInf.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/IsNaN.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Less.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/LessEqual.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/LinSpace.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Log.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Log1p.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalAnd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalNot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/LogicalOr.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/lrn_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/lrn_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/LRN.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/lrn_grad_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/LRNGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Max_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Max.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Maximum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool3D.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/max_pool_backprop_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPool3DGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolWithArgmax_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/MaxPoolWithArgmax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Mean_impl.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Mean.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Min.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Minimum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/mirror_pad_gpu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/mirror_pad_packed_gpu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/MirrorPad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Mod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/multinomial_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/RealDiv.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Sub.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Softmax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Multinomial.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Neg.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV3.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV4.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/NonMaxSuppressionV5.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/onehot_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/OneHot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ZerosLike.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/OnesLike.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Pack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/pad_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/pad_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/PadV2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Pow.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Prod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/RaggedGather.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/RaggedRange.js:
  (**
   * @license
   * Copyright 2022 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/RaggedTensorToTensor.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Range.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Reciprocal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Relu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Relu6.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/resize_bilinear_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/resize_bilinear_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeBilinear.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/resize_bilinear_backprop_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeBilinearGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeNearestNeighbor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/resize_nearest_neighbor_backprop_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ResizeNearestNeighborGrad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/reverse_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/reverse_packed_gpu.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Reverse.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/rotate_gpu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/RotateWithOffset.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Round.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Rsqrt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/scatter_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/scatter_packed_gpu.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/ScatterNd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/search_sorted_gpu.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/SearchSorted.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/select_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Select.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Selu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Sigmoid.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Sign.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Sin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Sinh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Softplus.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/SpaceToBatchND.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/SparseFillEmptyRows.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/SparseReshape.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/SparseSegmentMean.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/SparseSegmentSum.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/SparseToDense.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/SplitV.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Sqrt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Square.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/SquaredDifference.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/StaticRegexReplace.js:
  (**
   * @license
   * Copyright 2023 Google LLC.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Step.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/strided_slice_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/StridedSlice.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/StringNGrams.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/StringSplit.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/StringToHashBucketFast.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Tan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Tanh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/TensorScatterUpdate.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/tile_gpu.js:
  (**
   * @license
   * Copyright 2017 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Tile.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/TopK.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/transform_gpu.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Transform.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Unique.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the License);
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an AS IS BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/Unpack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/segment_gpu.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/kernels/UnsortedSegmentSum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/register_all_kernels.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-backend-webgl/dist/index.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/ops_for_converter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-converter/dist/flags.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/data/compiled_api.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/custom_op/register.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/arithmetic.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/basic_math.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/control.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/convolution.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/creation.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/dynamic.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/evaluation.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/graph.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/hash_table.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/image.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/logical.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/matrices.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/normalization.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/reduction.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/slice_join.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/sparse.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/spectral.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/string.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/op_list/transformation.js:
  (**
   * @license
   * Copyright 2023 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/operation_mapper.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/custom_op/node_value_impl.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/arithmetic_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/basic_math_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/tensor_utils.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/tensor_array.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/tensor_list.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/control_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/convolution_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/creation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/dynamic_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/evaluation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/graph_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/hash_table.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/hash_table_executor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/image_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/logical_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/matrices_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/normalization_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/ragged_executor.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/reduction_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/slice_join_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/sparse_executor.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/spectral_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/string_executor.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/executors/transformation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/operations/operation_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/model_analysis.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/graph_executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/executor/graph_model.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-converter/dist/version.js:
  (** @license See the LICENSE file. *)

@tensorflow/tfjs-converter/dist/index.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/abs.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/acos.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/acosh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/add.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/all.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/any.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/arg_max.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/arg_min.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/as_scalar.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/as_type.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/as1d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/as2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/as3d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/as4d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/as5d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/asin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/asinh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/atan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/atan2.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/atanh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/batch_to_space_nd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/batchnorm.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/broadcast_to.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/cast.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/ceil.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/clip_by_value.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/concat.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/conv1d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/conv2d_transpose.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/conv2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/cos.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/cosh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/cumprod.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the 'License');
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an 'AS IS' BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/cumsum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/depth_to_space.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/depthwise_conv2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/dilation2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/div_no_nan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/div.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/dot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/elu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/erf.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/euclidean_norm.js:
  (**
   * @license
   * Copyright 2021 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/exp.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/expand_dims.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/expm1.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/fft.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/flatten.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/floor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/floorDiv.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/gather.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/greater_equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/greater.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/ifft.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/irfft.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/is_finite.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/is_inf.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/is_nan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/leaky_relu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/less_equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/less.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/local_response_normalization.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/log_sigmoid.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/log_softmax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/log_sum_exp.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/log.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/log1p.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/logical_and.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/logical_not.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/logical_or.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/logical_xor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/mat_mul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/max.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/maximum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/mean.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/min.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/minimum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/mirror_pad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/mod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/mul.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/neg.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/norm.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/not_equal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/one_hot.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/ones_like.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/pad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/pow.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/prelu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/prod.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/reciprocal.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/relu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/relu6.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/reshape_as.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/reshape.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/resize_bilinear.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/resize_nearest_neighbor.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/reverse.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/rfft.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/round.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/rsqrt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/selu.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/separable_conv2d.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/sigmoid.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/sign.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/sin.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/sinh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/slice.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/softmax.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/softplus.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/space_to_batch_nd.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/split.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/sqrt.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/square.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/squared_difference.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/squeeze.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/stack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/step.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/strided_slice.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/sub.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/sum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/tan.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/tanh.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/tile.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/to_bool.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/to_float.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/to_int.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/topk.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/transpose.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/unique.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/unsorted_segment_sum.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/unstack.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/where.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/zeros_like.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/public/chained_ops/register_all_chained_ops.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Abs_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Acos_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Acosh_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Add_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/AddN_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/ArgMax_grad.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/ArgMin_grad.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Asin_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Asinh_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Atan2_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Atan_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Atanh_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/avg_pool_3d_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/AvgPool3D_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/avg_pool_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/AvgPool_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/BatchMatMul_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/BatchToSpaceND_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/BroadcastTo_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Cast_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Ceil_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/ClipByValue_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/ComplexAbs_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Concat_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Conv2D_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Conv2DBackpropInput_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/conv3d_backprop_filter.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Conv3D_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Cos_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Cosh_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Cumsum_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/DepthwiseConv2dNative_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Dilation2D_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Elu_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Erf_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Exp_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/ExpandDims_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Expm1_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Floor_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/FloorDiv_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/FusedBatchNorm_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/GatherV2_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/GreaterEqual_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Identity_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/IsFinite_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/IsInf_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/IsNan_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/LeakyRelu_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Log1p_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Log_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/LogSoftmax_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/local_response_normalization_backprop.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/LRN_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/min_max_grad_util.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Max_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Maximum_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/max_pool_3d_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/MaxPool3D_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/ops/max_pool_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/MaxPool_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Mean_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Min_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Minimum_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/MirrorPad_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Mod_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Multiply_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Neg_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/OneHot_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/OnesLike_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Pack_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/PadV2_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Pow_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Prelu_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Prod_grad.js:
  (**
   * @license
   * Copyright 2022 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/RealDiv_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Reciprocal_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Relu6_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Relu_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Reshape_grad.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/ResizeBilinear_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/ResizeNearestNeighbor_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Reverse_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Round_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Rsqrt_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Select_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Selu_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Sigmoid_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Sign_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Sin_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Sinh_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Slice_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Softmax_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Softplus_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/SpaceToBatchND_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/SplitV_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Sqrt_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Square_grad.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/SquaredDifference_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Step_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Sub_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Sum_grad.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Tan_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Tanh_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Tile_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Transpose_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/Unpack_grad.js:
  (**
   * @license
   * Copyright 2020 Google Inc. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/UnsortedSegmentSum_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/gradients/ZerosLike_grad.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-core/dist/register_all_gradients.js:
  (**
   * @license
   * Copyright 2020 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-data/dist/util/deep_map.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/util/deep_clone.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/util/ring_buffer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/util/growing_ring_buffer.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/iterators/lazy_iterator.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/dataset.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/datasets/text_line_dataset.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/datasets/csv_dataset.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/iterators/microphone_iterator.js:
  (**
   * @license
   * Copyright 2019 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/iterators/webcam_iterator.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/datasource.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/iterators/string_iterator.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/iterators/byte_chunk_iterator.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/iterators/file_chunk_iterator.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/iterators/url_chunk_iterator.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/util/source_util.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/sources/file_data_source.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/sources/url_data_source.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/readers.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   *
   * =============================================================================
   *)

@tensorflow/tfjs-data/dist/version.js:
  (** @license See the LICENSE file. *)

@tensorflow/tfjs-data/dist/index.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs-layers/dist/errors.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/utils/executor_utils.js:
  (**
   * @license
   * Copyright 2022 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/utils/generic_utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/backend/state.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/keras_format/common.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/common.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/utils/math_utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/backend/common.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/backend/tfjs_backend.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/keras_format/initializer_config.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/initializers.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/utils/types_utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/utils/variable_utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/variables.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/engine/topology.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/engine/input_layer.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/engine/executor.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/flags_layers.js:
  (**
   * @license
   * Copyright 2022 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/constraints.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/exports_constraints.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/exports_initializers.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/logs.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/base_callbacks.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/serialization.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/losses.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/metrics.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/optimizers.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/user_defined_metadata.js:
  (**
   * @license
   * Copyright 2019 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/utils/layer_utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/utils/serialization_utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/version.js:
  (** @license See the LICENSE file. *)

@tensorflow/tfjs-layers/dist/engine/container.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/engine/training_utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/engine/training_dataset.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/engine/training_tensors.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/engine/training.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/models.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/exports.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/activations.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/regularizers.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/advanced_activations.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/utils/conv_utils.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/convolutional.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/convolutional_depthwise.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/recurrent.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/convolutional_recurrent.js:
  (**
   * @license
   * Copyright 2020 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/core.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/embeddings.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/merge.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/noise.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/normalization.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/padding.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/pooling.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/wrappers.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/preprocessing/image_preprocessing.js:
  (**
   * @license
   * Copyright 2022 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/preprocessing/center_crop.js:
  (**
   * @license
   * Copyright 2022 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/preprocessing/preprocessing_utils.js:
  (**
   * @license
   * Copyright 2022 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/preprocessing/category_encoding.js:
  (**
   * @license
   * Copyright 2022 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/preprocessing/image_resizing.js:
  (**
   * @license
   * Copyright 2022 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/backend/random_seed.js:
  (**
   * @license
   * Copyright 2023 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/engine/base_random_layer.js:
  (**
   * @license
   * Copyright 2023 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/layers/preprocessing/random_width.js:
  (**
   * @license
   * Copyright 2023 CodeSmith LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/exports_layers.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/exports_models.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/exports_regularizers.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/callbacks.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)

@tensorflow/tfjs-layers/dist/index.js:
  (**
   * @license
   * Copyright 2018 Google LLC
   *
   * Use of this source code is governed by an MIT-style
   * license that can be found in the LICENSE file or at
   * https://opensource.org/licenses/MIT.
   * =============================================================================
   *)
*/
/*! Bundled license information:

@tensorflow/tfjs/dist/version.js:
  (** @license See the LICENSE file. *)

@tensorflow/tfjs/dist/index.js:
  (**
   * @license
   * Copyright 2018 Google LLC. All Rights Reserved.
   * Licensed under the Apache License, Version 2.0 (the "License");
   * you may not use this file except in compliance with the License.
   * You may obtain a copy of the License at
   *
   * http://www.apache.org/licenses/LICENSE-2.0
   *
   * Unless required by applicable law or agreed to in writing, software
   * distributed under the License is distributed on an "AS IS" BASIS,
   * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   * See the License for the specific language governing permissions and
   * limitations under the License.
   * =============================================================================
   *)
*/
